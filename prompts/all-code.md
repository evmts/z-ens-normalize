<rust>

```rs [./tests/ens_tests.rs]

use ens_normalize_rs::EnsNameNormalizer;

use lazy_static::lazy_static;

use rayon::prelude::*;

use rstest::rstest;

use serde::Deserialize;



#[derive(Debug, Clone, Deserialize)]

#[serde(untagged)]

pub enum Entry {

Â  Â  VersionInfo {

Â  Â  Â  Â  name: String,

Â  Â  Â  Â  validated: String,

Â  Â  Â  Â  built: String,

Â  Â  Â  Â  cldr: String,

Â  Â  Â  Â  derived: String,

Â  Â  Â  Â  ens_hash_base64: String,

Â  Â  Â  Â  nf_hash_base64: String,

Â  Â  Â  Â  spec_hash: String,

Â  Â  Â  Â  unicode: String,

Â  Â  Â  Â  version: String,

Â  Â  },

Â  Â  TestCase(TestCase),

}



#[derive(Debug, Clone, Deserialize, Default)]

pub struct TestCase {

Â  Â  name: String,

Â  Â  comment: Option<String>,

Â  Â  #[serde(default)]

Â  Â  error: bool,

Â  Â  norm: Option<String>,

}



pub type IndexedTestCase<'a> = (usize, &'a TestCase);



lazy_static! {

Â  Â  pub static ref ENS_TESTS: Vec<Entry> =

Â  Â  Â  Â  serde_json::from_str(include_str!("ens_cases.json")).unwrap();

}



#[rstest]

fn ens_tests() {

Â  Â  test_cases_parallel(&only_cases(&ENS_TESTS))

}



fn test_cases_parallel(cases: &[IndexedTestCase]) {

Â  Â  let normalizer = EnsNameNormalizer::default();

Â  Â  let results = cases

Â  Â  Â  Â  .par_iter() // Parallel iterator from Rayon

Â  Â  Â  Â  .map(|(i, test_case)| (i, process_test_case(&normalizer, test_case)))

Â  Â  Â  Â  .filter_map(|(i, r)| r.err().map(|e| (i, e)))

Â  Â  Â  Â  .collect::<Vec<_>>();



Â  Â  if !results.is_empty() {

Â  Â  Â  Â  let info = results

Â  Â  Â  Â  Â  Â  .iter()

Â  Â  Â  Â  Â  Â  .map(|(i, e)| format!("{}: {}", i, e))

Â  Â  Â  Â  Â  Â  .collect::<Vec<_>>()

Â  Â  Â  Â  Â  Â  .join("\n");

Â  Â  Â  Â  panic!("{} cases failed:\n{}", results.len(), info);

Â  Â  }

}



fn process_test_case(normalizer: &EnsNameNormalizer, case: &TestCase) -> Result<(), anyhow::Error> {

Â  Â  let test_name = match (case.comment.as_ref(), case.name.as_str()) {

Â  Â  Â  Â  (Some(comment), name) if name.len() < 64 => format!("{comment} (`{name}`)"),

Â  Â  Â  Â  (Some(comment), _) => comment.clone(),

Â  Â  Â  Â  (None, name) => name.to_string(),

Â  Â  };

Â  Â  let result = normalizer.process(&case.name);



Â  Â  match result {

Â  Â  Â  Â  Err(_e) if case.error => (),

Â  Â  Â  Â  Ok(processed) if !case.error => {

Â  Â  Â  Â  Â  Â  let actual = processed.normalize();

Â  Â  Â  Â  Â  Â  if let Some(expected) = &case.norm {

Â  Â  Â  Â  Â  Â  Â  Â  assert_eq!(

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  actual,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  expected.to_string(),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "in test case '{test_name}': expected '{expected}', got '{actual}'"

Â  Â  Â  Â  Â  Â  Â  Â  );

Â  Â  Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  Â  Â  assert_eq!(

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  actual, case.name,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "in test case '{test_name}': expected '{}', got '{actual}'",

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  case.name

Â  Â  Â  Â  Â  Â  Â  Â  );

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  Err(e) => anyhow::bail!("in test case '{test_name}': expected no error, got {e}"),

Â  Â  Â  Â  Ok(_) => anyhow::bail!("in test case '{test_name}': expected error, got success"),

Â  Â  }



Â  Â  Ok(())

}



fn only_cases(entries: &[Entry]) -> Vec<IndexedTestCase> {

Â  Â  entries

Â  Â  Â  Â  .iter()

Â  Â  Â  Â  .filter_map(|e| match e {

Â  Â  Â  Â  Â  Â  Entry::TestCase(t) => Some(t),

Â  Â  Â  Â  Â  Â  _ => None,

Â  Â  Â  Â  })

Â  Â  Â  Â  .enumerate()

Â  Â  Â  Â  .collect()

}

```

```rs [./tests/e2e.rs]

use ens_normalize_rs::{CurrableError, DisallowedSequence, EnsNameNormalizer, ProcessError};

use pretty_assertions::assert_eq;

use rstest::{fixture, rstest};



#[fixture]

#[once]

fn normalizer() -> EnsNameNormalizer {

Â  Â  EnsNameNormalizer::default()

}



#[rstest]

#[case("vitalik.eth", Ok(("vitalik.eth", "vitalik.eth")))]

#[case("VITALIK.ETH", Ok(("vitalik.eth", "vitalik.eth")))]

#[case("vitalikâ¤ï¸â€ğŸ”¥.eth", Ok(("vitalikâ¤â€ğŸ”¥.eth", "vitalikâ¤ï¸â€ğŸ”¥.eth")))]

#[case("ğŸ…°ğŸ…±ğŸ…²", Ok(("ğŸ…°ğŸ…±ğŸ…²", "ğŸ…°ï¸ğŸ…±ï¸ğŸ…²")))]

#[case("-Î¾1âƒ£", Ok(("-Î¾1âƒ£", "-Î1ï¸âƒ£")))]

#[case("______________vitalik", Ok(("______________vitalik", "______________vitalik")))]

#[case(

Â  Â  "vitalik__",

Â  Â  Err(currable_error(CurrableError::UnderscoreInMiddle, 7, "_", Some("")))

)]

#[case(

Â  Â  "xx--xx",

Â  Â  Err(currable_error(CurrableError::HyphenAtSecondAndThird, 2, "--", Some("")))

)]

#[case(

Â  Â  "abcd.\u{303}eth",

Â  Â  Err(currable_error(CurrableError::CmStart, 0, "\u{303}", Some("")))

)]

#[case(

Â  Â  "viğŸ‘\u{303}talik",

Â  Â  Err(currable_error(CurrableError::CmAfterEmoji, 3, "\u{303}", Some("")))

)]

#[case(

Â  Â  "ãƒ»abcd",

Â  Â  Err(currable_error(CurrableError::FencedLeading, 0, "ãƒ»", Some("")))

)]

#[case(

Â  Â  "abcdãƒ»",

Â  Â  Err(currable_error(CurrableError::FencedTrailing, 4, "ãƒ»", Some("")))

)]

#[case(

Â  Â  "aãƒ»â€™a",

Â  Â  Err(currable_error(CurrableError::FencedConsecutive, 1, "ãƒ»â€™", Some("ãƒ»")))

)]

#[case("vitalik .eth", Err(disallowed(" ")))]

#[case("vitalik..eth", Err(empty_label()))]

#[case("..", Err(empty_label()))]

fn e2e_tests(

Â  Â  #[case] name: &str,

Â  Â  #[case] expected: Result<(&str, &str), ProcessError>,

Â  Â  normalizer: &EnsNameNormalizer,

) {

Â  Â  let actual = normalizer.process(name);

Â  Â  match expected {

Â  Â  Â  Â  Ok((expected_normalized, expected_beautified)) => {

Â  Â  Â  Â  Â  Â  let res = actual.expect("process should succeed");

Â  Â  Â  Â  Â  Â  let normalized = res.normalize();

Â  Â  Â  Â  Â  Â  assert_eq!(

Â  Â  Â  Â  Â  Â  Â  Â  normalized, expected_normalized,

Â  Â  Â  Â  Â  Â  Â  Â  "expected '{expected_normalized}', got '{normalized}'"

Â  Â  Â  Â  Â  Â  );

Â  Â  Â  Â  Â  Â  let beautified = res.beautify();

Â  Â  Â  Â  Â  Â  assert_eq!(

Â  Â  Â  Â  Â  Â  Â  Â  beautified, expected_beautified,

Â  Â  Â  Â  Â  Â  Â  Â  "expected '{expected_beautified}', got '{beautified}'"

Â  Â  Â  Â  Â  Â  );

Â  Â  Â  Â  }

Â  Â  Â  Â  Err(expected) => assert_eq!(actual.unwrap_err(), expected),

Â  Â  }

}



fn disallowed(sequence: &str) -> ProcessError {

Â  Â  ProcessError::DisallowedSequence(DisallowedSequence::Invalid(sequence.to_string()))

}



fn empty_label() -> ProcessError {

Â  Â  ProcessError::DisallowedSequence(DisallowedSequence::EmptyLabel)

}



fn currable_error(

Â  Â  inner: CurrableError,

Â  Â  index: usize,

Â  Â  sequence: &str,

Â  Â  maybe_suggest: Option<&str>,

) -> ProcessError {

Â  Â  ProcessError::CurrableError {

Â  Â  Â  Â  inner,

Â  Â  Â  Â  index,

Â  Â  Â  Â  sequence: sequence.to_string(),

Â  Â  Â  Â  maybe_suggest: maybe_suggest.map(|s| s.to_string()),

Â  Â  }

}

```

```rs [./examples/tokens.rs]

use ens_normalize_rs::EnsNameNormalizer;



fn main() {

Â  Â  let normalizer = EnsNameNormalizer::default();



Â  Â  let name = "NÃ meâ€ğŸ§™â€â™‚.eth";

Â  Â  let result = normalizer.tokenize(name).unwrap();



Â  Â  for token in result.tokens {

Â  Â  Â  Â  if token.is_disallowed() {

Â  Â  Â  Â  Â  Â  println!("disallowed: {:?}", token.as_string());

Â  Â  Â  Â  }

Â  Â  }

}

```

```rs [./examples/benchmark.rs]

const SIZE: usize = 100;

const NAME_LENGTH: usize = 1000;

const NAME: &str = "$Sand-#ï¸âƒ£ğŸ‡ªğŸ‡¨";



fn main() {

Â  Â  let now = std::time::Instant::now();

Â  Â  let name = std::iter::repeat(NAME)

Â  Â  Â  Â  .take(NAME_LENGTH / NAME.len())

Â  Â  Â  Â  .collect::<Vec<_>>()

Â  Â  Â  Â  .join("");

Â  Â  let normalizer = ens_normalize_rs::EnsNameNormalizer::default();

Â  Â  for _ in 0..SIZE {

Â  Â  Â  Â  let _name = normalizer.process(&name).unwrap();

Â  Â  }

Â  Â  // Total time to process 100 names: 728.916542ms

Â  Â  println!("Total time to process {SIZE} names: {:?}", now.elapsed());

}

```

```rs [./examples/simple.rs]

fn main() {

Â  Â  // Using normalizer to reuse preloaded data

Â  Â  let normalizer = ens_normalize_rs::EnsNameNormalizer::default();

Â  Â  let name = "ğŸ…°ï¸ğŸ…±.eth";

Â  Â  let processed = normalizer.process(name).unwrap();

Â  Â  let beautified_name = processed.beautify();

Â  Â  let normalized_name = processed.normalize();



Â  Â  assert_eq!(normalized_name, "ğŸ…°ğŸ…±.eth");

Â  Â  assert_eq!(beautified_name, "ğŸ…°ï¸ğŸ…±ï¸.eth");



Â  Â  // Using normalize directly

Â  Â  let normalized = normalizer.normalize("Levvv.eth").unwrap();

Â  Â  assert_eq!(normalized, "levvv.eth");



Â  Â  // Handling errors

Â  Â  assert!(matches!(

Â  Â  Â  Â  normalizer.normalize("Levvv..eth"),

Â  Â  Â  Â  Err(ens_normalize_rs::ProcessError::DisallowedSequence(

Â  Â  Â  Â  Â  Â  ens_normalize_rs::DisallowedSequence::EmptyLabel

Â  Â  Â  Â  ))

Â  Â  ));

Â  Â  assert!(matches!(

Â  Â  Â  Â  // U+200D ZERO WIDTH JOINER

Â  Â  Â  Â  normalizer.normalize("Niâ€ck.ETH"),

Â  Â  Â  Â  Err(ens_normalize_rs::ProcessError::DisallowedSequence(

Â  Â  Â  Â  Â  Â  ens_normalize_rs::DisallowedSequence::InvisibleCharacter(0x200d)

Â  Â  Â  Â  ))

Â  Â  ));

}

```

```rs [./src/join.rs]

use crate::{constants, utils, CodePoint, EnsNameToken, ValidatedLabel};



/// Joins validated labels into a string

pub fn join_labels(labels: &[ValidatedLabel]) -> String {

Â  Â  let labels_cps = labels.iter().map(|label| {

Â  Â  Â  Â  label

Â  Â  Â  Â  Â  Â  .tokens

Â  Â  Â  Â  Â  Â  .iter()

Â  Â  Â  Â  Â  Â  .filter_map(|token| match token {

Â  Â  Â  Â  Â  Â  Â  Â  EnsNameToken::Disallowed(_) | EnsNameToken::Ignored(_) | EnsNameToken::Stop(_) => {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  None

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(token) => Some(&token.cps),

Â  Â  Â  Â  Â  Â  Â  Â  EnsNameToken::Mapped(token) => Some(&token.cps),

Â  Â  Â  Â  Â  Â  Â  Â  EnsNameToken::Nfc(token) => Some(&token.cps),

Â  Â  Â  Â  Â  Â  Â  Â  EnsNameToken::Emoji(token) => Some(&token.cps_no_fe0f),

Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  Â  Â  .flatten()

Â  Â  Â  Â  Â  Â  .cloned()

Â  Â  Â  Â  Â  Â  .collect::<Vec<_>>()

Â  Â  });



Â  Â  join_cps(labels_cps)

}



/// Joins code points into a string

pub fn join_cps(cps: impl Iterator<Item = Vec<CodePoint>>) -> String {

Â  Â  let cps_flatten = itertools::intersperse(cps, vec![constants::CP_STOP])

Â  Â  Â  Â  .flatten()

Â  Â  Â  Â  .collect::<Vec<_>>();



Â  Â  utils::cps2str(&cps_flatten)

}

```

```rs [./src/constants.rs]

#![allow(dead_code)]



use crate::CodePoint;



pub const CP_STOP: CodePoint = 0x2E;

pub const CP_FE0F: CodePoint = 0xFE0F;

pub const CP_APOSTROPHE: CodePoint = 8217;

pub const CP_SLASH: CodePoint = 8260;

pub const CP_MIDDLE_DOT: CodePoint = 12539;

pub const CP_XI_SMALL: CodePoint = 0x3BE;

pub const CP_XI_CAPITAL: CodePoint = 0x39E;

pub const CP_UNDERSCORE: CodePoint = 0x5F;

pub const CP_HYPHEN: CodePoint = 0x2D;

pub const CP_ZERO_WIDTH_JOINER: CodePoint = 0x200D;

pub const CP_ZERO_WIDTH_NON_JOINER: CodePoint = 0x200C;



pub const GREEK_GROUP_NAME: &str = "Greek";

pub const MAX_EMOJI_LEN: usize = 0x2d;

pub const STR_FE0F: &str = "\u{fe0f}";

```

```rs [./src/error.rs]

use crate::CodePoint;



#[derive(Debug, Clone, thiserror::Error, PartialEq, Eq)]

pub enum ProcessError {

Â  Â  #[error("contains visually confusing characters from multiple scripts: {0}")]

Â  Â  Confused(String),

Â  Â  #[error("contains visually confusing characters from {group1} and {group2} scripts")]

Â  Â  ConfusedGroups { group1: String, group2: String },

Â  Â  #[error("invalid character ('{sequence}') at position {index}: {inner}")]

Â  Â  CurrableError {

Â  Â  Â  Â  inner: CurrableError,

Â  Â  Â  Â  index: usize,

Â  Â  Â  Â  sequence: String,

Â  Â  Â  Â  maybe_suggest: Option<String>,

Â  Â  },

Â  Â  #[error("disallowed sequence: {0}")]

Â  Â  DisallowedSequence(#[from] DisallowedSequence),

}



#[derive(Debug, Clone, thiserror::Error, PartialEq, Eq)]

pub enum CurrableError {

Â  Â  #[error("underscore in middle")]

Â  Â  UnderscoreInMiddle,

Â  Â  #[error("hyphen at second and third position")]

Â  Â  HyphenAtSecondAndThird,

Â  Â  #[error("combining mark in disallowed position at the start of the label")]

Â  Â  CmStart,

Â  Â  #[error("combining mark in disallowed position after an emoji")]

Â  Â  CmAfterEmoji,

Â  Â  #[error("fenced character at the start of a label")]

Â  Â  FencedLeading,

Â  Â  #[error("fenced character at the end of a label")]

Â  Â  FencedTrailing,

Â  Â  #[error("consecutive sequence of fenced characters")]

Â  Â  FencedConsecutive,

}



#[derive(Debug, Clone, thiserror::Error, PartialEq, Eq)]

pub enum DisallowedSequence {

Â  Â  #[error("disallowed character: {0}")]

Â  Â  Invalid(String),

Â  Â  #[error("invisible character: {0}")]

Â  Â  InvisibleCharacter(CodePoint),

Â  Â  #[error("empty label")]

Â  Â  EmptyLabel,

Â  Â  #[error("nsm too many")]

Â  Â  NsmTooMany,

Â  Â  #[error("nsm repeated")]

Â  Â  NsmRepeated,

}

```

```rs [./src/lib.rs]

mod beautify;

mod code_points;

pub(crate) mod constants;

mod error;

mod join;

mod normalizer;

mod static_data;

mod tokens;

mod utils;

mod validate;



pub use code_points::*;

pub use error::{CurrableError, DisallowedSequence, ProcessError};

pub use normalizer::{beautify, normalize, process, tokenize, EnsNameNormalizer, ProcessedName};

pub use tokens::*;

pub use validate::{LabelType, ValidatedLabel};

```

```rs [./src/normalizer.rs]

use crate::{

Â  Â  beautify::beautify_labels, join::join_labels, validate::validate_name, CodePointsSpecs,

Â  Â  ProcessError, TokenizedName, ValidatedLabel,

};



#[derive(Default)]

pub struct EnsNameNormalizer {

Â  Â  specs: CodePointsSpecs,

}



#[derive(Debug, Clone, PartialEq, Eq)]

pub struct ProcessedName {

Â  Â  pub labels: Vec<ValidatedLabel>,

Â  Â  pub tokenized: TokenizedName,

}



impl EnsNameNormalizer {

Â  Â  pub fn new(specs: CodePointsSpecs) -> Self {

Â  Â  Â  Â  Self { specs }

Â  Â  }



Â  Â  pub fn tokenize(&self, input: impl AsRef<str>) -> Result<TokenizedName, ProcessError> {

Â  Â  Â  Â  TokenizedName::from_input(input.as_ref(), &self.specs, true)

Â  Â  }



Â  Â  pub fn process(&self, input: impl AsRef<str>) -> Result<ProcessedName, ProcessError> {

Â  Â  Â  Â  let input = input.as_ref();

Â  Â  Â  Â  let tokenized = self.tokenize(input)?;

Â  Â  Â  Â  let labels = validate_name(&tokenized, &self.specs)?;

Â  Â  Â  Â  Ok(ProcessedName { tokenized, labels })

Â  Â  }



Â  Â  pub fn normalize(&self, input: impl AsRef<str>) -> Result<String, ProcessError> {

Â  Â  Â  Â  self.process(input).map(|processed| processed.normalize())

Â  Â  }



Â  Â  pub fn beautify(&self, input: impl AsRef<str>) -> Result<String, ProcessError> {

Â  Â  Â  Â  self.process(input).map(|processed| processed.beautify())

Â  Â  }

}



impl ProcessedName {

Â  Â  pub fn normalize(&self) -> String {

Â  Â  Â  Â  join_labels(&self.labels)

Â  Â  }



Â  Â  pub fn beautify(&self) -> String {

Â  Â  Â  Â  beautify_labels(&self.labels)

Â  Â  }

}



pub fn tokenize(input: impl AsRef<str>) -> Result<TokenizedName, ProcessError> {

Â  Â  EnsNameNormalizer::default().tokenize(input)

}



pub fn process(input: impl AsRef<str>) -> Result<ProcessedName, ProcessError> {

Â  Â  EnsNameNormalizer::default().process(input)

}



pub fn normalize(input: impl AsRef<str>) -> Result<String, ProcessError> {

Â  Â  EnsNameNormalizer::default().normalize(input)

}



pub fn beautify(input: impl AsRef<str>) -> Result<String, ProcessError> {

Â  Â  EnsNameNormalizer::default().beautify(input)

}

```

```rs [./src/validate.rs]

use crate::{

Â  Â  constants, static_data::spec_json, utils, CodePoint, CodePointsSpecs, CollapsedEnsNameToken,

Â  Â  CurrableError, DisallowedSequence, EnsNameToken, ParsedGroup, ParsedWholeValue, ProcessError,

Â  Â  TokenizedLabel, TokenizedName,

};

use itertools::Itertools;

use std::collections::HashSet;

pub type LabelType = spec_json::GroupName;



/// Represents a validated ENS label as result of the `validate_label` function.

/// Contains the original tokenized label and the type of the label.

#[derive(Debug, Clone, PartialEq, Eq)]

pub struct ValidatedLabel {

Â  Â  pub tokens: Vec<EnsNameToken>,

Â  Â  pub label_type: LabelType,

}



pub fn validate_name(

Â  Â  name: &TokenizedName,

Â  Â  specs: &CodePointsSpecs,

) -> Result<Vec<ValidatedLabel>, ProcessError> {

Â  Â  if name.is_empty() {

Â  Â  Â  Â  return Ok(vec![]);

Â  Â  }

Â  Â  let labels = name

Â  Â  Â  Â  .iter_labels()

Â  Â  Â  Â  .map(|label| validate_label(label, specs))

Â  Â  Â  Â  .collect::<Result<Vec<_>, _>>()?;

Â  Â  Ok(labels)

}



/// Validates a tokenized ENS label according to the ENSIP 15 specification

/// https://docs.ens.domains/ensip/15#validate

pub fn validate_label(

Â  Â  label: TokenizedLabel<'_>,

Â  Â  specs: &CodePointsSpecs,

) -> Result<ValidatedLabel, ProcessError> {

Â  Â  non_empty(&label)?;

Â  Â  check_token_types(&label)?;

Â  Â  if label.is_fully_emoji() {

Â  Â  Â  Â  return Ok(ValidatedLabel {

Â  Â  Â  Â  Â  Â  tokens: label.tokens.to_owned(),

Â  Â  Â  Â  Â  Â  label_type: LabelType::Emoji,

Â  Â  Â  Â  });

Â  Â  };

Â  Â  underscore_only_at_beginning(&label)?;

Â  Â  if label.is_fully_ascii() {

Â  Â  Â  Â  no_hyphen_at_second_and_third(&label)?;

Â  Â  Â  Â  return Ok(ValidatedLabel {

Â  Â  Â  Â  Â  Â  tokens: label.tokens.to_owned(),

Â  Â  Â  Â  Â  Â  label_type: LabelType::Ascii,

Â  Â  Â  Â  });

Â  Â  }

Â  Â  check_fenced(&label, specs)?;

Â  Â  check_cm_leading_emoji(&label, specs)?;

Â  Â  let group = check_and_get_group(&label, specs)?;

Â  Â  Ok(ValidatedLabel {

Â  Â  Â  Â  tokens: label.tokens.to_owned(),

Â  Â  Â  Â  label_type: group.name,

Â  Â  })

}



fn non_empty(label: &TokenizedLabel) -> Result<(), ProcessError> {

Â  Â  let non_ignored_token_exists = label.tokens.iter().any(|token| !token.is_ignored());

Â  Â  if !non_ignored_token_exists {

Â  Â  Â  Â  return Err(ProcessError::DisallowedSequence(

Â  Â  Â  Â  Â  Â  DisallowedSequence::EmptyLabel,

Â  Â  Â  Â  ));

Â  Â  }

Â  Â  Ok(())

}



fn check_token_types(label: &TokenizedLabel) -> Result<(), ProcessError> {

Â  Â  if let Some(token) = label

Â  Â  Â  Â  .tokens

Â  Â  Â  Â  .iter()

Â  Â  Â  Â  .find(|token| token.is_disallowed() || token.is_stop())

Â  Â  {

Â  Â  Â  Â  let cps = token.cps();

Â  Â  Â  Â  let maybe_invisible_cp = cps.iter().find(|cp| {

Â  Â  Â  Â  Â  Â  *cp == &constants::CP_ZERO_WIDTH_JOINER || *cp == &constants::CP_ZERO_WIDTH_NON_JOINER

Â  Â  Â  Â  });

Â  Â  Â  Â  if let Some(invisible_cp) = maybe_invisible_cp {

Â  Â  Â  Â  Â  Â  return Err(ProcessError::DisallowedSequence(

Â  Â  Â  Â  Â  Â  Â  Â  DisallowedSequence::InvisibleCharacter(*invisible_cp),

Â  Â  Â  Â  Â  Â  ));

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  return Err(ProcessError::DisallowedSequence(

Â  Â  Â  Â  Â  Â  Â  Â  DisallowedSequence::Invalid(utils::cps2str(&cps)),

Â  Â  Â  Â  Â  Â  ));

Â  Â  Â  Â  }

Â  Â  }

Â  Â  Ok(())

}



fn underscore_only_at_beginning(label: &TokenizedLabel) -> Result<(), ProcessError> {

Â  Â  let leading_underscores = label

Â  Â  Â  Â  .iter_cps()

Â  Â  Â  Â  .take_while(|cp| *cp == constants::CP_UNDERSCORE)

Â  Â  Â  Â  .count();

Â  Â  let underscore_in_middle = label

Â  Â  Â  Â  .iter_cps()

Â  Â  Â  Â  .enumerate()

Â  Â  Â  Â  .skip(leading_underscores)

Â  Â  Â  Â  .find(|(_, cp)| *cp == constants::CP_UNDERSCORE);

Â  Â  if let Some((index, _)) = underscore_in_middle {

Â  Â  Â  Â  return Err(ProcessError::CurrableError {

Â  Â  Â  Â  Â  Â  inner: CurrableError::UnderscoreInMiddle,

Â  Â  Â  Â  Â  Â  index,

Â  Â  Â  Â  Â  Â  sequence: utils::cps2str(&[constants::CP_UNDERSCORE]),

Â  Â  Â  Â  Â  Â  maybe_suggest: Some("".to_string()),

Â  Â  Â  Â  });

Â  Â  }

Â  Â  Ok(())

}



// The 3rd and 4th characters must not both be 2D (-) HYPHEN-MINUS.

// Must not match /^..--/

// Examples: "ab-c" and "---a"are valid, "xn--" and ---- are invalid.

fn no_hyphen_at_second_and_third(label: &TokenizedLabel) -> Result<(), ProcessError> {

Â  Â  if label.iter_cps().nth(2) == Some(constants::CP_HYPHEN)

Â  Â  Â  Â  && label.iter_cps().nth(3) == Some(constants::CP_HYPHEN)

Â  Â  {

Â  Â  Â  Â  return Err(ProcessError::CurrableError {

Â  Â  Â  Â  Â  Â  inner: CurrableError::HyphenAtSecondAndThird,

Â  Â  Â  Â  Â  Â  index: 2,

Â  Â  Â  Â  Â  Â  sequence: utils::cps2str(&[constants::CP_HYPHEN, constants::CP_HYPHEN]),

Â  Â  Â  Â  Â  Â  maybe_suggest: Some("".to_string()),

Â  Â  Â  Â  });

Â  Â  }

Â  Â  Ok(())

}



fn check_fenced(label: &TokenizedLabel, specs: &CodePointsSpecs) -> Result<(), ProcessError> {

Â  Â  if let Some(first_cp) = label.iter_cps().next() {

Â  Â  Â  Â  if specs.is_fenced(first_cp) {

Â  Â  Â  Â  Â  Â  return Err(ProcessError::CurrableError {

Â  Â  Â  Â  Â  Â  Â  Â  inner: CurrableError::FencedLeading,

Â  Â  Â  Â  Â  Â  Â  Â  index: 0,

Â  Â  Â  Â  Â  Â  Â  Â  sequence: utils::cps2str(&[first_cp]),

Â  Â  Â  Â  Â  Â  Â  Â  maybe_suggest: Some("".to_string()),

Â  Â  Â  Â  Â  Â  });

Â  Â  Â  Â  }

Â  Â  }

Â  Â  if let Some(last_cp) = label.iter_cps().last() {

Â  Â  Â  Â  if specs.is_fenced(last_cp) {

Â  Â  Â  Â  Â  Â  return Err(ProcessError::CurrableError {

Â  Â  Â  Â  Â  Â  Â  Â  inner: CurrableError::FencedTrailing,

Â  Â  Â  Â  Â  Â  Â  Â  index: label.iter_cps().count() - 1,

Â  Â  Â  Â  Â  Â  Â  Â  sequence: utils::cps2str(&[last_cp]),

Â  Â  Â  Â  Â  Â  Â  Â  maybe_suggest: Some("".to_string()),

Â  Â  Â  Â  Â  Â  });

Â  Â  Â  Â  }

Â  Â  }



Â  Â  for (i, window) in label.iter_cps().tuple_windows().enumerate() {

Â  Â  Â  Â  let (one, two) = window;

Â  Â  Â  Â  if specs.is_fenced(one) && specs.is_fenced(two) {

Â  Â  Â  Â  Â  Â  return Err(ProcessError::CurrableError {

Â  Â  Â  Â  Â  Â  Â  Â  inner: CurrableError::FencedConsecutive,

Â  Â  Â  Â  Â  Â  Â  Â  index: i,

Â  Â  Â  Â  Â  Â  Â  Â  sequence: utils::cps2str(&[one, two]),

Â  Â  Â  Â  Â  Â  Â  Â  maybe_suggest: Some(utils::cp2str(one)),

Â  Â  Â  Â  Â  Â  });

Â  Â  Â  Â  }

Â  Â  }

Â  Â  Ok(())

}



fn check_cm_leading_emoji(

Â  Â  label: &TokenizedLabel,

Â  Â  specs: &CodePointsSpecs,

) -> Result<(), ProcessError> {

Â  Â  let mut index = 0;

Â  Â  let collapsed = label.collapse_into_text_or_emoji();

Â  Â  for (i, token) in collapsed.iter().enumerate() {

Â  Â  Â  Â  if let CollapsedEnsNameToken::Text(token) = token {

Â  Â  Â  Â  Â  Â  if let Some(cp) = token.cps.first() {

Â  Â  Â  Â  Â  Â  Â  Â  if specs.is_cm(*cp) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if i == 0 {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return Err(ProcessError::CurrableError {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  inner: CurrableError::CmStart,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  index,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sequence: utils::cps2str(&[*cp]),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  maybe_suggest: Some("".to_string()),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  });

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return Err(ProcessError::CurrableError {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  inner: CurrableError::CmAfterEmoji,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  index,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sequence: utils::cps2str(&[*cp]),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  maybe_suggest: Some("".to_string()),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  });

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  index += token.input_size();

Â  Â  }



Â  Â  Ok(())

}



fn check_and_get_group(

Â  Â  label: &TokenizedLabel,

Â  Â  specs: &CodePointsSpecs,

) -> Result<ParsedGroup, ProcessError> {

Â  Â  let cps = label.get_cps_of_not_ignored_text();

Â  Â  let unique_cps = cps

Â  Â  Â  Â  .clone()

Â  Â  Â  Â  .into_iter()

Â  Â  Â  Â  .collect::<HashSet<_>>()

Â  Â  Â  Â  .into_iter()

Â  Â  Â  Â  .collect::<Vec<_>>();

Â  Â  let group = determine_group(&unique_cps, specs).cloned()?;

Â  Â  check_group(&group, &cps, specs)?;

Â  Â  check_whole(&group, &unique_cps, specs)?;

Â  Â  Ok(group)

}



fn check_group(

Â  Â  group: &ParsedGroup,

Â  Â  cps: &[CodePoint],

Â  Â  specs: &CodePointsSpecs,

) -> Result<(), ProcessError> {

Â  Â  for cp in cps.iter() {

Â  Â  Â  Â  if !group.contains_cp(*cp) {

Â  Â  Â  Â  Â  Â  return Err(ProcessError::Confused(format!(

Â  Â  Â  Â  Â  Â  Â  Â  "symbol {} not present in group {}",

Â  Â  Â  Â  Â  Â  Â  Â  utils::cp2str(*cp),

Â  Â  Â  Â  Â  Â  Â  Â  group.name

Â  Â  Â  Â  Â  Â  )));

Â  Â  Â  Â  }

Â  Â  }

Â  Â  if group.cm_absent {

Â  Â  Â  Â  let decomposed = utils::nfd_cps(cps, specs);

Â  Â  Â  Â  let mut i = 1;

Â  Â  Â  Â  let e = decomposed.len();

Â  Â  Â  Â  while i < e {

Â  Â  Â  Â  Â  Â  if specs.is_nsm(decomposed[i]) {

Â  Â  Â  Â  Â  Â  Â  Â  let mut j = i + 1;

Â  Â  Â  Â  Â  Â  Â  Â  while j < e && specs.is_nsm(decomposed[j]) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if j - i + 1 > specs.nsm_max() as usize {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return Err(ProcessError::DisallowedSequence(

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  DisallowedSequence::NsmTooMany,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ));

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for k in i..j {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if decomposed[k] == decomposed[j] {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return Err(ProcessError::DisallowedSequence(

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  DisallowedSequence::NsmRepeated,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ));

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  j += 1;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  i = j;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  i += 1;

Â  Â  Â  Â  }

Â  Â  }

Â  Â  Ok(())

}



fn check_whole(

Â  Â  group: &ParsedGroup,

Â  Â  unique_cps: &[CodePoint],

Â  Â  specs: &CodePointsSpecs,

) -> Result<(), ProcessError> {

Â  Â  let (maker, shared) = get_groups_candidates_and_shared_cps(unique_cps, specs);

Â  Â  for group_name in maker {

Â  Â  Â  Â  let confused_group_candidate = specs.group_by_name(group_name).expect("group must exist");

Â  Â  Â  Â  if confused_group_candidate.contains_all_cps(&shared) {

Â  Â  Â  Â  Â  Â  return Err(ProcessError::ConfusedGroups {

Â  Â  Â  Â  Â  Â  Â  Â  group1: group.name.to_string(),

Â  Â  Â  Â  Â  Â  Â  Â  group2: confused_group_candidate.name.to_string(),

Â  Â  Â  Â  Â  Â  });

Â  Â  Â  Â  }

Â  Â  }

Â  Â  Ok(())

}



fn get_groups_candidates_and_shared_cps(

Â  Â  unique_cps: &[CodePoint],

Â  Â  specs: &CodePointsSpecs,

) -> (Vec<String>, Vec<CodePoint>) {

Â  Â  let mut maybe_groups: Option<Vec<String>> = None;

Â  Â  let mut shared: Vec<CodePoint> = Vec::new();



Â  Â  for cp in unique_cps {

Â  Â  Â  Â  match specs.whole_map(*cp) {

Â  Â  Â  Â  Â  Â  Some(ParsedWholeValue::Number(_)) => {

Â  Â  Â  Â  Â  Â  Â  Â  return (vec![], vec![]);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Some(ParsedWholeValue::WholeObject(whole)) => {

Â  Â  Â  Â  Â  Â  Â  Â  let confused_groups_names = whole

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .m

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .get(cp)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .expect("since we got `whole` from cp, `M` must have a value for `cp`");



Â  Â  Â  Â  Â  Â  Â  Â  match maybe_groups.as_mut() {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Some(groups) => {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  groups.retain(|g| confused_groups_names.contains(g));

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  None => {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  maybe_groups = Some(confused_groups_names.iter().cloned().collect());

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  None => {

Â  Â  Â  Â  Â  Â  Â  Â  shared.push(*cp);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  };

Â  Â  }



Â  Â  (maybe_groups.unwrap_or_default(), shared)

}



fn determine_group<'a>(

Â  Â  unique_cps: &'a [CodePoint],

Â  Â  specs: &'a CodePointsSpecs,

) -> Result<&'a ParsedGroup, ProcessError> {

Â  Â  specs

Â  Â  Â  Â  .groups_for_cps(unique_cps)

Â  Â  Â  Â  .next()

Â  Â  Â  Â  .ok_or(ProcessError::Confused(format!(

Â  Â  Â  Â  Â  Â  "no group found for {:?}",

Â  Â  Â  Â  Â  Â  unique_cps

Â  Â  Â  Â  )))

}



#[cfg(test)]

mod tests {

Â  Â  use crate::TokenizedName;



Â  Â  use super::*;

Â  Â  use pretty_assertions::assert_eq;

Â  Â  use rstest::{fixture, rstest};



Â  Â  #[fixture]

Â  Â  #[once]

Â  Â  fn specs() -> CodePointsSpecs {

Â  Â  Â  Â  CodePointsSpecs::default()

Â  Â  }



Â  Â  #[rstest]

Â  Â  // success

Â  Â  #[case::hello("hello", Ok(LabelType::Ascii))]

Â  Â  #[case::latin("Eï¸Ìƒ", Ok(LabelType::Other("Latin".to_string())))]

Â  Â  #[case::cyrillic("Ğ²ÑĞµĞ¼-Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚", Ok(LabelType::Other("Cyrillic".to_string())))]

Â  Â  #[case::with_fenced_in_middle("aãƒ»aâ€™s", Ok(LabelType::Other("Han".to_string())))]

Â  Â  #[case::ascii_with_hyphen("ab-c", Ok(LabelType::Ascii))]

Â  Â  // errors

Â  Â  #[case::hyphen_at_second_and_third("ab--", Err(ProcessError::CurrableError {

Â  Â  Â  Â  inner: CurrableError::HyphenAtSecondAndThird,

Â  Â  Â  Â  index: 2,

Â  Â  Â  Â  sequence: "--".to_string(),

Â  Â  Â  Â  maybe_suggest: Some("".to_string())

Â  Â  }))]

Â  Â  #[case::fenced_leading("â€™85", Err(ProcessError::CurrableError {

Â  Â  Â  Â  inner: CurrableError::FencedLeading,

Â  Â  Â  Â  index: 0,

Â  Â  Â  Â  sequence: "â€™".to_string(),

Â  Â  Â  Â  maybe_suggest: Some("".to_string())

Â  Â  }))]

Â  Â  #[case::fenced_contiguous("aãƒ»ãƒ»a", Err(ProcessError::CurrableError {

Â  Â  Â  Â  inner: CurrableError::FencedConsecutive,

Â  Â  Â  Â  index: 1,

Â  Â  Â  Â  sequence: "ãƒ»ãƒ»".to_string(),

Â  Â  Â  Â  maybe_suggest: Some("ãƒ»".to_string())

Â  Â  }))]

Â  Â  #[case::cm_after_emoji("ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜\u{300}hello", Err(ProcessError::CurrableError {

Â  Â  Â  Â  inner: CurrableError::CmAfterEmoji,

Â  Â  Â  Â  index: 8,

Â  Â  Â  Â  sequence: "\u{300}".to_string(),

Â  Â  Â  Â  maybe_suggest: Some("".to_string())

Â  Â  }))]

Â  Â  #[case::cm_leading("\u{300}hello", Err(ProcessError::CurrableError {

Â  Â  Â  Â  inner: CurrableError::CmStart,

Â  Â  Â  Â  index: 0,

Â  Â  Â  Â  sequence: "\u{300}".to_string(),

Â  Â  Â  Â  maybe_suggest: Some("".to_string())

Â  Â  }))]

Â  Â  fn test_validate_and_get_type(

Â  Â  Â  Â  #[case] input: &str,

Â  Â  Â  Â  #[case] expected: Result<LabelType, ProcessError>,

Â  Â  Â  Â  specs: &CodePointsSpecs,

Â  Â  ) {

Â  Â  Â  Â  let name = TokenizedName::from_input(input, specs, true).unwrap();

Â  Â  Â  Â  let label = name.iter_labels().next().unwrap();

Â  Â  Â  Â  let result = validate_label(label, specs);

Â  Â  Â  Â  assert_eq!(

Â  Â  Â  Â  Â  Â  result.clone().map(|v| v.label_type),

Â  Â  Â  Â  Â  Â  expected,

Â  Â  Â  Â  Â  Â  "{:?}",

Â  Â  Â  Â  Â  Â  result

Â  Â  Â  Â  );

Â  Â  }



Â  Â  #[rstest]

Â  Â  #[case::emoji("\"Emoji\"", LabelType::Emoji)]

Â  Â  #[case::ascii("\"ASCII\"", LabelType::Ascii)]

Â  Â  #[case::greek("\"Greek\"", LabelType::Greek)]

Â  Â  #[case::other("\"FooBar\"", LabelType::Other("FooBar".to_string()))]

Â  Â  fn test_deserialize_label_type(#[case] input: &str, #[case] expected: LabelType) {

Â  Â  Â  Â  let result: LabelType = serde_json::from_str(input).unwrap();

Â  Â  Â  Â  assert_eq!(result, expected);

Â  Â  }

}

```

```rs [./src/tokens/types.rs]

use crate::{constants, utils, CodePoint};



/// Represents a token in an ENS name.

/// see https://docs.ens.domains/ensip/15#tokenize for more details.

#[derive(Debug, Clone, PartialEq, Eq)]

pub enum EnsNameToken {

Â  Â  Valid(TokenValid),

Â  Â  Mapped(TokenMapped),

Â  Â  Ignored(TokenIgnored),

Â  Â  Disallowed(TokenDisallowed),

Â  Â  Stop(TokenStop),

Â  Â  Nfc(TokenNfc),

Â  Â  Emoji(TokenEmoji),

}



impl EnsNameToken {

Â  Â  pub fn cps(&self) -> Vec<CodePoint> {

Â  Â  Â  Â  match self {

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(t) => t.cps.clone(),

Â  Â  Â  Â  Â  Â  EnsNameToken::Mapped(t) => t.cps.clone(),

Â  Â  Â  Â  Â  Â  EnsNameToken::Nfc(t) => t.cps.clone(),

Â  Â  Â  Â  Â  Â  EnsNameToken::Emoji(t) => t.cps_no_fe0f.clone(),

Â  Â  Â  Â  Â  Â  EnsNameToken::Disallowed(t) => vec![t.cp],

Â  Â  Â  Â  Â  Â  EnsNameToken::Stop(t) => vec![t.cp],

Â  Â  Â  Â  Â  Â  EnsNameToken::Ignored(t) => vec![t.cp],

Â  Â  Â  Â  }

Â  Â  }



Â  Â  pub fn input_size(&self) -> usize {

Â  Â  Â  Â  match self {

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(t) => t.cps.len(),

Â  Â  Â  Â  Â  Â  EnsNameToken::Nfc(t) => t.input.len(),

Â  Â  Â  Â  Â  Â  EnsNameToken::Emoji(t) => t.cps_input.len(),

Â  Â  Â  Â  Â  Â  EnsNameToken::Mapped(_) => 1,

Â  Â  Â  Â  Â  Â  EnsNameToken::Disallowed(_) => 1,

Â  Â  Â  Â  Â  Â  EnsNameToken::Ignored(_) => 1,

Â  Â  Â  Â  Â  Â  EnsNameToken::Stop(_) => 1,

Â  Â  Â  Â  }

Â  Â  }



Â  Â  pub fn is_text(&self) -> bool {

Â  Â  Â  Â  matches!(

Â  Â  Â  Â  Â  Â  self,

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(_) | EnsNameToken::Mapped(_) | EnsNameToken::Nfc(_)

Â  Â  Â  Â  )

Â  Â  }



Â  Â  pub fn is_emoji(&self) -> bool {

Â  Â  Â  Â  matches!(self, EnsNameToken::Emoji(_))

Â  Â  }



Â  Â  pub fn is_ignored(&self) -> bool {

Â  Â  Â  Â  matches!(self, EnsNameToken::Ignored(_))

Â  Â  }



Â  Â  pub fn is_disallowed(&self) -> bool {

Â  Â  Â  Â  matches!(self, EnsNameToken::Disallowed(_))

Â  Â  }



Â  Â  pub fn is_stop(&self) -> bool {

Â  Â  Â  Â  matches!(self, EnsNameToken::Stop(_))

Â  Â  }



Â  Â  pub fn stop() -> Self {

Â  Â  Â  Â  Self::Stop(TokenStop {

Â  Â  Â  Â  Â  Â  cp: constants::CP_STOP,

Â  Â  Â  Â  })

Â  Â  }



Â  Â  pub fn as_string(&self) -> String {

Â  Â  Â  Â  utils::cps2str(&self.cps())

Â  Â  }

}



#[derive(Debug, Clone, PartialEq, Eq)]

pub struct TokenValid {

Â  Â  pub cps: Vec<CodePoint>,

}

#[derive(Debug, Clone, PartialEq, Eq)]

pub struct TokenMapped {

Â  Â  pub cps: Vec<CodePoint>,

Â  Â  pub cp: CodePoint,

}



#[derive(Debug, Clone, PartialEq, Eq)]

pub struct TokenIgnored {

Â  Â  pub cp: CodePoint,

}



#[derive(Debug, Clone, PartialEq, Eq)]

pub struct TokenDisallowed {

Â  Â  pub cp: CodePoint,

}

#[derive(Debug, Clone, PartialEq, Eq)]

pub struct TokenStop {

Â  Â  pub cp: CodePoint,

}

#[derive(Debug, Clone, PartialEq, Eq)]

pub struct TokenNfc {

Â  Â  pub cps: Vec<CodePoint>,

Â  Â  pub input: Vec<CodePoint>,

}



#[derive(Debug, Clone, PartialEq, Eq)]

pub struct TokenEmoji {

Â  Â  pub input: String,

Â  Â  pub emoji: Vec<CodePoint>,

Â  Â  pub cps_input: Vec<CodePoint>,

Â  Â  pub cps_no_fe0f: Vec<CodePoint>,

}



#[derive(Debug, Clone, PartialEq, Eq)]

pub enum CollapsedEnsNameToken {

Â  Â  Text(TokenValid),

Â  Â  Emoji(TokenEmoji),

}



impl CollapsedEnsNameToken {

Â  Â  pub fn input_size(&self) -> usize {

Â  Â  Â  Â  match self {

Â  Â  Â  Â  Â  Â  CollapsedEnsNameToken::Text(t) => t.cps.len(),

Â  Â  Â  Â  Â  Â  CollapsedEnsNameToken::Emoji(t) => t.cps_input.len(),

Â  Â  Â  Â  }

Â  Â  }

}

```

```rs [./src/tokens/tokenize.rs]

use crate::{

Â  Â  tokens::{

Â  Â  Â  Â  CollapsedEnsNameToken, EnsNameToken, TokenDisallowed, TokenEmoji, TokenIgnored,

Â  Â  Â  Â  TokenMapped, TokenNfc, TokenStop, TokenValid,

Â  Â  },

Â  Â  utils, CodePoint, CodePointsSpecs, ProcessError,

};



/// Represents a full ENS name, including the original input and the sequence of tokens

/// vitalik.eth

/// ^^^^^^^^^^^

/// name

#[derive(Debug, Clone, PartialEq, Eq)]

pub struct TokenizedName {

Â  Â  pub input: String,

Â  Â  pub tokens: Vec<EnsNameToken>,

}



/// Represents a tokenized ENS label (part of a name separated by periods), including sequence of tokens

/// vitalik.eth

/// ^^^^^^^

/// label 1

///Â  Â  Â  Â  Â ^^^

///Â  Â  Â  Â  Â label 2

#[derive(Debug, Clone, PartialEq, Eq)]

pub struct TokenizedLabel<'a> {

Â  Â  pub tokens: &'a [EnsNameToken],

}



impl TokenizedName {

Â  Â  pub fn empty() -> Self {

Â  Â  Â  Â  Self {

Â  Â  Â  Â  Â  Â  input: "".to_string(),

Â  Â  Â  Â  Â  Â  tokens: vec![],

Â  Â  Â  Â  }

Â  Â  }



Â  Â  /// Tokenizes an input string, applying NFC normalization if requested.

Â  Â  pub fn from_input(

Â  Â  Â  Â  input: impl AsRef<str>,

Â  Â  Â  Â  specs: &CodePointsSpecs,

Â  Â  Â  Â  apply_nfc: bool,

Â  Â  ) -> Result<Self, ProcessError> {

Â  Â  Â  Â  tokenize_name(input, specs, apply_nfc)

Â  Â  }



Â  Â  pub fn is_empty(&self) -> bool {

Â  Â  Â  Â  self.tokens.is_empty()

Â  Â  }



Â  Â  /// Returns an iterator over all tokens in the tokenized name.

Â  Â  pub fn iter_tokens(&self) -> impl Iterator<Item = &EnsNameToken> {

Â  Â  Â  Â  self.tokens.iter()

Â  Â  }



Â  Â  /// Returns an iterator over all labels in the tokenized name.

Â  Â  /// Basically, it splits the tokenized name by stop tokens.

Â  Â  pub fn iter_labels(&self) -> impl Iterator<Item = TokenizedLabel<'_>> {

Â  Â  Â  Â  self.tokens

Â  Â  Â  Â  Â  Â  .split(|t| matches!(t, EnsNameToken::Stop(_)))

Â  Â  Â  Â  Â  Â  .map(TokenizedLabel::from)

Â  Â  }



Â  Â  pub fn labels(&self) -> Vec<TokenizedLabel<'_>> {

Â  Â  Â  Â  self.iter_labels().collect()

Â  Â  }

}



impl TokenizedLabel<'_> {

Â  Â  /// Returns true if all tokens in the label are emoji tokens

Â  Â  pub fn is_fully_emoji(&self) -> bool {

Â  Â  Â  Â  self.tokens

Â  Â  Â  Â  Â  Â  .iter()

Â  Â  Â  Â  Â  Â  .all(|t| matches!(t, EnsNameToken::Emoji(_)))

Â  Â  }



Â  Â  /// Returns true if all codepoints in all tokens are ASCII characters

Â  Â  pub fn is_fully_ascii(&self) -> bool {

Â  Â  Â  Â  self.tokens

Â  Â  Â  Â  Â  Â  .iter()

Â  Â  Â  Â  Â  Â  .all(|token| token.cps().into_iter().all(utils::is_ascii))

Â  Â  }



Â  Â  /// Returns an iterator over all codepoints in all tokens.

Â  Â  pub fn iter_cps(&self) -> impl DoubleEndedIterator<Item = CodePoint> + '_ {

Â  Â  Â  Â  self.tokens.iter().flat_map(|token| token.cps())

Â  Â  }



Â  Â  /// Collapses consecutive text tokens into single text tokens, keeping emoji tokens separate.

Â  Â  /// Returns a vector of either Text or Emoji tokens.

Â  Â  pub fn collapse_into_text_or_emoji(&self) -> Vec<CollapsedEnsNameToken> {

Â  Â  Â  Â  let mut current_text_cps = vec![];

Â  Â  Â  Â  let mut collapsed = vec![];

Â  Â  Â  Â  for token in self.tokens.iter() {

Â  Â  Â  Â  Â  Â  match token {

Â  Â  Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(_) | EnsNameToken::Mapped(_) | EnsNameToken::Nfc(_) => {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_text_cps.extend(token.cps().iter());

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  EnsNameToken::Emoji(token) => {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if !current_text_cps.is_empty() {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  collapsed.push(CollapsedEnsNameToken::Text(TokenValid {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cps: current_text_cps,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }));

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_text_cps = vec![];

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  collapsed.push(CollapsedEnsNameToken::Emoji(token.clone()));

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  EnsNameToken::Ignored(_) | EnsNameToken::Disallowed(_) | EnsNameToken::Stop(_) => {}

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  if !current_text_cps.is_empty() {

Â  Â  Â  Â  Â  Â  collapsed.push(CollapsedEnsNameToken::Text(TokenValid {

Â  Â  Â  Â  Â  Â  Â  Â  cps: current_text_cps,

Â  Â  Â  Â  Â  Â  }));

Â  Â  Â  Â  }

Â  Â  Â  Â  collapsed

Â  Â  }



Â  Â  /// Returns a vector of codepoints from all text tokens, excluding emoji and ignored tokens

Â  Â  pub fn get_cps_of_not_ignored_text(&self) -> Vec<CodePoint> {

Â  Â  Â  Â  self.collapse_into_text_or_emoji()

Â  Â  Â  Â  Â  Â  .into_iter()

Â  Â  Â  Â  Â  Â  .filter_map(|token| {

Â  Â  Â  Â  Â  Â  Â  Â  if let CollapsedEnsNameToken::Text(token) = token {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Some(token.cps)

Â  Â  Â  Â  Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  None

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  Â  Â  .flatten()

Â  Â  Â  Â  Â  Â  .collect()

Â  Â  }

}



impl<'a, T> From<&'a T> for TokenizedLabel<'a>

where

Â  Â  T: AsRef<[EnsNameToken]> + ?Sized,

{

Â  Â  fn from(tokens: &'a T) -> Self {

Â  Â  Â  Â  TokenizedLabel {

Â  Â  Â  Â  Â  Â  tokens: tokens.as_ref(),

Â  Â  Â  Â  }

Â  Â  }

}



fn tokenize_name(

Â  Â  name: impl AsRef<str>,

Â  Â  specs: &CodePointsSpecs,

Â  Â  apply_nfc: bool,

) -> Result<TokenizedName, ProcessError> {

Â  Â  let name = name.as_ref();

Â  Â  if name.is_empty() {

Â  Â  Â  Â  return Ok(TokenizedName::empty());

Â  Â  }

Â  Â  let tokens = tokenize_input(name, specs, apply_nfc)?;

Â  Â  Ok(TokenizedName {

Â  Â  Â  Â  input: name.to_string(),

Â  Â  Â  Â  tokens,

Â  Â  })

}



fn tokenize_input(

Â  Â  input: impl AsRef<str>,

Â  Â  specs: &CodePointsSpecs,

Â  Â  apply_nfc: bool,

) -> Result<Vec<EnsNameToken>, ProcessError> {

Â  Â  let input = input.as_ref();

Â  Â  let emojis = specs.finditer_emoji(input).collect::<Vec<_>>();



Â  Â  let mut tokens = Vec::new();

Â  Â  let mut input_cur = 0;



Â  Â  while input_cur < input.len() {

Â  Â  Â  Â  if let Some(emoji) = maybe_starts_with_emoji(input_cur, input, &emojis, specs) {

Â  Â  Â  Â  Â  Â  let cursor_offset = emoji.input.len();

Â  Â  Â  Â  Â  Â  tokens.push(EnsNameToken::Emoji(emoji));

Â  Â  Â  Â  Â  Â  input_cur += cursor_offset;

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  let char = input[input_cur..]

Â  Â  Â  Â  Â  Â  Â  Â  .chars()

Â  Â  Â  Â  Â  Â  Â  Â  .next()

Â  Â  Â  Â  Â  Â  Â  Â  .expect("input_cur is in bounds");

Â  Â  Â  Â  Â  Â  let cursor_offset = char.len_utf8();

Â  Â  Â  Â  Â  Â  let cp = char as CodePoint;

Â  Â  Â  Â  Â  Â  let token = process_one_cp(cp, specs);

Â  Â  Â  Â  Â  Â  tokens.push(token);

Â  Â  Â  Â  Â  Â  input_cur += cursor_offset;

Â  Â  Â  Â  }

Â  Â  }



Â  Â  if apply_nfc {

Â  Â  Â  Â  perform_nfc_transform(&mut tokens, specs);

Â  Â  }

Â  Â  collapse_valid_tokens(&mut tokens);

Â  Â  Ok(tokens)

}



fn perform_nfc_transform(tokens: &mut Vec<EnsNameToken>, specs: &CodePointsSpecs) {

Â  Â  let mut i = 0;

Â  Â  let mut start = -1i32;



Â  Â  while i < tokens.len() {

Â  Â  Â  Â  let token = &tokens[i];

Â  Â  Â  Â  match token {

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(_) | EnsNameToken::Mapped(_) => {

Â  Â  Â  Â  Â  Â  Â  Â  let cps = token.cps();

Â  Â  Â  Â  Â  Â  Â  Â  if specs.cps_requires_check(&cps) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let mut end = i + 1;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (pos, token) in tokens.iter().enumerate().skip(end) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  match token {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(_) | EnsNameToken::Mapped(_) => {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if !specs.cps_requires_check(&cps) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  end = pos + 1;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  EnsNameToken::Ignored(_) => {}

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  _ => break,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if start < 0 {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  start = i as i32;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let slice = &tokens[start as usize..end];

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let mut cps = Vec::new();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for tok in slice {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  match tok {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(_) | EnsNameToken::Mapped(_) => {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cps.extend(&tok.cps());

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  _ => {}

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let str0 = utils::cps2str(&cps);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let str = utils::nfc(&str0);



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if str0 == str {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  i = end - 1;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let new_token = EnsNameToken::Nfc(TokenNfc {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  input: cps,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cps: utils::str2cps(&str),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  });

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tokens.splice(start as usize..end, vec![new_token]);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  i = start as usize;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  start = -1;

Â  Â  Â  Â  Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  start = i as i32;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  EnsNameToken::Ignored(_) => {}

Â  Â  Â  Â  Â  Â  _ => {

Â  Â  Â  Â  Â  Â  Â  Â  start = -1;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  i += 1;

Â  Â  }

}



// given array of codepoints

// returns the longest valid emoji sequence (or undefined if no match)

fn maybe_starts_with_emoji(

Â  Â  i: usize,

Â  Â  label: &str,

Â  Â  emojis: &[regex::Match],

Â  Â  specs: &CodePointsSpecs,

) -> Option<TokenEmoji> {

Â  Â  emojis.iter().find_map(|emoji| {

Â  Â  Â  Â  let start = emoji.start();

Â  Â  Â  Â  if start == i {

Â  Â  Â  Â  Â  Â  let end = emoji.end();

Â  Â  Â  Â  Â  Â  let input_cps = utils::str2cps(&label[start..end]);

Â  Â  Â  Â  Â  Â  let cps_no_fe0f = utils::filter_fe0f(&input_cps);

Â  Â  Â  Â  Â  Â  let emoji = specs

Â  Â  Â  Â  Â  Â  Â  Â  .cps_emoji_no_fe0f_to_pretty(&cps_no_fe0f)

Â  Â  Â  Â  Â  Â  Â  Â  .expect("emoji should be found")

Â  Â  Â  Â  Â  Â  Â  Â  .clone();

Â  Â  Â  Â  Â  Â  Some(TokenEmoji {

Â  Â  Â  Â  Â  Â  Â  Â  input: label[start..end].to_string(),

Â  Â  Â  Â  Â  Â  Â  Â  cps_input: input_cps,

Â  Â  Â  Â  Â  Â  Â  Â  emoji,

Â  Â  Â  Â  Â  Â  Â  Â  cps_no_fe0f,

Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  None

Â  Â  Â  Â  }

Â  Â  })

}



fn process_one_cp(cp: CodePoint, specs: &CodePointsSpecs) -> EnsNameToken {

Â  Â  if specs.is_stop(cp) {

Â  Â  Â  Â  EnsNameToken::Stop(TokenStop { cp })

Â  Â  } else if specs.is_valid(cp) {

Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![cp] })

Â  Â  } else if specs.is_ignored(cp) {

Â  Â  Â  Â  EnsNameToken::Ignored(TokenIgnored { cp })

Â  Â  } else if let Some(normalized) = specs.maybe_normalize(cp) {

Â  Â  Â  Â  EnsNameToken::Mapped(TokenMapped {

Â  Â  Â  Â  Â  Â  cp,

Â  Â  Â  Â  Â  Â  cps: normalized.clone(),

Â  Â  Â  Â  })

Â  Â  } else {

Â  Â  Â  Â  EnsNameToken::Disallowed(TokenDisallowed { cp })

Â  Â  }

}



fn collapse_valid_tokens(tokens: &mut Vec<EnsNameToken>) {

Â  Â  let mut i = 0;

Â  Â  while i < tokens.len() {

Â  Â  Â  Â  if let EnsNameToken::Valid(token) = &tokens[i] {

Â  Â  Â  Â  Â  Â  let mut j = i + 1;

Â  Â  Â  Â  Â  Â  let mut cps = token.cps.clone();

Â  Â  Â  Â  Â  Â  while j < tokens.len() {

Â  Â  Â  Â  Â  Â  Â  Â  if let EnsNameToken::Valid(next_token) = &tokens[j] {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cps.extend(next_token.cps.iter());

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  j += 1;

Â  Â  Â  Â  Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  let new_token = EnsNameToken::Valid(TokenValid { cps });

Â  Â  Â  Â  Â  Â  tokens.splice(i..j, vec![new_token].into_iter());

Â  Â  Â  Â  }

Â  Â  Â  Â  i += 1;

Â  Â  }

}



#[cfg(test)]

mod tests {

Â  Â  use super::*;

Â  Â  use pretty_assertions::assert_eq;

Â  Â  use rstest::{fixture, rstest};



Â  Â  #[fixture]

Â  Â  #[once]

Â  Â  fn specs() -> CodePointsSpecs {

Â  Â  Â  Â  CodePointsSpecs::default()

Â  Â  }



Â  Â  #[rstest]

Â  Â  #[case::empty(vec![], vec![])]

Â  Â  #[case::single(

Â  Â  Â  Â  vec![EnsNameToken::Valid(TokenValid { cps: vec![1, 2, 3] })],

Â  Â  Â  Â  vec![EnsNameToken::Valid(TokenValid { cps: vec![1, 2, 3] })],

Â  Â  )]

Â  Â  #[case::two(

Â  Â  Â  Â  vec![

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![1, 2, 3] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![4, 5, 6] }),

Â  Â  Â  Â  ],

Â  Â  Â  Â  vec![EnsNameToken::Valid(TokenValid { cps: vec![1, 2, 3, 4, 5, 6] })],

Â  Â  )]

Â  Â  #[case::full(

Â  Â  Â  Â  vec![

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![1, 2, 3] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Disallowed(TokenDisallowed { cp: 0 }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![4, 5, 6] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![7, 8, 9] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![10, 11, 12] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Disallowed(TokenDisallowed { cp: 10 }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Stop(TokenStop { cp: 11 }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![12] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Ignored(TokenIgnored { cp: 13 }),

Â  Â  Â  Â  ],

Â  Â  Â  Â  vec![

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![1, 2, 3] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Disallowed(TokenDisallowed { cp: 0 }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![4, 5, 6, 7, 8, 9, 10, 11, 12] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Disallowed(TokenDisallowed { cp: 10 }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Stop(TokenStop { cp: 11 }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![12] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Ignored(TokenIgnored { cp: 13 }),

Â  Â  Â  Â  ],

Â  Â  )]

Â  Â  fn test_collapse_valid_tokens(

Â  Â  Â  Â  #[case] input: Vec<EnsNameToken>,

Â  Â  Â  Â  #[case] expected: Vec<EnsNameToken>,

Â  Â  ) {

Â  Â  Â  Â  let mut tokens = input;

Â  Â  Â  Â  collapse_valid_tokens(&mut tokens);

Â  Â  Â  Â  assert_eq!(tokens, expected);

Â  Â  }



Â  Â  #[rstest]

Â  Â  #[case::xyz(

Â  Â  Â  Â  "xyzğŸ‘¨ğŸ»/",

Â  Â  Â  Â  true,

Â  Â  Â  Â  vec![

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![120, 121, 122] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Emoji(TokenEmoji { input: "ğŸ‘¨ğŸ»".to_string(), cps_input: vec![128104, 127995], emoji: vec![128104, 127995], cps_no_fe0f: vec![128104, 127995] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Disallowed(TokenDisallowed { cp: 47 }),

Â  Â  Â  Â  ]

Â  Â  )]

Â  Â  #[case::a_poop_b(

Â  Â  Â  Â  "AğŸ’©ï¸ï¸b",

Â  Â  Â  Â  true,

Â  Â  Â  Â  vec![

Â  Â  Â  Â  Â  Â  EnsNameToken::Mapped(TokenMapped { cp: 65, cps: vec![97] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Emoji(TokenEmoji { input: "ğŸ’©".to_string(), cps_input: vec![128169], emoji: vec![128169, 65039], cps_no_fe0f: vec![128169] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Ignored(TokenIgnored { cp: 65038 }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Ignored(TokenIgnored { cp: 65038 }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![98] }),

Â  Â  Â  Â  ]

Â  Â  )]

Â  Â  #[case::atm(

Â  Â  Â  Â  "aâ„¢ï¸",

Â  Â  Â  Â  true,

Â  Â  Â  Â  vec![

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![97] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Mapped(TokenMapped { cp: 8482, cps: vec![116, 109] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Ignored(TokenIgnored { cp: 65039 }),

Â  Â  Â  Â  ]

Â  Â  )]

Â  Â  #[case::no_nfc(

Â  Â  Â  Â  "_RğŸ’©\u{FE0F}a\u{FE0F}\u{304}\u{AD}.",

Â  Â  Â  Â  false,

Â  Â  Â  Â  vec![

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![95] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Mapped(TokenMapped { cp: 82, cps: vec![114] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Emoji(TokenEmoji { input: "ğŸ’©ï¸".to_string(), cps_input: vec![128169, 65039], emoji: vec![128169, 65039], cps_no_fe0f: vec![128169] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![97] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Ignored(TokenIgnored { cp: 65039 }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![772] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Ignored(TokenIgnored { cp: 173 }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Stop(TokenStop { cp: 46 }),

Â  Â  Â  Â  ]

Â  Â  )]

Â  Â  #[case::with_nfc(

Â  Â  Â  Â  "_RğŸ’©\u{FE0F}a\u{FE0F}\u{304}\u{AD}.",

Â  Â  Â  Â  true,

Â  Â  Â  Â  vec![

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![95] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Mapped(TokenMapped { cp: 82, cps: vec![114] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Emoji(TokenEmoji { input: "ğŸ’©ï¸".to_string(), cps_input: vec![128169, 65039], emoji: vec![128169, 65039], cps_no_fe0f: vec![128169] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Nfc(TokenNfc { input: vec![97, 772], cps: vec![257] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Ignored(TokenIgnored { cp: 173 }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Stop(TokenStop { cp: 46 }),

Â  Â  Â  Â  ]

Â  Â  )]

Â  Â  #[case::raffy(

Â  Â  Â  Â  "RaFFYğŸš´â€â™‚ï¸.eTh",

Â  Â  Â  Â  true,

Â  Â  Â  Â  vec![

Â  Â  Â  Â  Â  Â  EnsNameToken::Mapped(TokenMapped { cp: 82, cps: vec![114] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![97] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Mapped(TokenMapped { cp: 70, cps: vec![102] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Mapped(TokenMapped { cp: 70, cps: vec![102] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Mapped(TokenMapped { cp: 89, cps: vec![121] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Emoji(TokenEmoji { input: "ğŸš´\u{200d}â™‚\u{fe0f}".to_string(), cps_input: vec![128692, 8205, 9794, 65039], emoji: vec![128692, 8205, 9794, 65039], cps_no_fe0f: vec![128692, 8205, 9794] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Stop(TokenStop { cp: 46 }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![101] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Mapped(TokenMapped { cp: 84, cps: vec![116] }),

Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(TokenValid { cps: vec![104] }),

Â  Â  Â  Â  ]

Â  Â  )]

Â  Â  #[case::emojis(

Â  Â  Â  Â  "â›¹ï¸â€â™€",

Â  Â  Â  Â  true,

Â  Â  Â  Â  vec![

Â  Â  Â  Â  Â  Â  EnsNameToken::Emoji(TokenEmoji { input: "â›¹ï¸â€â™€".to_string(), cps_input: vec![9977, 65039, 8205, 9792], emoji: vec![9977, 65039, 8205, 9792, 65039], cps_no_fe0f: vec![9977, 8205, 9792] }),

Â  Â  Â  Â  ]

Â  Â  )]

Â  Â  fn test_ens_tokenize(

Â  Â  Â  Â  #[case] input: &str,

Â  Â  Â  Â  #[case] apply_nfc: bool,

Â  Â  Â  Â  #[case] expected: Vec<EnsNameToken>,

Â  Â  Â  Â  specs: &CodePointsSpecs,

Â  Â  ) {

Â  Â  Â  Â  let tokens = tokenize_input(input, specs, apply_nfc).expect("tokenize");

Â  Â  Â  Â  assert_eq!(tokens, expected);

Â  Â  }



Â  Â  #[rstest]

Â  Â  #[case::leading_cm(

Â  Â  Â  Â  "ó …‘ğ‘†»ğŸ‘±ğŸ¿â€â™€ï¸xyz",

Â  Â  Â  Â  vec![

Â  Â  Â  Â  Â  Â  CollapsedEnsNameToken::Text(TokenValid { cps: vec![70075] }),

Â  Â  Â  Â  Â  Â  CollapsedEnsNameToken::Emoji(TokenEmoji { input: "ğŸ‘±ğŸ¿â€â™€ï¸".to_string(), cps_input: vec![128113, 127999, 8205, 9792, 65039], emoji: vec![128113, 127999, 8205, 9792, 65039], cps_no_fe0f: vec![128113, 127999, 8205, 9792] }),

Â  Â  Â  Â  Â  Â  CollapsedEnsNameToken::Text(TokenValid { cps: vec![120, 121, 122] }),

Â  Â  Â  Â  ]

Â  Â  )]

Â  Â  #[case::atm(

Â  Â  Â  Â  "aâ„¢ï¸",

Â  Â  Â  Â  vec![

Â  Â  Â  Â  Â  Â  CollapsedEnsNameToken::Text(TokenValid { cps: vec![97, 116, 109] }),

Â  Â  Â  Â  ]

Â  Â  )]

Â  Â  fn test_collapse(

Â  Â  Â  Â  #[case] input: &str,

Â  Â  Â  Â  #[case] expected: Vec<CollapsedEnsNameToken>,

Â  Â  Â  Â  specs: &CodePointsSpecs,

Â  Â  ) {

Â  Â  Â  Â  let tokens = tokenize_input(input, specs, true).expect("tokenize");

Â  Â  Â  Â  let label = TokenizedLabel::from(&tokens);

Â  Â  Â  Â  let result = label.collapse_into_text_or_emoji();

Â  Â  Â  Â  assert_eq!(result, expected);

Â  Â  }

}

```

```rs [./src/tokens/mod.rs]

mod tokenize;

mod types;



pub use tokenize::{TokenizedLabel, TokenizedName};

pub use types::*;

```

```rs [./src/beautify.rs]

use crate::{constants, join::join_cps, CodePoint, EnsNameToken, LabelType, ValidatedLabel};



/// Beautifies a list of validated labels by

/// - replacing Greek code points with their pretty variants

/// - using pretty variants of emojis

pub fn beautify_labels(labels: &[ValidatedLabel]) -> String {

Â  Â  let labels_cps = labels.iter().map(|label| {

Â  Â  Â  Â  label

Â  Â  Â  Â  Â  Â  .tokens

Â  Â  Â  Â  Â  Â  .iter()

Â  Â  Â  Â  Â  Â  .filter_map(|token| match token {

Â  Â  Â  Â  Â  Â  Â  Â  EnsNameToken::Emoji(emoji) => Some(emoji.emoji.clone()),

Â  Â  Â  Â  Â  Â  Â  Â  EnsNameToken::Valid(_) | EnsNameToken::Mapped(_) | EnsNameToken::Nfc(_) => {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Some(cps_replaced_greek(token.cps(), &label.label_type))

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  EnsNameToken::Ignored(_) | EnsNameToken::Disallowed(_) | EnsNameToken::Stop(_) => {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  None

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  Â  Â  .flatten()

Â  Â  Â  Â  Â  Â  .collect::<Vec<_>>()

Â  Â  });

Â  Â  join_cps(labels_cps)

}



fn cps_replaced_greek(mut cps: Vec<CodePoint>, label_type: &LabelType) -> Vec<CodePoint> {

Â  Â  if !label_type.is_greek() {

Â  Â  Â  Â  cps.iter_mut().for_each(|cp| {

Â  Â  Â  Â  Â  Â  if *cp == constants::CP_XI_SMALL {

Â  Â  Â  Â  Â  Â  Â  Â  *cp = constants::CP_XI_CAPITAL;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  });

Â  Â  }



Â  Â  cps

}

```

```rs [./src/utils.rs]

use crate::{CodePoint, CodePointsSpecs};

use unicode_normalization::UnicodeNormalization;



const FE0F: CodePoint = 0xfe0f;

const LAST_ASCII_CP: CodePoint = 0x7f;



#[inline]

pub fn filter_fe0f(cps: &[CodePoint]) -> Vec<CodePoint> {

Â  Â  cps.iter().filter(|cp| **cp != FE0F).cloned().collect()

}



#[inline]

pub fn cps2str(cps: &[CodePoint]) -> String {

Â  Â  cps.iter()

Â  Â  Â  Â  .filter_map(|&code_point| char::from_u32(code_point))

Â  Â  Â  Â  .collect()

}



#[inline]

pub fn cp2str(cp: CodePoint) -> String {

Â  Â  cps2str(&[cp])

}



#[inline]

pub fn str2cps(str: &str) -> Vec<CodePoint> {

Â  Â  str.chars().map(|c| c as CodePoint).collect()

}



#[inline]

pub fn is_ascii(cp: CodePoint) -> bool {

Â  Â  cp <= LAST_ASCII_CP

}



#[inline]

pub fn nfc(str: &str) -> String {

Â  Â  str.nfc().collect()

}



#[inline]

pub fn nfd_cps(cps: &[CodePoint], specs: &CodePointsSpecs) -> Vec<CodePoint> {

Â  Â  let mut decomposed = Vec::new();

Â  Â  for cp in cps {

Â  Â  Â  Â  if let Some(decomposed_cp) = specs.decompose(*cp) {

Â  Â  Â  Â  Â  Â  decomposed.extend(decomposed_cp);

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  decomposed.push(*cp);

Â  Â  Â  Â  }

Â  Â  }

Â  Â  decomposed

}

```

```rs [./src/code_points/types.rs]

use crate::static_data::spec_json;

use std::collections::{HashMap, HashSet};



pub type CodePoint = u32;



#[derive(Debug, Clone, PartialEq, Eq)]

pub struct ParsedGroup {

Â  Â  pub name: spec_json::GroupName,

Â  Â  pub primary: HashSet<CodePoint>,

Â  Â  pub secondary: HashSet<CodePoint>,

Â  Â  pub primary_plus_secondary: HashSet<CodePoint>,

Â  Â  pub cm_absent: bool,

}



impl From<spec_json::Group> for ParsedGroup {

Â  Â  fn from(g: spec_json::Group) -> Self {

Â  Â  Â  Â  Self {

Â  Â  Â  Â  Â  Â  name: g.name,

Â  Â  Â  Â  Â  Â  primary: g.primary.clone().into_iter().collect(),

Â  Â  Â  Â  Â  Â  secondary: g.secondary.clone().into_iter().collect(),

Â  Â  Â  Â  Â  Â  primary_plus_secondary: g

Â  Â  Â  Â  Â  Â  Â  Â  .primary

Â  Â  Â  Â  Â  Â  Â  Â  .clone()

Â  Â  Â  Â  Â  Â  Â  Â  .into_iter()

Â  Â  Â  Â  Â  Â  Â  Â  .chain(g.secondary.clone())

Â  Â  Â  Â  Â  Â  Â  Â  .collect(),

Â  Â  Â  Â  Â  Â  cm_absent: g.cm.is_empty(),

Â  Â  Â  Â  }

Â  Â  }

}



impl ParsedGroup {

Â  Â  pub fn contains_cp(&self, cp: CodePoint) -> bool {

Â  Â  Â  Â  self.primary_plus_secondary.contains(&cp)

Â  Â  }



Â  Â  pub fn contains_all_cps(&self, cps: &[CodePoint]) -> bool {

Â  Â  Â  Â  cps.iter().all(|cp| self.contains_cp(*cp))

Â  Â  }

}



pub type ParsedWholeMap = HashMap<CodePoint, ParsedWholeValue>;



pub enum ParsedWholeValue {

Â  Â  Number(u32),

Â  Â  WholeObject(ParsedWholeObject),

}



impl TryFrom<spec_json::WholeValue> for ParsedWholeValue {

Â  Â  type Error = anyhow::Error;

Â  Â  fn try_from(value: spec_json::WholeValue) -> Result<Self, Self::Error> {

Â  Â  Â  Â  match value {

Â  Â  Â  Â  Â  Â  spec_json::WholeValue::Number(number) => Ok(ParsedWholeValue::Number(number)),

Â  Â  Â  Â  Â  Â  spec_json::WholeValue::WholeObject(object) => {

Â  Â  Â  Â  Â  Â  Â  Â  Ok(ParsedWholeValue::WholeObject(object.try_into()?))

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

}



pub struct ParsedWholeObject {

Â  Â  pub v: HashSet<CodePoint>,

Â  Â  pub m: HashMap<CodePoint, HashSet<String>>,

}



impl TryFrom<spec_json::WholeObject> for ParsedWholeObject {

Â  Â  type Error = anyhow::Error;



Â  Â  fn try_from(value: spec_json::WholeObject) -> Result<Self, Self::Error> {

Â  Â  Â  Â  let v = value.v.into_iter().collect();

Â  Â  Â  Â  let m = value

Â  Â  Â  Â  Â  Â  .m

Â  Â  Â  Â  Â  Â  .into_iter()

Â  Â  Â  Â  Â  Â  .map(|(k, v)| {

Â  Â  Â  Â  Â  Â  Â  Â  let k = k.parse::<CodePoint>()?;

Â  Â  Â  Â  Â  Â  Â  Â  let v = v.into_iter().collect();

Â  Â  Â  Â  Â  Â  Â  Â  Ok((k, v))

Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  Â  Â  .collect::<Result<HashMap<CodePoint, HashSet<String>>, anyhow::Error>>()?;

Â  Â  Â  Â  Ok(Self { v, m })

Â  Â  }

}

```

```rs [./src/code_points/specs.rs]

use super::types::*;

use crate::{

Â  Â  constants,

Â  Â  static_data::{

Â  Â  Â  Â  nf_json,

Â  Â  Â  Â  spec_json::{self, GroupName},

Â  Â  },

Â  Â  utils, CodePoint,

};

use regex::Regex;

use std::collections::{HashMap, HashSet};



/// This struct contains logic for validating and normalizing code points.

pub struct CodePointsSpecs {

Â  Â  cm: HashSet<CodePoint>,

Â  Â  ignored: HashSet<CodePoint>,

Â  Â  mapped: HashMap<CodePoint, Vec<CodePoint>>,

Â  Â  nfc_check: HashSet<CodePoint>,

Â  Â  whole_map: ParsedWholeMap,

Â  Â  fenced: HashMap<CodePoint, String>,

Â  Â  groups: Vec<ParsedGroup>,

Â  Â  group_name_to_index: HashMap<spec_json::GroupName, usize>,

Â  Â  valid: HashSet<CodePoint>,

Â  Â  nsm: HashSet<CodePoint>,

Â  Â  nsm_max: u32,

Â  Â  emoji_no_fe0f_to_pretty: HashMap<Vec<CodePoint>, Vec<CodePoint>>,

Â  Â  decomp: HashMap<CodePoint, Vec<CodePoint>>,

Â  Â  emoji_regex: Regex,

}



impl CodePointsSpecs {

Â  Â  pub fn new(spec: spec_json::Spec, nf: nf_json::Nf) -> Self {

Â  Â  Â  Â  let emoji: HashSet<Vec<CodePoint>> = spec.emoji.into_iter().collect();

Â  Â  Â  Â  let emoji_no_fe0f_to_pretty = emoji

Â  Â  Â  Â  Â  Â  .iter()

Â  Â  Â  Â  Â  Â  .map(|e| (utils::filter_fe0f(e), e.clone()))

Â  Â  Â  Â  Â  Â  .collect();

Â  Â  Â  Â  let decomp = nf

Â  Â  Â  Â  Â  Â  .decomp

Â  Â  Â  Â  Â  Â  .into_iter()

Â  Â  Â  Â  Â  Â  .map(|item| (item.number, item.nested_numbers))

Â  Â  Â  Â  Â  Â  .collect();

Â  Â  Â  Â  let groups: Vec<ParsedGroup> = spec.groups.into_iter().map(ParsedGroup::from).collect();

Â  Â  Â  Â  let group_name_to_index: HashMap<spec_json::GroupName, usize> = groups

Â  Â  Â  Â  Â  Â  .iter()

Â  Â  Â  Â  Â  Â  .enumerate()

Â  Â  Â  Â  Â  Â  .map(|(i, g)| (g.name.clone(), i))

Â  Â  Â  Â  Â  Â  .collect();

Â  Â  Â  Â  let valid = compute_valid(&groups, &decomp);

Â  Â  Â  Â  let whole_map = compute_whole_map(spec.whole_map);

Â  Â  Â  Â  let emoji_str_list = emoji

Â  Â  Â  Â  Â  Â  .iter()

Â  Â  Â  Â  Â  Â  .map(|cps| utils::cps2str(cps))

Â  Â  Â  Â  Â  Â  .collect::<Vec<_>>();

Â  Â  Â  Â  let emoji_regex =

Â  Â  Â  Â  Â  Â  create_emoji_regex_pattern(emoji_str_list).expect("failed to create emoji regex");



Â  Â  Â  Â  Self {

Â  Â  Â  Â  Â  Â  cm: spec.cm.into_iter().collect(),

Â  Â  Â  Â  Â  Â  emoji_no_fe0f_to_pretty,

Â  Â  Â  Â  Â  Â  ignored: spec.ignored.into_iter().collect(),

Â  Â  Â  Â  Â  Â  mapped: spec.mapped.into_iter().map(|m| (m.from, m.to)).collect(),

Â  Â  Â  Â  Â  Â  nfc_check: spec.nfc_check.into_iter().collect(),

Â  Â  Â  Â  Â  Â  fenced: spec.fenced.into_iter().map(|f| (f.from, f.to)).collect(),

Â  Â  Â  Â  Â  Â  valid,

Â  Â  Â  Â  Â  Â  groups,

Â  Â  Â  Â  Â  Â  nsm: spec.nsm.into_iter().collect(),

Â  Â  Â  Â  Â  Â  nsm_max: spec.nsm_max,

Â  Â  Â  Â  Â  Â  decomp,

Â  Â  Â  Â  Â  Â  whole_map,

Â  Â  Â  Â  Â  Â  group_name_to_index,

Â  Â  Â  Â  Â  Â  emoji_regex,

Â  Â  Â  Â  }

Â  Â  }

}



impl Default for CodePointsSpecs {

Â  Â  fn default() -> Self {

Â  Â  Â  Â  let spec = spec_json::Spec::default();

Â  Â  Â  Â  let nf = nf_json::Nf::default();

Â  Â  Â  Â  Self::new(spec, nf)

Â  Â  }

}



impl CodePointsSpecs {

Â  Â  pub fn get_mapping(&self, cp: CodePoint) -> Option<&Vec<CodePoint>> {

Â  Â  Â  Â  self.mapped.get(&cp)

Â  Â  }



Â  Â  pub fn cps_is_emoji(&self, cps: &[CodePoint]) -> bool {

Â  Â  Â  Â  let s = utils::cps2str(cps);

Â  Â  Â  Â  let maybe_match = self.finditer_emoji(&s).next();

Â  Â  Â  Â  maybe_match

Â  Â  Â  Â  Â  Â  .map(|m| m.start() == 0 && m.end() == s.len())

Â  Â  Â  Â  Â  Â  .unwrap_or(false)

Â  Â  }



Â  Â  pub fn finditer_emoji<'a>(&'a self, s: &'a str) -> impl Iterator<Item = regex::Match<'_>> {

Â  Â  Â  Â  self.emoji_regex.find_iter(s)

Â  Â  }



Â  Â  pub fn cps_requires_check(&self, cps: &[CodePoint]) -> bool {

Â  Â  Â  Â  cps.iter().any(|cp| self.nfc_check.contains(cp))

Â  Â  }



Â  Â  pub fn cps_emoji_no_fe0f_to_pretty(&self, cps: &[CodePoint]) -> Option<&Vec<CodePoint>> {

Â  Â  Â  Â  self.emoji_no_fe0f_to_pretty.get(cps)

Â  Â  }



Â  Â  pub fn maybe_normalize(&self, cp: CodePoint) -> Option<&Vec<CodePoint>> {

Â  Â  Â  Â  self.mapped.get(&cp)

Â  Â  }



Â  Â  pub fn is_valid(&self, cp: CodePoint) -> bool {

Â  Â  Â  Â  self.valid.contains(&cp)

Â  Â  }



Â  Â  pub fn is_ignored(&self, cp: CodePoint) -> bool {

Â  Â  Â  Â  self.ignored.contains(&cp)

Â  Â  }



Â  Â  pub fn is_stop(&self, cp: CodePoint) -> bool {

Â  Â  Â  Â  cp == constants::CP_STOP

Â  Â  }



Â  Â  pub fn is_fenced(&self, cp: CodePoint) -> bool {

Â  Â  Â  Â  self.fenced.contains_key(&cp)

Â  Â  }



Â  Â  pub fn is_cm(&self, cp: CodePoint) -> bool {

Â  Â  Â  Â  self.cm.contains(&cp)

Â  Â  }



Â  Â  pub fn groups_for_cps<'a>(

Â  Â  Â  Â  &'a self,

Â  Â  Â  Â  cps: &'a [CodePoint],

Â  Â  ) -> impl Iterator<Item = &'a ParsedGroup> {

Â  Â  Â  Â  self.groups

Â  Â  Â  Â  Â  Â  .iter()

Â  Â  Â  Â  Â  Â  .filter(|group| cps.iter().all(|cp| group.contains_cp(*cp)))

Â  Â  }



Â  Â  pub fn is_nsm(&self, cp: CodePoint) -> bool {

Â  Â  Â  Â  self.nsm.contains(&cp)

Â  Â  }



Â  Â  pub fn nsm_max(&self) -> u32 {

Â  Â  Â  Â  self.nsm_max

Â  Â  }



Â  Â  pub fn decompose(&self, cp: CodePoint) -> Option<&Vec<CodePoint>> {

Â  Â  Â  Â  self.decomp.get(&cp)

Â  Â  }



Â  Â  pub fn whole_map(&self, cp: CodePoint) -> Option<&ParsedWholeValue> {

Â  Â  Â  Â  self.whole_map.get(&cp)

Â  Â  }



Â  Â  pub fn group_by_name(&self, name: impl Into<GroupName>) -> Option<&ParsedGroup> {

Â  Â  Â  Â  self.group_name_to_index

Â  Â  Â  Â  Â  Â  .get(&name.into())

Â  Â  Â  Â  Â  Â  .and_then(|i| self.groups.get(*i))

Â  Â  }

}



fn compute_valid(

Â  Â  groups: &[ParsedGroup],

Â  Â  decomp: &HashMap<CodePoint, Vec<CodePoint>>,

) -> HashSet<CodePoint> {

Â  Â  let mut valid = HashSet::new();

Â  Â  for g in groups {

Â  Â  Â  Â  valid.extend(g.primary_plus_secondary.iter());

Â  Â  }



Â  Â  let ndf: Vec<CodePoint> = valid

Â  Â  Â  Â  .iter()

Â  Â  Â  Â  .flat_map(|cp| decomp.get(cp).cloned().unwrap_or_default())

Â  Â  Â  Â  .collect();

Â  Â  valid.extend(ndf);

Â  Â  valid

}



fn compute_whole_map(whole_map: HashMap<String, spec_json::WholeValue>) -> ParsedWholeMap {

Â  Â  whole_map

Â  Â  Â  Â  .into_iter()

Â  Â  Â  Â  .map(|(k, v)| (k.parse::<CodePoint>().unwrap(), v.try_into().unwrap()))

Â  Â  Â  Â  .collect()

}



fn create_emoji_regex_pattern(emojis: Vec<impl AsRef<str>>) -> Result<Regex, regex::Error> {

Â  Â  let fe0f = regex::escape(constants::STR_FE0F);



Â  Â  // Make FE0F optional

Â  Â  let make_emoji = |emoji: &str| regex::escape(emoji).replace(&fe0f, &format!("{}?", fe0f));



Â  Â  // Order emojis to match the longest ones first

Â  Â  let order = |emoji: &str| emoji.replace(constants::STR_FE0F, "").len();



Â  Â  let mut sorted_emojis = emojis;

Â  Â  sorted_emojis.sort_by_key(|b| std::cmp::Reverse(order(b.as_ref())));



Â  Â  let emoji_regex = sorted_emojis

Â  Â  Â  Â  .into_iter()

Â  Â  Â  Â  .map(|emoji| make_emoji(emoji.as_ref()))

Â  Â  Â  Â  .collect::<Vec<_>>()

Â  Â  Â  Â  .join("|");



Â  Â  regex::Regex::new(&emoji_regex)

}



#[cfg(test)]

mod tests {

Â  Â  use super::*;

Â  Â  use pretty_assertions::assert_eq;

Â  Â  use rstest::{fixture, rstest};



Â  Â  #[fixture]

Â  Â  #[once]

Â  Â  fn specs() -> CodePointsSpecs {

Â  Â  Â  Â  CodePointsSpecs::default()

Â  Â  }



Â  Â  #[rstest]

Â  Â  #[case::letter_a('A', "a")]

Â  Â  #[case::roman_numeral_vi('â…¥', "vi")]

Â  Â  fn test_mapped(#[case] input: char, #[case] output: &str, specs: &CodePointsSpecs) {

Â  Â  Â  Â  let mapped = specs.get_mapping(input as u32);

Â  Â  Â  Â  let expected = output.chars().map(|c| c as u32).collect::<Vec<_>>();

Â  Â  Â  Â  assert_eq!(mapped, Some(&expected));

Â  Â  }



Â  Â  #[rstest]

Â  Â  #[case::slash("â„")]

Â  Â  fn test_fenced(#[case] fence: &str, specs: &CodePointsSpecs) {

Â  Â  Â  Â  assert!(

Â  Â  Â  Â  Â  Â  specs

Â  Â  Â  Â  Â  Â  Â  Â  .fenced

Â  Â  Â  Â  Â  Â  Â  Â  .contains_key(&(fence.chars().next().unwrap() as u32)),

Â  Â  Â  Â  Â  Â  "Fence {fence} not found"

Â  Â  Â  Â  );

Â  Â  }



Â  Â  #[rstest]

Â  Â  #[case::string("helloğŸ˜€", vec![("ğŸ˜€", 5, 9)])]

Â  Â  #[case::man_technologist("ğŸ‘¨â€ğŸ’»", vec![("ğŸ‘¨â€ğŸ’»", 0, 11)])]

Â  Â  fn test_emoji(

Â  Â  Â  Â  #[case] emoji: &str,

Â  Â  Â  Â  #[case] expected: Vec<(&str, usize, usize)>,

Â  Â  Â  Â  specs: &CodePointsSpecs,

Â  Â  ) {

Â  Â  Â  Â  let matches = specs.finditer_emoji(emoji).collect::<Vec<_>>();

Â  Â  Â  Â  assert_eq!(matches.len(), expected.len());

Â  Â  Â  Â  for (i, (emoji, start, end)) in expected.into_iter().enumerate() {

Â  Â  Â  Â  Â  Â  assert_eq!(matches[i].as_str(), emoji);

Â  Â  Â  Â  Â  Â  assert_eq!(matches[i].start(), start);

Â  Â  Â  Â  Â  Â  assert_eq!(matches[i].end(), end);

Â  Â  Â  Â  }

Â  Â  }



Â  Â  #[rstest]

Â  Â  #[case::small(&[36, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 95, 97])]

Â  Â  #[case::big(&[205743, 205742, 205741, 205740, 205739, 205738, 205737, 205736])]

Â  Â  fn test_valid(#[case] cps: &[CodePoint], specs: &CodePointsSpecs) {

Â  Â  Â  Â  for cp in cps {

Â  Â  Â  Â  Â  Â  assert!(

Â  Â  Â  Â  Â  Â  Â  Â  specs.is_valid(*cp),

Â  Â  Â  Â  Â  Â  Â  Â  "Codepoint {cp} is not valid, but should be"

Â  Â  Â  Â  Â  Â  );

Â  Â  Â  Â  }

Â  Â  }



Â  Â  #[rstest]

Â  Â  #[case(&[82])]

Â  Â  fn test_not_valid(#[case] cps: &[CodePoint], specs: &CodePointsSpecs) {

Â  Â  Â  Â  for cp in cps {

Â  Â  Â  Â  Â  Â  assert!(

Â  Â  Â  Â  Â  Â  Â  Â  !specs.is_valid(*cp),

Â  Â  Â  Â  Â  Â  Â  Â  "Codepoint {cp} is valid, but should not be"

Â  Â  Â  Â  Â  Â  );

Â  Â  Â  Â  }

Â  Â  }

}

```

```rs [./src/code_points/mod.rs]

mod specs;

mod types;



pub use specs::CodePointsSpecs;

pub use types::*;

```



</rust>

<csharp>

```cs [ENSNormalize.cs/ENSNormalize/OutputToken.cs]

ï»¿using System.Collections.Generic;



namespace ADRaffy.ENSNormalize

{

Â  Â  public class OutputToken

Â  Â  {

Â  Â  Â  Â  public readonly IList<int> Codepoints;

Â  Â  Â  Â  public readonly EmojiSequence? Emoji;

Â  Â  Â  Â  public bool IsEmoji { get => Emoji != null; }

Â  Â  Â  Â  public OutputToken(IList<int> cps, EmojiSequence? emoji = null)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Codepoints = cps;

Â  Â  Â  Â  Â  Â  Emoji = emoji;

Â  Â  Â  Â  }

Â  Â  Â  Â  public override string ToString()Â 

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  string name = IsEmoji ? "Emoji" : "Text";

Â  Â  Â  Â  Â  Â  return $"{name}[{Codepoints.ToHexSequence()}]";

Â  Â  Â  Â  }

Â  Â  }

}

```

```cs [ENSNormalize.cs/ENSNormalize/Decoder.cs]

ï»¿using System;

using System.Linq;

using System.Collections.Generic;



namespace ADRaffy.ENSNormalize

{

Â  Â  public class Decoder

Â  Â  {

Â  Â  Â  Â  static int AsSigned(int i)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  return (i & 1) != 0 ? ~i >> 1 : i >> 1;

Â  Â  Â  Â  }



Â  Â  Â  Â  private readonly uint[] Words;

Â  Â  Â  Â  private readonly int[] Magic;

Â  Â  Â  Â  private int Index, Bits;

Â  Â  Â  Â  private uint Word;

Â  Â  Â  Â  public Decoder(uint[] words) {

Â  Â  Â  Â  Â  Â  Words = words;

Â  Â  Â  Â  Â  Â  Index = 0;

Â  Â  Â  Â  Â  Â  Word = 0;

Â  Â  Â  Â  Â  Â  Bits = 0;

Â  Â  Â  Â  Â  Â  Magic = ReadMagic();

Â  Â  Â  Â  }

Â  Â  Â  Â  public bool ReadBit()

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  if (Bits == 0)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Word = Words[Index++];

Â  Â  Â  Â  Â  Â  Â  Â  Bits = 1;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  bool bit = (Word & Bits) != 0;

Â  Â  Â  Â  Â  Â  Bits <<= 1;

Â  Â  Â  Â  Â  Â  return bit;

Â  Â  Â  Â  }

Â  Â  Â  Â  // read an ascending arrayÂ 

Â  Â  Â  Â  private int[] ReadMagic()

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  List<int> magic = new();

Â  Â  Â  Â  Â  Â  int w = 0;

Â  Â  Â  Â  Â  Â  while (true)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  int dw = ReadUnary();

Â  Â  Â  Â  Â  Â  Â  Â  if (dw == 0) break;

Â  Â  Â  Â  Â  Â  Â  Â  magic.Add(w += dw);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  return magic.ToArray();

Â  Â  Â  Â  }

Â  Â  Â  Â  // 1*0 = number of 1s

Â  Â  Â  Â  // eg. 4 = 11110

Â  Â  Â  Â  //Â  Â  Â 1 = 10

Â  Â  Â  Â  //Â  Â  Â 0 = 0

Â  Â  Â  Â  public int ReadUnary()

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  int x = 0;

Â  Â  Â  Â  Â  Â  while (ReadBit()) x++;

Â  Â  Â  Â  Â  Â  return x;

Â  Â  Â  Â  }

Â  Â  Â  Â  // read w-bits => interpret as w-bit intÂ 

Â  Â  Â  Â  // MSB first

Â  Â  Â  Â  public int ReadBinary(int w)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  int x = 0;

Â  Â  Â  Â  Â  Â  for (int b = 1 << (w - 1); b > 0; b >>= 1)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  if (ReadBit())

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x |= b;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }Â Â 

Â  Â  Â  Â  Â  Â  return x;

Â  Â  Â  Â  }

Â  Â  Â  Â  // read magic-encoded int

Â  Â  Â  Â  public int ReadUnsigned()

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  int a = 0;

Â  Â  Â  Â  Â  Â  int w;

Â  Â  Â  Â  Â  Â  int n;

Â  Â  Â  Â  Â  Â  for (int i = 0; ; )

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  w = Magic[i];

Â  Â  Â  Â  Â  Â  Â  Â  n = 1 << w;

Â  Â  Â  Â  Â  Â  Â  Â  if (++i == Magic.Length || !ReadBit()) break;

Â  Â  Â  Â  Â  Â  Â  Â  a += n;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  return a + ReadBinary(w);

Â  Â  Â  Â  }

Â  Â  Â  Â  public int[] ReadSortedAscending(int n) => ReadArray(n, (prev, x) => prev + 1 + x);

Â  Â  Â  Â  public int[] ReadUnsortedDeltas(int n) => ReadArray(n, (prev, x) => prev + AsSigned(x));

Â  Â  Â  Â  public int[] ReadArray(int count, Func<int,int,int> fn)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  int[] v = new int[count];

Â  Â  Â  Â  Â  Â  if (count > 0)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  int prev = -1;

Â  Â  Â  Â  Â  Â  Â  Â  for (int i = 0; i < count; i++)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  v[i] = prev = fn(prev, ReadUnsigned());

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  return v;

Â  Â  Â  Â  }

Â  Â  Â  Â  public List<int> ReadUnique()

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  List<int> ret = new(ReadSortedAscending(ReadUnsigned()));

Â  Â  Â  Â  Â  Â  int n = ReadUnsigned();

Â  Â  Â  Â  Â  Â  int[] vX = ReadSortedAscending(n);

Â  Â  Â  Â  Â  Â  int[] vS = ReadUnsortedDeltas(n);

Â  Â  Â  Â  Â  Â  for (int i = 0; i < n; i++)

Â  Â  Â  Â  Â  Â  {Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  for (int x = vX[i], e = x + vS[i]; x < e; x++)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ret.Add(x);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  return ret;

Â  Â  Â  Â  }

Â  Â  Â  Â  public List<int[]> ReadTree()

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  List<int[]> ret = new();

Â  Â  Â  Â  Â  Â  ReadTree(ret, new());

Â  Â  Â  Â  Â  Â  return ret;

Â  Â  Â  Â  }

Â  Â  Â  Â  private void ReadTree(List<int[]> ret, List<int> path)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  int i = path.Count;

Â  Â  Â  Â  Â  Â  path.Add(0);

Â  Â  Â  Â  Â  Â  foreach (int x in ReadSortedAscending(ReadUnsigned()))

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  path[i] = x;

Â  Â  Â  Â  Â  Â  Â  Â  ret.Add(path.ToArray());

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  foreach (int x in ReadSortedAscending(ReadUnsigned()))

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  path[i] = x;

Â  Â  Â  Â  Â  Â  Â  Â  ReadTree(ret, path);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  path.RemoveAt(i);

Â  Â  Â  Â  }

Â  Â  Â  Â  // convenience

Â  Â  Â  Â  public string ReadString() => ReadUnsortedDeltas(ReadUnsigned()).Implode();

Â  Â  Â  Â  public int[] ReadSortedUnique()

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  int[] v = ReadUnique().ToArray();

Â  Â  Â  Â  Â  Â  Array.Sort(v);

Â  Â  Â  Â  Â  Â  return v;

Â  Â  Â  Â  }

Â  Â  }



}

```

```cs [ENSNormalize.cs/ENSNormalize/InvalidLabelException.cs]

ï»¿using System;



namespace ADRaffy.ENSNormalize

{

Â  Â  public class InvalidLabelException : Exception

Â  Â  {

Â  Â  Â  Â  public readonly string Label;

Â  Â  Â  Â  public NormException Error { get => (NormException)InnerException!; }

Â  Â  Â  Â  public InvalidLabelException(string label, string message, NormException inner) : base(message, inner)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Label = label;

Â  Â  Â  Â  }

Â  Â  }

}

```

```cs [ENSNormalize.cs/ENSNormalize/EmojiSequence.cs]

ï»¿using System.Linq;

using System.Collections.ObjectModel;



namespace ADRaffy.ENSNormalize

{

Â  Â  public class EmojiSequence

Â  Â  {

Â  Â  Â  Â  public readonly string Form;

Â  Â  Â  Â  public readonly ReadOnlyCollection<int> Beautified;

Â  Â  Â  Â  public readonly ReadOnlyCollection<int> Normalized;

Â  Â  Â  Â  public bool IsMangled { get => Beautified != Normalized; }

Â  Â  Â  Â  public bool HasZWJ { get => Normalized.Contains(0x200D); }

Â  Â  Â  Â  internal EmojiSequence(int[] cps)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Beautified = new(cps);

Â  Â  Â  Â  Â  Â  Form = cps.Implode();

Â  Â  Â  Â  Â  Â  int[] norm = cps.Where(cp => cp != 0xFE0F).ToArray();

Â  Â  Â  Â  Â  Â  Normalized = norm.Length < cps.Length ? new(norm) : Beautified;

Â  Â  Â  Â  }

Â  Â  Â  Â  public override string ToString()Â 

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  return $"Emoji[{Beautified.ToHexSequence()}]";

Â  Â  Â  Â  }



Â  Â  }

}

```

```cs [ENSNormalize.cs/ENSNormalize/Blobs.cs]

// generated: 2024-09-14T19:28:59.655Z

namespace ADRaffy.ENSNormalize

{

Â  Â  internal static class Blobs

Â  Â  {

Â  Â  Â  Â  // created: 2024-09-13T06:42:44.238Z

Â  Â  Â  Â  // unicode: 16.0.0 (2024-09-10T20:47:54.200Z)

Â  Â  Â  Â  // cldr: 45 (2024-04-19T05:36:55.332Z)

Â  Â  Â  Â  // hash: 4b3c5210a328d7097500b413bf075ec210bbac045cd804deae5d1ed771304825

Â  Â  Â  Â  // magic: 1 3 7 13 16 17 18 19

Â  Â  Â  Â  internal static readonly uint[] ENSIP15 = new uint[] { // 30391 bytes

Â  Â  Â  Â  Â  Â  0xD2AEFDED,0x421F100F,0x7E74243F,0x71EBC2F3,0xAF9B03D7,0xDA00E116,0x4172ECC0,0x32D4E8F5,0x9DC6ADC7,0x1DA2F5E6,

Â  Â  Â  Â  Â  Â  0xA4397D34,0x85FE2457,0xCD239A03,0xD066194A,0xB7B81C21,0x00E566FB,0xE3F5B5F1,0xD7C54B8E,0x07AE9087,0x97AB51BE,

Â  Â  Â  Â  Â  Â  0xF12FFA87,0xD8611B6A,0x1DF37283,0xF007AD65,0x301DA00E,0xC232C83C,0x350F3338,0xCEBB3CE6,0xBB5AD4BD,0x16E6B34E,

Â  Â  Â  Â  Â  Â  0xEBB0AE03,0xE8007A9E,0xE1B1DF00,0x1FC00FC9,0x5C783E94,0xCD3C002E,0x3B46988F,0x7B407120,0x7B068DE5,0x54C74BF4,

Â  Â  Â  Â  Â  Â  0x5B1C680E,0xF8B65A39,0x0203B201,0x06F440E1,0x8003A061,0x600FD447,0x62C871AE,0xCB8C83A0,0x587ED15C,0x9EA00721,

Â  Â  Â  Â  Â  Â  0x4720D814,0x1CA60E03,0x76E43FB0,0xF040E3E0,0x19C161A4,0x1AB4000E,0xAE7ADEE6,0x938F5209,0x70C53CCE,0x0621C4CB,

Â  Â  Â  Â  Â  Â  0x16A6651B,0xA6651987,0x6C1AC716,0x198716A6,0x62D4CCB6,0x1AC5681F,0xC6B99EA7,0x651A0601,0x18071AA6,0x4219E468,

Â  Â  Â  Â  Â  Â  0xB28EC38D,0xF67E1B70,0x721A3621,0x18A7B1D1,0x00780CAA,0x531A827C,0x43D86C1F,0x46A9871C,0xD9D4751D,0x00FED997,

Â  Â  Â  Â  Â  Â  0x7407A0C2,0xD1601E66,0x669CA745,0x9AE6D1A8,0x1C6100F9,0xA1DF00E3,0x0729D3D0,0x6FF60ECC,0xD3A554F2,0xA81F8BF8,

Â  Â  Â  Â  Â  Â  0x09CA6958,0xBA6D1EE7,0x631EB629,0x99526992,0x6E301FA8,0xD472318F,0x00C7D323,0x00F09962,0xB996C1D1,0x362FB40E,

Â  Â  Â  Â  Â  Â  0x4F3B8CFF,0x9380C33B,0xC8CE3A2D,0x74314C33,0xC500F95A,0x16843368,0xDE7D8987,0x4B50D241,0xA5C070EE,0x0EE4B98D,

Â  Â  Â  Â  Â  Â  0x39081F9B,0x396259E0,0x99C6D200,0xDD3D0EBC,0xFCB6AC41,0x100EFB30,0xC0E1C816,0xF65340EA,0x460F7E2B,0xACF8A4E6,

Â  Â  Â  Â  Â  Â  0x5E66D387,0x5D10D1ED,0x60F498DC,0x8FB81D55,0x38F60075,0xE6AB0CF3,0x88752B23,0x1FF80E1A,0x7AE83C64,0xFA90FDC0,

Â  Â  Â  Â  Â  Â  0x33BCFF96,0x2038D01E,0x0CD2D0BE,0xD688D431,0xB1A8C934,0x8A60300F,0xC4328D03,0xDD0CA38C,0x90C1EB43,0xD00C3072,

Â  Â  Â  Â  Â  Â  0x03D6E5B1,0xAA421896,0x0D5A1221,0xA8071491,0x06928621,0xD884201C,0x21CC6B19,0x547518A6,0x41B07969,0xD34CCA0D,

Â  Â  Â  Â  Â  Â  0x0F03143B,0x729A4E30,0x1C0741B8,0xFA340C2A,0x30EE6358,0x4C338CF3,0x8340D359,0x0C68F252,0x43E0C039,0x4A406C31,

Â  Â  Â  Â  Â  Â  0x91C0681E,0x349A3A18,0x19069C85,0x4F86E1D8,0xCC3A0C83,0x219861B0,0x1A0C50E3,0x01C1E807,0x8F21EB62,0x034F8696,

Â  Â  Â  Â  Â  Â  0x8313528F,0xA00714D7,0x00C83CE4,0xA0D23283,0x6201D683,0xE201C62E,0xB4F86550,0xE591DADA,0x24331E26,0xE5F5EBB3,

Â  Â  Â  Â  Â  Â  0xA8741A87,0x99497B21,0x25070038,0x594756D2,0x78903853,0xFC00FE20,0x9B070C01,0x26C18672,0x31A8799B,0xCA6C19E7,

Â  Â  Â  Â  Â  Â  0x5BC0C219,0xB4CD340C,0xFD3286BB,0x37CE5342,0xEEBB0AE0,0x380C33A9,0x01C601F7,0x37963D06,0xFD9901E0,0xD0CDE80E,

Â  Â  Â  Â  Â  Â  0x5500E91D,0xCB3007CD,0xF9A7F045,0x0768D311,0xB6800E7E,0x6C1CA749,0x212603AA,0x73B2BA3D,0x37D94769,0xD900FC59,

Â  Â  Â  Â  Â  Â  0x70F56B8A,0x03B57900,0xB0E5BAC0,0xD8F81E2B,0x07B6BED8,0xA401D253,0x1EDA0E75,0x61681870,0xEC39E20F,0xA307ED15,

Â  Â  Â  Â  Â  Â  0x03ECD9E3,0xFF894F50,0xB721D080,0x8F836043,0x070CC8BC,0x6C1EE650,0x4826B9AD,0x6B3A4E3D,0x85D07B9A,0x95681C86,

Â  Â  Â  Â  Â  Â  0x359946D1,0x9B06B1C7,0xEC308F35,0x740E433C,0x01C6B140,0xE87F5A06,0x74DB4655,0x1A3621F5,0x5AE5D172,0x94A4A58D,

Â  Â  Â  Â  Â  Â  0x8B681A52,0x7908E254,0xC90F2188,0x751AA61E,0x1AE751D4,0x01E300FC,0x01F83284,0x1A06D9E5,0xD4D000F8,0xC39E8FF3,

Â  Â  Â  Â  Â  Â  0x7EA6654C,0xBA69EE81,0x803AA81D,0xD368FAB2,0xAA379D4D,0x2654A771,0xC7FFEC7E,0xF0996200,0x96C1D100,0x2FB40EB9,

Â  Â  Â  Â  Â  Â  0x078CFF36,0x701867A8,0x38CF3CCA,0x87A98979,0x201CBB58,0x0986691A,0x2F6302FA,0x301B37D3,0x61ED301C,0xDC0665A4,

Â  Â  Â  Â  Â  Â  0xC074F36C,0x3F701FB7,0x99C79700,0x275D0EBC,0x6C20F81B,0x1AD87E5D,0x2C201C76,0xA0636076,0x3D84AFA9,0xC0389918,

Â  Â  Â  Â  Â  Â  0x0F598E49,0xE09A3CAF,0x8751B407,0xFF80E1A8,0xAE83C641,0xA90FDC07,0x1B52396F,0xD032F26A,0x180DC3C0,0xC0601F62,

Â  Â  Â  Â  Â  Â  0x811C4314,0x0229BB81,0xC5A64A41,0x20442048,0x8842D0C5,0x116D129D,0x43C1B060,0x0C4210AA,0x01840308,0x4201C183,

Â  Â  Â  Â  Â  Â  0x14E4301A,0x01806183,0x19503083,0x0956C434,0x4D268942,0x0641A721,0x10F8661E,0xC0654862,0x340EBA41,0x50C40320,

Â  Â  Â  Â  Â  Â  0x92A5EA07,0x60340C22,0x4C0DA18B,0x98D5838A,0x0F4350F2,0x772368E0,0x43A01D5A,0x60D86A19,0x300E394A,0xA4BD90D4,

Â  Â  Â  Â  Â  Â  0x75801C4C,0x70A6B28F,0xFC40F120,0x5803F801,0x20E26D83,0x07999C7D,0x4DB064DB,0x41B3641C,0x6D835AFA,0x6CD80792,

Â  Â  Â  Â  Â  Â  0x1A45BE90,0xCEB4C0F4,0xEBDCE030,0xE18FA5B6,0x203E401C,0x94669073,0xD0075C03,0xFBD0BB17,0x3EC67F34,0x64007B00,

Â  Â  Â  Â  Â  Â  0x980E81D5,0x01D5360E,0x7657479B,0x8F49C4CE,0xC83F8CFA,0x1705DC01,0x072E07EA,0x1285ABE9,0x2EC38A76,0xF301C3DE,

Â  Â  Â  Â  Â  Â  0x0C07A003,0x710D7A0F,0x21C96900,0x7D883F16,0x47A963C0,0x5C7E6A0C,0x74340F27,0xE36E43A5,0x7C1FDC1C,0x386645E4,

Â  Â  Â  Â  Â  Â  0x60F73280,0x4827F007,0x6B3A4E3D,0x83D07B9A,0x765C07EB,0xE831B03D,0xBA2E83A6,0x00F1AB5C,0x79DC81C5,0xA61D520E,

Â  Â  Â  Â  Â  Â  0x40759839,0x2C03E579,0xC17BCF5B,0x53FE30E9,0x70D8399D,0xC79527E0,0xFD8C7B41,0x96C1D100,0x2FB40EB9,0x078CDF3E,

Â  Â  Â  Â  Â  Â  0xE299E66A,0xCA01FB80,0xCBE827C5,0x07960394,0x1CD80E9C,0x79E038F8,0xD3A0E7D8,0x278A5423,0x583D6785,0xEAE094F3,

Â  Â  Â  Â  Â  Â  0xF01C3510,0xD078C83F,0x21FB80F5,0x1A472DF5,0x26A1947A,0x3C0D032F,0x01F680DC,0xC4314C06,0x1090F211,0x94922182,

Â  Â  Â  Â  Â  Â  0xD49A0671,0x420340E0,0x68948090,0x360C390A,0x03020C70,0x100088C4,0x807D4842,0x25EC86A1,0xC400E265,0x5C13F1FB,

Â  Â  Â  Â  Â  Â  0x00E019A0,0x10B628D7,0x0F341873,0xB8644072,0x4318D3D1,0xC401E40F,0x0F033803,0x03D0D63D,0x9DAA501C,0x7FDE06C1,

Â  Â  Â  Â  Â  Â  0xF00661BF,0x07B8DC80,0x8D501780,0xB0C71B39,0x83ED1C0D,0x58EA8BA8,0xD2F38107,0x01C03AAA,0x55555530,0x35555555,

Â  Â  Â  Â  Â  Â  0x35625AA8,0x48751AE7,0x9F355555,0x90C83E54,0x3C8D8ACF,0x3AAA2EF5,0x5AD6C0F3,0x7BCEC0EB,0x41886580,0x0698DA74,

Â  Â  Â  Â  Â  Â  0x0EE00748,0x02754D22,0x55555551,0x55555555,0x55555555,0xE9DA66D5,0x8792E940,0xB8395E01,0x7AB87B03,0xA1007C80,

Â  Â  Â  Â  Â  Â  0x365AFE4D,0x70003B86,0xC184A643,0x505B492D,0xBDE461CB,0xE06CDF66,0xD221CAC1,0x689F061C,0x40D038D4,0xB20E3207,

Â  Â  Â  Â  Â  Â  0xC76E3394,0x271D077F,0x73589A1F,0x1B737DE0,0xC6D6C52C,0xE690F419,0x0FFAC7D2,0x3DA81EB9,0x44E53760,0x1C47C807,

Â  Â  Â  Â  Â  Â  0x81A7D175,0x0F4168FA,0xE69A0D44,0xF93A403E,0x358F63D4,0xC707C8C0,0x3A0038A6,0xCE63A8D8,0x35AD5A38,0xE63878A7,

Â  Â  Â  Â  Â  Â  0xD601E900,0xC7AD0701,0x9E880F0C,0xA8AC7D1A,0x58FA0F8F,0x96F3D2FE,0xB3A90698,0x4A4756E7,0x1E981EBD,0xA7E9FA7E,

Â  Â  Â  Â  Â  Â  0x0BCC7E9F,0xD35C47E5,0xE1807588,0xD539A0E2,0x3A180654,0xE9AF83E6,0x27ACEA80,0xE876DF51,0x348E9334,0x0651D924,

Â  Â  Â  Â  Â  Â  0x26A1D58D,0xC25A736A,0x485BD354,0x822DA0D9,0x0FD72C03,0x5EC41D0C,0x8769F06D,0x38826C9C,0x83A781C7,0xB5EE83BE,

Â  Â  Â  Â  Â  Â  0x65F601D0,0xA0719CC6,0xB407A834,0xC68F480E,0x0A4FD31C,0x757CD319,0x5F6836F2,0x68A1FA63,0x3FB88C6B,0xD5BEB069,

Â  Â  Â  Â  Â  Â  0x2609CDF6,0xCC10E90D,0x80D9F3C1,0x751AC7C9,0x1FC671C6,0x9525406C,0x8C8320EC,0x791B8698,0x1C96B1B2,0xC3DE70EC,

Â  Â  Â  Â  Â  Â  0xA7787AAF,0x42108421,0x10842108,0x84210842,0xE1084210,0x16386800,0x84369471,0x21084210,0x08421084,0x42108429,

Â  Â  Â  Â  Â  Â  0xD084210A,0x0DA94A52,0xF36A5034,0x6A4621A4,0x5251A869,0x887D183A,0x0E05A521,0x661084ED,0x10FA6108,0x84210842,

Â  Â  Â  Â  Â  Â  0x21084210,0x08421484,0xF9308421,0x160C2340,0xA4F380FB,0xEB4A5294,0xCE86920F,0x0A481D23,0x42108421,0xB0A42108,

Â  Â  Â  Â  Â  Â  0x84210872,0x21084210,0x08421084,0x42108421,0x10842108,0xA5294BB6,0x294A5294,0x4A5294A5,0x5294A529,0xA1B4694A,

Â  Â  Â  Â  Â  Â  0x0D294A53,0x034B06D2,0x4B58340D,0x5294BC69,0x94A5294A,0x856B40D2,0x21084210,0x08421084,0x42108421,0x10842108,

Â  Â  Â  Â  Â  Â  0x84210842,0x48384210,0x21684215,0xD87AE85C,0xC43D0375,0x084210FB,0x50D3BEF7,0x8DD83025,0x084210A0,0x42108421,

Â  Â  Â  Â  Â  Â  0x10842108,0x84210842,0x21084210,0x08424184,0xADFB8425,0xA3699B0F,0x421C0687,0x39842198,0x96719843,0x58E98330,

Â  Â  Â  Â  Â  Â  0x120C003B,0xE0610842,0x21084210,0x1002D52C,0x0214A428,0xE50C760C,0x07C8F218,0x87780EAC,0x9D241844,0x9C2108E2,

Â  Â  Â  Â  Â  Â  0x32463C92,0x1C3C233C,0x4F34478C,0xD211C168,0x218783B0,0xD86908EA,0xBB10C3C1,0x84210B42,0x2C584210,0x08421084,

Â  Â  Â  Â  Â  Â  0x42108421,0x10842108,0x4C210842,0x2108421E,0x08421084,0x42108421,0x10842108,0x763E400E,0x084210B7,0x42108421,

Â  Â  Â  Â  Â  Â  0x10842108,0x84210842,0x21084210,0x08421084,0x42108421,0x95CC2108,0xA5294A52,0x294A5294,0x4A5294A5,0x5294A529,

Â  Â  Â  Â  Â  Â  0x94A5294A,0xA5294A52,0x294A5294,0x488694A5,0x7A501C03,0x1C4F723A,0x2F3505EB,0x5310D236,0x78C8372D,0x58091D53,

Â  Â  Â  Â  Â  Â  0xC649A068,0x0983609B,0x73503986,0x01BA6980,0x9A621A66,0x6F58A611,0xEA8E69AC,0x0C3B001D,0xC360C937,0xEE00758C,

Â  Â  Â  Â  Â  Â  0x076AC330,0x671926CC,0x21CA8DA2,0x1B86A1A9,0x60DE80E1,0x18301C03,0x76C1846A,0x03AC6318,0x56004768,0xDF28E09A,

Â  Â  Â  Â  Â  Â  0x46700700,0x4582611B,0x33183806,0xCDC76CD9,0xAB649AF6,0x641886C9,0x3B6601BD,0x65E8727E,0x60DA01B8,0x1803A563,

Â  Â  Â  Â  Â  Â  0x3806C907,0x5AD43384,0xD8310C83,0x0E419A01,0xC6B20DF2,0x541CAB18,0x438C6418,0x069C0720,0x8074703A,0x5643A564,

Â  Â  Â  Â  Â  Â  0x3F0E0207,0x3AC5B34D,0xD0330DFB,0x86E0071C,0xC835443A,0x368C4310,0xD2803B4A,0x304E3A06,0xE18261D3,0x33583926,

Â  Â  Â  Â  Â  Â  0x959001C2,0x328C9F0E,0x1C0B3CCA,0x9F6E1904,0x1CB36683,0x806098C4,0xCE077483,0x340C380E,0x21A1B1C0,0xA81DD40E,

Â  Â  Â  Â  Â  Â  0x901CAB2A,0x720DA118,0x81AE6B80,0xB2303A46,0x52703B4E,0xB76839C6,0x800720DA,0xCD432A86,0x50E62874,0x4D0B50DA,

Â  Â  Â  Â  Â  Â  0x6D50D834,0x00C636B1,0xCA334C23,0xD28CDB60,0x0973079E,0x1C3FF8CF,0x7A303898,0x981C2A60,0x4CC0E10C,0x03842108,

Â  Â  Â  Â  Â  Â  0x3086E3D5,0x8421A4C5,0xE1084210,0x21084A00,0x08421084,0x42108421,0x601C2108,0x42B6070F,0x74B4034B,0x47C0FEE0,

Â  Â  Â  Â  Â  Â  0x5219F03A,0x10A52D0A,0xA86D2842,0x30380641,0x87540E10,0x43284CB0,0x79543484,0xE2072C1A,0xC45F780E,0xCF3E88BA,

Â  Â  Â  Â  Â  Â  0xE4768F9C,0x3AEF92D1,0xC3B1D5E9,0xCF0C17E6,0x385C5C14,0xC3A0F31B,0x0A724B5E,0x42948429,0x0F84210A,0xB289D2AA,

Â  Â  Â  Â  Â  Â  0xCA277023,0x811DC08E,0xA276513B,0x89DC08EC,0x477023B2,0x1DC08EE0,0xFA33BB81,0xC40F5616,0x88BEF01D,0x28F80175,

Â  Â  Â  Â  Â  Â  0x63C931C5,0x4F134762,0x90703DF2,0x8FC73C4B,0x963EC64F,0x79B2A789,0xC008E817,0x7C07F6C1,0x1FD728F0,0x1E43DC8E,

Â  Â  Â  Â  Â  Â  0x8FBFA07B,0xF6D1FC66,0x687F689D,0xE8D64FBF,0x011F3EE9,0x8F66487A,0xEA39E1B5,0xC87B091E,0x7C8B0F50,0xD3EF399E,

Â  Â  Â  Â  Â  Â  0x703ED65C,0xF56E817A,0xE8F0E687,0xD0369F39,0x0D3ED253,0x532C18F6,0x94A4294A,0xA5294A52,0x294A4A94,0x29421084,

Â  Â  Â  Â  Â  Â  0x421094A5,0x10852948,0x84214842,0x42198587,0x10842108,0x84210842,0x21084210,0x08421084,0x42108421,0x10842108,

Â  Â  Â  Â  Â  Â  0x84210842,0x21084210,0x08421084,0x42108421,0x10842108,0x84210842,0xA8F140B7,0xD13D1F70,0x6D87CF61,0x4F9A08FC,

Â  Â  Â  Â  Â  Â  0x13B73CED,0x53F40D9E,0x901A7B70,0x2C2E3EC7,0x8B9D083D,0x0EAE6775,0x3A7C1CD9,0xE268F257,0x7B1C568F,0x00F01A3A,

Â  Â  Â  Â  Â  Â  0x5C2E6E58,0xCA6E7908,0x5C1E7527,0x0792D9CA,0x35E0F59E,0x03E2219E,0x5CD079A9,0x4D1E4AC7,0x394DC3F5,0xF098F203,

Â  Â  Â  Â  Â  Â  0xC19C202F,0xB0F59539,0xE8119EB1,0x23838DE1,0x74E8580F,0x9387D9CA,0x4EAB1724,0x3A201C07,0xE7F17397,0x9891C3F8,

Â  Â  Â  Â  Â  Â  0x5078A547,0xE9C778E7,0xD737BB89,0xF8D81E6C,0x3D3E3613,0x8EE8B0F0,0x3DAEDD37,0xCDC0F623,0xED3C1F2E,0xB75163E6,

Â  Â  Â  Â  Â  Â  0x1C838E36,0x76DDB83C,0xE7C1EC30,0xC7F3333D,0x9678F175,0x680C7D47,0xEF4EBAC7,0xABBF103C,0xFD618FFA,0xB423CEEC,

Â  Â  Â  Â  Â  Â  0xB7FF1A7B,0x3CCF8E96,0x12C38330,0x51FC848F,0xDBC63DF3,0xA80F52FB,0x9CBCE1F6,0x53707DC3,0x44F9898F,0xB9E9C3CD,

Â  Â  Â  Â  Â  Â  0xE3867605,0x723EAAE1,0x7A3A47A3,0x8BE1F229,0x07FFDC3C,0x8E68F00C,0x601CDC8F,0x0F67307B,0xD854E842,0x0EB39E05,

Â  Â  Â  Â  Â  Â  0x10F2974F,0x538DC9C2,0x2E296716,0x7B9C5C5F,0x1E273E18,0xF26C2F8E,0xF81FB7DC,0x478D89CC,0x1504F32E,0x501DD68F,

Â  Â  Â  Â  Â  Â  0x2575523B,0xD1D0F0E2,0xC71F93B7,0xDCD88EA7,0x7A7CB939,0xC8E8E0F5,0x103EDC33,0xA1EAB877,0xAB783CC7,0x9D8F62C3,

Â  Â  Â  Â  Â  Â  0xB1DCE0FD,0x0F3BF3A0,0xF822ED20,0x5F3F48A3,0x30E95270,0x07AE11CE,0xE4E07456,0xB981C6EA,0xE274AC07,0x41D600EB,

Â  Â  Â  Â  Â  Â  0xFF10E7B4,0x7C1E7B98,0x27BF49D0,0xA840FC4D,0xCD5DE08F,0x8971803B,0x79C484EA,0x777A13B8,0xDDB9AEAE,0xFE8A78CD,

Â  Â  Â  Â  Â  Â  0x99E86F8F,0xAD483FF5,0x90A76603,0x529CD10E,0x34768438,0x43C0C4EB,0xEAB67A43,0x49E3E00F,0xF81B3D40,0x100F4A9B,

Â  Â  Â  Â  Â  Â  0x3DBE11E3,0x1743E6BE,0xA9AE7167,0x6797523D,0xE8587F41,0xA5A5D102,0xA8873783,0xED9C3F8E,0xA9774C38,0x58D112E4,

Â  Â  Â  Â  Â  Â  0x164E6517,0x87EEB33D,0xEA50F366,0x51CED61F,0xF5C407B0,0xED4E2600,0xB27B011D,0x1EF7A7A1,0xFAD9C378,0xB4870403,

Â  Â  Â  Â  Â  Â  0x1E1E632E,0x4F2F287E,0x1849F4A3,0xB5DB413D,0x5F1CB46F,0x8F3EC878,0x5501FD08,0x0C7C919C,0x6F956721,0x7CF8DC7B,

Â  Â  Â  Â  Â  Â  0xB2B7A72C,0xA91DB84F,0x20F55DBA,0xDC111F0A,0x5A23B6B1,0xD4B20D73,0x287906C3,0xCE5D47A5,0x3A149C10,0xE01076F9,

Â  Â  Â  Â  Â  Â  0xCB08D6BC,0x49BB889D,0xD9E29A78,0x38BC1F86,0x6EC87420,0x470A039A,0x1C480EE0,0x764C3AE0,0xDDD8EC40,0x0E87C750,

Â  Â  Â  Â  Â  Â  0x80742DE2,0x81C318EF,0x872B039C,0x1D6A4EF5,0x761839E8,0xC3C0EE04,0x2A139361,0x71861607,0x590681B0,0xDAD81C2D,

Â  Â  Â  Â  Â  Â  0xE1CBE0E3,0x3B3609BD,0xE72071B8,0x3881D8B0,0xB89D330E,0x48741038,0x5543B366,0x3A591C1B,0xE66675E0,0x4F76DD60,

Â  Â  Â  Â  Â  Â  0x8947F01E,0xC2430FC5,0x2C79AE27,0x61FC00E5,0xDB00C3D1,0xE759021C,0xD001CF48,0x1C400EFD,0x71403B31,0x83B46320,

Â  Â  Â  Â  Â  Â  0x8E810749,0x20720D4D,0x3383BF6D,0x000E8C07,0xF15A081E,0x875ED640,0x6D900ED2,0x60EFD074,0xB69E81D3,0x3D9EF1CD,

Â  Â  Â  Â  Â  Â  0xAA1C850E,0xC900F51A,0x6843BB41,0x694E2FA7,0x603AB01E,0x40E40873,0xB90706C1,0x319981D2,0x344038A6,0xC3B8A1E4,

Â  Â  Â  Â  Â  Â  0x0E530702,0x3B641CDC,0xEA087150,0x8431C820,0xA2C70D03,0x001D830E,0xC4E0ED18,0x946FCB16,0x77003F47,0xD390E300,

Â  Â  Â  Â  Â  Â  0x5783B5E1,0x320E4707,0x203A0F1C,0x40E74072,0xADC37CC0,0x44E49476,0x6961F7D4,0x3F196BC0,0xD84F4FE6,0x3813F1CC,

Â  Â  Â  Â  Â  Â  0x23C84AED,0x9791F9F6,0x83E6007A,0x09663B34,0x4C308483,0x1401903A,0x02030120,0x02030003,0x980900CB,0x40281013,

Â  Â  Â  Â  Â  Â  0x2A420600,0x933031A3,0x0D010301,0x0410C088,0x30020060,0x81058106,0x614490A9,0x00831A40,0xE0398207,0x87919C03,

Â  Â  Â  Â  Â  Â  0xB4FC1935,0x08102043,0x80102004,0x10020040,0x20040080,0x02040810,0x04008010,0x08010020,0x01060040,0x00801002,

Â  Â  Â  Â  Â  Â  0x01002004,0x70020408,0x1288707A,0x84210842,0x210B1610,0x08421084,0x42108421,0x10842108,0xA7530842,0x21084210,

Â  Â  Â  Â  Â  Â  0x08421084,0x42108421,0xF0842108,0x3F063C04,0x4A529E80,0xEF34A55B,0x53280716,0x94A4294A,0xA5294A52,0x294A4A94,

Â  Â  Â  Â  Â  Â  0x29421084,0x421094A5,0x10852948,0x00ED4842,0x95787865,0x81C4C0E1,0xE15303D1,0x070864C0,0x21084266,0x371EA81C,

Â  Â  Â  Â  Â  Â  0x0D262984,0x42108421,0x42500708,0x10842108,0x84210842,0xE1084210,0x21876201,0x7EF87E06,0x08424507,0x1082929F,

Â  Â  Â  Â  Â  Â  0x84210842,0x21084210,0x08421084,0x42108421,0x10842108,0x1C210842,0x84210888,0x21084210,0x08421084,0x42108421,

Â  Â  Â  Â  Â  Â  0x10842108,0x1C210842,0x84210BA8,0x21084210,0x08421085,0x42108421,0x10842908,0xACE14842,0x8421085F,0x21084210,

Â  Â  Â  Â  Â  Â  0x08421084,0x42108421,0x10842108,0x84210842,0x21084210,0x08421084,0x08429C07,0x42108421,0x10842108,0x5C210842,

Â  Â  Â  Â  Â  Â  0x842109BD,0x21084210,0x08421084,0x42108421,0x10842108,0x08F28BC2,0x42108421,0x10842108,0x84210842,0x21084210,

Â  Â  Â  Â  Â  Â  0xB7C21084,0x108431BB,0x84210842,0x21084210,0x08421084,0x0C801C21,0x42108421,0x10858B08,0x84210842,0x21084210,

Â  Â  Â  Â  Â  Â  0x08421084,0x43C98421,0x10842108,0x84210842,0x21084210,0xE4C21084,0x42108421,0x10842108,0x84210842,0x61084210,

Â  Â  Â  Â  Â  Â  0x084210F2,0x42108521,0x10842108,0x84210842,0x210843C9,0x08421084,0x42108421,0x10842108,0x8421E4C2,0x21084210,

Â  Â  Â  Â  Â  Â  0x08421084,0x42108421,0x14F26108,0x8425094A,0x21084290,0x08793084,0x4210A521,0x10852108,0x84210842,0x21087930,

Â  Â  Â  Â  Â  Â  0x08421084,0x42108421,0x10842108,0x843C9842,0x21084210,0x08421084,0x42108421,0x1E4C2108,0x84A10852,0x21084210,

Â  Â  Â  Â  Â  Â  0x08421085,0x42108693,0x10842108,0x84210842,0x21084210,0x0A43C984,0x4210A421,0x10842D48,0x84349842,0x21084210,

Â  Â  Â  Â  Â  Â  0x08421084,0x42108421,0x1E4C2108,0x84210842,0x21084210,0x08421084,0x26108421,0x1084210F,0x84210842,0x21084210,

Â  Â  Â  Â  Â  Â  0x08421084,0x42108793,0x10842108,0x84210842,0x21084210,0x0843C984,0x42108421,0x10842108,0x84210842,0x21E4C210,

Â  Â  Â  Â  Â  Â  0x08421084,0x42108421,0x10842108,0xF2610842,0x21084210,0x08421084,0x42108421,0x30842108,0x84210879,0x21084210,

Â  Â  Â  Â  Â  Â  0x08421084,0x42108421,0x10843C98,0x84210842,0x21084210,0x08421084,0x421E4C21,0x10842108,0x84210842,0x21084210,

Â  Â  Â  Â  Â  Â  0x0F261084,0x42108421,0x10842108,0x84210842,0x93084210,0x08421087,0x42108421,0x10842108,0x84210842,0x210843C9,

Â  Â  Â  Â  Â  Â  0x08421084,0x42108421,0x10842108,0x1093D1C2,0x84210842,0x21084210,0x0987C184,0x26108421,0x1084210D,0x84210842,

Â  Â  Â  Â  Â  Â  0x84484210,0x0F084210,0xC0E1E2FB,0x775C3497,0x084210E4,0x42108421,0xC1842108,0x84210987,0x210D2610,0x08421084,

Â  Â  Â  Â  Â  Â  0x42108421,0x42108448,0xE2FB0F08,0x3497C0E1,0x10E4775C,0x84210842,0x21084210,0x0987C184,0x26108421,0x1084210D,

Â  Â  Â  Â  Â  Â  0x84210842,0x84484210,0x0F084210,0xC0E1E2FB,0x775C3497,0x084210E4,0x42108421,0xC1842108,0x84210987,0x210D2610,

Â  Â  Â  Â  Â  Â  0x08421084,0x42108421,0x42108448,0xE2FB0F08,0x3497C0E1,0x10E4775C,0x84210842,0x21084210,0x0987C184,0x26108421,

Â  Â  Â  Â  Â  Â  0x1084210D,0x84210842,0x84484210,0x0F084210,0xC0E1E2FB,0xF75C3497,0x21086A58,0x18421084,0x4210843C,0x1E0C2108,

Â  Â  Â  Â  Â  Â  0x84210842,0x210F0610,0x08421084,0x42108783,0x1F842108,0x8421128D,0x21084210,0x08421084,0x42108421,0x10842108,

Â  Â  Â  Â  Â  Â  0x47E10842,0x65686D69,0x50FB098A,0x421C0CE3,0xC1A07B18,0xF4611D86,0x69286432,0xB80E94A0,0xD36CC81D,0xC0C3394C,

Â  Â  Â  Â  Â  Â  0x07B18421,0x11D86C1A,0x94321C46,0x6188DAC1,0xD8D30186,0x4611D503,0x76B0701C,0x6640EDC0,0xA1CA669B,0x853819C6,

Â  Â  Â  Â  Â  Â  0x6C1A07B1,0x1C4611D8,0x52C19432,0x32B43B1A,0x0FB09859,0x2180CE35,0x60D03D8C,0x7A308EC3,0x34943219,0xB6634A50,

Â  Â  Â  Â  Â  Â  0x7D84C532,0x0C0671A8,0x0681EC61,0xD184761B,0xA4A190CB,0x4D3A5281,0x21E8CA3C,0x08421084,0x42108421,0x10842108,

Â  Â  Â  Â  Â  Â  0xF1E10842,0xA2A13CDF,0xA2E7BAB3,0xC3FFA91F,0xF492B806,0xC09E2104,0x07FF15E5,0xE3D57767,0x8303E85A,0xDB72F9BD,

Â  Â  Â  Â  Â  Â  0x3CF781F9,0x3AC7ECB0,0xC1FBBE70,0xF3B13D45,0x950FC713,0x81F386E6,0x3F8507B7,0x78FE33C4,0xCEF7BC22,0xCDDD034F,

Â  Â  Â  Â  Â  Â  0x8F122C7B,0x2EC1FEB5,0x3478B41D,0xECC50F9A,0x67B7B19C,0xD1FBC91E,0xF256A7BF,0x8DAF0E84,0x10E7B0BE,0x84210842,

Â  Â  Â  Â  Â  Â  0xFAFDBCF0,0x39443F10,0x1E7D087E,0x00E11A40,0x59B301C8,0xFA4D200E,0x047FD7D0,0x9490FDD5,0x71B4641F,0xFC0D887E,

Â  Â  Â  Â  Â  Â  0x187EE008,0x10FD0B4B,0xB621FA7B,0xD251C23B,0xFC436CA3,0xA9FA9FD4,0xC3D2392F,0x74587DEC,0xC0372CC3,0x587CE2C3,

Â  Â  Â  Â  Â  Â  0x899A695B,0xAC630986,0x5310D835,0x87E0950C,0xA40FC2CC,0x383187DB,0xBF390FC1,0x03A6721F,0xECA0704D,0xB368E080,

Â  Â  Â  Â  Â  Â  0x6F00756D,0x9B467DAA,0x1AC60983,0x7843946C,0x660F5307,0xE79C041C,0x9159FC84,0x4D0BAD83,0xC0F3C071,0x7E6C0788,

Â  Â  Â  Â  Â  Â  0x50FD9FA8,0x94601CD7,0xEDDB06F1,0x5ED01687,0x571D343F,0xF200EE19,0x6647A481,0x8F23D23A,0x3A1F88DB,0xFDB43F51,

Â  Â  Â  Â  Â  Â  0xB8651827,0x3F03BA1F,0x3907CB74,0xFD747086,0x4A3FB451,0x600E9196,0x88C3FDAD,0xFB4187E4,0x1F9E830F,0x8C79A606,

Â  Â  Â  Â  Â  Â  0x51E10203,0xA46A3F6D,0xEE582665,0x68FF0751,0x18D1F8EC,0x4AF7A8FC,0x25A7EF19,0xDC8B4FD8,0xFC3BE61F,0xA47D5C20,

Â  Â  Â  Â  Â  Â  0xEA1A3CCC,0x8F1ACB1F,0x89C7EBB7,0x268F10E9,0xAC9CD1F4,0x075CD433,0xF01D1EC2,0xECCE8F8C,0x0FDBF587,0x1E03F8EB,

Â  Â  Â  Â  Â  Â  0xC695C52D,0x61C46F9B,0x4DAF1956,0x075ECC35,0x6039E6F0,0xEEEEC3F7,0xEEF23D87,0x39A6E407,0x3EC3F1C0,0xF23D87E1,

Â  Â  Â  Â  Â  Â  0x1F69FA01,0xBE63F593,0x05966099,0x63F4731F,0x87E199E5,0xE70FD34B,0x070583E1,0xEAEB1F96,0x6C7B3363,0x983EF3E1,

Â  Â  Â  Â  Â  Â  0x64A0F2A5,0xE43EF00E,0xFB89A78C,0x40DA9F48,0xC3FD0C3B,0x82C7ED43,0x38D8E3E5,0x61107FA0,0x62EE1F9D,0x0F99DC3F,

Â  Â  Â  Â  Â  Â  0x78341F28,0x6B8FC65C,0x01C700E0,0x3F4F0390,0xB87E6DDC,0xEF9E3E83,0xC3F11BC7,0x1787E82B,0x7C0DE3F6,0x4C2B7DBC,

Â  Â  Â  Â  Â  Â  0x62F87E13,0x87CF2C3D,0x67C3F2AD,0xD28047F6,0x91FB7F0F,0x581E080E,0x0D8B6C59,0x84651B17,0x3F157E1F,0xDA0F25FC,

Â  Â  Â  Â  Â  Â  0xAF04F2EC,0xFD59509F,0x23F51FE1,0xC190F490,0xD5B57F0F,0x1E83F87E,0x3F3A99D0,0xB227FF11,0x1B80CEB7,0xFB3080FD,

Â  Â  Â  Â  Â  Â  0x23FACE01,0x2047E9B0,0x94E08FF0,0x23DE411F,0xEC23F34C,0xE85847EC,0xDA223F04,0x88FCB20E,0x49E31CA8,0x8B493F32,

Â  Â  Â  Â  Â  Â  0x93CF2927,0x8260994A,0x3C000EF1,0x1D27E5A9,0xEB3623F1,0x8FE9AC47,0xB11FBC38,0x57D83F9D,0xFF25B07E,0xE498CA48,

Â  Â  Â  Â  Â  Â  0x004FDC40,0xAC9EE1D0,0x17648FDC,0x47EA9917,0x99607E72,0xE4FE9B27,0xFFEC9EB0,0x609FB401,0x91D23F21,0xC9EDDA77,

Â  Â  Â  Â  Â  Â  0xFC84FF8B,0xFA8991F9,0x996FF323,0x0787991F,0xEDC29EE8,0x6A18CC53,0x0BB91F80,0x91F86707,0x6514FE77,0xFC4D227F,

Â  Â  Â  Â  Â  Â  0x4F2FE7C8,0x0A27F3A9,0xC5BC8FC5,0x54F9BCA7,0x3F0CFAC0,0x147E824A,0xCE153F77,0xCDB40AA7,0xFD354F3E,0x2CDEAE27,

Â  Â  Â  Â  Â  Â  0x7F15713F,0x28FDB9E2,0xF651FE63,0xFC6CA3F7,0x3F30C080,0x400E092A,0xFEF8A8FC,0xA3F60551,0xA887F4F2,0xC8BE8FCA,

Â  Â  Â  Â  Â  Â  0x0070C9A7,0x3E9A69E3,0x13479DCD,0x6B53E3FE,0x39DE27A4,0xEAA10FC4,0xB9EAAB72,0xA1ED3F6E,0xFC7AC701,0x29DF8F92,

Â  Â  Â  Â  Â  Â  0x8FC4B50D,0x0D1FA206,0x001D9BC4,0x2075003A,0x52D540F2,0xFA0ED407,0xA349301E,0x3AA068FD,0xF0A07078,0xD3E4DD27,

Â  Â  Â  Â  Â  Â  0xFCF34A07,0xD1FBD9E8,0x19A3F823,0x723327EC,0x7682C9FB,0x9B27E3B0,0x181433F0,0xDBB4986E,0x968207EC,0x0072503D,

Â  Â  Â  Â  Â  Â  0x9E699F7D,0x8E33F2D1,0x8719ED9A,0xF291133E,0x47EFDBA3,0xCF20EA57,0x0299FC64,0x9FE7F0BC,0xCE073AE6,0x0E8C8A7E,

Â  Â  Â  Â  Â  Â  0x0E29CCF1,0x38681C20,0x0063F308,0xFDBF47E7,0x0EA80744,0x3A18FDD0,0xDFD3B37B,0xD791F3E5,0x7D2AAEFB,0xF00F2397,

Â  Â  Â  Â  Â  Â  0x9AA998FD,0xF914C7E6,0x7ED98601,0x98FC374C,0x70D83ECE,0xA01C25A0,0xDD30E43D,0x1F81798F,0xDDCFCA33,0xFD77B9F0,

Â  Â  Â  Â  Â  Â  0x69FB7B98,0x193CFE96,0x53FA629E,0xDCB1F8D2,0xA7E09075,0xCF60ECDD,0xFAC7EA4B,0xD2274FD4,0x3F7CCE9F,0xE999A236,

Â  Â  Â  Â  Â  Â  0x8FC256C7,0xB5E7DC4D,0x0E8DBCFC,0xDDB34D38,0xE9FD5EF3,0xBF63F5C7,0x81D2E0F1,0x3CBFE787,0xFAB00BCB,0x33F22671,

Â  Â  Â  Â  Â  Â  0x7867F09C,0x0388C1C2,0x09CE3F3E,0x0BFF105F,0x906019EA,0xE05906A1,0x1C402DC7,0x0FA401F5,0x254C4E3F,0x600F81A6,

Â  Â  Â  Â  Â  Â  0x8701D386,0xCA7276A3,0x2190CB81,0x48E2A1B7,0x613C8E43,0x6FA99579,0x03C46A69,0x32000F4C,0x319EB85C,0x197381A6,

Â  Â  Â  Â  Â  Â  0xE43EC6A4,0x1C0DC3D0,0xBE4304EA,0x0EF1F8B2,0x72BECE66,0x0DC1A873,0x46112C06,0x10C53118,0xB3E304E2,0xAEEB90D3,

Â  Â  Â  Â  Â  Â  0xC463DA45,0x421821F5,0x94A6ADC8,0x8D211AD6,0x003A423C,0xCA6D88FA,0x67DF7623,0x906F5867,0x52947FC7,0x0A520423,

Â  Â  Â  Â  Â  Â  0x6018C189,0x184A90A4,0x212C2620,0xD2206052,0x3C09ED00,0x00100002,0xE1301A36,0x11C06960,0xB0721E06,0xA460E434,

Â  Â  Â  Â  Â  Â  0x30198701,0x00067650,0x10000020,0xF94E4F58,0x900007B0,0x00040C08,0x12001024,0x01012004,0x00902106,0x90000200,

Â  Â  Â  Â  Â  Â  0x731A0010,0x0C120026,0x31234C92,0x6ADCF410,0xA2A87A1A,0x98653486,0xCD3E4EAC,0x338E3590,0x9FC308FA,0x00047FFA,

Â  Â  Â  Â  Â  Â  0xEB99F0F0,0x0001E7C3,0x53E1E000,0x69F0F003,0x47948B0E,0x64007EEC,0x4B7610DF,0xF06C204F,0xA0079003,0x7A403886,

Â  Â  Â  Â  Â  Â  0x45A06200,0xF4671A67,0x88670631,0x403E67CD,0xAB7E0076,0x6C1B6719,0x6C1F4608,0xCE900E08,0x1C18D8B2,0xF46B5CA0,

Â  Â  Â  Â  Â  Â  0x421D9027,0x10842108,0x84210F06,0x8E1E46ED,0x06010761,0xC8C0A000,0x50380D23,0x108435D8,0x0C210842,0x2108421E,

Â  Â  Â  Â  Â  Â  0x0F061084,0x29C00DAB,0x05A80E22,0xC0009308,0xC00532A4,0x29364CA4,0x1A4C014E,0x7C980498,0x6626000A,0x49052612,

Â  Â  Â  Â  Â  Â  0x20A4C24C,0x93053889,0x4C014C22,0x024C491C,0xB1364E93,0x3A9314E0,0xD93A4C05,0x793193A4,0x4E4C538A,0x9D262990,

Â  Â  Â  Â  Â  Â  0x2629F26C,0x69C1938E,0xDA620DDC,0xD3DDB86C,0x90202480,0xD8003580,0x959B11F0,0xD9BEEC47,0x5781E9AB,0x409F9ED3,

Â  Â  Â  Â  Â  Â  0x6D6B92C8,0x4350C8B9,0xB4D33F8C,0xCE318F0B,0x3C8C83B4,0xC191654A,0x68711F66,0xCC221907,0xD3A0D835,0x5CD53ACE,

Â  Â  Â  Â  Â  Â  0xEEB10D83,0x0000D7D3,0x40378000,0x61AEC63A,0x0380918B,0x256010A0,0xC2006528,0x000332AB,0xE0000000,0x72E79955,

Â  Â  Â  Â  Â  Â  0xF01C208A,0x98299C99,0xC199043C,0xD374C3E9,0xCA4C14E2,0xB4C03064,0x4CAB424C,0x740364CA,0x2B007568,0x00C64E93,

Â  Â  Â  Â  Â  Â  0x4C14CF4E,0x300C538A,0x4F9364FD,0x829C7131,0xCAC16956,0x060C1800,0xC0000021,0xC00D93F4,0x987433F4,0x0E800674,

Â  Â  Â  Â  Â  Â  0x8C207003,0xB1A7E103,0xCA075CC3,0x9E1CCF0E,0x7B8C325D,0x03D76A58,0x34A53DA0,0xF06D4F50,0xE81A529E,0x93A0C7BC,

Â  Â  Â  Â  Â  Â  0x215C201E,0x499DD40F,0x1E0D160D,0x03A70F20,0x7AAD6E0E,0x06C9C850,0x6ED4638B,0x38C60B09,0x76EB2BF1,0x361AB794,

Â  Â  Â  Â  Â  Â  0x2A0794DB,0xF187800E,0xB9ECED8F,0x438F01D3,0xCEE007AF,0xE93A0F37,0xBAB3EBE1,0xE5B54C13,0x1F0EE300,0x8C03EE52,

Â  Â  Â  Â  Â  Â  0xA01A4430,0x3A9657E4,0xD7B130C4,0x0E600E10,0xF344E6BD,0xF5D0708D,0x348ED62D,0x42E801EA,0x180C03CB,0x36886004,

Â  Â  Â  Â  Â  Â  0xC6E344FC,0xA90D06C1,0x791B0658,0x00D34190,0x483CA603,0xD8360CCD,0xA7958801,0xDD8D755B,0x407A4C07,0x41833A0A,

Â  Â  Â  Â  Â  Â  0xA4E12182,0x10B5B1C7,0x0C201806,0x85680ED1,0x0CF80E11,0x60186734,0xE1468394,0xB701CCE8,0x32503939,0x0C0300D4,

Â  Â  Â  Â  Â  Â  0xEC1AF530,0x639CF611,0x180601A8,0xCCEBEA60,0x0681807D,0x01AC621F,0x9DE231FA,0xB08073D8,0x308C66F7,0x332328FC,

Â  Â  Â  Â  Â  Â  0x3CA3F0C2,0x88F29DA2,0x080001ED,0x2CD009FD,0x01DC04F3,0x1F000200,0xB7A380F7,0x2070471F,0x6A100000,0x10842108,

Â  Â  Â  Â  Â  Â  0xF9F92AC2,0x43EC3CB8,0xA1A64AA7,0x34B4241C,0xB7027A44,0x42108421,0x3C996108,0x80761852,0xEE751D97,0x4DE066EA,

Â  Â  Â  Â  Â  Â  0x18D55791,0x431D218F,0x8701A48E,0x3890C788,0x31F31C86,0x83C863BC,0x3B07D20F,0x790C7486,0x8512C1C8,0x18E90C78,

Â  Â  Â  Â  Â  Â  0x90C78972,0x54C7218E,0x63A431E2,0x34C531C8,0x40942074,0x14201048,0x6000ED0A,0x10842108,0x32700AC2,0xF21A8609,

Â  Â  Â  Â  Â  Â  0x8314C080,0x10843933,0x84290842,0x290A5210,0x184210A4,0xC4350EBF,0x008807B8,0x00000000,0x00900120,0x10204008,

Â  Â  Â  Â  Â  Â  0x11200060,0x04084080,0x00200106,0x00080001,0x00020004,0xCC002801,0x2002400B,0x98001001,0x08004088,0x34000810,

Â  Â  Â  Â  Â  Â  0x4805E600,0x04200900,0x80018102,0x21080104,0x08041810,0x10008004,0x28100080,0x4892F300,0x30230604,0x18D1210A,

Â  Â  Â  Â  Â  Â  0x6060449B,0x89230302,0x00440841,0x02240853,0x18181303,0x20420C49,0x04429802,0x8042A50C,0x06674612,0xFB34E000,

Â  Â  Â  Â  Â  Â  0x300F2378,0x18486D10,0x6C97F1FC,0x48EC3476,0x38F3073D,0x68C00B98,0xD8EC3270,0xC0700015,0x01B80E0D,0xA38DD070,

Â  Â  Â  Â  Â  Â  0x26DC0746,0x1160EC1F,0x0D3BDC40,0xC4009B07,0x0000B6EB,0x2D4700C7,0x3E1E4443,0x1EA7C3C9,0x4651F861,0x47E18466,

Â  Â  Â  Â  Â  Â  0x7D11F919,0x18EC4795,0x84210842,0x4FCF0610,0x27A76180,0x08421C50,0x78308421,0x0F842108,0x3143CCC7,0x8676D8FB,

Â  Â  Â  Â  Â  Â  0x210F0610,0x08421084,0x325ABF83,0xD3578000,0x2F0BCA3E,0x7BACE47A,0x60DEB86C,0xD9BD4FF3,0xBE0D1B8A,0x3F830EE3,

Â  Â  Â  Â  Â  Â  0x00000A7D,0x78E900DE,0x06A1EC61,0xB735457B,0xC92C1F7C,0x41D7B221,0x41A01009,0x04467180,0x875B0002,0x0A02C695,

Â  Â  Â  Â  Â  Â  0x63800100,0x1D231C58,0x2649C431,0x34E6251D,0xA861C0C8,0x8A1A0709,0xF2ABEE36,0x55780001,0x8C9CA5CE,0x61A07D1A,

Â  Â  Â  Â  Â  Â  0x52003F06,0x87430A86,0x00000006,0x081E4000,0xC3003866,0xC40E2581,0x4905C073,0x8207060C,0x5930FA61,0x3086330B,

Â  Â  Â  Â  Â  Â  0x86330B49,0x330B4930,0xF4C2D14E,0xC53E4D93,0xC9B261E4,0xD2649843,0x610F26C9,0x63274992,0x9F2629F2,0x2610F262,

Â  Â  Â  Â  Â  Â  0xC9FA6169,0x807B985A,0x2D0A2610,0x24C218CC,0xC218CC2D,0x18CC2D24,0xCC2D24C2,0x330B4538,0x0B493086,0x42718793,

Â  Â  Â  Â  Â  Â  0x71879309,0x87930942,0x93094271,0x09427187,0x33DCC306,0x0B7A1684,0x6E34CF73,0x30942718,0x94271879,0x93086330,

Â  Â  Â  Â  Â  Â  0x9843A9A4,0xC21D4D24,0x3A4E2924,0x4C53E4D9,0x21E4C53E,0x9869324C,0x2610F264,0xC9B27499,0x8A7C98A7,0x649843C9,

Â  Â  Â  Â  Â  Â  0x0F26C9D2,0x7930A261,0xA9A49308,0xF2649843,0x53492610,0x0879314F,0x6298A493,0x98A6298A,0x5201CA62,0x0C18294C,

Â  Â  Â  Â  Â  Â  0x60C18306,0x0C661830,0x81719261,0x60C182C9,0x060C1830,0x10C66183,0xE8171926,0x88924C21,0x43108793,0x58818498,

Â  Â  Â  Â  Â  Â  0x7122409C,0xCAA27BEA,0x4A8CA398,0xC7D06918,0x2C4071CF,0x2600F90D,0x04F41A86,0x38DB09D4,0xDCC07444,0x82616A73,

Â  Â  Â  Â  Â  Â  0xF22F2AFE,0x301B7243,0xB0AAFF4F,0x5AC0309B,0x44780007,0x204C7707,0x610A42B5,0x00C534A0,0x18908583,0x97D93C22,

Â  Â  Â  Â  Â  Â  0xEA7CF757,0xAD46998E,0xF1328D83,0xF8780023,0xAFA23CD4,0x0D53433B,0x631AE8B6,0x4A0741B7,0x000FC007,0x3C80758D,

Â  Â  Â  Â  Â  Â  0x803E4C30,0x8F16F9B6,0xCCE5E73B,0xC270E69E,0x631F4649,0x6B1503F4,0xFA23C66D,0xF0B18BBA,0x001C5300,0x96116C9D,

Â  Â  Â  Â  Â  Â  0xFC00EEDC,0x368F037E,0xCD3BBEF8,0xEC3D230F,0x7E73E7BF,0x19DA679A,0x0D251D86,0x5B1AFD38,0xEEBE88F0,0x461C2C34,

Â  Â  Â  Â  Â  Â  0xEEB7003A,0x4CF2B07A,0x37336F5B,0xA0C40C0B,0xDE701CF0,0x9A69E622,0x9644E309,0x21E81E68,0x1B6C0EF9,0x2C1D4420,

Â  Â  Â  Â  Â  Â  0x8A43E80C,0x62604F2F,0x4D038A00,0x03484257,0xC09E1185,0x34D47AD5,0x280710D8,0xFDDC6B9D,0x09E21F06,0x465D85AC,

Â  Â  Â  Â  Â  Â  0x0180779E,0x0E6B6AE3,0x8314E836,0xB187413E,0xDE601C17,0x2F836403,0x403DA7DD,0x0704FE30,0xD4209F20,0x332E9324,

Â  Â  Â  Â  Â  Â  0xCE93F0E0,0x0C5CE733,0xC560E836,0x13C31487,0x4A827A58,0x09EB904F,0x88413C3A,0x3E472827,0x38C13080,0x76100F43,

Â  Â  Â  Â  Â  Â  0xBE4DAB1F,0x354C5C50,0xC31C6CE6,0x0FB47036,0x58EB8BA2,0xBE4EB907,0xFA9E7F9D,0x291B7640,0x2B3694AD,0x1896C007,

Â  Â  Â  Â  Â  Â  0x0A0716C8,0x5D34ED23,0x61ED756E,0xB60354C3,0xDA41E361,0x341BA69E,0x9846324C,0x20C229CC,0xC0CA58C1,0x721E6BBD,

Â  Â  Â  Â  Â  Â  0x5E6601A8,0x81C060F0,0x3C4614E6,0x60D07824,0x1F2B83C4,0x1C23C54F,0x7666C3F7,0x2B7E83D4,0x7D9DF01F,0x1A47AD90,

Â  Â  Â  Â  Â  Â  0x01D980E6,0xCE72B1A4,0x9C0F4631,0xE470700C,0x9364FC00,0xE0D336CD,0x52E2DEE5,0x4078C435,0xA0D7C0F2,0xA78D8579,

Â  Â  Â  Â  Â  Â  0x683F3038,0x01A0694D,0xF0614C07,0x8340D834,0x1C4398C5,0x50360EB4,0x3A0E832D,0xA07DCA50,0x838A0612,0x1F6A1A0D,

Â  Â  Â  Â  Â  Â  0x53D4A738,0xD14D230D,0xD2781D07,0x9875A143,0x238B07B1,0x385E368E,0x74F1F5FA,0x518DB61D,0x56303E7B,0x401E500F,

Â  Â  Â  Â  Â  Â  0xEA3A7439,0x0074D49D,0x0741B061,0xF036803D,0xE01E8300,0x79BEC03A,0x58C0EA5D,0x81F5BD1C,0x8483C872,0xBDCF4A1E,

Â  Â  Â  Â  Â  Â  0x1F9792F6,0x07F9D071,0x3D80621A,0x4C9BF2CA,0x07A0ED39,0xB68C0F51,0x6D198701,0xA68611C2,0x46484AB6,0x7A01C108,

Â  Â  Â  Â  Â  Â  0x08E40388,0x0601D503,0x20483D6C,0x29E0D031,0x1E521AB6,0xC120E620,0x62102120,0x1C4830EB,0x48CA4860,0x64C80F43,

Â  Â  Â  Â  Â  Â  0x8759A503,0xE1A8701B,0x37A01D43,0x0EB407A3,0x3CEA32B0,0x9324E293,0x1B4781C7,0xD68102BE,0x34921A87,0x0D03D0C4,

Â  Â  Â  Â  Â  Â  0xCB48C4D8,0xC1C96226,0x21B5B090,0xA07C1B87,0x46CC3CD9,0xC531003C,0x783EA108,0xE80F01DF,0x81E88ABE,0x436CAA7D,

Â  Â  Â  Â  Â  Â  0x11B7D83C,0xC3B781D2,0x5F5D372A,0x341A7074,0x17B953BE,0xF5BE7AE6,0xD035EA80,0x4397AD3B,0x334E8D2F,0x039401E1,

Â  Â  Â  Â  Â  Â  0xE4E90F90,0x60BDBFC9,0x5A1F0847,0xE0CC0F86,0xD507DA3D,0xA1E56677,0x86403F7C,0x8EEBD2A3,0x285F26D5,0xF93E0A1E,

Â  Â  Â  Â  Â  Â  0x8DBE5176,0x9B4A5694,0x4B600395,0x038B640C,0x9A769185,0xF6BAB72E,0x01AA61B0,0x20F1B0DB,0x0DD34F6D,0x2319261A,

Â  Â  Â  Â  Â  Â  0x6114E64C,0x652C6090,0x0F35DEE0,0x3300D439,0xE030782F,0x230A7340,0x683C121E,0x95C1E230,0x11E2A78F,0x3361FB8E,

Â  Â  Â  Â  Â  Â  0xBF41EA3B,0xCEF80F95,0x23D6C83E,0xECC0730D,0x3958D200,0x07A318E7,0x3838064E,0xB2660072,0x4FBB66C9,0x310D54BE,

Â  Â  Â  Â  Â  Â  0xF03C901E,0x615E6835,0xCC0E29E3,0x1A535A0F,0x5301C068,0x360D3C18,0xE63160D0,0x83AD0710,0xA0CB540D,0x72940E83,

Â  Â  Â  Â  Â  Â  0x8184A81F,0x868360E2,0x29CE07DA,0x48C354F5,0x0741F453,0x6850F49E,0xC1EC661D,0x8DA388E2,0x7D7E8E17,0x6D875D3C,

Â  Â  Â  Â  Â  Â  0x0F9ED463,0x9403D58C,0x9D0E5007,0x35277A8E,0x6C18401D,0xA00F41D0,0xA0C03C0D,0xB00EB807,0x3A975E6F,0x6F471630,

Â  Â  Â  Â  Â  Â  0xF21CA07D,0xD287A120,0xE4BDAF73,0x741C47E5,0x188681FE,0xFCB28F60,0x3B4E5326,0x03D441E8,0x61C06DA3,0xB6309B46,

Â  Â  Â  Â  Â  Â  0x0846484A,0x887A01C1,0x0308E403,0x6C0601D5,0x3120483D,0xB629E0D0,0x201E521A,0x20C120E6,0xEB621021,0x601C4830,

Â  Â  Â  Â  Â  Â  0x4348CA48,0x0364C80F,0x1B8759A5,0x43E1A870,0xA337A01D,0xB00EB407,0x933CEA32,0xC79324E2,0xBE1B4781,0x87D68102,

Â  Â  Â  Â  Â  Â  0xC434921A,0xD80D03D0,0x26CB48C4,0x90C1C962,0x8721B5B0,0xD9A07C1B,0x8C6B5ECA,0x9019061E,0x1C303476,0x1D311CA0,

Â  Â  Â  Â  Â  Â  0xB52B7CA4,0x3D473007,0x1D07D3EA,0x86E1946D,0x2187221E,0xC443C0D3,0xFC5C7201,0x6978EA40,0x7D07C9C8,0x8107CC4B,

Â  Â  Â  Â  Â  Â  0xDF9D300F,0x96FA7D58,0xE8721AA6,0x79F0F261,0x198751B4,0xAE2A019A,0xC3D4FA34,0x1E78310C,0x9BA7E1C0,0x03313836,

Â  Â  Â  Â  Â  Â  0x6398001C,0x1847F18C,0xC701A07E,0x09FA1C18,0x00F245B7,0xDE92C079,0x9401FBC3,0x0C21B003,0x0C1C63D2,0x499801DA,

Â  Â  Â  Â  Â  Â  0x84791946,0x311A47C1,0xF91F07C4,0xA3194831,0x15F6F83F,0x246F47E3,0x93E903D5,0xE480790D,0xBA01EE00,0x27A59403,

Â  Â  Â  Â  Â  Â  0xB56386C3,0x878A17C9,0x5DBE4F82,0xA5236F94,0xE566D295,0x0312D800,0x6140E2D9,0xCBA69DA4,0x6C3DAEAD,0x36C06A98,

Â  Â  Â  Â  Â  Â  0xDB483C6C,0x868374D3,0x9308C649,0x24184539,0xB8194B18,0x0E43CD77,0x0BCCC035,0xD0380C1E,0x8788C29C,0x841A0F04,

Â  Â  Â  Â  Â  Â  0x1CAFB783,0x2A9F607C,0x3BBEE3DB,0x6C3F71C2,0xE83D4766,0xDF01F2B7,0x7AD907D9,0x980E61A4,0x2B1A401D,0xF4631CE7,

Â  Â  Â  Â  Â  Â  0x0700C9C0,0x4DE00E47,0xF76CD936,0x21AA97C9,0x079203C6,0x2BCD06BE,0x81C53C6C,0x4A6B41F9,0x60380D03,0xC1A7830A,

Â  Â  Â  Â  Â  Â  0xC62C1A06,0x75A0E21C,0x196A81B0,0x5281D074,0x309503EE,0xD06C1C50,0x39C0FB50,0x186A9EA5,0xE83E8A69,0x0A1E93C0,

Â  Â  Â  Â  Â  Â  0x3D8CC3AD,0xB4711C58,0xA621C2F1,0xD781D211,0x6907B983,0xE8BEBA6F,0x7C6834E0,0xB6C3698D,0x07CF6A31,0xCA01EAC6,

Â  Â  Â  Â  Â  Â  0x4E872803,0x9A93BD47,0x360C200E,0xD007A0E8,0xD0601E06,0xD8075C03,0x1D4BAF37,0xB7A38B18,0x790E503E,0xE943D090,

Â  Â  Â  Â  Â  Â  0xF25ED7B9,0x3A0E23F2,0x0C4340FF,0x7E5947B0,0x1DA72993,0x81EA20F4,0xE1E036D1,0x7AE61786,0xEA80F5BE,0xAD3BD035,

Â  Â  Â  Â  Â  Â  0x8D2F4397,0x84DA330E,0x324255B1,0xD00E0842,0x47201C43,0x300EA818,0x0241EB60,0x4F068189,0xF290D5B1,0x09073100,

Â  Â  Â  Â  Â  Â  0x10810906,0xE241875B,0x46524300,0x26407A1A,0x3ACD281B,0x1E1370DC,0x1E003940,0x93D9D21F,0x8EC17B7F,0x3E194610,

Â  Â  Â  Â  Â  Â  0x337A01D4,0x00EB407A,0x33CEA32B,0x79324E29,0xE1B4781C,0x7D68102B,0x434921A8,0x80D03D0C,0x6CB48C4D,0x0C1C9622,

Â  Â  Â  Â  Â  Â  0x721B5B09,0x9A07C1B8,0xF07343ED,0x47BC1981,0xCEFAA0FB,0xEF943CAC,0x5470C807,0x9B801CBA,0x475F0CAF,0x47C1E108,

Â  Â  Â  Â  Â  Â  0x17ADD01E,0xE21B56DC,0x421E1BB9,0x23A4D07D,0x003B601C,0x80EAC07F,0x790B63F2,0x6D53F16C,0x7C9B5638,0xF82878A1,

Â  Â  Â  Â  Â  Â  0xF945DBE4,0x295A5236,0x800E566D,0x2D90312D,0xDA46140E,0xEADCBA69,0xA986C3DA,0xC6C36C06,0x4D3DB483,0x64986837,

Â  Â  Â  Â  Â  Â  0x5399308C,0xB1824184,0xD77B8194,0x0350E43C,0xC1E0BCCC,0x29CD0380,0xF048788C,0x783841A0,0x07C1CAFB,0x3DB2A9F6,

Â  Â  Â  Â  Â  Â  0x1C23BBEE,0x7666C3F7,0x2B7E83D4,0x7D9DF01F,0x1A47AD90,0x01D980E6,0xCE72B1A4,0x9C0F4631,0xE470700C,0x9364DE00,

Â  Â  Â  Â  Â  Â  0x7C9F76CD,0x3C621AA9,0x6BE07920,0xC6C2BCD0,0x1F981C53,0xD034A6B4,0x30A60380,0xA06C1A78,0x21CC62C1,0x1B075A0E,

Â  Â  Â  Â  Â  Â  0x074196A8,0x3EE5281D,0xC5030950,0xB50D06C1,0xEA539C0F,0xA69186A9,0x3C0E83E8,0x3AD0A1E9,0xC583D8CC,0x2F1B4711,

Â  Â  Â  Â  Â  Â  0x211A621C,0x983D781D,0xA6F6907B,0x4E0E8BEB,0x98D7C683,0xA31B6C36,0xAC607CF6,0x803CA01E,0xD474E872,0x00E9A93B,

Â  Â  Â  Â  Â  Â  0x0E8360C2,0xE06D007A,0xC03D0601,0xF37D8075,0xB181D4BA,0x03EB7A38,0x090790E5,0x7B9E943D,0x3F2F25ED,0x0FF3A0E2,

Â  Â  Â  Â  Â  Â  0x7B00C434,0x9937E594,0x0F41DA72,0x6D181EA2,0x786E1E03,0x5BE7AE61,0x035EA80F,0x397AD3BD,0x30E8D2F4,0x5B184DA3,

Â  Â  Â  Â  Â  Â  0x84232425,0xC43D00E0,0x81847201,0xB60300EA,0x1890241E,0x5B14F068,0x100F290D,0x90609073,0x75B10810,0x300E2418,

Â  Â  Â  Â  Â  Â  0xA1A46524,0x81B26407,0x0DC3ACD2,0x9401E137,0x21F1E003,0xB7F93D9D,0x6108EC17,0x1D43E194,0x07A337A0,0x32B00EB4,

Â  Â  Â  Â  Â  Â  0xE2933CEA,0x81C79324,0x02BE1B47,0x1A87D681,0xD0C43492,0xC4D80D03,0x6226CB48,0xB090C1C9,0x1B8721B5,0x3ED9A07C,

Â  Â  Â  Â  Â  Â  0x981F0734,0x0FB47BC1,0xCACCEFAA,0x807EF943,0xDBA5470C,0x3C0D1B7E,0x180F2178,0xA8023DA6,0xAAAAAAAA,0xB549AAAA,

Â  Â  Â  Â  Â  Â  0x35CE6AC5,0xAAAA90EA,0xCB87CE6A,0xD3681B46,0xC73A4817,0xBAC243B8,0x17C9B563,0x4F82878A,0x6F945DBE,0xD295A523,

Â  Â  Â  Â  Â  Â  0xD800E566,0xE2D90312,0x9DA46140,0xAEADCBA6,0x6A986C3D,0x3C6C36C0,0x74D3DB48,0xC6498683,0x45399308,0x4B182418,

Â  Â  Â  Â  Â  Â  0xCD77B819,0xC0350E43,0x0C1E0BCC,0xC29CD038,0x0F048788,0x70788C1A,0x78A9E3E5,0xD87EE384,0xD07A8ECC,0xBE03E56F,

Â  Â  Â  Â  Â  Â  0xF5B20FB3,0x301CC348,0x5634803B,0xE8C639CE,0x0E019381,0x9E801C8E,0xE4FBF36C,0xE310D54B,0x5F03C901,0x3615E683,

Â  Â  Â  Â  Â  Â  0xFCC0E29E,0x81A535A0,0x85301C06,0x0360D3C1,0x0E63160D,0xD83AD071,0x3A0CB540,0xF72940E8,0x28184A81,0xA868360E,

Â  Â  Â  Â  Â  Â  0x529CE07D,0x348C354F,0xE0741F45,0xD6850F49,0x2C1EC661,0x78DA388E,0xC7D7E8E1,0x36D875D3,0xC0F9ED46,0x79403D58,

Â  Â  Â  Â  Â  Â  0xE9D0E500,0xD35277A8,0x06C18401,0xDA00F41D,0x7A0C03C0,0xFB00EB80,0x03A975E6,0xD6F47163,0x0F21CA07,0x3D287A12,

Â  Â  Â  Â  Â  Â  0x5E4BDAF7,0xE741C47E,0x0188681F,0x6FCB28F6,0x83B4E532,0x303D441E,0x661C06DA,0x212AD8C0,0x07042119,0x900E21E8,

Â  Â  Â  Â  Â  Â  0x07540C23,0x20F5B018,0x8340C481,0x486AD8A7,0x83988079,0x40848304,0x20C3AD88,0x29218071,0x203D0D23,0x66940D93,

Â  Â  Â  Â  Â  Â  0xA1C06E1D,0x80750F86,0xD01E8CDE,0xA8CAC03A,0x938A4CF3,0x1E071E4C,0x040AF86D,0x486A1F5A,0x0F4310D2,0x23136034,

Â  Â  Â  Â  Â  Â  0x25889B2D,0xD6C24307,0xF06E1C86,0x072B6681,0xA3C86620,0xF1163F0D,0x2B785728,0xEF90E533,0x47C1FFC1,0x3294641E,

Â  Â  Â  Â  Â  Â  0x4F5370CA,0x800FA131,0x60807480,0xC30781BC,0xACF19E43,0xAE0314FB,0x9E04F4B3,0x33EEA56D,0x0F0310CF,0x9C264C38,

Â  Â  Â  Â  Â  Â  0xA06B18A4,0xC7B1EF13,0x03CC0661,0x30F2A1C4,0xC701806D,0x300F391B,0x71AC6270,0x18201F21,0xA85AB861,0x9B873EA7,

Â  Â  Â  Â  Â  Â  0x7CB3BCB2,0x720E38CF,0x92C5BBEA,0xD683CA52,0x9B3BE238,0x4835FD3A,0x10C2110E,0xC630C703,0x3E41ABD8,0xF0CCB600,

Â  Â  Â  Â  Â  Â  0x0C3C140C,0x0D130E16,0x775C4E31,0x42F936AC,0xC9F050F1,0x6DF28BB7,0xDA52B4A4,0x5B001CAC,0x1C5B2062,0xD3B48C28,

Â  Â  Â  Â  Â  Â  0xB5D5B974,0x0D530D87,0x078D86D8,0x6E9A7B69,0x18C930D0,0x08A73261,0x29630483,0x79AEF703,0x9806A1C8,0x0183C179,

Â  Â  Â  Â  Â  Â  0x18539A07,0x41E090F1,0xAE0F1183,0x8F153C7C,0x9B0FDC70,0xFA0F51D9,0x77C07CAD,0x1EB641F6,0x66039869,0xCAC69007,

Â  Â  Â  Â  Â  Â  0x3D18C739,0xC1C03270,0x93D00391,0x7C9F7E6D,0x3C621AA9,0x6BE07920,0xC6C2BCD0,0x1F981C53,0xD034A6B4,0x30A60380,

Â  Â  Â  Â  Â  Â  0xA06C1A78,0x21CC62C1,0x1B075A0E,0x074196A8,0x3EE5281D,0xC5030950,0xB50D06C1,0xEA539C0F,0xA69186A9,0x3C0E83E8,

Â  Â  Â  Â  Â  Â  0x3AD0A1E9,0xC583D8CC,0x2F1B4711,0x78FAFD1C,0xC6DB0EBA,0x181F3DA8,0x0F2807AB,0x1D3A1CA0,0x3A6A4EF5,0xA0D83080,

Â  Â  Â  Â  Â  Â  0x1B401E83,0x0F418078,0xDF601D70,0x60752EBC,0xFADE8E2C,0x41E43940,0xE7A50F42,0xCBC97B5E,0xFCE8388F,0xC0310D03,

Â  Â  Â  Â  Â  Â  0x4DF9651E,0xD0769CA6,0x4607A883,0x0CC380DB,0x24255B18,0x00E08423,0x7201C43D,0x00EA8184,0x241EB603,0xF0681890,

Â  Â  Â  Â  Â  Â  0x290D5B14,0x9073100F,0x08109060,0x241875B1,0x6524300E,0x6407A1A4,0xACD281B2,0xD4380DC3,0xD00EA1F0,0x5A03D19B,

Â  Â  Â  Â  Â  Â  0x75195807,0x9271499E,0xA3C0E3C9,0x40815F0D,0x490D43EB,0x81E8621A,0xA4626C06,0xE4B11365,0xDAD84860,0x3E0DC390,

Â  Â  Â  Â  Â  Â  0x00F56CD0,0x970304C1,0x011EC651,0x7B0D5DCF,0x3AA06DCE,0xA5294A49,0x83AB4A81,0x1A5294A7,0xC03A0E28,0x25917D08,

Â  Â  Â  Â  Â  Â  0xDC1B0601,0x1E1A8601,0x87C1B060,0x3B43B41B,0xEE52B600,0x03990D83,0x284564F9,0xC0300D43,0xE3D8F749,0x16E70330,

Â  Â  Â  Â  Â  Â  0x8EA56847,0x392F7237,0x00F1048C,0x112304C2,0x368D7ECF,0x9EFB3F5A,0x0D0308F2,0xA5C0EB58,0xEC6C338C,0xE50A0CA9,

Â  Â  Â  Â  Â  Â  0x8318C100,0x48E2310C,0x610BD384,0x03EED3A0,0x280761C5,0x40300E3D,0xC1846C1E,0xB7BE1BC7,0x034C4301,0x159F6D09,

Â  Â  Â  Â  Â  Â  0x3E0D3182,0x3E0F8844,0x94EE80F2,0x1F7821E1,0xF06A5840,0x5F7DE0FC,0x3EC0FFA5,0x1E21B655,0xE908DBEC,0x9561DBC0,

Â  Â  Â  Â  Â  Â  0x3A2FAE9B,0xDF1A0D38,0x730BDCA9,0x407ADF3D,0x9DE81AF5,0x97A1CBD6,0xF099A746,0xC801CA00,0xE4F27487,0x23B05EDF,

Â  Â  Â  Â  Â  Â  0xC32D0F84,0x1EF06607,0x3BEA83ED,0xBE50F2B3,0x51C3201F,0x6C0076E9,0x1F07A1A5,0x8671F463,0x036253C6,0x3D8F7C9F,

Â  Â  Â  Â  Â  Â  0x1943530E,0x87950E20,0x380D0368,0x0CBDC8CE,0xB0613030,0xD200F50E,0xE08E9372,0x394063B0,0xF0E0B6EF,0xBB6DE3CF,

Â  Â  Â  Â  Â  Â  0x007A7D27,0xE639F566,0x68586C1C,0x1A66C007,0x069D0CAA,0x60F0811D,0x20BC7372,0x6B9E4E36,0xB5EDA17A,0x88741F46,

Â  Â  Â  Â  Â  Â  0x8408E83E,0x5F077E43,0x89B591C3,0xFA179B16,0x86F1A401,0x49B27A19,0x387A1987,0xC036E33C,0xE2D08F19,0x01F62D04,

Â  Â  Â  Â  Â  Â  0x2FA81973,0x032F7B34,0xE4113C0C,0x0C337003,0x7808E830,0x7B5FA25D,0x340E2B1B,0x1E832A72,0xD66F9D34,0x989B46C1,

Â  Â  Â  Â  Â  Â  0xEA089881,0x4689B801,0x0992F860,0x1A56DFA7,0x80C7F4E8,0x4A01D871,0x900C038F,0xD06E1807,0x6DEF86F1,0x40D310C0,

Â  Â  Â  Â  Â  Â  0x003B4303,0x61B0CAB4,0x80F030A0,0xEB738B84,0x6DD1798E,0xF8F3DCFE,0xF3DCF479,0xB9E7D3A0,0xA6E61C06,0xD6B5A8EB,

Â  Â  Â  Â  Â  Â  0x3A7D6B5A,0x520EB579,0x35B4383F,0xFB500385,0xFCC0BC97,0xF25F4C33,0xBFAD4B30,0x0DA3CECB,0x00054794,0x8E390084,

Â  Â  Â  Â  Â  Â  0xDE00F500,0x380C0344,0x134330F0,0x340F32CF,0xDE6700E0,0x0DC350E3,0x781B4834,0xD26C77C0,0xE4681946,0x8F034A68,

Â  Â  Â  Â  Â  Â  0xDA00F901,0x368F833C,0xCA7C0C29,0x4C38F63D,0xD880650D,0x0C03697B,0xBDC8DE38,0x690381B4,0x08072804,0x11981BC6,

Â  Â  Â  Â  Â  Â  0xEBB7C786,0x1DAE8E1C,0x31661D48,0x16F00748,0xC364781A,0xDEC380A1,0x3C6790ED,0xA58079D4,0x81E0324E,0x0310C288,

Â  Â  Â  Â  Â  Â  0xC0EF352F,0x803A4183,0xD2434332,0x0609B671,0x3CCC4B28,0x00748070,0x8681B263,0xEA9177D2,0x019B70BB,0xE40B7ED2,

Â  Â  Â  Â  Â  Â  0x5790F411,0xC036E43C,0x01E6A805,0xCDFB483C,0x5200C234,0xDC8FBB2E,0x6C1CF60E,0x33AE877B,0xE9F87F8D,0x1B06FEF0,

Â  Â  Â  Â  Â  Â  0x33803A42,0xC24DC0CF,0x0F85B435,0xE90AEDC0,0x0E5CD200,0xD87AE92C,0x5DBEABA0,0xA00E61D5,0xA42338AC,0xB4330803,

Â  Â  Â  Â  Â  Â  0x5B46F5A1,0xEA36E1BA,0x36CF43A0,0x01D21136,0x19861182,0xB78DD242,0x781D4749,0x1E473185,0xA001D21C,0x5C1AC6B9,

Â  Â  Â  Â  Â  Â  0xEDDE07E2,0xC7A8EB70,0xDE578E37,0xDFB4800B,0xA70F0302,0xBE29722F,0x0759B748,0x0AF16CDD,0x34C500E9,0xFF7A48A9,

Â  Â  Â  Â  Â  Â  0x375D876E,0xCD58F41D,0x9203E9D1,0x1D205E07,0xEC665A80,0x23BC2461,0x981689B7,0x8001D21D,0x3BE24C55,0xD2025BCE,

Â  Â  Â  Â  Â  Â  0x46C9A401,0x78BBE2C8,0x01D2039B,0x1C06C9B4,0x3EFABC4E,0x0403A403,0xF5D00CE3,0xDCD7AA5A,0x00748126,0xF7D5316C,

Â  Â  Â  Â  Â  Â  0x8FDE50D3,0x85930D5B,0x4BEB06C1,0x8048392D,0xAC608074,0x1CB606C1,0x20F830F2,0xC1F10677,0x69016D94,0x1B86599F,

Â  Â  Â  Â  Â  Â  0x430BE24C,0x0415F25B,0x803BC01E,0xD204F87E,0x3205A401,0x6D923E12,0x3E36CEA3,0xA35403A4,0xC7043E81,0x8EDDFCF0,

Â  Â  Â  Â  Â  Â  0x3A489E80,0x00E90841,0x218330C9,0x1DB885E1,0x74983888,0x01D210D0,0x18264998,0x788BD25F,0x720D3F9B,0x41DF6200,

Â  Â  Â  Â  Â  Â  0xDFB48706,0xF339A172,0x4072B721,0x041F5551,0xAAAAAAB8,0xAAAAAAAA,0xAAAAAAAA,0xC06500EA,0x41EBC874,0x70300CAA,

Â  Â  Â  Â  Â  Â  0x4846A819,0x1B262807,0xEF09287A,0x05DC6D18,0x00748426,0xB3819E6D,0x0EDDAEF8,0x6BDA4140,0x8482C19E,0xC4C644CF,

Â  Â  Â  Â  Â  Â  0x690ACCCB,0xC986599F,0xDE2D6B7A,0xC0745B72,0x0F7B4803,0x599F690A,0xC25C19C6,0x3719B66D,0x7ED21558,0x24950D33,

Â  Â  Â  Â  Â  Â  0x3A39D49F,0xA7580EFF,0x9618781E,0x48607259,0x08162007,0xC067D249,0x0741D26D,0x3AE6695E,0x7003A428,0xC5930D13,

Â  Â  Â  Â  Â  Â  0x0AB6E117,0x130803A4,0x94BC308C,0x8EB3699B,0x03A0D832,0x98E736EE,0x1D2101C6,0x98629840,0x76DE25E1,0x2DD0699B,

Â  Â  Â  Â  Â  Â  0xD2121E96,0x86198401,0xC9FEFA4A,0x4B62217C,0x34803A40,0xEA4308DE,0xB78F15F1,0x00E900CD,0x372322D2,0x6D4A2FC9,

Â  Â  Â  Â  Â  Â  0x13C203F0,0x5E8631C6,0x20C1F168,0x6499401D,0x3DF509AC,0xECF7C62F,0x0720F0B6,0x181E76E0,0x19B401D2,0xBC4C1F06,

Â  Â  Â  Â  Â  Â  0xA40AB63D,0x0DF36803,0xDC878D1B,0xC89DF143,0x00E9002D,0x8D0374C6,0xE723F128,0x07ACC8B6,0x145CC6E0,0x199C01D2,

Â  Â  Â  Â  Â  Â  0xBBC25606,0x89749B71,0xC01D2119,0x2CBC691B,0x2DBF85E1,0x5B64007A,0xE6F00748,0x0948781A,0xB40EDEB7,0xA429B1EE,

Â  Â  Â  Â  Â  Â  0x0D0B7803,0xD49C245F,0xC3F1BE79,0x00E903CC,0x0CC308C1,0xF28287AC,0xA672B721,0xA8E844EE,0x9BC6C185,0x8201D21C,

Â  Â  Â  Â  Â  Â  0x12882611,0x0ADBE45E,0xE908EDFB,0x0370D900,0x219FA20C,0x6C433F57,0x6BDA40DB,0xE1A030A1,0x3C3BD790,0x6D949DF0,

Â  Â  Â  Â  Â  Â  0x45AF6900,0xDE928906,0x4348DB9B,0xB0DD320C,0x6BDA42B9,0xBC255E8D,0x2661B6F3,0x5ED21E19,0xE120E41B,0xB74DB95D,

Â  Â  Â  Â  Â  Â  0xF690CAC9,0x242C6599,0x46C4A47C,0x4872659D,0x06542CFB,0xDDBEFC93,0x0C03C4FA,0xF37CD434,0xA415380E,0x7D1B567D,

Â  Â  Â  Â  Â  Â  0xAFF77D10,0xCDBBDDF1,0xED800ED7,0x7DA40B39,0xE93119D6,0x370D148B,0x619E46DD,0xACFB484A,0xAF157C33,0x69004DB5,

Â  Â  Â  Â  Â  Â  0x18C699BF,0x68477C5C,0x6FDA416B,0xF882A181,0x8066C9EE,0x390ADFB4,0xB0781F88,0xF6907C03,0xE325215B,0x329BF73B,

Â  Â  Â  Â  Â  Â  0xD6EE77C4,0xA1641A27,0x001D2125,0xA1D06058,0x7FC3EF0C,0xDC3EFAC6,0x94616C06,0x6160D438,0x1DA6E9C0,0x003A4024,

Â  Â  Â  Â  Â  Â  0xC3A0CCB0,0xF3B13848,0x5987E0EE,0x8001D20B,0x43D57A35,0xEF90E501,0xD36EC327,0xB01D0741,0xC038901C,0x90C0C358,

Â  Â  Â  Â  Â  Â  0x322D000E,0xDBC87AA4,0x04B6E277,0x8B4003A4,0xF8AC308C,0x8326D5EE,0x816C0074,0x1C3207A1,0xE83CB4F2,0x68B24FB2,

Â  Â  Â  Â  Â  Â  0x3586A21D,0xC86A1F16,0x001D205E,0xA581CC5B,0x12B59FBC,0x0D030EC6,0xBB99E752,0xC0074835,0x58601B16,0x0E17E43D,

Â  Â  Â  Â  Â  Â  0xC2FDBD79,0x03A40532,0x3E8CCB60,0x8D3DF182,0x838FD395,0x6779D69E,0x61C7A9F1,0xC603C86A,0xBD3F5BC1,0x6D90CA3A,

Â  Â  Â  Â  Â  Â  0xEE46F1C0,0x43418065,0x07486623,0x2118A620,0x26D2D788,0x62007482,0xC4A2718A,0x6436A177,0x02F46F19,0x7CC400E9,

Â  Â  Â  Â  Â  Â  0x43F12443,0x0C0476EC,0x058801D2,0x91FAC0C2,0x291F2EEA,0x1986E9B7,0xD9BF0EA0,0x2291E6B2,0x2B1003A4,0x84B03C0C,

Â  Â  Â  Â  Â  Â  0xFD36C377,0x3A43CB7A,0x44D13700,0x7F7A4A23,0x584F836E,0xDE6C9AC6,0x801D2031,0x31E0619B,0xD74E5DF4,0x4A96E977,

Â  Â  Â  Â  Â  Â  0x0194A38B,0xAA7D40E2,0x74810729,0x41866E00,0x86C7BEBA,0x9DE74A74,0xFE310FC5,0x338D8330,0x7003A42B,0xE1A30D33,

Â  Â  Â  Â  Â  Â  0x2775AF23,0xDB958FC1,0x07481261,0x361896E0,0x08E07BE8,0x59DE7627,0x40EB30FC,0xC2B0803A,0xEF890384,0x48266DF0,

Â  Â  Â  Â  Â  Â  0x18561007,0x177D007F,0xB48BBEAD,0x401D2069,0x21A86F1A,0x36A7F7C5,0x4803A419,0x24920DE3,0xE779D89C,0x00CCC3FA,

Â  Â  Â  Â  Â  Â  0x78D200E9,0xEF097423,0xC5826D8A,0x007486A6,0x4631BC69,0xCFBEF896,0x8E661F46,0x74850721,0x93326900,0xDAEC8F84,

Â  Â  Â  Â  Â  Â  0x0FAD9B74,0x64D200E9,0xE1290C43,0x8076EE33,0x81D020E7,0x9007487D,0x64611B26,0x6D12EF89,0xA8A7A1C4,0x803A4153,

Â  Â  Â  Â  Â  Â  0x03D0D734,0x6EAF7C48,0xD7B40C73,0x3A4183CE,0xE0D8B480,0xFC7BE983,0xDE7727CB,0x834F7C79,0x30F3930E,0x9401D21D,

Â  Â  Â  Â  Â  Â  0x481A0671,0x2D888CFC,0xCA00E903,0x2A8C6338,0x39B7CBBE,0x19401D20,0xF5218467,0xA33A438E,0xFBE86EF3,0x85C4C3A4,

Â  Â  Â  Â  Â  Â  0x007486E6,0x91C73C65,0xC6DFCEF0,0x48426D99,0x18165007,0xC8FD047A,0x3849FBAB,0xE900943B,0x037CDA00,0x1DE12B0E,

Â  Â  Â  Â  Â  Â  0xCB3A8DBF,0xA00E90B8,0x30E2342D,0x7C2CAEFA,0x40936777,0xC631803A,0xE77C4130,0x3A40736B,0x78C63180,0x8BEF8A63,

Â  Â  Â  Â  Â  Â  0x07482B6D,0xA1182630,0x70B721EB,0xF7EDE7C8,0x1D20C5B7,0xE06C98C0,0xDE17C481,0x03A409B6,0x2CB59318,0x0DAD5DE1,

Â  Â  Â  Â  Â  Â  0x90D0DE3B,0xD64C600E,0xF577C49A,0xE3A0DC36,0x1D20588C,0x0D2B98C0,0xB55DE12D,0x88C93B0D,0x4CE00E90,0x17D606D6,

Â  Â  Â  Â  Â  Â  0x288BEAB1,0x01D2005B,0x1B8691BC,0xC5D78F40,0xF6936EE3,0x90AE1655,0x348DE00E,0xBBE2A8C6,0xD2039B5C,0x0609BC01,

Â  Â  Â  Â  Â  Â  0xC77C489E,0x3A406B63,0x50C13780,0x0F7C4A23,0x0394F36F,0x050F3B40,0x44DE00E9,0xE5EF491D,0x8701DA6D,0x1ED964DC,

Â  Â  Â  Â  Â  Â  0x9BC01D20,0x25218068,0x59B227BC,0xD21D5BB7,0xCAE9BC01,0x83DE12E8,0x8D53A8D8,0xDE00E90C,0xF1668374,0x042D95DD,

Â  Â  Â  Â  Â  Â  0x74DE00E9,0xBE260E83,0x2025B73B,0x6E9BC01D,0xBC2521A8,0x0E85B1CF,0xE90FEDC0,0x0308C100,0xD6D78975,0x0D238E06,

Â  Â  Â  Â  Â  Â  0x0403A429,0x88350C23,0x36FAF784,0x42AB36EB,0xC230403A,0x47EB0308,0xE47E2D5E,0x1EBBAEDD,0x16F07D71,0xA8F4D20F,

Â  Â  Â  Â  Â  Â  0x0403A431,0xA4310C13,0xB6FCF784,0x1D8801E8,0x98201D21,0x2531806A,0x16CF247C,0x3FB6803D,0xD30403A4,0xCFC5D00C,

Â  Â  Â  Â  Â  Â  0x906CD810,0x358D100E,0x8EFA18E0,0x6F477D51,0x403A40B3,0xC330CE32,0xB0A77A4A,0x875A0E03,0x4876836B,0x1A86C807,

Â  Â  Â  Â  Â  Â  0x1F7D7463,0xB60FBEAE,0xA01D20F5,0xD1826E1A,0x7B5D1D25,0xA413A9E7,0x585B6661,0x06680748,0x09586119,0xCE6DD3EF,

Â  Â  Â  Â  Â  Â  0x7484767D,0x31AA6C00,0x6EF89746,0x6B1BC6DA,0x86A6118C,0xA56C0074,0x047EB321,0xC047E372,0xD732F46D,0x3A4023F4,

Â  Â  Â  Â  Â  Â  0xE8C8B700,0xC8F84983,0xCABA4DB4,0xA00E90BC,0x48FC32CD,0xF57519FA,0x1CB62A33,0x737803A4,0x1E883C0D,0xDC878CF2,

Â  Â  Â  Â  Â  Â  0xA4EB07DE,0x2149B665,0x6698201D,0x878C91E8,0x9DF043DC,0xE9006DB2,0x0E1CC100,0x80CF7A6F,0xCED0CA61,0xF833BCE8,

Â  Â  Â  Â  Â  Â  0x3419C741,0x6187D00D,0x6C0769BA,0xE4700203,0x0192CC69,0x3D34D800,0x06006D00,0x0329C0E5,0x1E19C01D,0x1C120000,

Â  Â  Â  Â  Â  Â  0x3E806524,0x0F402003,0x84829081,0xCD906918,0x80C00000,0xC0887104,0x91280010,0x480C481C,0xA1946426,0x840800C8,

Â  Â  Â  Â  Â  Â  0x06000214,0xC00CB12D,0xC09921A0,0xFA0C9901,0xB81C8320,0x0C28A0E2,0x88E994C9,0x7C9F40C2,0x0702039E,0x418818D0,

Â  Â  Â  Â  Â  Â  0x0B000002,0x00000002,0xC0700000,0x0000000D,0x00000000,0x00000080,0x00000000,0x00000000,0x00000000,0x00000000,

Â  Â  Â  Â  Â  Â  0x00000000,0x00000000,0x00840400,0x00000000,0x00000000,0x00000000,0x00000000,0x00000000,0x00320401,0x00000000,

Â  Â  Â  Â  Â  Â  0x00000000,0x00000000,0x00000000,0x00000000,0x00000000,0x00000000,0x00000000,0x00000000,0x00000000,0x00000000,

Â  Â  Â  Â  Â  Â  0x00000000,0x00000000,0x00000000,0x00000000,0x00020000,0x00000000,0x00000000,0x00000000,0x0080C000,0x00000008,

Â  Â  Â  Â  Â  Â  0x02540000,0x00503000,0x42606242,0x081867A3,0x8953041A,0x00000005,0x00000000,0x00000000,0x00000000,0x00000000,

Â  Â  Â  Â  Â  Â  0x00C98000,0x00000000,0x00000000,0x00000000,0x00000000,0x804000C8,0x94400004,0x38000018,0x000009A0,0x008903A4,

Â  Â  Â  Â  Â  Â  0x00000000,0x00000000,0x00200000,0x00000200,0x00000000,0x00000000,0x00000000,0x00000000,0x00000000,0x00000000,

Â  Â  Â  Â  Â  Â  0x00000000,0x00000000,0x00000000,0x00000000,0x6C000000,0x10000006,0x00C80001,0x00000000,0x00000000,0x00000000,

Â  Â  Â  Â  Â  Â  0x00000540,0x00000080,0xDF000005,0x400FA86E,0xA1BB7C13,0xF04D003E,0x00FA86ED,0x1BB7C134,0x04D003EA,0x0FA86EDF,

Â  Â  Â  Â  Â  Â  0xBB7C1340,0x4D003EA1,0xFA86EDF0,0xB7C13400,0xD003EA1B,0xA86EDF04,0x7C13400F,0x003EA1BB,0x86EDF04D,0xC13400FA,

Â  Â  Â  Â  Â  Â  0x03EA1BB7,0x1BB7C4D0,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,

Â  Â  Â  Â  Â  Â  0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,

Â  Â  Â  Â  Â  Â  0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,

Â  Â  Â  Â  Â  Â  0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x376F2943,0x021AADF4,0xC50DDBE0,

Â  Â  Â  Â  Â  Â  0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,

Â  Â  Â  Â  Â  Â  0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,

Â  Â  Â  Â  Â  Â  0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,

Â  Â  Â  Â  Â  Â  0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,

Â  Â  Â  Â  Â  Â  0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x0DDBEA1B,0x7EC1FBC5,0xEDF1B056,0x0DDBE286,0x8A1BB7C5,0xDF14376F,

Â  Â  Â  Â  Â  Â  0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0xA1BB794A,0xA010D56F,0xB7D0DDBC,0xF780086A,0xB40F0983,

Â  Â  Â  Â  Â  Â  0x286EDF4D,0xF050DDBE,0x81E1307E,0x0DDBE9B6,0x0A1BB7C5,0x3C260FDE,0xBB7D36D0,0x4376F8A1,0x84C1FBC1,0x6FA6DA07,

Â  Â  Â  Â  Â  Â  0x6EDF1437,0x983F7828,0xF4DB40F0,0xDBE286ED,0x07EF050D,0x9B681E13,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,

Â  Â  Â  Â  Â  Â  0x6F8A1BB7,0x6EDF1437,0x86EDE528,0x004355BE,0x7D0DDBCA,0x940086AB,0x56FA1BB7,0x6F28010D,0x1AADF437,0x0DDBE002,

Â  Â  Â  Â  Â  Â  0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,

Â  Â  Â  Â  Â  Â  0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x8A1BB7D4,0x67C383F7,0x24C8FB25,0x7C50DDBE,0x76F8A1BB,0x86EDF143,

Â  Â  Â  Â  Â  Â  0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,

Â  Â  Â  Â  Â  Â  0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,

Â  Â  Â  Â  Â  Â  0x376F8A1B,0x286EDF14,0x7C50DDBE,0xFE0CA1BB,0x3003D459,0x432200A0,0x1075167F,0x44040400,0xA8B3FA18,0x00020223,

Â  Â  Â  Â  Â  Â  0x67EA0001,0x0E80C0D1,0xEA2CFF40,0xF28074A8,0x0D013459,0xD459F90C,0x08020041,0x8B3E5280,0x01851266,0x507A8B3F,

Â  Â  Â  Â  Â  Â  0x67D20100,0x030AA0D1,0x840D167E,0xC0612688,0x640EA2CF,0xD860400B,0x008EA2CF,0x00000004,0x8B3E8180,0x80860A3A,

Â  Â  Â  Â  Â  Â  0xD167E121,0x8B3E4182,0x4008113A,0x167E2084,0x459FC875,0xA1951E83,0x003A8B3F,0x50040002,0xA2CFF060,0x1002088E,

Â  Â  Â  Â  Â  Â  0x2CFD4094,0xCA4CE4EA,0x3A8B3F50,0x3E10A9AA,0xE103868B,0xF08CD167,0x84183459,0x19D459F8,0x0DDBE3B0,0x8A1BB7C5,

Â  Â  Â  Â  Â  Â  0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,

Â  Â  Â  Â  Â  Â  0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,

Â  Â  Â  Â  Â  Â  0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,

Â  Â  Â  Â  Â  Â  0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,

Â  Â  Â  Â  Â  Â  0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,

Â  Â  Â  Â  Â  Â  0xFBD4376F,0x0DD67EC1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x0FDEA1BB,0x8FAEB3F6,0xDF14376F,

Â  Â  Â  Â  Â  Â  0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,

Â  Â  Â  Â  Â  Â  0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,

Â  Â  Â  Â  Â  Â  0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,

Â  Â  Â  Â  Â  Â  0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,

Â  Â  Â  Â  Â  Â  0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x76F29437,0x21AADF43,0x50DDBE00,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,

Â  Â  Â  Â  Â  Â  0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,

Â  Â  Â  Â  Â  Â  0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,

Â  Â  Â  Â  Â  Â  0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,

Â  Â  Â  Â  Â  Â  0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x4376F294,0x0021AADF,

Â  Â  Â  Â  Â  Â  0xBE86EDE5,0x72804355,0x6CD3F83F,0xA07C400C,0xF1581E6D,0x76FA86ED,0x307EF143,0xDF74703E,0xDDBE286E,0x286EDF50,

Â  Â  Â  Â  Â  Â  0x07C60FDE,0x0DDBEE8E,0x0A1BB7C5,0x3E260FDE,0xAC0F36D0,0x7D4376F8,0x3F78A1BB,0xBA381F18,0xDF14376F,0x376FA86E,

Â  Â  Â  Â  Â  Â  0xE307EF14,0xEDF74703,0x0DDBE286,0x1307EF05,0x079B681F,0xA1BB7C56,0xBC50DDBE,0x1C0F8C1F,0x8A1BB7DD,0xB7D4376F,

Â  Â  Â  Â  Â  Â  0x83F78A1B,0xFBA381F1,0xEDF14376,0x83F78286,0xCDB40F89,0xDDBE2B03,0x286EDF50,0x07C60FDE,0x0DDBEE8E,0xEA1BB7C5,

Â  Â  Â  Â  Â  Â  0xFBC50DDB,0xD1C0F8C1,0xF8A1BB7D,0xFBC14376,0xDA07C4C1,0xDF1581E6,0x376FA86E,0xE307EF14,0xEDF74703,0x0DDBE286,

Â  Â  Â  Â  Â  Â  0xE286EDF5,0xE07C60FD,0x50DDBEE8,0xE0A1BB7C,0x03E260FD,0x8AC0F36D,0xB7D4376F,0x83F78A1B,0xFBA381F1,0xEDF14376,

Â  Â  Â  Â  Â  Â  0x4376FA86,0x3E307EF1,0x6EDF7470,0x50DDBE28,0x7D0DDBCA,0xE50086AB,0xD9A7F07E,0x40F08018,0x86EDF4DB,0x050DDBE2,

Â  Â  Â  Â  Â  Â  0x1E1307EF,0xDDBE9B68,0xA1BB7C50,0xC260FDE0,0xB7D36D03,0x376F8A1B,0x4C1FBC14,0xFA6DA078,0xEDF14376,0x83F78286,

Â  Â  Â  Â  Â  Â  0x4DB40F09,0xBE286EDF,0x7EF050DD,0xB681E130,0xC50DDBE9,0x6F8A1BB7,0x6EDF1437,0x86EDE528,0x004355BE,0xF8A1BB7C,

Â  Â  Â  Â  Â  Â  0x6F294376,0x1AADF437,0xC1FB9402,0x0063669F,0xD36D03C2,0x6F8A1BB7,0x1FBC1437,0x6DA0784C,0xF14376FA,0xF78286ED,

Â  Â  Â  Â  Â  Â  0xB40F0983,0x286EDF4D,0xF050DDBE,0x81E1307E,0x0DDBE9B6,0x0A1BB7C5,0x3C260FDE,0xBB7D36D0,0x4376F8A1,0x84C1FBC1,

Â  Â  Â  Â  Â  Â  0x6FA6DA07,0x6EDF1437,0x86EDE528,0x804355BE,0xDF4376F2,0xDE0021AA,0xD03C260F,0xA1BB7D36,0xC14376F8,0x0784C1FB,

Â  Â  Â  Â  Â  Â  0x376FA6DA,0x286EDF14,0xF0983F78,0xEDF4DB40,0x0DDBE286,0x1307EF05,0xBE9B681E,0xBB7C50DD,0x60FDE0A1,0xD36D03C2,

Â  Â  Â  Â  Â  Â  0x6F8A1BB7,0x1FBC1437,0x6DA0784C,0xF14376FA,0xDE5286ED,0x355BE86E,0x376F2804,0x021AADF4,0xC260FDE0,0xB7D36D03,

Â  Â  Â  Â  Â  Â  0x376F8A1B,0x4C1FBC14,0xFA6DA078,0xEDF14376,0x83F78286,0x4DB40F09,0xBE286EDF,0x7EF050DD,0xB681E130,0xC50DDBE9,

Â  Â  Â  Â  Â  Â  0xDE0A1BB7,0xD03C260F,0xA1BB7D36,0xC14376F8,0x0784C1FB,0x376FA6DA,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,

Â  Â  Â  Â  Â  Â  0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,

Â  Â  Â  Â  Â  Â  0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,

Â  Â  Â  Â  Â  Â  0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xF50DDBE2,0xFDE286ED,0x7E4B3F60,0xDF5C303E,0xDDBE286E,

Â  Â  Â  Â  Â  Â  0xF83F70D0,0x7C79FEBF,0xDDBE69A0,0xFDBFF050,0xFB7FE20D,0xFC4703DB,0xFF04FF6F,0xBFF5DFDB,0xBFF057FD,0x6FFC4DFD,

Â  Â  Â  Â  Â  Â  0xF6FFCAFF,0xF6FFC15F,0xFDBFF08F,0x7FDBFF4B,0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,

Â  Â  Â  Â  Â  Â  0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0x83EC1FBD,0x1BB7C44A,0x14376F8A,0xBE286EDF,0xBB7C50DD,

Â  Â  Â  Â  Â  Â  0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x0FDEA1BB,0x80C9B3F6,0xDF14376F,0xDDBE286E,

Â  Â  Â  Â  Â  Â  0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,

Â  Â  Â  Â  Â  Â  0x376F8A1B,0xE1C1FBD4,0x2A7E2541,0x86EDF1FD,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,

Â  Â  Â  Â  Â  Â  0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xF7A86EDF,

Â  Â  Â  Â  Â  Â  0x7581F183,0xF14376F9,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0x6EDF50DD,0xC60FDE28,0x6F9EAACF,0x76F29437,

Â  Â  Â  Â  Â  Â  0x21AADF43,0x86EDE500,0x004355BE,0xF8A1BB7C,0x6F294376,0x1AADF437,0x6EDE5002,0x04355BE8,0xD0DDBCA0,0x40086AB7,

Â  Â  Â  Â  Â  Â  0x6FA1BB79,0xF28010D5,0xAADF4376,0xEDE50021,0x4355BE86,0x0DDBCA00,0x0086AB7D,0xFA1BB794,0x28010D56,0xADF4376F,

Â  Â  Â  Â  Â  Â  0xDE50021A,0x355BE86E,0xDDBCA004,0x086AB7D0,0x14376F80,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,

Â  Â  Â  Â  Â  Â  0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,

Â  Â  Â  Â  Â  Â  0x6F294376,0x1AADF437,0x6EDE5002,0x04355BE8,0xD0DDBCA0,0x50086AB7,0x9A7F07EE,0xFD86018D,0xD54CB52C,0xCE2C1986,

Â  Â  Â  Â  Â  Â  0xC92C76E1,0xE4C0E906,0x009287E0,0x303E031A,0xF15F3668,0x1C0EE353,0xDF081EE9,0xDDBE286E,0xA1BB7C50,0xC50DDBE0,

Â  Â  Â  Â  Â  Â  0x967EC1FB,0x00ACFCF7,0x3F60FDE2,0xFDE07BCB,0x3BCB3F60,0xF0E0FDE0,0xBC01DE59,0xCB3E1C1F,0xF2CF843B,0xD83F780E,

Â  Â  Â  Â  Â  Â  0x780EF2CF,0x967C383F,0x07EF0077,0x0EF2CF87,0x03BCB3E1,0xB3F60FDE,0x0FDE03BC,0x1DE59F0E,0xF8C1FBC0,0xBB7DD1C0,

Â  Â  Â  Â  Â  Â  0x60FDE0A1,0xBEE8E07C,0x7EF050DD,0x74703E30,0x78286EDF,0xCFE8783F,0x6D54CB52,0x1CE2C198,0x8366101E,0xF0726074,

Â  Â  Â  Â  Â  Â  0x8D004943,0xD9A0C0F6,0x234FC57C,0x81F001DD,0xE286EDF0,0xB7C50DDB,0xDDBE0A1B,0x4C1FBC50,0x8DEF2CF8,0x8ECB3F91,

Â  Â  Â  Â  Â  Â  0x60FDE000,0xE5EF2CFC,0x0023B2CF,0x3F183F78,0xB3E97BCB,0xF78004EC,0xA381F183,0xC14376FB,0xC0F8C1FB,0xA1BB7DD1,

Â  Â  Â  Â  Â  Â  0x7C60FDE0,0xDDBEE8E0,0xF07EF050,0x96A59FD0,0x8330DAA9,0x203C39C5,0xC0E906CC,0x9287E0E4,0x81ED1A00,0x8AF9B341,

Â  Â  Â  Â  Â  Â  0x03BA469F,0xDBE103E0,0x1BB7C50D,0x14376F8A,0x78A1BB7C,0x59F0983F,0x7F231BDE,0xC0011D96,0x59F8C1FB,0x659FCBDE,

Â  Â  Â  Â  Â  Â  0x7EF00047,0xF7967E30,0x51D967D2,0xE307EF00,0xEDF74703,0x83F78286,0xFBA381F1,0xFBC14376,0xD1C0F8C1,0xE0A1BB7D,

Â  Â  Â  Â  Â  Â  0x3FA1E0FD,0xB5532D4B,0x738B0661,0x0D984078,0xC1C981D2,0x3401250F,0x668303DA,0x8D3F15F3,0x07C00774,0x8A1BB7C2,

Â  Â  Â  Â  Â  Â  0xDF14376F,0x76F8286E,0x307EF143,0x37BCB3E1,0x3B2CFE46,0x83F78002,0x97BCB3F1,0x008ECB3F,0xFC60FDE0,0xCFA5EF2C,

Â  Â  Â  Â  Â  Â  0xDE0223B2,0x8E07C60F,0x050DDBEE,0x03E307EF,0x86EDF747,0xF183F782,0x76FBA381,0xC1FBC143,0x5A967F43,0x0CC36AA6,

Â  Â  Â  Â  Â  Â  0x80F0E716,0x03A41B30,0x4A1F8393,0x07B46802,0x2BE6CD06,0x0EE91A7E,0x6F840F80,0x6EDF1437,0x50DDBE28,0xE286EDF0,

Â  Â  Â  Â  Â  Â  0x67C260FD,0xFC8C6F79,0x00047659,0x67E307EF,0x967F2F79,0xFBC0011D,0xDE59F8C1,0x47659F4B,0x8C1FBC10,0xB7DD1C0F,

Â  Â  Â  Â  Â  Â  0x0FDE0A1B,0xEE8E07C6,0xEF050DDB,0x4703E307,0x8286EDF7,0xFE8783F7,0xD54CB52C,0xCE2C1986,0x366101E1,0x07260748,

Â  Â  Â  Â  Â  Â  0xD004943F,0x9A0C0F68,0x34FC57CD,0x1F001DD2,0x286EDF08,0x7C50DDBE,0xDBE0A1BB,0xC1FBC50D,0xDEF2CF84,0xECB3F918,

Â  Â  Â  Â  Â  Â  0x0FDE0008,0x5EF2CFC6,0x023B2CFE,0xF183F780,0x3E97BCB3,0x78008ECB,0x381F183F,0x14376FBA,0x0F8C1FBC,0x1BB7DD1C,

Â  Â  Â  Â  Â  Â  0xC60FDE0A,0xDBEE8E07,0xDDBCA50D,0x086AB7D0,0x7F07EE50,0x86018D9A,0x4CB52CFD,0x2C1986D5,0x2C76E1CE,0xC0E906C9,

Â  Â  Â  Â  Â  Â  0x9287E0E4,0x3C031A00,0x5F366830,0x8EE353F1,0xC207BA47,0x6F8A1BB7,0x6EDF1437,0x4376F828,0xF8707EF1,0x67E1EF2C,

Â  Â  Â  Â  Â  Â  0x07EF1005,0x1EF2CF87,0x3F60FDE0,0xFDE03BCB,0xDE59F0E0,0x1C1FBC01,0x843BCB3E,0x780EF2CF,0xF2CFD83F,0x383F780E,

Â  Â  Â  Â  Â  Â  0x0077967C,0x03E307EF,0x86EDF747,0xF183F782,0x76FBA381,0xC1FBC143,0x7DD1C0F8,0xFDE0A1BB,0x4B3FA1E0,0x61B5532D,

Â  Â  Â  Â  Â  Â  0x78738B06,0xD20D9840,0x0FC1C981,0xDA340125,0xF3668303,0x748D3F15,0xC207C007,0x6F8A1BB7,0x6EDF1437,0x4376F828,

Â  Â  Â  Â  Â  Â  0xF1307EF1,0xE8C7BCB3,0x08ECB3F9,0x3B2CFE40,0x83F78002,0x3DE59F09,0x11D967F2,0x7659FC80,0x07EF0004,0x7BCB3E13,

Â  Â  Â  Â  Â  Â  0x13B2CFA4,0x3B2CFA40,0x60FDE001,0xBEE8E07C,0x7EF050DD,0x74703E30,0x78286EDF,0x381F183F,0x14376FBA,0xF43C1FBC,

Â  Â  Â  Â  Â  Â  0xAA65A967,0x7160CC36,0xB3080F0E,0x39303A41,0x8024A1F8,0xD0607B46,0xA7E2BE6C,0xF800EE91,0x4376F840,0xE286EDF1,

Â  Â  Â  Â  Â  Â  0xDF050DDB,0x0FDE286E,0xF7967E26,0x967F3D18,0x9FC8011D,0xF0004765,0xB3E1307E,0x2CFE47BC,0x3F90023B,0xE0008ECB,

Â  Â  Â  Â  Â  Â  0x67C260FD,0x59F48F79,0x9F481476,0xBC014765,0x1C0F8C1F,0x0A1BB7DD,0x07C60FDE,0x0DDBEE8E,0xE307EF05,0xEDF74703,

Â  Â  Â  Â  Â  Â  0x83F78286,0xB52CFE87,0x1986D54C,0x01E1CE2C,0x07483661,0x943F0726,0x0F68D004,0x57CD9A0C,0x1DD234FC,0xDF081F00,

Â  Â  Â  Â  Â  Â  0xDDBE286E,0xA1BB7C50,0xC50DDBE0,0xCFC4C1FB,0xE7A31EF2,0x0023B2CF,0x08ECB3F9,0x260FDE00,0xC8F7967C,0x0047659F,

Â  Â  Â  Â  Â  Â  0x11D967F2,0x4C1FBC00,0x91EF2CF8,0x088ECB3E,0x88ECB3E9,0xF183F780,0x76FBA381,0xC1FBC143,0x7DD1C0F8,0xFDE0A1BB,

Â  Â  Â  Â  Â  Â  0xE8E07C60,0xF050DDBE,0x9FD0F07E,0xDAA996A5,0x39C58330,0x06CC203C,0xE0E4C0E9,0x1A009287,0xB34181ED,0x469F8AF9,

Â  Â  Â  Â  Â  Â  0x03E003BA,0xC50DDBE1,0x6F8A1BB7,0xBB7C1437,0x983F78A1,0x63DE59F8,0x7659FCF4,0x967F2004,0xFBC0011D,0xF2CF84C1,

Â  Â  Â  Â  Â  Â  0xECB3F91E,0x2CFE4008,0xF780023B,0xE59F0983,0xD967D23D,0x967D2411,0x7EF0411D,0x74703E30,0x78286EDF,0x381F183F,

Â  Â  Â  Â  Â  Â  0x14376FBA,0x0F8C1FBC,0x1BB7DD1C,0x1E0FDE0A,0x32D4B3FA,0xB0661B55,0x84078738,0x981D20D9,0x1250FC1C,0x303DA340,

Â  Â  Â  Â  Â  Â  0xF15F3668,0x007748D3,0xBB7C207C,0x4376F8A1,0x8286EDF1,0xEF14376F,0xCB3F1307,0x3F9E8C7B,0xE4008ECB,0x0023B2CF,

Â  Â  Â  Â  Â  Â  0xF0983F78,0x7F23DE59,0xC8011D96,0x0047659F,0xE1307EF0,0xFA47BCB3,0xA4023B2C,0x0023B2CF,0x07C60FDE,0x0DDBEE8E,

Â  Â  Â  Â  Â  Â  0xE307EF05,0xEDF74703,0x83F78286,0xFBA381F1,0xEDF14376,0x6EDE5286,0x04355BE8,0xD0DDBCA0,0x40086AB7,0x6FA1BB79,

Â  Â  Â  Â  Â  Â  0xF28010D5,0xAADF4376,0x1FB94021,0x063669FC,0x36D03C20,0xF8A1BB7D,0xFBC14376,0xDA0784C1,0x14376FA6,0x78286EDF,

Â  Â  Â  Â  Â  Â  0x40F0983F,0x86EDF4DB,0x050DDBE2,0x1E1307EF,0xDDBE9B68,0xA1BB7C50,0xC260FDE0,0xB7D36D03,0x376F8A1B,0x4C1FBC14,

Â  Â  Â  Â  Â  Â  0xFA6DA078,0xEDF14376,0x0DDBE286,0xE1307EF5,0xDBE9B681,0x1BB7C50D,0xA1BB794A,0xA010D56F,0x34FE0FDC,0x1E10031B,

Â  Â  Â  Â  Â  Â  0xDDBE9B68,0xA1BB7C50,0xC260FDE0,0xB7D36D03,0x376F8A1B,0x4C1FBC14,0xFA6DA078,0xEDF14376,0x83F78286,0x4DB40F09,

Â  Â  Â  Â  Â  Â  0xBE286EDF,0x7EF050DD,0xB681E130,0xC50DDBE9,0xDE0A1BB7,0xD03C260F,0xA1BB7D36,0x294376F8,0xADF4376F,0xFB94021A,

Â  Â  Â  Â  Â  Â  0x63669FC1,0x6D03C200,0x8A1BB7D3,0xBC14376F,0xA0784C1F,0x4376FA6D,0x8286EDF1,0x0F0983F7,0x6EDF4DB4,0x50DDBE28,

Â  Â  Â  Â  Â  Â  0xE1307EF0,0xDBE9B681,0x1BB7C50D,0x260FDE0A,0x7D36D03C,0x76F8A1BB,0xC1FBC143,0xA6DA0784,0xDF14376F,0xEDE5286E,

Â  Â  Â  Â  Â  Â  0x4355BE86,0x0DDBCA00,0x0086AB7D,0xA7F07EE5,0xF08018D9,0xEDF4DB40,0x0DDBE286,0x1307EF05,0xBE9B681E,0xBB7C50DD,

Â  Â  Â  Â  Â  Â  0x60FDE0A1,0xD36D03C2,0x6F8A1BB7,0x1FBC1437,0x6DA0784C,0xF14376FA,0xF78286ED,0xB40F0983,0x286EDF4D,0xF050DDBE,

Â  Â  Â  Â  Â  Â  0x81E1307E,0x0DDBE9B6,0x4A1BB7C5,0x6FA1BB79,0xF28010D5,0xAADF4376,0xEDE50021,0x4355BE86,0x0DDBCA00,0x0086AB7D,

Â  Â  Â  Â  Â  Â  0xA7F07EE5,0xF08018D9,0xEDF4DB40,0x0DDBE286,0x1307EF05,0xBE9B681E,0xBB7C50DD,0x60FDE0A1,0xD36D03C2,0x6F8A1BB7,

Â  Â  Â  Â  Â  Â  0x1FBC1437,0x6DA0784C,0xF14376FA,0xF78286ED,0xB40F0983,0x286EDF4D,0xF050DDBE,0x81E1307E,0x0DDBE9B6,0x4A1BB7C5,

Â  Â  Â  Â  Â  Â  0x6FA1BB79,0xDF0010D5,0xDDBE286E,0xA1BB7C50,0xFA1BB794,0xF0010D56,0xDBE286ED,0x1BB7C50D,0x94376F8A,0xDF4376F2,

Â  Â  Â  Â  Â  Â  0xB94021AA,0x3669FC1F,0xD03C2006,0xA1BB7D36,0xC14376F8,0x0784C1FB,0x376FA6DA,0x286EDF14,0xF0983F78,0xEDF4DB40,

Â  Â  Â  Â  Â  Â  0x0DDBE286,0x1307EF05,0xBE9B681E,0xBB7C50DD,0x60FDE0A1,0xD36D03C2,0x6F8A1BB7,0x1FBC1437,0x6DA0784C,0xF14376FA,

Â  Â  Â  Â  Â  Â  0xDE5286ED,0x355BE86E,0x83F72804,0x00C6CD3F,0xA6DA0784,0xDF14376F,0x3F78286E,0xDB40F098,0xE286EDF4,0xEF050DDB,

Â  Â  Â  Â  Â  Â  0x681E1307,0x50DDBE9B,0xE0A1BB7C,0x03C260FD,0x1BB7D36D,0x14376F8A,0x784C1FBC,0x76FA6DA0,0x86EDF143,0x0983F782,

Â  Â  Â  Â  Â  Â  0xDF4DB40F,0xDDBE286E,0x0DDBCA50,0x0086AB7D,0x294376F8,0xADF4376F,0xDE50021A,0x355BE86E,0x83F72804,0x00C6CD3F,

Â  Â  Â  Â  Â  Â  0xA6DA0784,0xDF14376F,0x3F78286E,0xDB40F098,0xE286EDF4,0xEF050DDB,0x681E1307,0x50DDBE9B,0xE0A1BB7C,0x03C260FD,

Â  Â  Â  Â  Â  Â  0x1BB7D36D,0x14376F8A,0x784C1FBC,0x76FA6DA0,0x86EDF143,0x0983F782,0xDF4DB40F,0xDDBE286E,0x0DDBCA50,0x0086AB7D,

Â  Â  Â  Â  Â  Â  0xA7F07EE5,0xF08018D9,0xEDF4DB40,0x0DDBE286,0x1307EF05,0xBE9B681E,0xBB7C50DD,0x60FDE0A1,0xD36D03C2,0x6F8A1BB7,

Â  Â  Â  Â  Â  Â  0x1FBC1437,0x6DA0784C,0xF14376FA,0xF78286ED,0xB40F0983,0x286EDF4D,0xF050DDBE,0x81E1307E,0x0DDBE9B6,0x8A1BB7C5,

Â  Â  Â  Â  Â  Â  0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0xDDBCA50D,0x086AB7D0,0x94376F80,0xDF4376F2,0xBE0021AA,

Â  Â  Â  Â  Â  Â  0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,

Â  Â  Â  Â  Â  Â  0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xEDE5286E,0x4355BE86,

Â  Â  Â  Â  Â  Â  0xA1BB7C00,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,

Â  Â  Â  Â  Â  Â  0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,

Â  Â  Â  Â  Â  Â  0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,

Â  Â  Â  Â  Â  Â  0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,

Â  Â  Â  Â  Â  Â  0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,

Â  Â  Â  Â  Â  Â  0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,

Â  Â  Â  Â  Â  Â  0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,

Â  Â  Â  Â  Â  Â  0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,

Â  Â  Â  Â  Â  Â  0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,

Â  Â  Â  Â  Â  Â  0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,

Â  Â  Â  Â  Â  Â  0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,

Â  Â  Â  Â  Â  Â  0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,

Â  Â  Â  Â  Â  Â  0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,

Â  Â  Â  Â  Â  Â  0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,

Â  Â  Â  Â  Â  Â  0xE86EDE52,0xA004355B,0xB7D0DDBC,0xDE50086A,0x355BE86E,0xC1FBC004,0xA6DA0784,0xDF14376F,0x3F78286E,0xDB40F098,

Â  Â  Â  Â  Â  Â  0xE286EDF4,0xEF050DDB,0x681E1307,0x50DDBE9B,0xE0A1BB7C,0x03C260FD,0x1BB7D36D,0x14376F8A,0x784C1FBC,0x76FA6DA0,

Â  Â  Â  Â  Â  Â  0x86EDF143,0x0983F782,0xDF4DB40F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0xDDBCA50D,0x086AB7D0,0x14376F80,

Â  Â  Â  Â  Â  Â  0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xF4376F29,0x50021AAD,0x5BE86EDE,0xBCA00435,0x6AB7D0DD,0x376F8008,0x286EDF14,

Â  Â  Â  Â  Â  Â  0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,

Â  Â  Â  Â  Â  Â  0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,

Â  Â  Â  Â  Â  Â  0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,

Â  Â  Â  Â  Â  Â  0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,

Â  Â  Â  Â  Â  Â  0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,

Â  Â  Â  Â  Â  Â  0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0xC1FBD437,0xF0F0567E,0xDBE286ED,0x1BB7C50D,0x14376F8A,

Â  Â  Â  Â  Â  Â  0xBE286EDF,0xBB7C50DD,0xF60FDEA1,0x6F8842B3,0xC1FBD437,0xF42A59F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,

Â  Â  Â  Â  Â  Â  0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0xA86EDF14,0x0F0983F7,0x6EDF0A10,0x50DDBE28,0xF8A1BB7C,

Â  Â  Â  Â  Â  Â  0x6F294376,0x1AADF437,0xC1FB9402,0x0063669F,0xD36D03C2,0x6F8A1BB7,0x1FBC1437,0x6DA0784C,0xF14376FA,0xF78286ED,

Â  Â  Â  Â  Â  Â  0xB40F0983,0x286EDF4D,0xF050DDBE,0x81E1307E,0x0DDBE9B6,0x0A1BB7C5,0x3C260FDE,0xBB7D36D0,0x4376F8A1,0x84C1FBC1,

Â  Â  Â  Â  Â  Â  0x6FA6DA07,0x6EDF1437,0x86EDE528,0x804355BE,0xD3F83F72,0x78400C6C,0x76FA6DA0,0x86EDF143,0x0983F782,0xDF4DB40F,

Â  Â  Â  Â  Â  Â  0xDDBE286E,0x307EF050,0xE9B681E1,0xB7C50DDB,0x0FDE0A1B,0x36D03C26,0xF8A1BB7D,0xFBC14376,0xDA0784C1,0x14376FA6,

Â  Â  Â  Â  Â  Â  0x78286EDF,0x40F0983F,0x86EDF4DB,0xA50DDBE2,0xB7D0DDBC,0xEE50086A,0x8D9A7F07,0xB40F0801,0x286EDF4D,0xF050DDBE,

Â  Â  Â  Â  Â  Â  0x81E1307E,0x0DDBE9B6,0x0A1BB7C5,0x3C260FDE,0xBB7D36D0,0x4376F8A1,0x84C1FBC1,0x6FA6DA07,0x6EDF1437,0x983F7828,

Â  Â  Â  Â  Â  Â  0xF4DB40F0,0xDBE286ED,0x07EF050D,0x9B681E13,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xA50DDBE2,0xB7D0DDBC,0xEE50086A,

Â  Â  Â  Â  Â  Â  0x8D9A7F07,0xB40F0801,0x286EDF4D,0xF050DDBE,0x81E1307E,0x0DDBE9B6,0x0A1BB7C5,0x3C260FDE,0xBB7D36D0,0x4376F8A1,

Â  Â  Â  Â  Â  Â  0x84C1FBC1,0x6FA6DA07,0x6EDF1437,0x983F7828,0xF4DB40F0,0xDBE286ED,0x07EF050D,0x9B681E13,0x7C50DDBE,0xB794A1BB,

Â  Â  Â  Â  Â  Â  0x0D56FA1B,0x376F2801,0x021AADF4,0x9FC1FB94,0xC2006366,0xB7D36D03,0x376F8A1B,0x4C1FBC14,0xFA6DA078,0xEDF14376,

Â  Â  Â  Â  Â  Â  0x83F78286,0x4DB40F09,0xBE286EDF,0x7EF050DD,0xB681E130,0xC50DDBE9,0xDE0A1BB7,0xD03C260F,0xA1BB7D36,0xC14376F8,

Â  Â  Â  Â  Â  Â  0x0784C1FB,0x376FA6DA,0x286EDF14,0xBE86EDE5,0x72804355,0x6CD3F83F,0xA078400C,0x4376FA6D,0x8286EDF1,0x0F0983F7,

Â  Â  Â  Â  Â  Â  0x6EDF4DB4,0x50DDBE28,0xE1307EF0,0xDBE9B681,0x1BB7C50D,0x260FDE0A,0x7D36D03C,0x76F8A1BB,0xC1FBC143,0xA6DA0784,

Â  Â  Â  Â  Â  Â  0xDF14376F,0x3F78286E,0xDB40F098,0xE286EDF4,0xBCA50DDB,0x6AB7D0DD,0x376F8008,0x286EDF14,0x7C50DDBE,0x76F8A1BB,

Â  Â  Â  Â  Â  Â  0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,

Â  Â  Â  Â  Â  Â  0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,

Â  Â  Â  Â  Â  Â  0xB7C50DDB,0x376F8A1B,0x286EDF14,0xCA50DDBE,0xAB7D0DDB,0x7EE50086,0x18D9A7F0,0xDB40F080,0xE286EDF4,0xEF050DDB,

Â  Â  Â  Â  Â  Â  0x681E1307,0x50DDBE9B,0xE0A1BB7C,0x03C260FD,0x1BB7D36D,0x14376F8A,0x784C1FBC,0x76FA6DA0,0x86EDF143,0x0983F782,

Â  Â  Â  Â  Â  Â  0xDF4DB40F,0xDDBE286E,0x307EF050,0xE9B681E1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,

Â  Â  Â  Â  Â  Â  0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x4A1BB7C5,0x6FA1BB79,0xDCA010D5,

Â  Â  Â  Â  Â  Â  0x1B34FE0F,0x681E1003,0x50DDBE9B,0xE0A1BB7C,0x03C260FD,0x1BB7D36D,0x14376F8A,0x784C1FBC,0x76FA6DA0,0x86EDF143,

Â  Â  Â  Â  Â  Â  0x0983F782,0xDF4DB40F,0xDDBE286E,0x307EF050,0xE9B681E1,0xB7C50DDB,0x0FDE0A1B,0x36D03C26,0xF8A1BB7D,0x6F294376,

Â  Â  Â  Â  Â  Â  0x1AADF437,0xC1FB9402,0x0063669F,0xD36D03C2,0x6F8A1BB7,0x1FBC1437,0x6DA0784C,0xF14376FA,0xF78286ED,0xB40F0983,

Â  Â  Â  Â  Â  Â  0x286EDF4D,0xF050DDBE,0x81E1307E,0x0DDBE9B6,0x0A1BB7C5,0x3C260FDE,0xBB7D36D0,0x4376F8A1,0x84C1FBC1,0x6FA6DA07,

Â  Â  Â  Â  Â  Â  0x6EDF1437,0x86EDE528,0x804355BE,0xD3F83F72,0x7C400C6C,0x581E6DA0,0xFA86EDF1,0x7EF14376,0x74703E30,0xBE286EDF,

Â  Â  Â  Â  Â  Â  0x6EDF50DD,0xC60FDE28,0xDBEE8E07,0x1BB7C50D,0x260FDE0A,0x0F36D03E,0x4376F8AC,0x78A1BB7D,0x381F183F,0x14376FBA,

Â  Â  Â  Â  Â  Â  0x6FA86EDF,0x07EF1437,0xF74703E3,0xDBE286ED,0x07EF050D,0x9B681F13,0xBB7C5607,0x50DDBEA1,0x0F8C1FBC,0x1BB7DD1C,

Â  Â  Â  Â  Â  Â  0xD4376F8A,0xF78A1BB7,0xA381F183,0xF14376FB,0xF78286ED,0xB40F8983,0xBE2B03CD,0x6EDF50DD,0xC60FDE28,0xDBEE8E07,

Â  Â  Â  Â  Â  Â  0x1BB7C50D,0xC50DDBEA,0xC0F8C1FB,0xA1BB7DD1,0xC14376F8,0x07C4C1FB,0x1581E6DA,0x6FA86EDF,0x07EF1437,0xF74703E3,

Â  Â  Â  Â  Â  Â  0xDBE286ED,0x86EDF50D,0x7C60FDE2,0xDDBEE8E0,0xA1BB7C50,0xE260FDE0,0xC0F36D03,0xD4376F8A,0xF78A1BB7,0xA381F183,

Â  Â  Â  Â  Â  Â  0xF14376FB,0x76FA86ED,0x307EF143,0xDF74703E,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,

Â  Â  Â  Â  Â  Â  0xBE286EDF,0xBB7C50DD,0x1BB794A1,0x010D56FA,0xE286EDF0,0xB7C50DDB,0x376F8A1B,0x286EDF14,0xCA50DDBE,0xAB7D0DDB,

Â  Â  Â  Â  Â  Â  0x76F80086,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,

Â  Â  Â  Â  Â  Â  0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,

Â  Â  Â  Â  Â  Â  0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,

Â  Â  Â  Â  Â  Â  0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xEDE5286E,0x4355BE86,0xA1BB7C00,0x294376F8,

Â  Â  Â  Â  Â  Â  0xADF4376F,0xDBE0021A,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0x5286EDF1,0x5BE86EDE,0xBCA00435,

Â  Â  Â  Â  Â  Â  0x6AB7D0DD,0xBB794008,0x10D56FA1,0x4376F280,0x0021AADF,0xBE86EDE5,0xCA004355,0xAB7D0DDB,0xB7940086,0x0D56FA1B,

Â  Â  Â  Â  Â  Â  0x376F2801,0x021AADF4,0xC50DDBE0,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0x94A1BB7C,0x56FA1BB7,0xFDCA010D,0x31B34FE0,

Â  Â  Â  Â  Â  Â  0xB681E100,0xC50DDBE9,0xDE0A1BB7,0xD03C260F,0xA1BB7D36,0xC14376F8,0x0784C1FB,0x376FA6DA,0x286EDF14,0xF0983F78,

Â  Â  Â  Â  Â  Â  0xEDF4DB40,0x0DDBE286,0x1307EF05,0xBE9B681E,0xBB7C50DD,0x60FDE0A1,0xD36D03C2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,

Â  Â  Â  Â  Â  Â  0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xEDE5286E,0x4355BE86,0x0DDBCA00,0x0086AB7D,0xFA1BB794,

Â  Â  Â  Â  Â  Â  0x28010D56,0xADF4376F,0xDE50021A,0x355BE86E,0xDDBCA004,0x086AB7D0,0x7F07EE50,0x08018D9A,0xDF4DB40F,0xDDBE286E,

Â  Â  Â  Â  Â  Â  0x307EF050,0xE9B681E1,0xB7C50DDB,0x0FDE0A1B,0x36D03C26,0xF8A1BB7D,0xFBC14376,0xDA0784C1,0x14376FA6,0x78286EDF,

Â  Â  Â  Â  Â  Â  0x40F0983F,0x86EDF4DB,0x050DDBE2,0x1E1307EF,0xDDBE9B68,0xA1BB7C50,0xFA1BB794,0x28010D56,0xADF4376F,0xFB94021A,

Â  Â  Â  Â  Â  Â  0x63669FC1,0x6D03C200,0x8A1BB7D3,0xBC14376F,0xA0784C1F,0x4376FA6D,0x8286EDF1,0x0F0983F7,0x6EDF4DB4,0x50DDBE28,

Â  Â  Â  Â  Â  Â  0xE1307EF0,0xDBE9B681,0x1BB7C50D,0x260FDE0A,0x7D36D03C,0x76F8A1BB,0xC1FBC143,0xA6DA0784,0xDF14376F,0xEDE5286E,

Â  Â  Â  Â  Â  Â  0x4355BE86,0xF83F7280,0x400C6CD3,0xFA6DA078,0xEDF14376,0x83F78286,0x4DB40F09,0xBE286EDF,0x7EF050DD,0xB681E130,

Â  Â  Â  Â  Â  Â  0xC50DDBE9,0xDE0A1BB7,0xD03C260F,0xA1BB7D36,0xC14376F8,0x0784C1FB,0x376FA6DA,0x286EDF14,0xF0983F78,0xEDF4DB40,

Â  Â  Â  Â  Â  Â  0x0DDBE286,0xD0DDBCA5,0x50086AB7,0x9A7F07EE,0x0F08018D,0x6EDF4DB4,0x50DDBE28,0xE1307EF0,0xDBE9B681,0x1BB7C50D,

Â  Â  Â  Â  Â  Â  0x260FDE0A,0x7D36D03C,0x76F8A1BB,0xC1FBC143,0xA6DA0784,0xDF14376F,0x3F78286E,0xDB40F098,0xE286EDF4,0xEF050DDB,

Â  Â  Â  Â  Â  Â  0x681E1307,0x50DDBE9B,0xF8A1BB7C,0xEDF14376,0x983F7A86,0xF4DB40F0,0xDBE286ED,0xDDBCA50D,0x086AB7D0,0x7F07EE50,

Â  Â  Â  Â  Â  Â  0x08018D9A,0xDF4DB40F,0xDDBE286E,0x307EF050,0xE9B681E1,0xB7C50DDB,0x0FDE0A1B,0x36D03C26,0xF8A1BB7D,0xFBC14376,

Â  Â  Â  Â  Â  Â  0xDA0784C1,0x14376FA6,0x78286EDF,0x40F0983F,0x86EDF4DB,0x050DDBE2,0x1E1307EF,0xDDBE9B68,0xA1BB7C50,0xFA1BB794,

Â  Â  Â  Â  Â  Â  0xCA010D56,0xB34FE0FD,0x81E10031,0x0DDBE9B6,0x0A1BB7C5,0x3C260FDE,0xBB7D36D0,0x4376F8A1,0x84C1FBC1,0x6FA6DA07,

Â  Â  Â  Â  Â  Â  0x6EDF1437,0x983F7828,0xF4DB40F0,0xDBE286ED,0x07EF050D,0x9B681E13,0x7C50DDBE,0xFDE0A1BB,0x6D03C260,0x8A1BB7D3,

Â  Â  Â  Â  Â  Â  0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,

Â  Â  Â  Â  Â  Â  0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,

Â  Â  Â  Â  Â  Â  0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,

Â  Â  Â  Â  Â  Â  0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,

Â  Â  Â  Â  Â  Â  0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x794A1BB7,0xD56FA1BB,0x6EDF0010,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,

Â  Â  Â  Â  Â  Â  0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,

Â  Â  Â  Â  Â  Â  0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,

Â  Â  Â  Â  Â  Â  0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,

Â  Â  Â  Â  Â  Â  0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,

Â  Â  Â  Â  Â  Â  0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xE86EDE52,0xA004355B,0xB7D0DDBC,0x6F80086A,0x76F29437,0x21AADF43,0xFC1FB940,

Â  Â  Â  Â  Â  Â  0x20063669,0x7D36D03C,0x76F8A1BB,0xC1FBC143,0xA6DA0784,0xDF14376F,0x3F78286E,0xDB40F098,0xE286EDF4,0xEF050DDB,

Â  Â  Â  Â  Â  Â  0x681E1307,0x50DDBE9B,0xE0A1BB7C,0x03C260FD,0x1BB7D36D,0x14376F8A,0x784C1FBC,0x76FA6DA0,0x86EDF143,0xE86EDE52,

Â  Â  Â  Â  Â  Â  0x2804355B,0xCD3F83F7,0x078400C6,0x376FA6DA,0x286EDF14,0xF0983F78,0xEDF4DB40,0x0DDBE286,0x1307EF05,0xBE9B681E,

Â  Â  Â  Â  Â  Â  0xBB7C50DD,0x60FDE0A1,0xD36D03C2,0x6F8A1BB7,0x1FBC1437,0x6DA0784C,0xF14376FA,0xF78286ED,0xB40F0983,0x286EDF4D,

Â  Â  Â  Â  Â  Â  0x7C50DDBE,0xB794A1BB,0x0D56FA1B,0x86EDF001,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,

Â  Â  Â  Â  Â  Â  0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDE5286ED,0x355BE86E,0x83F72804,0x00C6CD3F,

Â  Â  Â  Â  Â  Â  0xA6DA0784,0xDF14376F,0x3F78286E,0xDB40F098,0xE286EDF4,0xEF050DDB,0x681E1307,0x50DDBE9B,0xE0A1BB7C,0x03C260FD,

Â  Â  Â  Â  Â  Â  0x1BB7D36D,0x14376F8A,0x784C1FBC,0x76FA6DA0,0x86EDF143,0x0983F782,0xDF4DB40F,0xDDBE286E,0x0DDBCA50,0x0086AB7D,

Â  Â  Â  Â  Â  Â  0xA7F07EE5,0xF88018D9,0xB03CDB40,0xF50DDBE2,0xFDE286ED,0xE8E07C60,0x7C50DDBE,0xDDBEA1BB,0x8C1FBC50,0xB7DD1C0F,

Â  Â  Â  Â  Â  Â  0x376F8A1B,0x4C1FBC14,0x1E6DA07C,0x86EDF158,0xF14376FA,0x703E307E,0x286EDF74,0xDF50DDBE,0x0FDE286E,0xEE8E07C6,

Â  Â  Â  Â  Â  Â  0xB7C50DDB,0x0FDE0A1B,0x36D03E26,0x76F8AC0F,0xA1BB7D43,0x1F183F78,0x376FBA38,0xA86EDF14,0xEF14376F,0x4703E307,

Â  Â  Â  Â  Â  Â  0xE286EDF7,0xEF050DDB,0x681F1307,0x7C56079B,0xDDBEA1BB,0x8C1FBC50,0xB7DD1C0F,0x376F8A1B,0x8A1BB7D4,0x81F183F7,

Â  Â  Â  Â  Â  Â  0x4376FBA3,0x8286EDF1,0x0F8983F7,0x2B03CDB4,0xDF50DDBE,0x0FDE286E,0xEE8E07C6,0xB7C50DDB,0x0DDBEA1B,0xF8C1FBC5,

Â  Â  Â  Â  Â  Â  0xBB7DD1C0,0x4376F8A1,0xC4C1FBC1,0x81E6DA07,0xA86EDF15,0xEF14376F,0x4703E307,0xE286EDF7,0xEDF50DDB,0x60FDE286,

Â  Â  Â  Â  Â  Â  0xBEE8E07C,0xBB7C50DD,0x1BB794A1,0x010D56FA,0x4FE0FDCA,0xE10031B3,0xDBE9B681,0x1BB7C50D,0x260FDE0A,0x7D36D03C,

Â  Â  Â  Â  Â  Â  0x76F8A1BB,0xC1FBC143,0xA6DA0784,0xDF14376F,0x3F78286E,0xDB40F098,0xE286EDF4,0xEF050DDB,0x681E1307,0x50DDBE9B,

Â  Â  Â  Â  Â  Â  0xE0A1BB7C,0x03C260FD,0x1BB7D36D,0x14376F8A,0xE5286EDF,0x55BE86ED,0x3F728043,0x0C6CD3F8,0xA967EC30,0x0756AA65,

Â  Â  Â  Â  Â  Â  0xE1CE2C19,0x48366101,0x3F072607,0x18D00494,0x68303FAA,0x4634FF36,0x881F001D,0x86EDF121,0xC50DDBE2,0xDE0A1BB7,

Â  Â  Â  Â  Â  Â  0x29B3F60F,0xC60FDE0E,0xDBEE8E07,0x07EF050D,0xF74703E3,0xF78286ED,0xA381F183,0xC14376FB,0x367EC1FB,0x4A6CFC25,

Â  Â  Â  Â  Â  Â  0x3F60FDE0,0xFDE0129B,0x129B3F60,0x61E0FDE0,0x532D4B3E,0x60C83AB5,0x080F0E71,0x303A41B3,0x24A1F839,0x607B4680,

Â  Â  Â  Â  Â  Â  0xE2BE6CD0,0x00EE91A7,0x76F840F8,0x86EDF143,0x050DDBE2,0xDE286EDF,0x567C260F,0xE3748F00,0x6CFC60FD,0xB2CFA78A,

Â  Â  Â  Â  Â  Â  0x2CFA4013,0xFDE0013B,0x8A6CFC60,0x23B2CFE7,0x183F7800,0x6FBA381F,0x1FBC1437,0xDD1C0F8C,0xDE0A1BB7,0x8E07C60F,

Â  Â  Â  Â  Â  Â  0x050DDBEE,0xF30F07EF,0xAA996A59,0x8B0641D5,0x98407873,0xC981D20D,0x01250FC1,0x8303DA34,0x3F15F366,0xC007748D,

Â  Â  Â  Â  Â  Â  0x1BB7C207,0x14376F8A,0xF8286EDF,0x7EF14376,0x02B3E130,0xEF1BA478,0x5367E307,0x1D967D3C,0xD967D205,0x07EF0051,

Â  Â  Â  Â  Â  Â  0x3C5367E3,0x011D967F,0xF8C1FBC0,0xBB7DD1C0,0x60FDE0A1,0xBEE8E07C,0x7EF050DD,0x74703E30,0x78286EDF,0xCF98783F,

Â  Â  Â  Â  Â  Â  0xAD54CB52,0x9C58320E,0x6CC203C3,0x0E4C0E90,0xA009287E,0x34181ED1,0x69F8AF9B,0x3E003BA4,0x50DDBE10,0xF8A1BB7C,

Â  Â  Â  Â  Â  Â  0xB7C14376,0x83F78A1B,0xC0159F09,0x3F78DD23,0xE29B3F18,0x88ECB3E9,0x8ECB3E90,0x183F7808,0xF9E29B3F,0x0008ECB3,

Â  Â  Â  Â  Â  Â  0x07C60FDE,0x0DDBEE8E,0xE307EF05,0xEDF74703,0x83F78286,0xFBA381F1,0xFBC14376,0x967CC3C1,0x756AA65A,0x1CE2C190,

Â  Â  Â  Â  Â  Â  0x8366101E,0xF0726074,0x8D004943,0xD9A0C0F6,0x234FC57C,0x81F001DD,0xE286EDF0,0xB7C50DDB,0xDDBE0A1B,0x4C1FBC50,

Â  Â  Â  Â  Â  Â  0x1E00ACF8,0xC1FBC6E9,0x4F14D9F8,0x9047659F,0x047659F4,0xF8C1FBC1,0x9FCF14D9,0xF0004765,0x703E307E,0x286EDF74,

Â  Â  Â  Â  Â  Â  0x1F183F78,0x376FBA38,0x8C1FBC14,0xB7DD1C0F,0x0FDE0A1B,0xD4B3E61E,0x83AB5532,0xF0E7160C,0xA41B3080,0x1F839303,

Â  Â  Â  Â  Â  Â  0xB468024A,0xE6CD0607,0xE91A7E2B,0x840F800E,0xDF14376F,0xDDBE286E,0x86EDF050,0xC260FDE2,0x48F00567,0xC60FDE37,

Â  Â  Â  Â  Â  Â  0xFA78A6CF,0xA4023B2C,0x0023B2CF,0xCFC60FDE,0x2CFE78A6,0xF780023B,0xA381F183,0xC14376FB,0xC0F8C1FB,0xA1BB7DD1,

Â  Â  Â  Â  Â  Â  0x7C60FDE0,0xDDBEE8E0,0x0DDBCA50,0x0086AB7D,0xFA1BB794,0x28010D56,0xADF4376F,0xFB94021A,0x63669FC1,0x6D03C200,

Â  Â  Â  Â  Â  Â  0x8A1BB7D3,0xBC14376F,0xA0784C1F,0x4376FA6D,0x8286EDF1,0x0F0983F7,0x6EDF4DB4,0x50DDBE28,0xE1307EF0,0xDBE9B681,

Â  Â  Â  Â  Â  Â  0x1BB7C50D,0x260FDE0A,0x7D36D03C,0x76F8A1BB,0xC1FBC143,0xA6DA0784,0xDF14376F,0xEDE5286E,0x4355BE86,0x0DDBCA00,

Â  Â  Â  Â  Â  Â  0x0086AB7D,0xA7F07EE5,0xF08018D9,0xEDF4DB40,0x0DDBE286,0x1307EF05,0xBE9B681E,0xBB7C50DD,0x60FDE0A1,0xD36D03C2,

Â  Â  Â  Â  Â  Â  0x6F8A1BB7,0x1FBC1437,0x6DA0784C,0xF14376FA,0xF78286ED,0xB40F0983,0x286EDF4D,0xF050DDBE,0x81E1307E,0x0DDBE9B6,

Â  Â  Â  Â  Â  Â  0x4A1BB7C5,0x6FA1BB79,0xDCA010D5,0x1B34FE0F,0x681E1003,0x50DDBE9B,0xE0A1BB7C,0x03C260FD,0x1BB7D36D,0x14376F8A,

Â  Â  Â  Â  Â  Â  0x784C1FBC,0x76FA6DA0,0x86EDF143,0x0983F782,0xDF4DB40F,0xDDBE286E,0x307EF050,0xE9B681E1,0xB7C50DDB,0x0FDE0A1B,

Â  Â  Â  Â  Â  Â  0x36D03C26,0xF8A1BB7D,0x6F294376,0x1AADF437,0xC1FB9402,0x0063669F,0xD36D03C2,0x6F8A1BB7,0x1FBC1437,0x6DA0784C,

Â  Â  Â  Â  Â  Â  0xF14376FA,0xF78286ED,0xB40F0983,0x286EDF4D,0xF050DDBE,0x81E1307E,0x0DDBE9B6,0x0A1BB7C5,0x3C260FDE,0xBB7D36D0,

Â  Â  Â  Â  Â  Â  0x4376F8A1,0x84C1FBC1,0x6FA6DA07,0x6EDF1437,0x86EDE528,0x804355BE,0xD3F83F72,0x78400C6C,0x76FA6DA0,0x86EDF143,

Â  Â  Â  Â  Â  Â  0x0983F782,0xDF4DB40F,0xDDBE286E,0x307EF050,0xE9B681E1,0xB7C50DDB,0x0FDE0A1B,0x36D03C26,0xF8A1BB7D,0xFBC14376,

Â  Â  Â  Â  Â  Â  0xDA0784C1,0x14376FA6,0x78286EDF,0x40F0983F,0x86EDF4DB,0xA50DDBE2,0xB7D0DDBC,0xEE50086A,0x8D9A7F07,0xB40F0801,

Â  Â  Â  Â  Â  Â  0x286EDF4D,0xF050DDBE,0x81E1307E,0x0DDBE9B6,0x0A1BB7C5,0x3C260FDE,0xBB7D36D0,0x4376F8A1,0x84C1FBC1,0x6FA6DA07,

Â  Â  Â  Â  Â  Â  0x6EDF1437,0x983F7828,0xF4DB40F0,0xDBE286ED,0x07EF050D,0x9B681E13,0x7C50DDBE,0xB794A1BB,0x0D56FA1B,0xE0FDCA01,

Â  Â  Â  Â  Â  Â  0x0031B34F,0xE9B681E1,0xB7C50DDB,0x0FDE0A1B,0x36D03C26,0xF8A1BB7D,0xFBC14376,0xDA0784C1,0x14376FA6,0x78286EDF,

Â  Â  Â  Â  Â  Â  0x40F0983F,0x86EDF4DB,0x050DDBE2,0x1E1307EF,0xDDBE9B68,0xA1BB7C50,0xC260FDE0,0xB7D36D03,0x376F8A1B,0x4376F294,

Â  Â  Â  Â  Â  Â  0x4021AADF,0x69FC1FB9,0x3C200636,0xBB7D36D0,0x4376F8A1,0x84C1FBC1,0x6FA6DA07,0x6EDF1437,0x983F7828,0xF4DB40F0,

Â  Â  Â  Â  Â  Â  0xDBE286ED,0x07EF050D,0x9B681E13,0x7C50DDBE,0xFDE0A1BB,0x6D03C260,0x8A1BB7D3,0xBC14376F,0xA0784C1F,0x4376FA6D,

Â  Â  Â  Â  Â  Â  0x5286EDF1,0x5BE86EDE,0xF7280435,0xC6CD3F83,0xDA078400,0x14376FA6,0x78286EDF,0x40F0983F,0x86EDF4DB,0x050DDBE2,

Â  Â  Â  Â  Â  Â  0x1E1307EF,0xDDBE9B68,0xA1BB7C50,0xC260FDE0,0xB7D36D03,0x376F8A1B,0x4C1FBC14,0xFA6DA078,0xEDF14376,0x83F78286,

Â  Â  Â  Â  Â  Â  0x4DB40F09,0xBE286EDF,0xBB7C50DD,0x260FDEA1,0x7D36D03C,0x76F8A1BB,0x86EDF143,0xF0983F7A,0xEDF4DB40,0x0DDBE286,

Â  Â  Â  Â  Â  Â  0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,

Â  Â  Â  Â  Â  Â  0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,

Â  Â  Â  Â  Â  Â  0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,

Â  Â  Â  Â  Â  Â  0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,

Â  Â  Â  Â  Â  Â  0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,

Â  Â  Â  Â  Â  Â  0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,0x14376F8A,0xBE286EDF,0xBB7C50DD,

Â  Â  Â  Â  Â  Â  0x4376F8A1,0xE286EDF1,0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,

Â  Â  Â  Â  Â  Â  0x6EDF1437,0x50DDBE28,0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,

Â  Â  Â  Â  Â  Â  0xDBE286ED,0x1BB7C50D,0x14376F8A,0xE5286EDF,0x55BE86ED,0xDBCA0043,0x86AB7D0D,0x1BB79400,0x010D56FA,0xE286EDF0,

Â  Â  Â  Â  Â  Â  0xB7C50DDB,0x376F8A1B,0x286EDF14,0x7C50DDBE,0x76F8A1BB,0x86EDF143,0xC50DDBE2,0x6F8A1BB7,0x6EDF1437,0x50DDBE28,

Â  Â  Â  Â  Â  Â  0xF8A1BB7C,0xEDF14376,0x0DDBE286,0x8A1BB7C5,0xDF14376F,0xDDBE286E,0xA1BB7C50,0xF14376F8,0xDBE286ED,0x1BB7C50D,

Â  Â  Â  Â  Â  Â  0xA1BB794A,0x8010D56F,0xDF4376F2,0xFE4021AA,0xE0023B2C,0x6CFC60FD,0xB2CFA459,0x0FDE0013,0x4596CFC6,0x0A3B2CFA,

Â  Â  Â  Â  Â  Â  0xFC60FDE0,0xCFA4596C,0xDE0223B2,0x96CFC60F,0x3B2CFA45,0x60FDE082,0xA4596CFC,0x4023B2CF,0x6FA1BB79,0xF28010D5,

Â  Â  Â  Â  Â  Â  0xAADF4376,0xEDE50021,0x4355BE86,0x0DDBCA00,0x0086AB7D,0xFA1BB794,0x28010D56,0xADF4376F,0xDE50021A,0x355BE86E,

Â  Â  Â  Â  Â  Â  0x615C2004,0x38A58E7D,0xFEF4F105,0xAC7B5EBB,0x5E253867,0x88A9C116,0x33CFCB87,0x9C1D13BD,0x0F07DF06,0x693E4B4E,

Â  Â  Â  Â  Â  Â  0xB801EBB0,0x46F31EB7,0xCA3A70C9,0x0FEDE349,0x7AF41DB8,0xA71D2B57,0x19851C27,0xE1470806,0x51C20686,0x708041F8,

Â  Â  Â  Â  Â  Â  0xF103A114,0xA1A1FB90,0x451E7603,0xF90E102A,0x709F2064,0xEB80F5DF,0x1992EFAE,0x8E3C8788,0x773F3E18,0x380A1DA0,

Â  Â  Â  Â  Â  Â  0xE3007584,0x07AEC3B8,0xBE838EF6,0x1E207AAD,0x70623BF2,0x878816C0,0x1EB50F02,0x21C202C2,0xC0A343CF,0x0F7C8700,

Â  Â  Â  Â  Â  Â  0x5DC81D31,0x01E100EA,0xB80F61A7,0x20607AEE,0x05AFA51C,0x9F0DC708,0xBC87B79F,0x7613840A,0x28E01805,0x45BAA1D5,

Â  Â  Â  Â  Â  Â  0xD775DD76,0xF39EDF5D,0x7643D071,0x743A3A40,0x20342E08,0x843E1D1C,0x4D638405,0x3E276819,0xBAE83D77,0x1EBBAEEB,

Â  Â  Â  Â  Â  Â  0x7FC77AA2,0xB7DB3C40,0x200F09EB,0x15DFED9C,0x76076708,0xC1D9C205,0xC270815D,0x102BC0F3,0xA73C932E,0xE087C026,

Â  Â  Â  Â  Â  Â  0x0833F788,0x101B6B97,0x20354F2E,0xFE1F951D,0x77C1CCEC,0xC5E3723F,0x0784F1FB,0x8799FA3F,0xAEFDE203,0xCE77FFF3,

Â  Â  Â  Â  Â  Â  0xECE27480,0x153BEBC0,0x84081038,0xFE27A3B3,0xE1767081,0xCE1003C4,0x01789E2E,0x014B69C2,0xF842133F,0x97083D00,

Â  Â  Â  Â  Â  Â  0x03DE0EEB,0x87E572E1,0xC1F0102B,0xCD03E3E8,0xA7043C25,0xB8409E3B,0x10203635,0x074F245E,0x78E22F7C,0x7A709752,

Â  Â  Â  Â  Â  Â  0xF3C05777,0x522F80ED,0xE06E8F14,0xB13C3D29,0x0245EF87,0x4E11EA4F,0xF80AEDEF,0xA3C7E099,0x1F4A789B,0x29E3EC4F,

Â  Â  Â  Â  Â  Â  0x80713C03,0x4F0645EF,0x1329E11A,0xEF82713C,0x74708B43,0xE13390FF,0x40AEE9F4,0xCBBE4C3D,0x0983FBB9,0xF1EF2ECF,

Â  Â  Â  Â  Â  Â  0x54193F92,0x488F1D5C,0xC21D01E3,0x5767AE55,0xA2CBF400,0xA07CED63,0x2767DE69,0x47C978F7,0x60D71559,0xE7EDC380,

Â  Â  Â  Â  Â  Â  0x3F706F91,0xCBC7AAF5,0x8681EABB,0x85972A03,0x4789AE1A,0x2E80F108,0x01F530F9,0xF55E0794,0x60AF51DA,0xDA32F901,

Â  Â  Â  Â  Â  Â  0x381EFB3C,0x2217D019,0x788B5C51,0xFD20EA98,0x1CA03F79,0x9CF7DEAE,0xA7A04DC9,0xA178F34E,0x83C26D71,0x34EA7869,

Â  Â  Â  Â  Â  Â  0xF82CB840,0xEA075AE1,0xA5F3AF91,0xF1EF2ECF,0xF07C8FE2,0xAE1232F5,0xFD4AB843,0x7480F2EC,0xCB6CFDE4,0x0341CF14,

Â  Â  Â  Â  Â  Â  0x611EA5D7,0x7675403C,0x7FA41CA0,0x578F0776,0x1C23D717,0x978813E1,0x7273EAF1,0xFA61CA03,0x9DDB4803,0xFED43E93,

Â  Â  Â  Â  Â  Â  0x7D71150E,0x73B9E1D2,0x9FD40713,0x406E20FD,0xC873ACBA,0x3FBAD9E4,0x90DC36FE,0xF74A8E21,0x9C620F79,0x78203C8E,

Â  Â  Â  Â  Â  Â  0xF01AE630,0xEC1F0753,0x32EEC2F1,0x23EF41CC,0x6E044F33,0x4289A7F0,0x15A8E8D8,0xBF88C1E1,0x5DA073B6,0x77583DA6,

Â  Â  Â  Â  Â  Â  0xFAD9FB40,0xD5B15E3D,0xD41C9B2E,0x47498DC0,0xDBF3E2EE,0xB815FC7C,0x61E3BE09,0x84C75C3C,0x0EE35987,0x5C567A07,

Â  Â  Â  Â  Â  Â  0x41DDC0FB,0xDD775DEC,0x77B9FA75,0x11CD711D,0xE4711CD7,0x203C47B9,0xA181EBBC,0x1CB00E31,0x3C263B14,0x039125F9,

Â  Â  Â  Â  Â  Â  0xE51D4F54,0xB70CA2F1,0x03A481E6,0xA79E13CC,0x483B6C3F,0xD47A6D23,0x83E800FA,0x665E2708,0x3746E899,0xDE23A61E,

Â  Â  Â  Â  Â  Â  0x4DF51F24,0x30F503DE,0xD1E72EFB,0xAF5C000F,0x8FC5EA7E,0x23371397,0xF9D9E61E,0xE900EF81,0xE1BCE248,0xE6E09B81,

Â  Â  Â  Â  Â  Â  0xBB0CC3C4,0xA005F03E,0x773CAE1E,0xAA41D93C,0x7D4FCE6B,0xE38E55F9,0xD3C3B416,0x73D35EE7,0x94BC7DF0,0xDF2FC907,

Â  Â  Â  Â  Â  Â  0xDC3BD63D,0xE2987092,0x501E337C,0x8FD307C5,0x729C300F,0x9439E319,0xE18E5E3F,0x56D27CD7,0x30E115B8,0x3B40CED7,

Â  Â  Â  Â  Â  Â  0xF6907DCC,0xC1C1C7F4,0xF8FB80E7,0x3FAB2FDD,0x9ADC7DD6,0x0CE1E470,0x96AE101E,0xC3C06064,0xCE1307CC,0xC37D2DBA,

Â  Â  Â  Â  Â  Â  0x1F13A9EF,0xCDBC7BB4,0xD20EF517,0xC25ED63F,0xA8CD4736,0x786FCB97,0x83E2753F,0xE59B8F7A,0x4E93E400,0xB47BA3C4,

Â  Â  Â  Â  Â  Â  0x9E73C923,0x39ED1F1D,0xD4C53F44,0xF7CD8A83,0x96DC5216,0x6F770F41,0xC678017C,0x5FF3A603,0xC0EA7EC3,0xCC6B178F,

Â  Â  Â  Â  Â  Â  0xE8380635,0xECFDA475,0x00C76E07,0x800F2987,0xF6BA786E,0xCF90FB10,0x72F1E4A1,0xAC7FCD5F,0x3E3DB83B,0xA23C6118,

Â  Â  Â  Â  Â  Â  0xF9CCBE4E,0x7F1EE21C,0xD1BE65CA,0x307C0770,0xFD40F8F3,0x0FC99789,0xD7387E58,0xF3D97C81,0xC96BD2C6,0xDF49F91A,

Â  Â  Â  Â  Â  Â  0xC4A503E0,0x8788A277,0x2985F119,0x250C03E2,0xB5E223BC,0xECCD7080,0xC5E0734D,0xC4307C36,0xDF179878,0xE61E3D89,

Â  Â  Â  Â  Â  Â  0x7B935C23,0x0F804AD3,0xF30F1C86,0xE696AF13,0x8406FD37,0x7307BCCB,0x76847081,0xC307C028,0x08FB878C,0xE9F5BA0F,

Â  Â  Â  Â  Â  Â  0xC8E1004C,0x200C99F9,0x0E791E5C,0x8D717838,0x2971F470,0x1A9B1E20,0xE03B40E2,0x603C7CD1,0x7EFA3843,0x68F00CC0,

Â  Â  Â  Â  Â  Â  0x76D1E03D,0x16304F00,0x22B0C708,0xAE768E10,0xC463840D,0x7081A807,0x3500E88C,0x09B18E10,0x830C63A4,0x1E0683E7,

Â  Â  Â  Â  Â  Â  0x8E102FED,0x840ECFDE,0x004B85A3,0xBEC898E1,0x6D307840,0x0816E5AF,0xBC0F9A27,0x4147BE02,0x3840D13C,0x15E07ED1,

Â  Â  Â  Â  Â  Â  0x0E3A2708,0x44E102BC,0x202F01CF,0xE03E189E,0x27802BBA,0x5EF80AD5,0x1C24F020,0x3C2817BE,0x05EF8089,0xE1224F06,

Â  Â  Â  Â  Â  Â  0x93C3817B,0xE05EF828,0xBE2A24F1,0x893C4417,0x0085EF8E,0x7BE2624F,0x5893C141,0xF1505EF8,0x17BE3624,0x83893C34,

Â  Â  Â  Â  Â  Â  0x4F1D05EF,0xC17BE2E2,0xF87893C0,0x24F1305E,0x7C17BE01,0xEF84493C,0x924F1705,0xC3C17BE0,0x5EF8A493,0x1924F108,

Â  Â  Â  Â  Â  Â  0x3C6417BE,0x85EF8149,0xE2D24F18,0x93C1217B,0xB85EF874,0xBE3324F0,0xC93C3217,0x1C85EF82,0x7BE2B24F,0xBC93C7A1,

Â  Â  Â  Â  Â  Â  0xF0985EF8,0x17BE20A4,0x84293C16,0x4F0385EF,0x617BE30A,0x84B293C6,0x01EBDF53,0xB8DFD4F1,0x34E10303,0x3C402AC8,

Â  Â  Â  Â  Â  Â  0x81E0360D,0x869C2057,0xA7081C5E,0xC2051611,0xAF03CC69,0x3A4D3840,0x534E101B,0xC205781D,0x8131CA69,0x147F1A70,

Â  Â  Â  Â  Â  Â  0x39A69C20,0xD3840AF0,0x9E01B3B4,0x6B4CF566,0x7BDA7081,0xF69C2057,0xA70815D9,0xC205777D,0x815D88E9,0x576A3A70,

Â  Â  Â  Â  Â  Â  0xDC8E9C20,0x93A70815,0xE9C20576,0x70815D94,0x2057733A,0x15DD2E9C,0x77CBA708,0x8AE9C205,0x2670815D,0x9E200E65,

Â  Â  Â  Â  Â  Â  0x55681A09,0x1D399C20,0x6533C010,0x8399C205,0xD33C01C1,0xC59C20DE,0x67081798,0x7C046749,0x57BE1F2F,0xBDE102B9,

Â  Â  Â  Â  Â  Â  0x84032E7C,0x0CB5F2F7,0xC52BDE10,0xAF7840F8,0x7803E394,0x6780A3D6,0x551B3CBD,0x19F59C20,0xFD670801,0x6CF00576,

Â  Â  Â  Â  Â  Â  0x1B3C0140,0x0D9C2052,0x9B3840CF,0xCE102BB0,0x840AEE26,0x02BBC9B3,0xAECA6CE1,0xBA9B3840,0xA6CE102B,0xCD9C2065,

Â  Â  Â  Â  Â  Â  0x670800D8,0x01624F4B,0x10C56CE1,0x755B3840,0x670803E2,0x007C4FAB,0x89CD6CE1,0xAD9C200F,0x8401F13D,0x02BB75B3,

Â  Â  Â  Â  Â  Â  0xAEFD6CE1,0x51B73840,0x087EF081,0x766F102A,0x102830CF,0xE2FBA45E,0x99917840,0x56E10053,0xB8405CF0,0x103B3E15,

Â  Â  Â  Â  Â  Â  0x0A4DE56E,0x9C891784,0x697D7081,0xAF5C207A,0x9708151E,0x02900FD3,0x81FE72E1,0xFE5C2018,0x840F703F,0xCE07602B,

Â  Â  Â  Â  Â  Â  0xF2457081,0xAE101940,0x02281C28,0x03CE95C2,0xD2B8402A,0x08094073,0xC80E0657,0xFAAAE103,0xC2068BB3,0x0767B5D5,

Â  Â  Â  Â  Â  Â  0x8A1B8404,0x1AE103C3,0x01B7B3FD,0xB1A635C2,0x398D7080,0xC5135E01,0xB84E0807,0xC196F626,0xF4CD7080,0xAE1025EA,

Â  Â  Â  Â  Â  Â  0x5A69BD29,0x781BA07C,0x101F054D,0xDB82E11F,0x5C205C01,0x0B803F70,0x071E0B84,0x217080F0,0x103900F2,0x301D442E,

Â  Â  Â  Â  Â  Â  0xE885C200,0xB8406403,0x1021B8B0,0x0A2D2C2E,0x8BCB0B84,0xE782E102,0x5C200201,0x01403D88,0xAF5E0B84,0x17080F8C,

Â  Â  Â  Â  Â  Â  0xC2023656,0xB07F588B,0x117840C7,0x18F60F1B,0xF3622F08,0xE1009EC1,0x7C01F782,0x7B245C20,0x784094EE,0xF60FDB11,

Â  Â  Â  Â  Â  Â  0xE2170814,0xE101500E,0x8773C8A2,0xF885C205,0xB8403403,0x69DCFE48,0xE2917080,0xE100D3B9,0x8773F4A2,0xCA45C206,

Â  Â  Â  Â  Â  Â  0x84074EE7,0x8CAF890B,0xE517081D,0x90343B9E,0xB68C242E,0x046D2BC3,0x039F05C2,0xA8B84064,0x80A1DCF0,0x00E92170,

Â  Â  Â  Â  Â  Â  0x2A2E102B,0x2048773F,0xC03E485C,0xBE0B8405,0x7080C807,0x7195ED21,0xDF82E100,0xC206532B,0xB003F485,0xF990B840,

Â  Â  Â  Â  Â  Â  0x708138CA,0x0300F0A1,0xBEE42E10,0x5C203632,0x6C657BC8,0x7050B840,0x17081E80,0x083B9FB5,0x1FF82E10,0x85C20320,

Â  Â  Â  Â  Â  Â  0x40F403E2,0x807A50B8,0xCA17080E,0xE101D00E,0xA32BF942,0x8A85C203,0xB840B403,0x0C807010,0x5E6A1708,0x2E101D19,

Â  Â  Â  Â  Â  Â  0x3A32BED4,0x7FA85C20,0xB840B465,0x0C807810,0x0FDA1708,0x42E10010,0x204201F7,0x803DE85C,0x3D0B8403,0x70810807,

Â  Â  Â  Â  Â  Â  0x1900E821,0xBF042E10,0x5C204332,0x0A403908,0x07A10B84,0x21708148,0x102900EC,0x201F842E,0x9985C205,0xB8404803,

Â  Â  Â  Â  Â  Â  0x09007B30,0x0E221708,0x42E10290,0x200201DB,0x803A185C,0xF30B8409,0x70815007,0x3C204BE1,0x8155BBF8,0x0E07FCF0,

Â  Â  Â  Â  Â  Â  0xF9E1024F,0x045E1D8F,0x3B600BC2,0x178408AC,0x1AE87150,0xFE702F08,0x5E1036E0,0x20C1F910,0xE120BC20,0x78403C83,

Â  Â  Â  Â  Â  Â  0xA20784C1,0xA982F080,0xE101040F,0x701EB305,0xE60BC200,0x840C6038,0x08B73C17,0xCD885E10,0x7C052CAB,0x40F84C47,

Â  Â  Â  Â  Â  Â  0xF8EF0999,0xBC207867,0x80458FA3,0x67218EF0,0x463BC205,0x840C83B8,0x20F28977,0x6681F016,0x3F5C2E13,0x3C200A1C,

Â  Â  Â  Â  Â  Â  0x32FBCFD8,0x1FB07840,0xF080E5F7,0x03EE2CE0,0x7EC1F103,0x1BB94C1F,0x77478403,0x0808007D,0x586B3E8F,0x9C843C20,

Â  Â  Â  Â  Â  Â  0x784071FB,0x880F2070,0xF60F081C,0x01DD01FF,0x3E1021E1,0x3C205340,0x0407BE04,0x07078409,0x88028C78,0x01F8C10F,

Â  Â  Â  Â  Â  Â  0x04B21F59,0x3BF943C2,0xC784011B,0x10203932,0x41EA5B1E,0xD43C2041,0x40D743E6,0x1DEBEC78,0x70838F08,0x043C2049,

Â  Â  Â  Â  Â  Â  0x0D3E07D6,0xBA45C784,0x1C1E1018,0x070583D8,0x7D0383C2,0x784090B0,0xA60F7808,0x0E0F0809,0x01ADC1E2,0x0FA6F1E1,

Â  Â  Â  Â  Â  Â  0x07078406,0x8075E0F9,0x1EA0E0F0,0x1E101302,0x2843CC1C,0x8383C206,0x8401B93D,0x10235827,0x43DC1C1E,0xC3C204A6,

Â  Â  Â  Â  Â  Â  0xBC907F6C,0xF0707840,0x08110D0F,0xA1F0CE0F,0xC1E10321,0x6EB43E21,0x852C3C20,0x84089D07,0x0830BA27,0xD0589E10,

Â  Â  Â  Â  Â  Â  0x3C20784D,0x6C9BD0B1,0x61627840,0xF081E937,0x1A6F22C4,0x5561E103,0x2036523F,0x9BB8B13C,0x58784021,0x1A280F0D,

Â  Â  Â  Â  Â  Â  0xF1AB0F08,0x9E101684,0x4FCDE658,0x93B13C20,0x78406003,0xB60F98D8,0x124F081B,0x3C207F79,0xFD87E338,0x8707840E,

Â  Â  Â  Â  Â  Â  0x811470F2,0x1ED0E0F0,0x1E1019CE,0x85C3FA1C,0xC383C204,0x40B0B878,0x077FB278,0xE0F080C4,0x1F211F30,0xD61C1E10,

Â  Â  Â  Â  Â  Â  0xC201FA23,0xF7B9C383,0x8707840D,0x80BD88F7,0x1FEBF0F0,0x1E103FDF,0xCD03EB7E,0x8F53C204,0x0F08019A,0x0151F88E,

Â  Â  Â  Â  Â  Â  0x99C1E103,0x20236A3E,0x47D2383C,0xA7840FDB,0x101A3D33,0x79611C1F,0x7840A80C,0x018FE470,0x8E0F081D,0x01F431FE,

Â  Â  Â  Â  Â  Â  0x3C31C1E1,0x3C206E46,0x80B9A703,0x1F3B88F0,0x33E00690,0xB1C1F7BC,0x04CF0834,0x103900F8,0x076D699E,0x7F6383C2,

Â  Â  Â  Â  Â  Â  0x784040EC,0x138F1C70,0x8E0F081D,0x003171EB,0x3E71C1E1,0x3C20262E,0xE5C7EE38,0x59678408,0x1E1008B2,0xDA23CD19,

Â  Â  Â  Â  Â  Â  0xFAB3C205,0x70784069,0x16478F7C,0xA97ACF08,0xF1C1E100,0x2049DE3F,0x02D79B3C,0x3DAB6784,0x1D9E1014,0xB3C2046C,

Â  Â  Â  Â  Â  Â  0x08171D73,0x09F04E0F,0x7B3E0020,0x509C1F1A,0x441CF081,0x39F00506,0x0F081713,0x5289EC4E,0x89C1E101,0x206C313F,

Â  Â  Â  Â  Â  Â  0x2789383C,0x07840D86,0x08C4F927,0xA4E0F081,0x1024589E,0x79689C1F,0x3E003D62,0xE102DA37,0xF13DC9C1,0x383C207B,

Â  Â  Â  Â  Â  Â  0x041127F9,0xF0A70784,0xF0801124,0xA49F14E0,0x9C1E1005,0x077493D2,0x7E5383C2,0x7840EE92,0xD24FAA70,0x4E0F080D,

Â  Â  Â  Â  Â  Â  0x007E49ED,0x3C69C1E1,0x3C207FA9,0x3D27AD38,0xA707840B,0x006164FD,0x051DBE7C,0x7BD383C2,0x7840CCF2,0x5E4FFA70,

Â  Â  Â  Â  Â  Â  0x27E7C001,0x383C205E,0x09BF27A3,0xF2670784,0xF080C014,0x029ECCE0,0x45AE101E,0x0000028F,

Â  Â  Â  Â  };

Â  Â  Â  Â  // created: 2024-09-10T23:29:36.232Z

Â  Â  Â  Â  // unicode: 16.0.0 (2024-09-10T20:47:54.200Z)

Â  Â  Â  Â  // magic: 2 6 8 11 14 15 18

Â  Â  Â  Â  internal static readonly uint[] NF = new uint[] { // 5090 bytes

Â  Â  Â  Â  Â  Â  0x04EBBB7B,0x3A2C208D,0x0F4901C0,0x8ABC1EC8,0x01A105CF,0x11110101,0x080D0B4C,0xE2788808,0x0FD80FDE,0x801FC2B3,

Â  Â  Â  Â  Â  Â  0xAC71FE32,0x322C87EF,0x81FA5832,0x5C461E59,0x1D1498B8,0xB0732888,0x668669C7,0x5C8687B4,0x129BC61C,0x2F15783C,

Â  Â  Â  Â  Â  Â  0xE329DC7B,0x53D8F91A,0x7D101746,0x080D0FC0,0x0D088808,0x0D0D8908,0x18880808,0x4E8703C3,0x764924EF,0xC1C18C2A,

Â  Â  Â  Â  Â  Â  0xE491C1C1,0xF8E01E4E,0x48CF7A03,0x8F598DAE,0x61C51F61,0x0A386529,0xB542CAD2,0xD14F13DA,0x223027B1,0xC7D1543A,

Â  Â  Â  Â  Â  Â  0xF8C0E3B9,0xC08EB1C7,0xFB51CB03,0x87A03E50,0xF4EEC602,0xEA10F5D0,0x85B44FEF,0xCE0180E8,0x7A583235,0x4107CF3C,

Â  Â  Â  Â  Â  Â  0xC7C8307A,0x8FC61A6A,0x4044402E,0x42304868,0x45C2C302,0xB5114500,0x39587000,0x604F470C,0x0E8D7310,0x5C785444,

Â  Â  Â  Â  Â  Â  0x374F187C,0x9AFFC7E9,0x952790D0,0xA9D92492,0x07070630,0x3B924707,0x652F81F9,0x3F8FC324,0xDD8CB64F,0x07EBA1E9,

Â  Â  Â  Â  Â  Â  0xD10B6926,0x65FC0301,0x80020E91,0x3861CAC3,0x3883027A,0x54FA5C91,0xFB73FB30,0x92652E5A,0x8F49A4DA,0x0A8AB868,

Â  Â  Â  Â  Â  Â  0xEC7F441F,0x128AF415,0xAB7C7174,0x7F6F5E86,0x47C35F75,0xE7B7D215,0x1FC680FA,0xFFD4E2CC,0x7FB7CAA6,0xCBE8883E,

Â  Â  Â  Â  Â  Â  0x2B0BE151,0x4F9EF27E,0x7BE37F2F,0x8BF3C604,0x10F2F11E,0x91D36386,0x1F57A1E3,0x7772F578,0x3D8CB8E3,0x6889EBDD,

Â  Â  Â  Â  Â  Â  0xB2FA9F0F,0x7A280F99,0xAE43D6E9,0xB2F0779E,0xFEA1CFBC,0x0517A7EC,0xF03EAF5C,0x1EB65BE3,0x4D21F52C,0x60F6AE1F,

Â  Â  Â  Â  Â  Â  0xBC1E07A3,0x4A73E0C9,0x508EF19F,0xD0788ACF,0x1ED943D6,0x8788F560,0xE2CD8D07,0x148F47A1,0x979DB3BA,0xA1FA603E,

Â  Â  Â  Â  Â  Â  0x60F7F6E8,0x3D32A7B8,0xB079E9B6,0xC1F2AB1F,0xB9746F60,0xF9E93C7D,0xABCF31C1,0x67D93479,0x3C2EBCFA,0x7526EF09,

Â  Â  Â  Â  Â  Â  0xCFD27B24,0x2765E661,0x23F6B79F,0xCC147DD1,0x73AE0FEC,0xD1307803,0x531E47B3,0x1F7021FA,0x968EF44A,0x24FA20CF,

Â  Â  Â  Â  Â  Â  0x73D23B8C,0xEF714ECB,0x2140FDB6,0x69F9921F,0x7E7CCF09,0x8D43D70B,0x21F0865F,0x6F4FEF3D,0xCCA27A01,0x92DEFD83,

Â  Â  Â  Â  Â  Â  0xF78ABEFD,0xFE723F42,0x156F516D,0x07D8967D,0xCD30BCA1,0xCF3425E7,0xCCE0788F,0xD21E83C3,0x8FEC59F6,0x7BC40F6A,

Â  Â  Â  Â  Â  Â  0xEC43DD60,0x48F74D1E,0x3D0FD794,0x368EED80,0xF84F2FAA,0xE007A47C,0x63E92FBD,0x965E5FA4,0xF4787E73,0xCAE219DC,

Â  Â  Â  Â  Â  Â  0x3BBE40F3,0x29E9B9C2,0x7EA68F54,0xEA15D92C,0xE56E1273,0xA5BAF0F4,0x629C3597,0x11EF9C3E,0x70F13AE5,0x3CEFA7A2,

Â  Â  Â  Â  Â  Â  0xBBFDF642,0x407B3B0F,0x1CE8C9C6,0x038BDCF0,0x0EF163D5,0x78CACF28,0x0E0CC080,0xF57C5F3A,0x6CBD0343,0x9F2301E2,

Â  Â  Â  Â  Â  Â  0x8ED9F2C8,0x9CC79367,0x0E91EF4C,0xA987B8F7,0xC29E4BDC,0xA79ED8F0,0xD18A7DEC,0xF9F1068F,0xB0505F40,0x1C6A079A,

Â  Â  Â  Â  Â  Â  0x76981E9D,0x3C1CB9D4,0x1AB5EC00,0x19F7245F,0xE15F1F7C,0x213EAB0B,0xEF7A19E3,0x9FA8F9E4,0x1887BA27,0x3DE7363D,

Â  Â  Â  Â  Â  Â  0xF5DF9F5D,0x8B70F114,0x991C6147,0xB6770E8E,0x5C9DFC87,0x48F5791E,0x2447828B,0xF3E2E03D,0xE9B6BE01,0x226FAFD5,

Â  Â  Â  Â  Â  Â  0x333CC8BA,0x0F7019E0,0x7CCB3922,0x9307E992,0x21EDEF3C,0x163B33AF,0x0CFF4A3C,0x4FAE1AF9,0x2BF1FD7F,0x08F3463E,

Â  Â  Â  Â  Â  Â  0x4775FF1F,0x3BD0D57B,0xF7799F75,0x3E0FF8E0,0x27CC90F5,0xFF813DF5,0xF13F50C3,0x7E73DEF0,0xF3C3D278,0x72A9DFCF,

Â  Â  Â  Â  Â  Â  0x0C1739FD,0x6F086A20,0xF5F57A92,0x66C1EBA5,0x2078880F,0x61EC41CF,0xB9436905,0xFCC13CAF,0x645F7641,0x88B748F6,

Â  Â  Â  Â  Â  Â  0xD2D34B63,0x5B8B2ACE,0x3166C9C0,0x3B849637,0x1064C1C4,0xEDBAB90B,0x2A7580E8,0x01C14079,0x567330E8,0xAA9DB039,

Â  Â  Â  Â  Â  Â  0xB40759EE,0x4444C624,0x8207470D,0xCEB91DF1,0x39A36524,0x14E8EDE2,0x3C9C15B3,0x89B7401E,0x8E68D263,0x60BB230F,

Â  Â  Â  Â  Â  Â  0x4821E06C,0x7CB19787,0xEFBFF132,0xF30EBFBA,0xDD7F978F,0xFA29EA9A,0xA3A63624,0x402E88D4,0xE4C89E93,0xDBB335CE,

Â  Â  Â  Â  Â  Â  0xE361CE5E,0x88437120,0x8E44CEDA,0xF898AB48,0x83BE8626,0x66771C09,0xC8C38A33,0x1400E3E1,0xD03BA632,0xC7538EF8,

Â  Â  Â  Â  Â  Â  0x1D59EC87,0x0F3A8E5A,0xFE607BA6,0x9474D61A,0x0EC8D9DA,0xA4070101,0xC459BABC,0x614E571F,0xD303AD87,0x477767C1,

Â  Â  Â  Â  Â  Â  0x55D48385,0x85D76F6D,0x72C4CC93,0x1BA3708E,0x730228EA,0x63BD32A7,0xC8E719C7,0xB83A8470,0xB51626DD,0x240D8DA2,

Â  Â  Â  Â  Â  Â  0xAB173865,0x049FC2FB,0xF763F846,0xEFA9C9FE,0x5AFF7D4D,0x7A9E8F3B,0xEBDFD0D7,0xA6BE94F6,0x5FDC686E,0x165FDF8E,

Â  Â  Â  Â  Â  Â  0x26D234FF,0x69AE9AB5,0xF71EBF54,0xAFE5F36F,0xA72A3520,0xEC0F2FE8,0x0DF03D6F,0xCBF88318,0x23CBF8E3,0x5F58BB4E,

Â  Â  Â  Â  Â  Â  0xDBFEE27C,0xE2DBFE11,0xFC08DE33,0xA1A49746,0xFFD1BD84,0x4D01044D,0x1BCA4915,0x5D5C4C41,0x57F00042,0xC567F682,

Â  Â  Â  Â  Â  Â  0xB2F006FC,0xBF91D2BF,0xB288EAD2,0xA73C2CDD,0x69330C67,0x1F4E5098,0xB2620ACA,0xED87268E,0x7C41DEC3,0x87D4F740,

Â  Â  Â  Â  Â  Â  0x07BE1D44,0x03FEB751,0x57F4D714,0x9757F34F,0x1255961F,0x46BF9E33,0x35FC0989,0x652B0FB4,0x6F78DB9A,0x56FBC675,

Â  Â  Â  Â  Â  Â  0xE6BF8146,0xD1A6BF85,0xBF94ACB2,0x96BFB056,0xDAABA8DB,0xBFFDF715,0x632BC01F,0xEBFC2306,0xFF6BFAB4,0xFA00EBFD,

Â  Â  Â  Â  Â  Â  0xCC0EAF6B,0x103E985B,0x18D207E1,0x3E50D952,0xC43FE4D0,0xE4C43FDF,0x0A092607,0x901FF92A,0xFE3FEFF9,0x9FC227EB,

Â  Â  Â  Â  Â  Â  0x3C7BF627,0xFF1D81F1,0x2A3EF2A9,0x75773FC0,0xFE9E07DC,0x4A235420,0x3E66C018,0x07FB64A8,0xE61BF9AD,0x5D5A1BF9,

Â  Â  Â  Â  Â  Â  0x8780485F,0xF4903251,0x849561A4,0x604D2434,0xCB5A0326,0xDFCB18DF,0x9778E698,0xBFBF34D2,0x31BFB5B1,0x7F36B9CD,

Â  Â  Â  Â  Â  Â  0xCD0FC6C8,0xF035D654,0x61F8B50F,0xA6FEDA82,0x21A6FE3F,0xCC07670F,0x61FD8B0F,0xECEC3E6B,0x11825F80,0x05A4C2F4,

Â  Â  Â  Â  Â  Â  0x33EF6ABF,0x2397BF18,0x896C6224,0xFF39F37F,0x011FF5E4,0xB507A56F,0xC5CDFD11,0x2E79CDFC,0x11F650F3,0xD8123F2B,

Â  Â  Â  Â  Â  Â  0xE07526FC,0xFA6B9BF8,0x28FE939B,0xEE651F82,0x6FE2716F,0x8CA3F0D1,0xA190547F,0xC56FE935,0x6FFD8DE0,0x415BFACA,

Â  Â  Â  Â  Â  Â  0xF8CF5BFE,0x58CD6B5B,0x306B01F8,0x60F91BA3,0x56FED2B2,0xE2D6FEEF,0xFAE34D0F,0xF31F8C98,0x6D6FF826,0xFAC36FE1,

Â  Â  Â  Â  Â  Â  0x96B7F658,0x35BF9C33,0x063515E9,0x8FD1EC7E,0xF0A23243,0xD7E9FC51,0xFF79E9FC,0x6DFC7C6D,0x6D6DFE48,0xA60E6DFD,

Â  Â  Â  Â  Â  Â  0xD1EDFD35,0x974EEDFC,0x1CFFEDFD,0xEFF6FEBC,0xE7813EF3,0x04FBA827,0x5B84F8A9,0x13256565,0x9F9844FB,0xE4EFEE68,

Â  Â  Â  Â  Â  Â  0xFAA4EFE0,0xEFE4D4EF,0x1E2FFFE4,0xF3762FEB,0x6AAF72EF,0xD2EAFF2B,0xE5249F29,0x838BAAEF,0x3ABBF86A,0x49F48615,

Â  Â  Â  Â  Â  Â  0xC1A93F76,0xCE9D1527,0xDFD4EEBF,0xC638E69D,0xFF62C9F3,0x1EFE850D,0x451EFFB4,0x48F7F486,0xC14F973E,0x12F629FC,

Â  Â  Â  Â  Â  Â  0xD15EFEC2,0x7BF8488E,0xC914FDA3,0x7F7056FF,0x9F41A16F,0xDADFFFF2,0xFD0DEFEE,0x6A7FE353,0xBFB6D099,0x6FBF89EF,

Â  Â  Â  Â  Â  Â  0xFFED4FC0,0x34C62469,0xFBB34FA1,0xF5D252EF,0xEFFE92EF,0xEBF7F3DA,0xF227F7F9,0xB0BB07F7,0xB3007FA4,0x0803FDC9,

Â  Â  Â  Â  Â  Â  0xFCCA03FE,0xE5FF5203,0xCEA3FD64,0xE9B7067F,0xCFEA867D,0x6781F448,0x320A15FF,0xDC7FDE3E,0xD063E65F,0x2CBE1F13,

Â  Â  Â  Â  Â  Â  0x088667E1,0xF168F82F,0x2023AD1F,0xE0FF7061,0x96E0FF16,0x14C499A3,0x2187BF36,0xBC30E72C,0x7F9C80AA,0xD9238770,

Â  Â  Â  Â  Â  Â  0xE0C3FFCE,0xC0449B3F,0x4851FE80,0xFFC391FE,0xA3FE64A1,0xA3FE4334,0xFF7F0E75,0x239F91B1,0x6029252C,0x189BBD3C,

Â  Â  Â  Â  Â  Â  0x3BA6AEF2,0x85CFA6A1,0x7A16B9F9,0xE7F4D73E,0x47FA0A8E,0xDC47F91A,0xB03CFA8E,0xEBEC479F,0x15F7FE73,0x73FE681D,

Â  Â  Â  Â  Â  Â  0x9F3EE3A0,0x76F6D4DD,0x3747FA50,0xAD6B47FA,0xFE5CC398,0x487E68B1,0x69A8FF11,0x47F24733,0x3547F193,0xE27F90BF,

Â  Â  Â  Â  Â  Â  0x427FA687,0xFCF5B9DB,0x13FDBD13,0xF6DE1E1D,0xDB1F39A5,0xC2C9FE5A,0xBF3389FE,0x0797F95C,0xF9E327F8,0x0AFDDDEF,

Â  Â  Â  Â  Â  Â  0xF7629F6E,0x53FDE653,0xFECC1C03,0xBE6390C7,0x3D3FC262,0xF5A4FFC2,0x3FC854FF,0xFE3A22FD,0x19FED719,0xE612BF8C,

Â  Â  Â  Â  Â  Â  0x4758AA57,0x32BE58D3,0xC06AFFF6,0x11FBDB3F,0xD5F6C0E3,0x7ABEBB31,0xD46F3FC3,0xFFF99EFF,0x6E61DADE,0xE67CFF43,

Â  Â  Â  Â  Â  Â  0x6BF4335F,0x25458501,0x5FEC0D44,0x271C6C44,0xC98F0180,0x3EA9D9B1,0x88E63092,0x0D99AC18,0x1D2BC55E,0xBCC7ECF8,

Â  Â  Â  Â  Â  Â  0x684903D5,0x44404040,0x6C484068,0x40404068,0x981E28C4,0x612E924D,0x9E7909E0,0xB2490264,0x079AB23B,0x280621DB,

Â  Â  Â  Â  Â  Â  0x93126999,0x50BD6778,0x92492493,0x1A165914,0x49249249,0xE8596452,0xB316C00F,0xF696281E,0x1D464740,0xFAA21993,

Â  Â  Â  Â  Â  Â  0x47599CB5,0xD0A09F3B,0xD0A0A0E0,0xC4B8C0E0,0x90D080F0,0xA8E6F8E0,0x48E098CC,0xB01F0617,0x1D9E9814,0x1FDE1152,

Â  Â  Â  Â  Â  Â  0xA8B03A9E,0x47070740,0x38F8F4EE,0xAC7198BA,0xEB946636,0x7B27B8D0,0xD8507950,0xC3DA7BD1,0x0E2E0E4E,0x0C69CA8E,

Â  Â  Â  Â  Â  Â  0x0D0C080B,0xF40E0A0A,0xDA6EBF41,0xF3B60E41,0x221F43EB,0x97834928,0x801FB4A4,0xE960C8BB,0x8D87C531,0x5D7EAFB1,

Â  Â  Â  Â  Â  Â  0xC1E8881F,0x71AB1F40,0x81415118,0x53205054,0x03431282,0x52B09480,0xC587C464,0x253FA00E,0x20710859,0x0E011144,

Â  Â  Â  Â  Â  Â  0x507C4441,0x88443850,0x8CDD8810,0x3DD9C27B,0x030901DD,0x6219361A,0x02A05429,0x00200102,0x00000030,0x03A2E202,

Â  Â  Â  Â  Â  Â  0x00091511,0x9C21A111,0x20200000,0x80084000,0x04400130,0x00189080,0x80004040,0x02610010,0x21000880,0x774F7518,

Â  Â  Â  Â  Â  Â  0x7B4F774F,0x774F774F,0x674F774F,0x774F674F,0x774F774F,0x7B4F774F,0x774F774F,0x674F774F,0x774F674F,0x774F774F,

Â  Â  Â  Â  Â  Â  0x3A7AB74F,0xBA7B3A7B,0xDA7BBA7B,0xBA7BBA7B,0xBA7B3A7B,0x5A7BBA7B,0xBA7BBA7B,0xBA7B3A7B,0xBA7BBA7B,0xBA7B3A7B,

Â  Â  Â  Â  Â  Â  0xBA7B3A7B,0xBA7BBA7B,0xBA7BBA7B,0xDA7BDA7B,0xD3D5BA7B,0x33DDD3DD,0x9EFA9EC4,0xF754F711,0xF7D4F7D4,0xBBA7AA2C,

Â  Â  Â  Â  Â  Â  0xBBA7BBA7,0x473DD467,0x7B7D1D01,0xDCD3D9F6,0x6C73DCD3,0x4E0F88D2,0xF601E867,0xAACCF6D4,0xBD27B3A7,0xD3D940E7,

Â  Â  Â  Â  Â  Â  0xD3DCD3DD,0xD3DCD3DD,0xD3DF53DD,0xD3DAD3DD,0xD3DAD3DD,0xD3DFD3DD,0x9EE433D9,0xF734F641,0xB7A7AF2C,0x73DE00E7,

Â  Â  Â  Â  Â  Â  0xBCC9D2E2,0xF675BCE7,0x0485C4BE,0x84444404,0x25370DF4,0xA0202425,0x3C253F20,0x130E2422,0x9C4B5382,0x0813D894,

Â  Â  Â  Â  Â  Â  0x49D9A80F,0x7B3CD3C3,0xDDD3DE06,0x0073D8D3,0xA7B041D2,0xA7B3A7B3,0xE7BEA7BB,0x7303A080,0xBA7BE0CF,0x9A7BBA7B,

Â  Â  Â  Â  Â  Â  0x4E7B9A7B,0x1DEBE82E,0xF38A96D0,0x413116CE,0x985852ED,0x837642E2,0x436D2B81,0xCB0AFD11,0x0300BC3A,0x224672D7,

Â  Â  Â  Â  Â  Â  0x517567AE,0xC45AC840,0xF028211D,0x16109718,0x3C38D616,0xEFE34F8C,0x0B0B084B,0x63D9DC6B,0x0202027C,0x17064202,

Â  Â  Â  Â  Â  Â  0xD7A0A010,0xF674F6F4,0xF774F774,0x00E7AC2C,0xD3DDD3D8,0xD3DDD3DD,0x10C073DD,0xE9EF5075,0xE90939EE,0xD9D3D814,

Â  Â  Â  Â  Â  Â  0xDDD3D9D3,0xDDD3DDD3,0xD9D3DDD3,0x039E88B3,0x4F774F70,0xCF674F77,0xA6F4149B,0x9EEE9EC4,0x9EEE9ECE,0x9ECE9EEE,

Â  Â  Â  Â  Â  Â  0x9EEE9EEE,0xF5459EEE,0x4ACCF774,0xA7B5A1D4,0xA7BDA7BB,0x314DE7BB,0x4F6CD37A,0xCF774F67,0x7A614A21,0xB4DE9F43,

Â  Â  Â  Â  Â  Â  0xD3DDD3D9,0xD3DDD3DD,0xD3DDD3D9,0x922873DD,0xE9ED3874,0xE9ECE9EE,0xE9EEE9EE,0xE9EEE9EE,0xE9EEE9EC,0xE9ECE9EC,

Â  Â  Â  Â  Â  Â  0xC9EEE9EE,0x380A094F,0x7BD91C4C,0xD7E67BBA,0xDDD3DDD3,0x26F3DDD3,0x53F1BD0E,0xF1BD4514,0xEE766F4D,0xEEE9EEE9,

Â  Â  Â  Â  Â  Â  0x774F5859,0x774F774F,0xF4349BCF,0xEE9EECE6,0xEE9EFA9E,0x74F5859E,0x74F774F7,0x46C9BCF7,0x4515446F,0xB951D451,

Â  Â  Â  Â  Â  Â  0xC8E7BBA7,0xA8A28A20,0x774F65A3,0x774F774F,0xAF0695CF,0xBD4512D5,0xADAF1B36,0xD6BD4512,0x1275AF18,0xBC66DAF5,

Â  Â  Â  Â  Â  Â  0x6BD44876,0x38DAF1FD,0xE76BD451,0x513DDAF1,0xF1B36BD4,0xD4512ADA,0xDAF1AF6B,0x6BD4512F,0x3EDAF1EB,0xC7FDAF51,

Â  Â  Â  Â  Â  Â  0xBD44E0EB,0x5DAF1876,0x0EBD4512,0xC02475F9,0xDAF1B76B,0xEBD4512B,0x2E3AF1A8,0xA8EBD451,0x22020243,0x4B5E4222,

Â  Â  Â  Â  Â  Â  0x24924925,0x24F29249,0x49249249,0x4924F0D2,0xD2492492,0x3AF1D8EB,0x8671D7AE,0xEC6EBD86,0x2E00A0F5,0x79516FB1,

Â  Â  Â  Â  Â  Â  0xDC6C6B1D,0x8F5EB6EB,0xC3D7801B,0x471BAF00,0x70DE6E5E,0x0187D781,0x4445A7AF,0x0622423C,0x6A5F040E,0x3AF262DF,

Â  Â  Â  Â  Â  Â  0xD7D0B0C2,0x32DEBDA3,0x0A8A6F01,0x884B1808,0x54161787,0x15155013,0xC5AEF410,0xBF148377,0xDDE0376B,0x90534A10,

Â  Â  Â  Â  Â  Â  0x20A51482,0x60284535,0x8F512A98,0x3CC387A4,0x20202330,0x20202020,0x20202020,0x20202820,0x4208410A,0xD2308210,

Â  Â  Â  Â  Â  Â  0x04046559,0x04040404,0x04040404,0x04050404,0x41082144,0x46104208,0x4949393A,0x2EB8161F,0x3E84BF16,0x05AC25F8,

Â  Â  Â  Â  Â  Â  0x900A4924,0x050080A4,0x4A924028,0x7EE21383,0x1E6232D9,0xB09015C3,0x30CE9D15,0xB0A880A6,0x2A870011,0x6BA5D0E0,

Â  Â  Â  Â  Â  Â  0x038B17CB,0xC4831292,0x47044BC7,0x450CBF7C,0x241CC001,0x493E9751,0x836D0161,0xA5A22294,0x4940D088,0x4452D161,

Â  Â  Â  Â  Â  Â  0x05852524,0x8A520DB4,0x42229688,0x45852503,0x5191114B,0x00C008C1,0x61084830,0x8D100308,0x687D0800,0x20423C46,

Â  Â  Â  Â  Â  Â  0x10A060F4,0x000C0084,0x1818A1BD,0xA0418E06,0x04188911,0x008D111A,0x831E2184,0x21122340,0x688D0C0C,0x21622342,

Â  Â  Â  Â  Â  Â  0x42042004,0x200E061B,0x08111222,0x4C801643,0x8D100000,0x19212440,0x18800021,0x30182D00,0x10448062,0x20640002,

Â  Â  Â  Â  Â  Â  0x8C004600,0x30011800,0xA0046002,0x423D400C,0x020183D1,0x80204208,0x00000040,0x00122144,0x200910A2,0x32263A2A,

Â  Â  Â  Â  Â  Â  0x4011922A,0x54644C78,0x10E22324,0x4600200B,0x18200000,0x20000021,0x42082118,0x92AB8020,0xC4B80220,0x00000000,

Â  Â  Â  Â  Â  Â  0x046BA81B,0x380003D6,0x35D7543C,0xA8B54F62,0xA0BAD75B,0xA1C5A2E2,0xA161456E,0x001B2765,0x520304F0,0x80015180,

Â  Â  Â  Â  Â  Â  0x2998F757,0xE0000000,0x4768DB65,0x6C30320B,0x1905A044,0x86044788,0x0828610A,0x0421E0C2,0x682D0822,0x10A21744,

Â  Â  Â  Â  Â  Â  0x18026180,0x8E903200,0xC10D0C4E,0xD0223218,0x20B46682,0x3218C103,0x010D10A2,0x82D00088,0x830D0C4E,0x019A0B47,

Â  Â  Â  Â  Â  Â  0x320B4000,0xA4588C10,0x46431020,0x83D14214,0x02884201,0x086682D1,0x90FA2844,0x00360C01,0x47A82D81,0x84388834,

Â  Â  Â  Â  Â  Â  0x38882083,0x6D082384,0x0C3847A8,0x20E10E22,0xA000D0A2,0xE220D11E,0x20820E10,0x1E8E10E2,0x0688F500,0xF4708711,

Â  Â  Â  Â  Â  Â  0x10188060,0x1C8E11EA,0x1F184315,0x0862A986,0x5530C3E3,0xC540A10C,0x0C540A10,0xA6187C61,0x0F8C218A,0x843154C3,

Â  Â  Â  Â  Â  Â  0x2A9861F1,0x0C3E3086,0x0A10C553,0x40A10C54,0x87C610C5,0x7C6B17A1,0x843154C3,0x2A9861F1,0x8C3E3086,0x8980001F,

Â  Â  Â  Â  Â  Â  0x00000001,0x00000000,0x00000000,0x00000000,0x7A718000,0xD060407C,0xB13C1D38,0x302020C0,0xD898A268,0x31BE3544,

Â  Â  Â  Â  Â  Â  0x1802783B,0xF1A183B3,0x45C1D98D,0xECC6061A,0x89E292E0,0x13418101,0x0152C4C5,0x00000000,0x00000000,0x00000000,

Â  Â  Â  Â  Â  Â  0xE0000000,0x0001FA23,0x00000000,0x11451451,0x00000000,0x28A20000,0xE000228A,0x250684C3,0x08544A88,0x00000000,

Â  Â  Â  Â  Â  Â  0x20000000,0x50B80230,0x088957E3,0x574E1A58,0x8F482B75,0xCF8C8A8A,0xA7C5E43B,0xED700A1D,0x491962FB,0xC7A110F1,

Â  Â  Â  Â  Â  Â  0xAFDF014B,0x94927103,0x7E08388A,0x090FC272,0x0824B7C1,0xC13C3E39,0x181D54F2,0x3013F011,0x229971F8,0x04454202,

Â  Â  Â  Â  Â  Â  0xAB29FC19,0x7FBD4A09,0xE3DC7B8C,0xC7BAF71E,0x607B627D,0xF3076CC7,0xEE3FD845,0x34865CD0,0x301DD9F2,0x358EB1C6,

Â  Â  Â  Â  Â  Â  0x7236F81D,0x1A01FAEA,0x7BE48FE6,0xD572F810,0x40079AA0,0xE3DC7B8E,0xC7B8F71E,0x8F71EE3D,0x5EE3D463,0x9A7ACDE8,

Â  Â  Â  Â  Â  Â  0x3FE5C947,0x0A33EDE2,0x52794E15,0x9AE3D8A3,0x65EC2A3E,0x75AA34A8,0xC3986343,0xEE30D6F0,0x4C7B8C75,0xC1E4D863,

Â  Â  Â  Â  Â  Â  0x8371F068,0x901E183D,0xF61CA5DF,0xE763F7E0,0x38ACED35,0x9FEA1FE0,0xEA85DAA3,0x08E87434,0x00880002,0xC5E0362F,

Â  Â  Â  Â  Â  Â  0x81D8BC16,0xE2F07B17,0xC11C5E00,0x7178138B,0x512E2E86,0x41AE2F00,0x1783B8BC,0x09E2F00F,0x8BC1BC5E,0x03F1782F,

Â  Â  Â  Â  Â  Â  0xA0B7187F,0x00D1F82B,0x0D1C42BA,0xD1E42BA0,0x34ACBA00,0x46D59742,0x08D6B2E8,0x2BC1615E,0x01A5781C,0x83E0B3AF,

Â  Â  Â  Â  Â  Â  0x2307C111,0x4BC87C01,0x9050F810,0x2EA1F030,0x4343E041,0x5A30F8C2,0x917461E8,0x185B187C,0x3E00C61F,0xDDC74625,

Â  Â  Â  Â  Â  Â  0x29F020C0,0xFD71D051,0x85FA9B41,0x0A090C20,0x1EDA53D2,0x8BC68D71,0x5440406C,0xFE3494DA,0xD42BF520,0xB61A6724,

Â  Â  Â  Â  Â  Â  0xE8622942,0x6A4E3C97,0x65CB7741,0x6233A88C,0x259E07BA,0x9A940704,0x102F92C7,0x9640E1FE,0x98A8BD77,0x99A099F9,

Â  Â  Â  Â  Â  Â  0xEB24303F,0x052E3DC9,0x47460506,0x1E060606,0x5CB76641,0x31BBB36F,0xF5B2FC33,0x1F508D20,0xD34E8366,0x43EBEF9F,

Â  Â  Â  Â  Â  Â  0x713C3FB7,0xE3DF4120,0x8071EA32,0x24546261,0x6090E019,0x11300851,0x82208C12,0x080CC121,0xB80B0F09,0x4A3DC5A8,

Â  Â  Â  Â  Â  Â  0x00F5B1FC,0xC415765F,0xF84A085F,0xB6C8F562,0x29F2F1C7,0x27A541CD,0xE11F18A0,0xF03DB613,0x33920550,0xE2CE603F,

Â  Â  Â  Â  Â  Â  0x8C075921,0x0FE01C65,0xD21BF10C,0x41902F31,0xF4EB879F,0x20D1F313,0x2671664B,0xF539E46A,0xB0E6E807,0xD759F875,

Â  Â  Â  Â  Â  Â  0x1D3D8ED0,0xDB718111,0x404054DE,0xE7D046B8,0x0484B1C0,0x0D0A407B,0x40596E9D,0x501947A8,0x852D1A19,0x5CBE43D8,

Â  Â  Â  Â  Â  Â  0x5D7494F9,0x740B0B6E,0x780F74E0,0x560B99A1,0xCBB1E070,0x5F9A0F41,0x2F97A7CD,0xFAA1EC1D,0xF4101B10,0x2F2370A1,

Â  Â  Â  Â  Â  Â  0x1CB00FC0,0x71A77EC0,0x86123E70,0x8FEF387E,0xE530508B,0xC7067887,0x07A36B05,0x45722BF7,0xA212286A,0x4460A0C9,

Â  Â  Â  Â  Â  Â  0x86050784,0x18801A05,0x1E161816,0xB8A01810,0x0A0C0864,0x18161404,0x05062088,0x1D0B0813,0xAC0300D0,0xE468F2B6,

Â  Â  Â  Â  Â  Â  0xA1610364,0x10A05441,0x219300E2,0x41A1F109,0x81018101,0xCE80C5C7,0xE23E6A27,0x15D8BF91,0x0C270141,0xE0AA89E9,

Â  Â  Â  Â  Â  Â  0xC2752253,0x02781054,0x00000004,

Â  Â  Â  Â  };

Â  Â  }

}```

```cs [ENSNormalize.cs/ENSNormalize/GroupKind.cs]

ï»¿namespace ADRaffy.ENSNormalize

{

Â  Â  public enum GroupKind: byte

Â  Â  {

Â  Â  Â  Â  Script,

Â  Â  Â  Â  Restricted,

Â  Â  Â  Â  ASCII,

Â  Â  Â  Â  Emoji

Â  Â  }

}

```

```cs [ENSNormalize.cs/ENSNormalize/Whole.cs]

ï»¿using System.Collections.Generic;



namespace ADRaffy.ENSNormalize

{

Â  Â  public class Whole

Â  Â  {

Â  Â  Â  Â  public readonly ReadOnlyIntSet Valid;

Â  Â  Â  Â  public readonly ReadOnlyIntSet Confused;



Â  Â  Â  Â  internal readonly Dictionary<int, int[]> Complement = new();

Â  Â  Â  Â  internal Whole(ReadOnlyIntSet valid, ReadOnlyIntSet confused)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Valid = valid;

Â  Â  Â  Â  Â  Â  Confused = confused;

Â  Â  Â  Â  }

Â  Â  Â  Â  public bool Contains(int cp) => Valid.Contains(cp) || Confused.Contains(cp);

Â  Â  }

}

```

```cs [ENSNormalize.cs/ENSNormalize/NF.cs]

ï»¿using System.Collections.Generic;

using System.Linq;



namespace ADRaffy.ENSNormalize

{

Â  Â  public class NF

Â  Â  {

Â  Â  Â  Â  const int SHIFT = 24;

Â  Â  Â  Â  const int MASK = (1 << SHIFT) - 1;

Â  Â  Â  Â  const int NONE = -1;



Â  Â  Â  Â  const int S0 = 0xAC00;

Â  Â  Â  Â  const int L0 = 0x1100;

Â  Â  Â  Â  const int V0 = 0x1161;

Â  Â  Â  Â  const int T0 = 0x11A7;

Â  Â  Â  Â  const int L_COUNT = 19;

Â  Â  Â  Â  const int V_COUNT = 21;

Â  Â  Â  Â  const int T_COUNT = 28;

Â  Â  Â  Â  const int N_COUNT = V_COUNT * T_COUNT;

Â  Â  Â  Â  const int S_COUNT = L_COUNT * N_COUNT;

Â  Â  Â  Â  const int S1 = S0 + S_COUNT;

Â  Â  Â  Â  const int L1 = L0 + L_COUNT;

Â  Â  Â  Â  const int V1 = V0 + V_COUNT;

Â  Â  Â  Â  const int T1 = T0 + T_COUNT;



Â  Â  Â  Â  static bool IsHangul(int cp)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  return cp >= S0 && cp < S1;

Â  Â  Â  Â  }



Â  Â  Â  Â  static int UnpackCC(int packed)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  return packed >> SHIFT;

Â  Â  Â  Â  }

Â  Â  Â  Â  static int UnpackCP(int packed)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  return packed & MASK;

Â  Â  Â  Â  }



Â  Â  Â  Â  public readonly string UnicodeVersion;



Â  Â  Â  Â  private readonly ReadOnlyIntSet Exclusions;

Â  Â  Â  Â  private readonly ReadOnlyIntSet QuickCheck; // TODO: apply NFC Quick Check

Â  Â  Â  Â  private readonly Dictionary<int, int> Rank = new();

Â  Â  Â  Â  private readonly Dictionary<int, int[]> Decomp = new();

Â  Â  Â  Â  private readonly Dictionary<int, Dictionary<int, int>> Recomp = new();



Â  Â  Â  Â  public NF(Decoder dec)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  UnicodeVersion = dec.ReadString();

Â  Â  Â  Â  Â  Â  Exclusions = new(dec.ReadUnique());

Â  Â  Â  Â  Â  Â  QuickCheck = new(dec.ReadUnique());

Â  Â  Â  Â  Â  Â  int[] decomp1 = dec.ReadSortedUnique();

Â  Â  Â  Â  Â  Â  int[] decomp1A = dec.ReadUnsortedDeltas(decomp1.Length);

Â  Â  Â  Â  Â  Â  for (int i = 0; i < decomp1.Length; i++)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Decomp.Add(decomp1[i], new int[] { decomp1A[i] });

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  int[] decomp2 = dec.ReadSortedUnique();

Â  Â  Â  Â  Â  Â  int n = decomp2.Length;

Â  Â  Â  Â  Â  Â  int[] decomp2A = dec.ReadUnsortedDeltas(n);

Â  Â  Â  Â  Â  Â  int[] decomp2B = dec.ReadUnsortedDeltas(n);

Â  Â  Â  Â  Â  Â  for (int i = 0; i < n; i++)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  int cp = decomp2[i];

Â  Â  Â  Â  Â  Â  Â  Â  int cpA = decomp2A[i];

Â  Â  Â  Â  Â  Â  Â  Â  int cpB = decomp2B[i];

Â  Â  Â  Â  Â  Â  Â  Â  Decomp.Add(cp, new int[] { cpB, cpA }); // reversed

Â  Â  Â  Â  Â  Â  Â  Â  if (!Exclusions.Contains(cp))

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (!Recomp.TryGetValue(cpA, out var recomp))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  recomp = new();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Recomp.Add(cpA, recomp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  recomp.Add(cpB, cp);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  for (int rank = 0; ; )

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  rank += 1 << SHIFT;

Â  Â  Â  Â  Â  Â  Â  Â  List<int> v = dec.ReadUnique();

Â  Â  Â  Â  Â  Â  Â  Â  if (v.Count == 0) break;

Â  Â  Â  Â  Â  Â  Â  Â  foreach (int cp in v)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Rank.Add(cp, rank);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  int ComposePair(int a, int b)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  if (a >= L0 && a < L1 && b >= V0 && b < V1)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  return S0 + (a - L0) * N_COUNT + (b - V0) * T_COUNT;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  else if (IsHangul(a) && b > T0 && b < T1 && (a - S0) % T_COUNT == 0)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  return a + (b - T0);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  else

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  if (Recomp.TryGetValue(a, out var recomp))

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (recomp.TryGetValue(b, out var cp))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return cp;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  return NONE;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }



Â  Â  Â  Â  internal class Packer

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  readonly NF NF;

Â  Â  Â  Â  Â  Â  bool CheckOrder = false;

Â  Â  Â  Â  Â  Â  internal List<int> Packed = new();

Â  Â  Â  Â  Â  Â  internal Packer(NF nf)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  NF = nf;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  internal void Add(int cp)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  if (NF.Rank.TryGetValue(cp, out var rank))

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  CheckOrder = true;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cp |= rank;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Packed.Add(cp);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  internal void FixOrder()

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  if (!CheckOrder || Packed.Count == 1) return;

Â  Â  Â  Â  Â  Â  Â  Â  int prev = UnpackCC(Packed[0]);

Â  Â  Â  Â  Â  Â  Â  Â  for (int i = 1; i < Packed.Count; i++)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  int cc = UnpackCC(Packed[i]);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (cc == 0 || prev <= cc)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prev = cc;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  int j = i - 1;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  while (true)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  int temp = Packed[j];

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Packed[j] = Packed[j + 1];

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Packed[j + 1] = temp;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (j == 0) break;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prev = UnpackCC(Packed[--j]);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (prev <= cc) break;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prev = UnpackCC(Packed[i]);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  internal List<int> Decomposed(IEnumerable<int> cps)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Packer p = new(this);

Â  Â  Â  Â  Â  Â  List<int> buf = new();

Â  Â  Â  Â  Â  Â  foreach (int cp0 in cps)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  int cp = cp0;

Â  Â  Â  Â  Â  Â  Â  Â  while (true)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (cp < 0x80)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  p.Packed.Add(cp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else if (IsHangul(cp))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  int s_index = cp - S0;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  int l_index = s_index / N_COUNT | 0;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  int v_index = (s_index % N_COUNT) / T_COUNT | 0;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  int t_index = s_index % T_COUNT;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  p.Add(L0 + l_index);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  p.Add(V0 + v_index);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (t_index > 0) p.Add(T0 + t_index);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (Decomp.TryGetValue(cp, out var decomp))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  buf.AddRange(decomp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  p.Add(cp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  int count = buf.Count;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (count == 0) break;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cp = buf[--count];

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  buf.RemoveAt(count);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  p.FixOrder();

Â  Â  Â  Â  Â  Â  return p.Packed;

Â  Â  Â  Â  }



Â  Â  Â  Â  // TODO: change this to an iterator

Â  Â  Â  Â  internal List<int> ComposedFromPacked(List<int> packed)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  List<int> cps = new();

Â  Â  Â  Â  Â  Â  List<int> stack = new();

Â  Â  Â  Â  Â  Â  int prev_cp = NONE;

Â  Â  Â  Â  Â  Â  int prev_cc = 0;

Â  Â  Â  Â  Â  Â  foreach (int p in packed)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  int cc = UnpackCC(p);

Â  Â  Â  Â  Â  Â  Â  Â  int cp = UnpackCP(p);

Â  Â  Â  Â  Â  Â  Â  Â  if (prev_cp == NONE)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (cc == 0)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prev_cp = cp;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cps.Add(cp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  else if (prev_cc > 0 && prev_cc >= cc)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (cc == 0)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cps.Add(prev_cp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cps.AddRange(stack);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stack.Clear();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prev_cp = cp;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stack.Add(cp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prev_cc = cc;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  else

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  int composed = ComposePair(prev_cp, cp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (composed != NONE)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prev_cp = composed;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else if (prev_cc == 0 && cc == 0)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cps.Add(prev_cp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prev_cp = cp;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stack.Add(cp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prev_cc = cc;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (prev_cp != NONE)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  cps.Add(prev_cp);

Â  Â  Â  Â  Â  Â  Â  Â  cps.AddRange(stack);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  return cps;

Â  Â  Â  Â  }



Â  Â  Â  Â  // primary

Â  Â  Â  Â  public List<int> NFD(IEnumerable<int> cps)Â 

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  return Decomposed(cps).Select(UnpackCP).ToList();

Â  Â  Â  Â  }



Â  Â  Â  Â  public List<int> NFC(IEnumerable<int> cps)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  return ComposedFromPacked(Decomposed(cps));

Â  Â  Â  Â  }



Â  Â  Â  Â  // convenience

Â  Â  Â  Â  public string NFC(string s)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  return NFC(s.Explode()).Implode();

Â  Â  Â  Â  }

Â  Â  Â  Â  public string NFD(string s)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  return NFD(s.Explode()).Implode();

Â  Â  Â  Â  }



Â  Â  }

}

```

```cs [ENSNormalize.cs/ENSNormalize/DisallowedCharacterException.cs]

ï»¿namespace ADRaffy.ENSNormalize

{

Â  Â  public class DisallowedCharacterException : NormException

Â  Â  {

Â  Â  Â  Â  public readonly int Codepoint;

Â  Â  Â  Â  internal DisallowedCharacterException(string reason, int cp) : base("disallowed character", reason)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Codepoint = cp;

Â  Â  Â  Â  }

Â  Â  }

}

```

```cs [ENSNormalize.cs/ENSNormalize/ConfusableException.cs]

ï»¿namespace ADRaffy.ENSNormalize

{

Â  Â  public class ConfusableException : NormException

Â  Â  {

Â  Â  Â  Â  public readonly Group Group;

Â  Â  Â  Â  public readonly Group OtherGroup;

Â  Â  Â  Â  internal ConfusableException(Group group, Group other) : base("whole-script confusable", $"{group}/{other}")

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Group = group;

Â  Â  Â  Â  Â  Â  OtherGroup = other;

Â  Â  Â  Â  }Â  Â 

Â  Â  }

}

```

```cs [ENSNormalize.cs/ENSNormalize/ENSIP15.cs]

ï»¿using System;

using System.Linq;

using System.Text;

using System.Collections.Generic;

using System.Collections.ObjectModel;



namespace ADRaffy.ENSNormalize

{

Â  Â  internal class EmojiNode

Â  Â  {

Â  Â  Â  Â  internal EmojiSequence? Emoji;

Â  Â  Â  Â  internal Dictionary<int, EmojiNode>? Dict;

Â  Â  Â  Â  internal EmojiNode Then(int cp)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Dict ??= new();

Â  Â  Â  Â  Â  Â  if (Dict.TryGetValue(cp, out var node)) return node;

Â  Â  Â  Â  Â  Â  return Dict[cp] = new();

Â  Â  Â  Â  }

Â  Â  }



Â  Â  internal class Extent

Â  Â  {

Â  Â  Â  Â  internal readonly HashSet<Group> Groups = new();

Â  Â  Â  Â  internal readonly List<int> Chars = new();

Â  Â  }



Â  Â  public class ENSIP15

Â  Â  {

Â  Â  Â  Â  const char STOP_CH = '.';



Â  Â  Â  Â  public readonly NF NF;

Â  Â  Â  Â  public readonly int MaxNonSpacingMarks;

Â  Â  Â  Â  public readonly ReadOnlyIntSet ShouldEscape;

Â  Â  Â  Â  public readonly ReadOnlyIntSet Ignored;

Â  Â  Â  Â  public readonly ReadOnlyIntSet CombiningMarks;

Â  Â  Â  Â  public readonly ReadOnlyIntSet NonSpacingMarks;

Â  Â  Â  Â  public readonly ReadOnlyIntSet NFCCheck;

Â  Â  Â  Â  public readonly ReadOnlyIntSet PossiblyValid;

Â  Â  Â  Â  public readonly IDictionary<int, string> Fenced;

Â  Â  Â  Â  public readonly IDictionary<int, ReadOnlyCollection<int>> Mapped;

Â  Â  Â  Â  public readonly ReadOnlyCollection<Group> Groups;

Â  Â  Â  Â  public readonly ReadOnlyCollection<EmojiSequence> Emojis;

Â  Â  Â  Â  public readonly ReadOnlyCollection<Whole> Wholes;



Â  Â  Â  Â  private readonly EmojiNode EmojiRoot = new();

Â  Â  Â  Â  private readonly Dictionary<int, Whole> Confusables = new();

Â  Â  Â  Â  private readonly Whole UNIQUE_PH = new(ReadOnlyIntSet.EMPTY, ReadOnlyIntSet.EMPTY);

Â  Â  Â  Â  private readonly Group LATIN, GREEK, ASCII, EMOJI;



Â  Â  Â  Â  // experimental

Â  Â  Â  Â  private readonly string[] POSSIBLY_CONFUSING = new string[] { "Ä…", "Ã§", "Ä™", "ÅŸ", "Ã¬", "Ã­", "Ã®", "Ã¯", "Ç", "Å‚" };



Â  Â  Â  Â  static Dictionary<int, ReadOnlyCollection<int>> DecodeMapped(Decoder dec)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Dictionary<int, ReadOnlyCollection<int>> ret = new();

Â  Â  Â  Â  Â  Â  while (true)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  int w = dec.ReadUnsigned();

Â  Â  Â  Â  Â  Â  Â  Â  if (w == 0) break;

Â  Â  Â  Â  Â  Â  Â  Â  int[] keys = dec.ReadSortedUnique();

Â  Â  Â  Â  Â  Â  Â  Â  int n = keys.Length;

Â  Â  Â  Â  Â  Â  Â  Â  List<List<int>> m = new();

Â  Â  Â  Â  Â  Â  Â  Â  for (int i = 0; i < n; i++) m.Add(new());

Â  Â  Â  Â  Â  Â  Â  Â  for (int j = 0; j < w; j++)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  int[] v = dec.ReadUnsortedDeltas(n);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (int i = 0; i < n; i++) m[i].Add(v[i]);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  for (int i = 0; i < n; i++) ret.Add(keys[i], new(m[i]));

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  return ret;

Â  Â  Â  Â  }



Â  Â  Â  Â  static Dictionary<int, string> DecodeNamedCodepoints(Decoder dec)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Dictionary<int, string> ret = new();

Â  Â  Â  Â  Â  Â  foreach (int cp in dec.ReadSortedAscending(dec.ReadUnsigned()))

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  ret.Add(cp, dec.ReadString());

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  return ret;

Â  Â  Â  Â  }



Â  Â  Â  Â  static IDictionary<K, V> AsReadOnlyDict<K, V>(Dictionary<K, V> dict) where K: notnullÂ 

Â  Â  Â  Â  {

#if NETSTANDARD1_1 || NET35

Â  Â  Â  Â  Â  Â  return dict; // pls no bully

#else

Â  Â  Â  Â  Â  Â  return new ReadOnlyDictionary<K,V>(dict);

#endif

Â  Â  Â  Â  }



Â  Â  Â  Â  static List<Group> DecodeGroups(Decoder dec)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  List<Group> ret = new();

Â  Â  Â  Â  Â  Â  while (true)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  string name = dec.ReadString();

Â  Â  Â  Â  Â  Â  Â  Â  if (name.Length == 0) break;

Â  Â  Â  Â  Â  Â  Â  Â  int bits = dec.ReadUnsigned();

Â  Â  Â  Â  Â  Â  Â  Â  GroupKind kind = (bits & 1) != 0 ? GroupKind.Restricted : GroupKind.Script;

Â  Â  Â  Â  Â  Â  Â  Â  bool cm = (bits & 2) != 0;

Â  Â  Â  Â  Â  Â  Â  Â  ret.Add(new(ret.Count, kind, name, cm, new(dec.ReadUnique()), new(dec.ReadUnique())));

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  return ret;

Â  Â  Â  Â  }



Â  Â  Â  Â  public ENSIP15(NF nf, Decoder dec)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  NF = nf;

Â  Â  Â  Â  Â  Â  ShouldEscape = new(dec.ReadUnique());

Â  Â  Â  Â  Â  Â  Ignored = new(dec.ReadUnique());

Â  Â  Â  Â  Â  Â  CombiningMarks = new(dec.ReadUnique());

Â  Â  Â  Â  Â  Â  MaxNonSpacingMarks = dec.ReadUnsigned();

Â  Â  Â  Â  Â  Â  NonSpacingMarks = new(dec.ReadUnique());

Â  Â  Â  Â  Â  Â  NFCCheck = new(dec.ReadUnique());

Â  Â  Â  Â  Â  Â  Fenced = AsReadOnlyDict(DecodeNamedCodepoints(dec));

Â  Â  Â  Â  Â  Â  Mapped = AsReadOnlyDict(DecodeMapped(dec));

Â  Â  Â  Â  Â  Â  Groups = new(DecodeGroups(dec));

Â  Â  Â  Â  Â  Â  Emojis = new(dec.ReadTree().Select(cps => new EmojiSequence(cps)).ToArray());



Â  Â  Â  Â  Â  Â  // precompute: confusable extent complements

Â  Â  Â  Â  Â  Â  List<Whole> wholes = new();

Â  Â  Â  Â  Â  Â  while (true)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  ReadOnlyIntSet confused = new(dec.ReadUnique());

Â  Â  Â  Â  Â  Â  Â  Â  if (confused.Count == 0) break;

Â  Â  Â  Â  Â  Â  Â  Â  ReadOnlyIntSet valid = new(dec.ReadUnique());

Â  Â  Â  Â  Â  Â  Â  Â  Whole w = new(valid, confused);

Â  Â  Â  Â  Â  Â  Â  Â  wholes.Add(w);

Â  Â  Â  Â  Â  Â  Â  Â  foreach (int cp in confused)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Confusables.Add(cp, w);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  HashSet<Group> groups = new();

Â  Â  Â  Â  Â  Â  Â  Â  List<Extent> extents = new();

Â  Â  Â  Â  Â  Â  Â  Â  foreach (int cp in confused.Concat(valid))

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Group[] gs = Groups.Where(g => g.Contains(cp)).ToArray();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Extent? extent = extents.FirstOrDefault(e => gs.Any(g => e.Groups.Contains(g)));

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (extent == null)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  extent = new();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  extents.Add(extent);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  extent.Chars.Add(cp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  extent.Groups.UnionWith(gs);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  groups.UnionWith(gs);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  foreach (Extent extent in extents)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  int[] complement = groups.Except(extent.Groups).Select(g => g.Index).ToArray();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Array.Sort(complement);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  foreach (int cp in extent.Chars)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  w.Complement.Add(cp, complement);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Wholes = new(wholes);



Â  Â  Â  Â  Â  Â  // precompute: emoji trie

Â  Â  Â  Â  Â  Â  foreach (EmojiSequence emoji in Emojis)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  List<EmojiNode> nodes = new() { EmojiRoot };

Â  Â  Â  Â  Â  Â  Â  Â  foreach (int cp in emoji.Beautified)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (cp == 0xFE0F)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (int i = 0, e = nodes.Count; i < e; i++)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  nodes.Add(nodes[i].Then(cp));

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (int i = 0, e = nodes.Count; i < e; i++)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  nodes[i] = nodes[i].Then(cp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  foreach (EmojiNode x in nodes)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x.Emoji = emoji;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }



Â  Â  Â  Â  Â  Â  // precompute: possibly valid

Â  Â  Â  Â  Â  Â  HashSet<int> union = new();

Â  Â  Â  Â  Â  Â  HashSet<int> multi = new();

Â  Â  Â  Â  Â  Â  foreach (Group g in Groups)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  foreach (int cp in g.Primary.Concat(g.Secondary))

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (union.Contains(cp))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  multi.Add(cp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  union.Add(cp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  PossiblyValid = new(union.Union(NF.NFD(union)));



Â  Â  Â  Â  Â  Â  // precompute: unique non-confusables

Â  Â  Â  Â  Â  Â  HashSet<int> unique = new(union);

Â  Â  Â  Â  Â  Â  unique.ExceptWith(multi);

Â  Â  Â  Â  Â  Â  unique.ExceptWith(Confusables.Keys);

Â  Â  Â  Â  Â  Â  foreach (int cp in unique)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Confusables.Add(cp, UNIQUE_PH);

Â  Â  Â  Â  Â  Â  }



Â  Â  Â  Â  Â  Â  // precompute: special groups

Â  Â  Â  Â  Â  Â  LATIN = Groups.First(g => g.Name == "Latin");

Â  Â  Â  Â  Â  Â  GREEK = Groups.First(g => g.Name == "Greek");

Â  Â  Â  Â  Â  Â  ASCII = new(-1, GroupKind.ASCII, "ASCII", false, new(PossiblyValid.Where(cp => cp < 0x80)), ReadOnlyIntSet.EMPTY);

Â  Â  Â  Â  Â  Â  EMOJI = new(-1, GroupKind.Emoji, "Emoji", false, ReadOnlyIntSet.EMPTY, ReadOnlyIntSet.EMPTY);

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // format as {HEX}

Â  Â  Â  Â  static string HexEscape(int cp)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  return $"{{{cp.ToHex()}}}";

Â  Â  Â  Â  }



Â  Â  Â  Â  // format as "X {HEX}" if possible

Â  Â  Â  Â  public string SafeCodepoint(int cp)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  return ShouldEscape.Contains(cp) ? HexEscape(cp) : $"\"{SafeImplode(new int[] { cp })}\" {HexEscape(cp)}";

Â  Â  Â  Â  }

Â  Â  Â  Â  public string SafeImplode(IList<int> cps)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  int n = cps.Count;

Â  Â  Â  Â  Â  Â  if (n == 0) return "";

Â  Â  Â  Â  Â  Â  StringBuilder sb = new(n + 16); // guess

Â  Â  Â  Â  Â  Â  if (CombiningMarks.Contains(cps[0]))

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  sb.AppendCodepoint(0x25CC);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  foreach (int cp in cps)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  if (ShouldEscape.Contains(cp))

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sb.Append(HexEscape(cp));

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  else

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sb.AppendCodepoint(cp);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  // some messages can be mixed-directional and result in spillover

Â  Â  Â  Â  Â  Â  // use 200E after a input string to reset the bidi direction

Â  Â  Â  Â  Â  Â  // https://www.w3.org/International/questions/qa-bidi-unicode-controls#exceptions

Â  Â  Â  Â  Â  Â  sb.AppendCodepoint(0x200E);

Â  Â  Â  Â  Â  Â  return sb.ToString();

Â  Â  Â  Â  }



Â  Â  Â  Â  // throws

Â  Â  Â  Â  public string Normalize(string name)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  return Transform(name, cps => OutputTokenize(cps, NF.NFC, e => e.Normalized), tokens => {

Â  Â  Â  Â  Â  Â  Â  Â  int[] norm = tokens.SelectMany(t => t.Codepoints).ToArray();

Â  Â  Â  Â  Â  Â  Â  Â  CheckValid(norm, tokens);

Â  Â  Â  Â  Â  Â  Â  Â  return norm;

Â  Â  Â  Â  Â  Â  });

Â  Â  Â  Â  }

Â  Â  Â  Â  // throws

Â  Â  Â  Â  public string Beautify(string name)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  return Transform(name, cps => OutputTokenize(cps, NF.NFC, e => e.Beautified), tokens => {

Â  Â  Â  Â  Â  Â  Â  Â  int[] norm = tokens.SelectMany(t => t.Codepoints).ToArray();

Â  Â  Â  Â  Â  Â  Â  Â  Group group = CheckValid(norm, tokens);

Â  Â  Â  Â  Â  Â  Â  Â  if (group != GREEK)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (int i = 0, e = norm.Length; i < e; i++)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Î¾ => Î if not greek

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (norm[i] == 0x3BE) norm[i] = 0x39E;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  return norm;

Â  Â  Â  Â  Â  Â  });

Â  Â  Â  Â  }

Â  Â  Â  Â  // only throws InvalidLabelException w/DisallowedCharacterException

Â  Â  Â  Â  public string NormalizeFragment(string name, bool decompose = false)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  return Transform(name, cps => OutputTokenize(cps, decompose ? NF.NFD : NF.NFC, e => e.Normalized), tokens => {

Â  Â  Â  Â  Â  Â  Â  Â  return tokens.SelectMany(t => t.Codepoints);

Â  Â  Â  Â  Â  Â  });

Â  Â  Â  Â  }



Â  Â  Â  Â  string Transform(string name, Func<List<int>, IList<OutputToken>> tokenizer, Func<IList<OutputToken>, IEnumerable<int>> fn)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  if (name.Length == 0) return ""; // empty name allowance

Â  Â  Â  Â  Â  Â  StringBuilder sb = new(name.Length + 16); // guess

Â  Â  Â  Â  Â  Â  string[] labels = name.Split(STOP_CH);

Â  Â  Â  Â  Â  Â  foreach (string label in labels)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  List<int> cps = label.Explode();

Â  Â  Â  Â  Â  Â  Â  Â  try

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  IList<OutputToken> tokens = tokenizer(cps);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (sb.Length > 0) sb.Append(STOP_CH);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sb.AppendCodepoints(fn(tokens));

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  catch (NormException e)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  throw new InvalidLabelException(label, $"Invalid label \"{SafeImplode(cps)}\": {e.Message}", e);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  return sb.ToString();

Â  Â  Â  Â  }



Â  Â  Â  Â  // never throws

Â  Â  Â  Â  public IList<Label> Split(string name)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  string[] labels = name.Split(STOP_CH);

Â  Â  Â  Â  Â  Â  List<Label> ret = new(labels.Length);

Â  Â  Â  Â  Â  Â  if (name.Length == 0) return ret; // empty name allowance

Â  Â  Â  Â  Â  Â  foreach (string label in labels)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  List<int> cps = label.Explode();

Â  Â  Â  Â  Â  Â  Â  Â  IList<OutputToken>? tokens = null;

Â  Â  Â  Â  Â  Â  Â  Â  try

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tokens = OutputTokenize(cps, NF.NFC, e => e.Normalized.ToList()); // make copy

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  int[] norm = tokens.SelectMany(t => t.Codepoints).ToArray();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Group group = CheckValid(norm, tokens);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ret.Add(new(cps, tokens, norm, group));

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  catch (NormException e)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ret.Add(new(cps, tokens, e));

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  return ret;

Â  Â  Â  Â  }

Â  Â  Â  Â  // experimental

Â  Â  Â  Â  // throws

Â  Â  Â  Â  public NormDetails NormalizeDetails(string name)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  HashSet<Group> groups = new();

Â  Â  Â  Â  Â  Â  HashSet<EmojiSequence> emojis = new();

Â  Â  Â  Â  Â  Â  string norm = Transform(name, cps => OutputTokenize(cps, NF.NFC, e => e.Normalized), tokens => {

Â  Â  Â  Â  Â  Â  Â  Â  int[] norm = tokens.SelectMany(t => t.Codepoints).ToArray();

Â  Â  Â  Â  Â  Â  Â  Â  Group group = CheckValid(norm, tokens);

Â  Â  Â  Â  Â  Â  Â  Â  emojis.UnionWith(tokens.Where(t => t.IsEmoji).Select(t => t.Emoji!));

Â  Â  Â  Â  Â  Â  Â  Â  if (group == LATIN && tokens.All(t => t.IsEmoji || t.Codepoints.All(cp => cp < 0x80)))

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  group = ASCII;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  groups.Add(group);

Â  Â  Â  Â  Â  Â  Â  Â  return norm;

Â  Â  Â  Â  Â  Â  });

Â  Â  Â  Â  Â  Â  if (groups.Contains(LATIN))

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  groups.Remove(ASCII);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (emojis.Count > 0)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  groups.Add(EMOJI);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  bool confusing = POSSIBLY_CONFUSING.Any(norm.Contains);

Â  Â  Â  Â  Â  Â  return new(norm, groups, emojis, confusing);

Â  Â  Â  Â  }



Â  Â  Â  Â  Group CheckValid(int[] norm, IList<OutputToken> tokens)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  if (norm.Length == 0)Â Â 

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  throw new NormException("empty label");

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  CheckLeadingUnderscore(norm);

Â  Â  Â  Â  Â  Â  bool emoji = tokens.Count > 1 || tokens[0].IsEmoji;

Â  Â  Â  Â  Â  Â  if (!emoji && norm.All(cp => cp < 0x80))

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  CheckLabelExtension(norm);

Â  Â  Â  Â  Â  Â  Â  Â  return ASCII;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  int[] chars = tokens.Where(t => !t.IsEmoji).SelectMany(x => x.Codepoints).ToArray();

Â  Â  Â  Â  Â  Â  if (emoji && chars.Length == 0)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  return EMOJI;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  CheckCombiningMarks(tokens);

Â  Â  Â  Â  Â  Â  CheckFenced(norm);

Â  Â  Â  Â  Â  Â  int[] unique = chars.Distinct().ToArray();

Â  Â  Â  Â  Â  Â  Group group = DetermineGroup(unique);

Â  Â  Â  Â  Â  Â  CheckGroup(group, chars); // need text in order

Â  Â  Â  Â  Â  Â  CheckWhole(group, unique); // only need unique text

Â  Â  Â  Â  Â  Â  return group;

Â  Â  Â  Â  }



Â  Â  Â  Â  // assume: Groups.length > 1

Â  Â  Â  Â  Group DetermineGroup(int[] unique)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Group[] gs = Groups.ToArray();

Â  Â  Â  Â  Â  Â  int prev = gs.Length;

Â  Â  Â  Â  Â  Â  foreach (int cp in unique) {

Â  Â  Â  Â  Â  Â  Â  Â  int next = 0;

Â  Â  Â  Â  Â  Â  Â  Â  for (int i = 0; i < prev; i++)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (gs[i].Contains(cp))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  gs[next++] = gs[i];

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  if (next == 0)

Â  Â  Â  Â  Â  Â  Â  Â  {Â  Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (!Groups.Any(g => g.Contains(cp)))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // the character was composed of valid parts

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // but it's NFC form is invalid

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  throw new DisallowedCharacterException(SafeCodepoint(cp), cp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // there is no group that contains all these characters

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // throw using the highest priority group that matched

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // https://www.unicode.org/reports/tr39/#mixed_script_confusables

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  throw CreateMixtureException(gs[0], cp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  prev = next;

Â  Â  Â  Â  Â  Â  Â  Â  if (prev == 1) break; // there is only one group left

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  return gs[0];

Â  Â  Â  Â  }



Â  Â  Â  Â  // assume: cps.length > 0

Â  Â  Â  Â  // assume: cps[0] isn't CM

Â  Â  Â  Â  void CheckGroup(Group g, int[] cps)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  foreach (int cp in cps)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  if (!g.Contains(cp))

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  throw CreateMixtureException(g, cp);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (!g.CMWhitelisted)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  List<int> decomposed = NF.NFD(cps);

Â  Â  Â  Â  Â  Â  Â  Â  for (int i = 1, e = decomposed.Count; i < e; i++)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // https://www.unicode.org/reports/tr39/#Optional_Detection

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (NonSpacingMarks.Contains(decomposed[i]))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  int j = i + 1;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (int cp; j < e && NonSpacingMarks.Contains(cp = decomposed[j]); j++)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (int k = i; k < j; k++)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // a. Forbid sequences of the same nonspacing mark.

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (decomposed[k] == cp)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  throw new NormException("duplicate non-spacing marks", SafeCodepoint(cp));

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // b. Forbid sequences of more than 4 nonspacing marks (gc=Mn or gc=Me).

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  int n = j - i;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (n > MaxNonSpacingMarks) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  throw new NormException("excessive non-spacing marks", $"{SafeImplode(decomposed.GetRange(i - 1, n))} ({n}/${MaxNonSpacingMarks})");

				Â  Â  Â  Â  }

				Â  Â  Â  Â  i = j;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }



Â  Â  Â  Â  void CheckWhole(Group g, int[] unique)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  int bound = 0;

Â  Â  Â  Â  Â  Â  int[]? maker = null;

Â  Â  Â  Â  Â  Â  List<int> shared = new();

Â  Â  Â  Â  Â  Â  foreach (int cp in unique)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  if (!Confusables.TryGetValue(cp, out var w))

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  shared.Add(cp);

Â  Â  Â  Â  Â  Â  Â  Â  }Â 

Â  Â  Â  Â  Â  Â  Â  Â  else if (w == UNIQUE_PH)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return; // unique, non-confusable

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  elseÂ 

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  int[] comp = w.Complement[cp]; // exists by construction

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (bound == 0)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  maker = comp.ToArray(); // non-empty

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  bound = comp.Length;Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else // intersect(comp, maker)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  int b = 0;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (int i = 0; i < bound; i++)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (comp.Contains(maker![i]))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (i > b) maker[b] = maker[i];

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ++b;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  bound = b;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (bound == 0)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return; // confusable intersection is empty

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (bound > 0)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  for (int i = 0; i < bound; i++)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Group group = Groups[maker![i]];

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (shared.All(group.Contains))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  throw new ConfusableException(g, group);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }



Â  Â  Â  Â  // find the longest emoji that matches at index

Â  Â  Â  Â  // if found, returns and updates the index

Â  Â  Â  Â  EmojiSequence? FindEmoji(List<int> cps, ref int index)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  EmojiNode? node = EmojiRoot;

Â  Â  Â  Â  Â  Â  EmojiSequence? last = null;

Â  Â  Â  Â  Â  Â  for (int i = index, e = cps.Count; i < e; )

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  if (node.Dict == null || !node.Dict.TryGetValue(cps[i++], out node)) break;

Â  Â  Â  Â  Â  Â  Â  Â  if (node.Emoji != null) // the emoji is valid

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  index = i; // eat the emoji

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  last = node.Emoji; // save it

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  return last; // last emoji found

Â  Â  Â  Â  }



Â  Â  Â  Â  IList<OutputToken> OutputTokenize(List<int> cps, Func<List<int>, List<int>> nf, Func<EmojiSequence, IList<int>> emojiStyler)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  List<OutputToken> tokens = new();

Â  Â  Â  Â  Â  Â  int n = cps.Count;

Â  Â  Â  Â  Â  Â  List<int> buf = new(n);

Â  Â  Â  Â  Â  Â  for (int i = 0; i < n; )

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  EmojiSequence? emoji = FindEmoji(cps, ref i);

Â  Â  Â  Â  Â  Â  Â  Â  if (emoji != null) // found an emoji

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (buf.Count > 0) // consume buffered

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tokens.Add(new(nf(buf)));

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  buf.Clear();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tokens.Add(new(emojiStyler(emoji), emoji)); // add emoji

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  else

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  int cp = cps[i++];

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (PossiblyValid.Contains(cp))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  buf.Add(cp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else if (Mapped.TryGetValue(cp, out var mapped))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  buf.AddRange(mapped);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else if (!Ignored.Contains(cp))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  throw new DisallowedCharacterException(SafeCodepoint(cp), cp);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (buf.Count > 0) // flush buffered

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  tokens.Add(new(nf(buf)));

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  return tokens;

Â  Â  Â  Â  }

Â  Â  Â  Â  // assume: cps.length > 0

Â  Â  Â  Â  void CheckFenced(int[] cps)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  if (Fenced.TryGetValue(cps[0], out var name))

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  throw new NormException("leading fenced", name);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  int n = cps.Length;

Â  Â  Â  Â  Â  Â  int last = -1;

Â  Â  Â  Â  Â  Â  string prev = "";

Â  Â  Â  Â  Â  Â  for (int i = 1; i < n; i++)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  if (Fenced.TryGetValue(cps[i], out name))

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (last == i)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  throw new NormException("adjacent fenced", $"{prev} + {name}");

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  last = i + 1;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prev = name;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (last == n)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  throw new NormException("trailing fenced", prev);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  void CheckCombiningMarks(IList<OutputToken> tokens)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  for (int i = 0, e = tokens.Count; i < e; i++)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  OutputToken t = tokens[i];

Â  Â  Â  Â  Â  Â  Â  Â  if (t.IsEmoji) continue;

Â  Â  Â  Â  Â  Â  Â  Â  int cp = t.Codepoints[0];

Â  Â  Â  Â  Â  Â  Â  Â  if (CombiningMarks.Contains(cp))

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (i == 0)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  throw new NormException("leading combining mark", SafeCodepoint(cp));

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elseÂ 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // note: the previous token must an EmojiSequence

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  throw new NormException("emoji + combining mark", $"{tokens[i - 1].Emoji!.Form} + {SafeCodepoint(cp)}");

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  // assume: ascii

Â  Â  Â  Â  static void CheckLabelExtension(int[] cps)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  const int HYPHEN = 0x2D;

Â  Â  Â  Â  Â  Â  if (cps.Length >= 4 && cps[2] == HYPHEN && cps[3] == HYPHEN)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  throw new NormException("invalid label extension", cps.Take(4).Implode());

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  static void CheckLeadingUnderscore(int[] cps)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  const int UNDERSCORE = 0x5F;

Â  Â  Â  Â  Â  Â  bool allowed = true;

Â  Â  Â  Â  Â  Â  foreach (int cp in cps)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  if (allowed)

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (cp != UNDERSCORE)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  allowed = false;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }Â 

Â  Â  Â  Â  Â  Â  Â  Â  else

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (cp == UNDERSCORE)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  throw new NormException("underscore allowed only at start");

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  private IllegalMixtureException CreateMixtureException(Group g, int cp)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  string conflict = SafeCodepoint(cp);

Â  Â  Â  Â  Â  Â  Group? other = Groups.FirstOrDefault(x => x.Primary.Contains(cp));

Â  Â  Â  Â  Â  Â  if (other != null)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  conflict = $"{other} {conflict}";

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  return new IllegalMixtureException($"{g} + {conflict}", cp, g, other);

Â  Â  Â  Â  }

Â  Â  }



}```

```cs [ENSNormalize.cs/ENSNormalize/ENSNormalize.cs]

ï»¿namespace ADRaffy.ENSNormalize

{

Â  Â  public static class ENSNormalize

Â  Â  {

Â  Â  Â  Â  public static readonly NF NF = new(new(Blobs.NF));

Â  Â  Â  Â  public static readonly ENSIP15 ENSIP15 = new(NF, new(Blobs.ENSIP15));

Â  Â  }

}

```

```cs [ENSNormalize.cs/ENSNormalize/NormDetails.cs]

ï»¿using System.Collections.Generic;

using System.Linq;



namespace ADRaffy.ENSNormalize

{

Â  Â  public class NormDetails

Â  Â  {

Â  Â  Â  Â  public readonly string Name;

Â  Â  Â  Â  public readonly HashSet<Group> Groups;

Â  Â  Â  Â  public readonly HashSet<EmojiSequence> Emojis;

Â  Â  Â  Â  public readonly bool PossiblyConfusing;

Â  Â  Â  Â  public string GroupDescription { get => string.Join("+", Groups.Select(g => g.Name).OrderBy(x => x).ToArray()); }

Â  Â  Â  Â  public bool HasZWJEmoji { get => Emojis.Any(x => x.HasZWJ); }

Â  Â  Â  Â  internal NormDetails(string norm, HashSet<Group> groups, HashSet<EmojiSequence> emojis, bool confusing) {

Â  Â  Â  Â  Â  Â  Name = norm;

Â  Â  Â  Â  Â  Â  Groups = groups;

Â  Â  Â  Â  Â  Â  Emojis = emojis;

Â  Â  Â  Â  Â  Â  PossiblyConfusing = confusing;

Â  Â  Â  Â  }

Â  Â  }

}

```

```cs [ENSNormalize.cs/ENSNormalize/Utils.cs]

ï»¿using System.Linq;

using System.Text;

using System.Collections.Generic;



namespace ADRaffy.ENSNormalize

{

Â  Â  public static class Utils

Â  Â  {

Â  Â  Â  Â  const int UTF16_BMP = 0x10000;

Â  Â  Â  Â  const int UTF16_BITS = 10;

Â  Â  Â  Â  const int UTF16_HEAD = ~0 << UTF16_BITS;Â  Â  Â  // upper 6 bits

Â  Â  Â  Â  const int UTF16_DATA = (1 << UTF16_BITS) - 1; // lower 10 bits

Â  Â  Â  Â  const int UTF16_HI = 0xD800; // 110110*

Â  Â  Â  Â  const int UTF16_LO = 0xDC00; // 110111*



Â  Â  Â  Â  // format strings/codepoints

Â  Â  Â  Â  static public string ToHex(this int cp) => cp.ToString("X").PadLeft(2, '0');

Â  Â  Â  Â  static public string ToHexSequence(this IEnumerable<int> v) => string.Join(" ", v.Select(x => x.ToHex()).ToArray());

Â  Â  Â  Â  static public string ToHexSequence(this string s) => s.Explode().ToHexSequence();

Â  Â  Â  Â Â 

Â  Â  Â  Â  // convert strings <=> codepoints

Â  Â  Â  Â  // note: we do not care if the string is invalid UTF-16

Â  Â  Â  Â  static public List<int> Explode(this string s)

Â  Â  Â  Â  {Â  Â  Â  Â  Â 

Â  Â  Â  Â  Â  Â  int n = s.Length;

Â  Â  Â  Â  Â  Â  List<int> v = new(n);

Â  Â  Â  Â  Â  Â  for (int i = 0; i < n; )

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  char ch0 = s[i++];

Â  Â  Â  Â  Â  Â  Â  Â  char ch1;

Â  Â  Â  Â  Â  Â  Â  Â  int head = ch0 & UTF16_HEAD;

Â  Â  Â  Â  Â  Â  Â  Â  if (head == UTF16_HI && i < n && ((ch1 = s[i]) & UTF16_HEAD) == UTF16_LO) // valid pair

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  v.Add(UTF16_BMP + (((ch0 & UTF16_DATA) << UTF16_BITS) | (ch1 & UTF16_DATA)));

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  i++;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  else // bmp OR illegal surrogates

Â  Â  Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  v.Add(ch0);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  // reference implementation

Â  Â  Â  Â  Â  Â  Â  Â  /*

Â  Â  Â  Â  Â  Â  Â  Â  int cp = char.ConvertToUtf32(s, i); // errors on invalid

Â  Â  Â  Â  Â  Â  Â  Â  v.Add(cp);

Â  Â  Â  Â  Â  Â  Â  Â  i += char.IsSurrogatePair(s, i) ? 2 : 1;

Â  Â  Â  Â  Â  Â  Â  Â  */

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  return v;

Â  Â  Â  Â  }

Â  Â  Â  Â  static public string Implode(this IEnumerable<int> cps)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  StringBuilder sb = new(cps.UTF16Length());

Â  Â  Â  Â  Â  Â  sb.AppendCodepoints(cps);

Â  Â  Â  Â  Â  Â  return sb.ToString();

Â  Â  Â  Â  }



Â  Â  Â  Â  // efficiently build strings from codepoints

Â  Â  Â  Â  static public int UTF16Length(this IEnumerable<int> cps) => cps.Sum(x => x < UTF16_BMP ? 1 : 2);

Â  Â  Â  Â  static public void AppendCodepoint(this StringBuilder sb, int cp)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  if (cp < UTF16_BMP)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  sb.Append((char)cp);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  else

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  cp -= UTF16_BMP;

Â  Â  Â  Â  Â  Â  Â  Â  sb.Append((char)(UTF16_HI | ((cp >> UTF16_BITS) & UTF16_DATA)));

Â  Â  Â  Â  Â  Â  Â  Â  sb.Append((char)(UTF16_LO | (cp & UTF16_DATA)));

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  // reference implementation

Â  Â  Â  Â  Â  Â  //sb.Append(char.ConvertFromUtf32(cp)); // allocates a string

Â  Â  Â  Â  }

Â  Â  Â  Â  static public void AppendCodepoints(this StringBuilder sb, IEnumerable<int> v)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  foreach (int cp in v)

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  sb.AppendCodepoint(cp);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }



}

```

```cs [ENSNormalize.cs/ENSNormalize/ReadOnlyIntSet.cs]

ï»¿using System.Collections;

using System.Collections.Generic;



namespace ADRaffy.ENSNormalize

{

Â  Â  public class ReadOnlyIntSet : IEnumerable<int>

Â  Â  {

Â  Â  Â  Â  static public readonly ReadOnlyIntSet EMPTY = new(new int[0]);



Â  Â  Â  Â  private readonly HashSet<int> Set;

Â  Â  Â  Â  public int Count { get => Set.Count; }

Â  Â  Â  Â  public ReadOnlyIntSet(IEnumerable<int> v)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Set = new(v);

Â  Â  Â  Â  }

Â  Â  Â  Â  IEnumerator<int> IEnumerable<int>.GetEnumerator() => Set.GetEnumerator(); // ew

Â  Â  Â  Â  IEnumerator IEnumerable.GetEnumerator() => Set.GetEnumerator();

Â  Â  Â  Â  public bool Contains(int x) => Set.Contains(x);



Â  Â  Â  Â  // note: uses less memory but 10% slower

Â  Â  Â  Â  /*

Â  Â  Â  Â  private readonly int[] Sorted;

Â  Â  Â  Â  public int this[int index] { get => Sorted[index]; }

Â  Â  Â  Â  public int Count {Â  get => Sorted.Length; }

Â  Â  Â  Â  public ReadOnlyIntSet(IEnumerable<int> v) {

Â  Â  Â  Â  Â  Â  Sorted = v.ToArray();

Â  Â  Â  Â  Â  Â  Array.Sort(Sorted);

Â  Â  Â  Â  }

Â  Â  Â  Â  IEnumerator<int> IEnumerable<int>.GetEnumerator() => ((IEnumerable<int>)Sorted).GetEnumerator();

Â  Â  Â  Â  IEnumerator IEnumerable.GetEnumerator() => Sorted.GetEnumerator();

Â  Â  Â  Â  public bool Contains(int x) => Array.BinarySearch(Sorted, x) >= 0;

Â  Â  Â  Â  */

Â  Â  }

}

```

```cs [ENSNormalize.cs/ENSNormalize/IllegalMixtureException.cs]

ï»¿namespace ADRaffy.ENSNormalize

{

Â  Â  public class IllegalMixtureException : NormException

Â  Â  {

Â  Â  Â  Â  public readonly Group Group;

Â  Â  Â  Â  public readonly int Codepoint;

Â  Â  Â  Â  public readonly Group? OtherGroup;

Â  Â  Â  Â  internal IllegalMixtureException(string reason, int cp, Group group, Group? other) : base("illegal mixture", reason)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Codepoint = cp;

Â  Â  Â  Â  Â  Â  Group = group;

Â  Â  Â  Â  Â  Â  OtherGroup = other;

Â  Â  Â  Â  }

Â  Â  }

}

```

```cs [ENSNormalize.cs/ENSNormalize/NormException.cs]

ï»¿using System;



namespace ADRaffy.ENSNormalize

{

Â  Â  public class NormException : Exception

Â  Â  {

Â  Â  Â  Â  public readonly string Kind;

Â  Â  Â  Â  public readonly string? Reason;

Â  Â  Â  Â  internal NormException(string kind, string? reason = null) : base(reason != null ? $"{kind}: {reason}" : kind)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Kind = kind;

Â  Â  Â  Â  Â  Â  Reason = reason;

Â  Â  Â  Â  }

Â  Â  }

}

```

```cs [ENSNormalize.cs/ENSNormalize/Label.cs]

ï»¿using System.Collections.Generic;



namespace ADRaffy.ENSNormalize

{

Â  Â  public class Label

Â  Â  {

Â  Â  Â  Â  // error: [Input, Tokens?, Error ]

Â  Â  Â  Â  // valid: [Input, Tokens, Group, Normalized ]



Â  Â  Â  Â  public readonly IList<int> Input;

Â  Â  Â  Â  public readonly IList<OutputToken>? Tokens;

Â  Â  Â  Â  public readonly NormException? Error;

Â  Â  Â  Â  public readonly int[]? Normalized;

Â  Â  Â  Â  public readonly Group? Group;



Â  Â  Â  Â  internal Label(IList<int> input, IList<OutputToken>? tokens, NormException e) {

Â  Â  Â  Â  Â  Â  Input = input;

Â  Â  Â  Â  Â  Â  Tokens = tokens;

Â  Â  Â  Â  Â  Â  Error = e;

Â  Â  Â  Â  }

Â  Â  Â  Â  internal Label(IList<int> input, IList<OutputToken> tokens, int[] cps, Group g)Â 

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Input = input;

Â  Â  Â  Â  Â  Â  Tokens = tokens;

Â  Â  Â  Â  Â  Â  Normalized = cps;

Â  Â  Â  Â  Â  Â  Group = g;

Â  Â  Â  Â  }

Â  Â  }

}

```

```cs [ENSNormalize.cs/ENSNormalize/Group.cs]

ï»¿namespace ADRaffy.ENSNormalize

{

Â  Â  public class Group

Â  Â  {

Â  Â  Â  Â  public readonly int Index;

Â  Â  Â  Â  public readonly string Name;

Â  Â  Â  Â  public readonly GroupKind Kind;

Â  Â  Â  Â  public readonly bool CMWhitelisted;

Â  Â  Â  Â  public readonly ReadOnlyIntSet Primary;

Â  Â  Â  Â  public readonly ReadOnlyIntSet Secondary;

Â  Â  Â  Â  public bool IsRestricted { get => Kind == GroupKind.Restricted; }

Â  Â  Â  Â  internal Group(int index, GroupKind kind, string name, bool cm, ReadOnlyIntSet primary, ReadOnlyIntSet secondary)

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Index = index;

Â  Â  Â  Â  Â  Â  Kind = kind;

Â  Â  Â  Â  Â  Â  Name = name;

Â  Â  Â  Â  Â  Â  CMWhitelisted = cm;

Â  Â  Â  Â  Â  Â  Primary = primary;

Â  Â  Â  Â  Â  Â  Secondary = secondary;

Â  Â  Â  Â  }

Â  Â  Â  Â  public bool Contains(int cp) => Primary.Contains(cp) || Secondary.Contains(cp);

Â  Â  Â  Â  public override string ToString()

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  return IsRestricted ? $"Restricted[{Name}]" : Name;

Â  Â  Â  Â  }

Â  Â  }

}

```

</csharp>

<zig>

```zig [./.zig-cache/o/ebd7ddab8ffe003267120d598aecce68/dependencies.zig]

pub const packages = struct {};

pub const root_deps: []const struct { []const u8, []const u8 } = &.{};

```

```zig [./.zig-cache/o/505d63aeafd9b53320c4cb9a6a47da84/dependencies.zig]

pub const packages = struct {

Â  Â  pub const @"argzon-0.4.0-Cl574lfJAQAg6_eaDCQ7ZqXdx0dRYBGuRsYyYYuOjKLt" = struct {

Â  Â  Â  Â  pub const build_root = "/Users/williamcory/.cache/zig/p/argzon-0.4.0-Cl574lfJAQAg6_eaDCQ7ZqXdx0dRYBGuRsYyYYuOjKLt";

Â  Â  Â  Â  pub const build_zig = @import("argzon-0.4.0-Cl574lfJAQAg6_eaDCQ7ZqXdx0dRYBGuRsYyYYuOjKLt");

Â  Â  Â  Â  pub const deps: []const struct { []const u8, []const u8 } = &.{

Â  Â  Â  Â  };

Â  Â  };

Â  Â  pub const @"zq-0.8.0-7XsKhb_oAAAHW2pzOFWl3gyMOxUkq4K3SiIczAH7rgqu" = struct {

Â  Â  Â  Â  pub const build_root = "/Users/williamcory/.cache/zig/p/zq-0.8.0-7XsKhb_oAAAHW2pzOFWl3gyMOxUkq4K3SiIczAH7rgqu";

Â  Â  Â  Â  pub const build_zig = @import("zq-0.8.0-7XsKhb_oAAAHW2pzOFWl3gyMOxUkq4K3SiIczAH7rgqu");

Â  Â  Â  Â  pub const deps: []const struct { []const u8, []const u8 } = &.{

Â  Â  Â  Â  Â  Â  .{ "argzon", "argzon-0.4.0-Cl574lfJAQAg6_eaDCQ7ZqXdx0dRYBGuRsYyYYuOjKLt" },

Â  Â  Â  Â  };

Â  Â  };

};



pub const root_deps: []const struct { []const u8, []const u8 } = &.{

Â  Â  .{ "zq", "zq-0.8.0-7XsKhb_oAAAHW2pzOFWl3gyMOxUkq4K3SiIczAH7rgqu" },

};

```

```zig [./build.zig]

const std = @import("std");



// Although this function looks imperative, note that its job is to

// declaratively construct a build graph that will be executed by an external

// runner.

pub fn build(b: *std.Build) void {

Â  Â  // Standard target options allows the person running `zig build` to choose

Â  Â  // what target to build for. Here we do not override the defaults, which

Â  Â  // means any target is allowed, and the default is native. Other options

Â  Â  // for restricting supported target set are available.

Â  Â  const target = b.standardTargetOptions(.{});



Â  Â  // Standard optimization options allow the person running `zig build` to select

Â  Â  // between Debug, ReleaseSafe, ReleaseFast, and ReleaseSmall. Here we do not

Â  Â  // set a preferred release mode, allowing the user to decide how to optimize.

Â  Â  const optimize = b.standardOptimizeOption(.{});



Â  Â  // This creates a "module", which represents a collection of source files alongside

Â  Â  // some compilation options, such as optimization mode and linked system libraries.

Â  Â  // Every executable or library we compile will be based on one or more modules.

Â  Â  const lib_mod = b.createModule(.{

Â  Â  Â  Â  // `root_source_file` is the Zig "entry point" of the module. If a module

Â  Â  Â  Â  // only contains e.g. external object files, you can make this `null`.

Â  Â  Â  Â  // In this case the main source file is merely a path, however, in more

Â  Â  Â  Â  // complicated build scripts, this could be a generated file.

Â  Â  Â  Â  .root_source_file = b.path("src/root.zig"),

Â  Â  Â  Â  .target = target,

Â  Â  Â  Â  .optimize = optimize,

Â  Â  });



Â  Â  // We will also create a module for our other entry point, 'main.zig'.

Â  Â  const exe_mod = b.createModule(.{

Â  Â  Â  Â  // `root_source_file` is the Zig "entry point" of the module. If a module

Â  Â  Â  Â  // only contains e.g. external object files, you can make this `null`.

Â  Â  Â  Â  // In this case the main source file is merely a path, however, in more

Â  Â  Â  Â  // complicated build scripts, this could be a generated file.

Â  Â  Â  Â  .root_source_file = b.path("src/main.zig"),

Â  Â  Â  Â  .target = target,

Â  Â  Â  Â  .optimize = optimize,

Â  Â  });



Â  Â  // Modules can depend on one another using the `std.Build.Module.addImport` function.

Â  Â  // This is what allows Zig source code to use `@import("foo")` where 'foo' is not a

Â  Â  // file path. In this case, we set up `exe_mod` to import `lib_mod`.

Â  Â  exe_mod.addImport("ens_normalize", lib_mod);



Â  Â  // Now, we will create a static library based on the module we created above.

Â  Â  // This creates a `std.Build.Step.Compile`, which is the build step responsible

Â  Â  // for actually invoking the compiler.

Â  Â  const lib = b.addLibrary(.{

Â  Â  Â  Â  .linkage = .static,

Â  Â  Â  Â  .name = "ens_normalize",

Â  Â  Â  Â  .root_module = lib_mod,

Â  Â  });



Â  Â  // This declares intent for the library to be installed into the standard

Â  Â  // location when the user invokes the "install" step (the default step when

Â  Â  // running `zig build`).

Â  Â  b.installArtifact(lib);



Â  Â  // This creates another `std.Build.Step.Compile`, but this one builds an executable

Â  Â  // rather than a static library.

Â  Â  const exe = b.addExecutable(.{

Â  Â  Â  Â  .name = "ens_normalize",

Â  Â  Â  Â  .root_module = exe_mod,

Â  Â  });



Â  Â  // This declares intent for the executable to be installed into the

Â  Â  // standard location when the user invokes the "install" step (the default

Â  Â  // step when running `zig build`).

Â  Â  b.installArtifact(exe);



Â  Â  // This *creates* a Run step in the build graph, to be executed when another

Â  Â  // step is evaluated that depends on it. The next line below will establish

Â  Â  // such a dependency.

Â  Â  const run_cmd = b.addRunArtifact(exe);



Â  Â  // By making the run step depend on the install step, it will be run from the

Â  Â  // installation directory rather than directly from within the cache directory.

Â  Â  // This is not necessary, however, if the application depends on other installed

Â  Â  // files, this ensures they will be present and in the expected location.

Â  Â  run_cmd.step.dependOn(b.getInstallStep());



Â  Â  // This allows the user to pass arguments to the application in the build

Â  Â  // command itself, like this: `zig build run -- arg1 arg2 etc`

Â  Â  if (b.args) |args| {

Â  Â  Â  Â  run_cmd.addArgs(args);

Â  Â  }



Â  Â  // This creates a build step. It will be visible in the `zig build --help` menu,

Â  Â  // and can be selected like this: `zig build run`

Â  Â  // This will evaluate the `run` step rather than the default, which is "install".

Â  Â  const run_step = b.step("run", "Run the app");

Â  Â  run_step.dependOn(&run_cmd.step);



Â  Â  // Creates a step for unit testing. This only builds the test executable

Â  Â  // but does not run it.

Â  Â  const lib_unit_tests = b.addTest(.{

Â  Â  Â  Â  .root_module = lib_mod,

Â  Â  });



Â  Â  const run_lib_unit_tests = b.addRunArtifact(lib_unit_tests);



Â  Â  const exe_unit_tests = b.addTest(.{

Â  Â  Â  Â  .root_module = exe_mod,

Â  Â  });



Â  Â  const run_exe_unit_tests = b.addRunArtifact(exe_unit_tests);



Â  Â  // Add integration tests

Â  Â  const integration_tests = b.addTest(.{

Â  Â  Â  Â  .root_source_file = b.path("tests/ens_tests.zig"),

Â  Â  Â  Â  .target = target,

Â  Â  Â  Â  .optimize = optimize,

Â  Â  });

Â  Â  integration_tests.root_module.addImport("ens_normalize", lib_mod);

Â  Â Â 

Â  Â  const run_integration_tests = b.addRunArtifact(integration_tests);

Â  Â Â 

Â  Â  // Add tokenization tests

Â  Â  const tokenization_tests = b.addTest(.{

Â  Â  Â  Â  .root_source_file = b.path("tests/tokenization_tests.zig"),

Â  Â  Â  Â  .target = target,

Â  Â  Â  Â  .optimize = optimize,

Â  Â  });

Â  Â  tokenization_tests.root_module.addImport("ens_normalize", lib_mod);

Â  Â Â 

Â  Â  const run_tokenization_tests = b.addRunArtifact(tokenization_tests);

Â  Â Â 

Â  Â  // Add tokenization fuzz tests

Â  Â  const tokenization_fuzz_tests = b.addTest(.{

Â  Â  Â  Â  .root_source_file = b.path("tests/tokenization_fuzz.zig"),

Â  Â  Â  Â  .target = target,

Â  Â  Â  Â  .optimize = optimize,

Â  Â  });

Â  Â  tokenization_fuzz_tests.root_module.addImport("ens_normalize", lib_mod);

Â  Â Â 

Â  Â  const run_tokenization_fuzz_tests = b.addRunArtifact(tokenization_fuzz_tests);

Â  Â Â 

Â  Â  // Similar to creating the run step earlier, this exposes a `test` step to

Â  Â  // the `zig build --help` menu, providing a way for the user to request

Â  Â  // running the unit tests.

Â  Â  const test_step = b.step("test", "Run unit tests");

Â  Â  test_step.dependOn(&run_lib_unit_tests.step);

Â  Â  test_step.dependOn(&run_exe_unit_tests.step);

Â  Â  test_step.dependOn(&run_integration_tests.step);

Â  Â  test_step.dependOn(&run_tokenization_tests.step);

Â  Â Â 

Â  Â  // Add validation tests

Â  Â  const validation_tests = b.addTest(.{

Â  Â  Â  Â  .root_source_file = b.path("tests/validation_tests.zig"),

Â  Â  Â  Â  .target = target,

Â  Â  Â  Â  .optimize = optimize,

Â  Â  });

Â  Â  validation_tests.root_module.addImport("ens_normalize", lib_mod);

Â  Â Â 

Â  Â  const run_validation_tests = b.addRunArtifact(validation_tests);

Â  Â Â 

Â  Â  // Add validation fuzz tests

Â  Â  const validation_fuzz_tests = b.addTest(.{

Â  Â  Â  Â  .root_source_file = b.path("tests/validation_fuzz.zig"),

Â  Â  Â  Â  .target = target,

Â  Â  Â  Â  .optimize = optimize,

Â  Â  });

Â  Â  validation_fuzz_tests.root_module.addImport("ens_normalize", lib_mod);

Â  Â Â 

Â  Â  const run_validation_fuzz_tests = b.addRunArtifact(validation_fuzz_tests);

Â  Â Â 

Â  Â  // Add separate fuzz test step

Â  Â  const fuzz_step = b.step("fuzz", "Run fuzz tests");

Â  Â  fuzz_step.dependOn(&run_tokenization_fuzz_tests.step);

Â  Â  fuzz_step.dependOn(&run_validation_fuzz_tests.step);

Â  Â Â 

Â  Â  // Add emoji tests

Â  Â  const emoji_tests = b.addTest(.{

Â  Â  Â  Â  .root_source_file = b.path("tests/emoji_token_tests.zig"),

Â  Â  Â  Â  .target = target,

Â  Â  Â  Â  .optimize = optimize,

Â  Â  });

Â  Â  emoji_tests.root_module.addImport("ens_normalize", lib_mod);

Â  Â Â 

Â  Â  const run_emoji_tests = b.addRunArtifact(emoji_tests);

Â  Â Â 

Â  Â  // Add script group tests

Â  Â  const script_group_tests = b.addTest(.{

Â  Â  Â  Â  .root_source_file = b.path("tests/script_group_tests.zig"),

Â  Â  Â  Â  .target = target,

Â  Â  Â  Â  .optimize = optimize,

Â  Â  });

Â  Â  script_group_tests.root_module.addImport("ens_normalize", lib_mod);

Â  Â Â 

Â  Â  const run_script_group_tests = b.addRunArtifact(script_group_tests);

Â  Â Â 

Â  Â  // Add script integration tests

Â  Â  const script_integration_tests = b.addTest(.{

Â  Â  Â  Â  .root_source_file = b.path("tests/script_integration_tests.zig"),

Â  Â  Â  Â  .target = target,

Â  Â  Â  Â  .optimize = optimize,

Â  Â  });

Â  Â  script_integration_tests.root_module.addImport("ens_normalize", lib_mod);

Â  Â Â 

Â  Â  const run_script_integration_tests = b.addRunArtifact(script_integration_tests);

Â  Â Â 

Â  Â  // Add confusable tests

Â  Â  const confusable_tests = b.addTest(.{

Â  Â  Â  Â  .root_source_file = b.path("tests/confusable_tests.zig"),

Â  Â  Â  Â  .target = target,

Â  Â  Â  Â  .optimize = optimize,

Â  Â  });

Â  Â  confusable_tests.root_module.addImport("ens_normalize", lib_mod);

Â  Â Â 

Â  Â  const run_confusable_tests = b.addRunArtifact(confusable_tests);

Â  Â Â 

Â  Â  // Add combining mark tests

Â  Â  const combining_mark_tests = b.addTest(.{

Â  Â  Â  Â  .root_source_file = b.path("tests/combining_mark_tests.zig"),

Â  Â  Â  Â  .target = target,

Â  Â  Â  Â  .optimize = optimize,

Â  Â  });

Â  Â  combining_mark_tests.root_module.addImport("ens_normalize", lib_mod);

Â  Â Â 

Â  Â  const run_combining_mark_tests = b.addRunArtifact(combining_mark_tests);

Â  Â Â 

Â  Â  // Add NSM validation tests

Â  Â  const nsm_validation_tests = b.addTest(.{

Â  Â  Â  Â  .root_source_file = b.path("tests/nsm_validation_tests.zig"),

Â  Â  Â  Â  .target = target,

Â  Â  Â  Â  .optimize = optimize,

Â  Â  });

Â  Â  nsm_validation_tests.root_module.addImport("ens_normalize", lib_mod);

Â  Â Â 

Â  Â  const run_nsm_validation_tests = b.addRunArtifact(nsm_validation_tests);

Â  Â Â 

Â  Â  // Add official test vectors tests

Â  Â  const official_test_vectors = b.addTest(.{

Â  Â  Â  Â  .root_source_file = b.path("tests/official_test_vectors.zig"),

Â  Â  Â  Â  .target = target,

Â  Â  Â  Â  .optimize = optimize,

Â  Â  });

Â  Â  official_test_vectors.root_module.addImport("ens_normalize", lib_mod);

Â  Â Â 

Â  Â  const run_official_test_vectors = b.addRunArtifact(official_test_vectors);

Â  Â Â 

Â  Â  // Update main test step

Â  Â  test_step.dependOn(&run_validation_tests.step);

Â  Â  test_step.dependOn(&run_emoji_tests.step);

Â  Â  test_step.dependOn(&run_script_group_tests.step);

Â  Â  test_step.dependOn(&run_script_integration_tests.step);

Â  Â  test_step.dependOn(&run_confusable_tests.step);

Â  Â  test_step.dependOn(&run_combining_mark_tests.step);

Â  Â  test_step.dependOn(&run_nsm_validation_tests.step);

Â  Â  test_step.dependOn(&run_official_test_vectors.step);

}

```

```zig [./tests/script_integration_tests.zig]

const std = @import("std");

const ens = @import("ens_normalize");

const tokenizer = ens.tokenizer;

const validator = ens.validator;

const static_data_loader = ens.static_data_loader;

const script_groups = ens.script_groups;

const code_points = ens.code_points;



test "script integration - ASCII label" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Create specs

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Create tokenized name

Â  Â  var tokenized = try tokenizer.TokenizedName.fromInput(allocator, "hello", &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  // Validate

Â  Â  const result = try validator.validateLabel(allocator, tokenized, &specs);

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  try testing.expect(result.isASCII());

Â  Â  try testing.expectEqualStrings("ASCII", result.script_group.name);

}



test "script integration - mixed script rejection" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Create specs

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Create tokenized name with mixed script (Latin 'a' + Greek 'Î±')

Â  Â  var tokenized = try tokenizer.TokenizedName.fromInput(allocator, "aÎ±", &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  // Validate - should fail with mixed script

Â  Â  const result = validator.validateLabel(allocator, tokenized, &specs);

Â  Â  try testing.expectError(validator.ValidationError.DisallowedCharacter, result);

}



test "script integration - Greek label" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Create specs

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Create tokenized name with Greek text

Â  Â  var tokenized = try tokenizer.TokenizedName.fromInput(allocator, "Î±Î²Î³Î´Îµ", &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  // Validate

Â  Â  const result = try validator.validateLabel(allocator, tokenized, &specs);

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  try testing.expectEqualStrings("Greek", result.script_group.name);

}



test "script integration - Han label" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Create specs

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Create tokenized name with Chinese text

Â  Â  var tokenized = try tokenizer.TokenizedName.fromInput(allocator, "ä½ å¥½ä¸–ç•Œ", &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  // Validate

Â  Â  const result = try validator.validateLabel(allocator, tokenized, &specs);

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  try testing.expectEqualStrings("Han", result.script_group.name);

}



test "script integration - NSM validation" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Load script groups to test NSM

Â  Â  var groups = try static_data_loader.loadScriptGroups(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  // Check that we loaded NSM data

Â  Â  try testing.expect(groups.nsm_set.count() > 0);

Â  Â  try testing.expectEqual(@as(u32, 4), groups.nsm_max);

Â  Â Â 

Â  Â  // Test some known NSM characters

Â  Â  try testing.expect(groups.isNSM(0x0610)); // Arabic sign sallallahou alayhe wassallam

}```

```zig [./tests/emoji_token_tests.zig]

const std = @import("std");

const ens_normalize = @import("ens_normalize");

const tokenizer = ens_normalize.tokenizer;

const code_points = ens_normalize.code_points;

const emoji = ens_normalize.emoji;

const static_data_loader = ens_normalize.static_data_loader;



test "emoji token - simple emoji" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test with thumbs up emoji

Â  Â  const input = "helloğŸ‘world";

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, input, &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  // Should have: valid("hello"), emoji(ğŸ‘), valid("world")

Â  Â  var found_emoji = false;

Â  Â  for (tokenized.tokens) |token| {

Â  Â  Â  Â  if (token.type == .emoji) {

Â  Â  Â  Â  Â  Â  found_emoji = true;

Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  try testing.expect(found_emoji);

}



test "emoji token - emoji with FE0F" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test with emoji that commonly has FE0F

Â  Â  const input = "â˜ºï¸"; // U+263A U+FE0F

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, input, &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  try testing.expect(tokenized.tokens.len > 0);

Â  Â  try testing.expectEqual(tokenizer.TokenType.emoji, tokenized.tokens[0].type);

}



test "emoji token - skin tone modifier" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test with emoji with skin tone

Â  Â  const input = "ğŸ‘ğŸ»"; // Thumbs up with light skin tone

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, input, &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  try testing.expect(tokenized.tokens.len == 1);

Â  Â  try testing.expectEqual(tokenizer.TokenType.emoji, tokenized.tokens[0].type);

}



test "emoji token - ZWJ sequence" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test with family emoji (ZWJ sequence)

Â  Â  const input = "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦"; // Family: man, woman, girl, boy

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, input, &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  // Should be recognized as a single emoji token if in spec.json

Â  Â  try testing.expect(tokenized.tokens.len >= 1);

}



test "emoji token - mixed text and emoji" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test mixed content

Â  Â  const input = "helloğŸ‘‹worldğŸŒtest";

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, input, &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  // Count emoji tokens

Â  Â  var emoji_count: usize = 0;

Â  Â  for (tokenized.tokens) |token| {

Â  Â  Â  Â  if (token.type == .emoji) {

Â  Â  Â  Â  Â  Â  emoji_count += 1;

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  try testing.expect(emoji_count >= 2); // Should have at least 2 emoji tokens

}



test "emoji data loading" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Test loading emoji data from spec.json

Â  Â  var emoji_map = try static_data_loader.loadEmoji(allocator);

Â  Â  defer emoji_map.deinit();

Â  Â Â 

Â  Â  // Should have loaded many emojis

Â  Â  try testing.expect(emoji_map.all_emojis.items.len > 100);

Â  Â Â 

Â  Â  // Test that we have some common emojis

Â  Â  // Note: These tests depend on what's actually in spec.json

}



test "emoji FE0F normalization" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test that emoji with and without FE0F produce the same token

Â  Â  const input1 = "â˜º"; // Without FE0F

Â  Â  const input2 = "â˜ºï¸"; // With FE0F

Â  Â Â 

Â  Â  const tokenized1 = try tokenizer.TokenizedName.fromInput(allocator, input1, &specs, false);

Â  Â  defer tokenized1.deinit();

Â  Â Â 

Â  Â  const tokenized2 = try tokenizer.TokenizedName.fromInput(allocator, input2, &specs, false);

Â  Â  defer tokenized2.deinit();

Â  Â Â 

Â  Â  // Both should produce emoji tokens if the emoji is in spec.json

Â  Â  // The exact behavior depends on what's in the spec

}```

```zig [./tests/fenced_character_tests.zig]

const std = @import("std");

const tokenizer = @import("../src/tokenizer.zig");

const validator = @import("../src/validator.zig");

const code_points = @import("../src/code_points.zig");

const character_mappings = @import("../src/character_mappings.zig");

const static_data_loader = @import("../src/static_data_loader.zig");



test "fenced characters - leading apostrophe" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test with apostrophe at beginning

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "'hello", &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  const result = validator.validateLabel(allocator, tokenized, &specs);

Â  Â  try testing.expectError(validator.ValidationError.FencedLeading, result);

}



test "fenced characters - trailing apostrophe" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test with apostrophe at end

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "hello'", &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  const result = validator.validateLabel(allocator, tokenized, &specs);

Â  Â  try testing.expectError(validator.ValidationError.FencedTrailing, result);

}



test "fenced characters - consecutive apostrophes" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test consecutive apostrophes in middle

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "hel''lo", &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  const result = validator.validateLabel(allocator, tokenized, &specs);

Â  Â  try testing.expectError(validator.ValidationError.FencedAdjacent, result);

}



test "fenced characters - valid single apostrophe" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test single apostrophe in middle (valid)

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "hel'lo", &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  const result = try validator.validateLabel(allocator, tokenized, &specs);

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  // Should succeed

Â  Â  try testing.expect(!result.isEmpty());

}



test "fenced characters - hyphen tests" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Valid single hyphen

Â  Â  {

Â  Â  Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "hello-world", &specs, false);

Â  Â  Â  Â  defer tokenized.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  const result = try validator.validateLabel(allocator, tokenized, &specs);

Â  Â  Â  Â  defer result.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  try testing.expect(!result.isEmpty());

Â  Â  }

Â  Â Â 

Â  Â  // Invalid consecutive hyphens in middle

Â  Â  {

Â  Â  Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "hello--world", &specs, false);

Â  Â  Â  Â  defer tokenized.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  const result = validator.validateLabel(allocator, tokenized, &specs);

Â  Â  Â  Â  try testing.expectError(validator.ValidationError.FencedAdjacent, result);

Â  Â  }

Â  Â Â 

Â  Â  // Valid trailing consecutive hyphens (special case!)

Â  Â  {

Â  Â  Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "hello---", &specs, false);

Â  Â  Â  Â  defer tokenized.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  const result = try validator.validateLabel(allocator, tokenized, &specs);

Â  Â  Â  Â  defer result.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Should succeed - trailing consecutive fenced are allowed

Â  Â  Â  Â  try testing.expect(!result.isEmpty());

Â  Â  }

}



test "fenced characters - mixed fenced types" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test consecutive different fenced characters

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "hello'-world", &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  const result = validator.validateLabel(allocator, tokenized, &specs);

Â  Â  try testing.expectError(validator.ValidationError.FencedAdjacent, result);

}



test "fenced characters - colon" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Leading colon

Â  Â  {

Â  Â  Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, ":hello", &specs, false);

Â  Â  Â  Â  defer tokenized.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  const result = validator.validateLabel(allocator, tokenized, &specs);

Â  Â  Â  Â  try testing.expectError(validator.ValidationError.FencedLeading, result);

Â  Â  }

Â  Â Â 

Â  Â  // Valid colon in middle

Â  Â  {

Â  Â  Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "hello:world", &specs, false);

Â  Â  Â  Â  defer tokenized.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  const result = try validator.validateLabel(allocator, tokenized, &specs);

Â  Â  Â  Â  defer result.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  try testing.expect(!result.isEmpty());

Â  Â  }

}



test "fenced characters - load from spec.json" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Test loading fenced characters

Â  Â  var fenced_set = try static_data_loader.loadFencedCharacters(allocator);

Â  Â  defer fenced_set.deinit();

Â  Â Â 

Â  Â  // Should contain the mapped apostrophe

Â  Â  try testing.expect(fenced_set.contains(8217)); // Right single quotation mark

Â  Â Â 

Â  Â  // Should contain other fenced characters

Â  Â  try testing.expect(fenced_set.contains(8260)); // Fraction slash

}```

```zig [./tests/validation_fuzz.zig]

const std = @import("std");

const ens_normalize = @import("ens_normalize");

const validator = ens_normalize.validator;

const tokenizer = ens_normalize.tokenizer;

const code_points = ens_normalize.code_points;

const testing = std.testing;



// Main fuzz testing function

pub fn fuzz_validation(input: []const u8) !void {

Â  Â  var gpa = std.heap.GeneralPurposeAllocator(.{}){};

Â  Â  defer _ = gpa.deinit();

Â  Â  const allocator = gpa.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Tokenize first (should never crash)

Â  Â  const tokenized = tokenizer.TokenizedName.fromInput(

Â  Â  Â  Â  allocator,Â 

Â  Â  Â  Â  input,Â 

Â  Â  Â  Â  &specs,Â 

Â  Â  Â  Â  false

Â  Â  ) catch |err| switch (err) {

Â  Â  Â  Â  error.InvalidUtf8 => return,

Â  Â  Â  Â  error.OutOfMemory => return,

Â  Â  Â  Â  else => return err,

Â  Â  };

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  // Validation should handle any tokenized input gracefully

Â  Â  const result = validator.validateLabel(

Â  Â  Â  Â  allocator,

Â  Â  Â  Â  tokenized,

Â  Â  Â  Â  &specs

Â  Â  ) catch |err| switch (err) {

Â  Â  Â  Â  error.EmptyLabel => return,

Â  Â  Â  Â  error.InvalidLabelExtension => return,

Â  Â  Â  Â  error.UnderscoreInMiddle => return,

Â  Â  Â  Â  error.LeadingCombiningMark => return,

Â  Â  Â  Â  error.CombiningMarkAfterEmoji => return,

Â  Â  Â  Â  error.FencedLeading => return,

Â  Â  Â  Â  error.FencedTrailing => return,

Â  Â  Â  Â  error.FencedAdjacent => return,

Â  Â  Â  Â  error.DisallowedCharacter => return,

Â  Â  Â  Â  error.IllegalMixture => return,

Â  Â  Â  Â  error.WholeScriptConfusable => return,

Â  Â  Â  Â  error.DuplicateNSM => return,

Â  Â  Â  Â  error.ExcessiveNSM => return,

Â  Â  Â  Â  error.OutOfMemory => return,

Â  Â  Â  Â  error.InvalidUtf8 => return,

Â  Â  Â  Â  else => return err,

Â  Â  };

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  // Validate result invariants

Â  Â  try validateValidationInvariants(result);

}



fn validateValidationInvariants(result: validator.ValidatedLabel) !void {

Â  Â  // Basic invariants

Â  Â  try testing.expect(result.tokens.len > 0); // Should not be empty if validation succeeded

Â  Â Â 

Â  Â  // Script group should be valid

Â  Â  _ = result.script_group.toString();

Â  Â Â 

Â  Â  // Should have valid script group

Â  Â  try testing.expect(result.script_group != .Unknown);

}



// Underscore placement fuzzing

test "fuzz_underscore_placement" {

Â  Â  const test_cases = [_][]const u8{

Â  Â  Â  Â  "hello",

Â  Â  Â  Â  "_hello",

Â  Â  Â  Â  "he_llo",

Â  Â  Â  Â  "hello_",

Â  Â  Â  Â  "___hello",

Â  Â  Â  Â  "hel_lo_world",

Â  Â  Â  Â  "_",

Â  Â  Â  Â  "__",

Â  Â  Â  Â  "___",

Â  Â  };

Â  Â Â 

Â  Â  for (test_cases) |case| {

Â  Â  Â  Â  try fuzz_validation(case);

Â  Â  }

}



// Fenced character fuzzing

test "fuzz_fenced_characters" {

Â  Â  const fenced_chars = [_][]const u8{ "'", "Â·", "â„" };

Â  Â  const base_strings = [_][]const u8{ "hello", "test", "world" };

Â  Â Â 

Â  Â  for (fenced_chars) |fenced| {

Â  Â  Â  Â  for (base_strings) |base| {

Â  Â  Â  Â  Â  Â  // Leading fenced

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  const input = std.fmt.allocPrint(testing.allocator, "{s}{s}", .{ fenced, base }) catch return;

Â  Â  Â  Â  Â  Â  Â  Â  defer testing.allocator.free(input);

Â  Â  Â  Â  Â  Â  Â  Â  try fuzz_validation(input);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Trailing fenced

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  const input = std.fmt.allocPrint(testing.allocator, "{s}{s}", .{ base, fenced }) catch return;

Â  Â  Â  Â  Â  Â  Â  Â  defer testing.allocator.free(input);

Â  Â  Â  Â  Â  Â  Â  Â  try fuzz_validation(input);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Middle fenced

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  const input = std.fmt.allocPrint(testing.allocator, "he{s}llo", .{fenced}) catch return;

Â  Â  Â  Â  Â  Â  Â  Â  defer testing.allocator.free(input);

Â  Â  Â  Â  Â  Â  Â  Â  try fuzz_validation(input);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Adjacent fenced

Â  Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  Â  Â  const input = std.fmt.allocPrint(testing.allocator, "he{s}{s}llo", .{ fenced, fenced }) catch return;

Â  Â  Â  Â  Â  Â  Â  Â  defer testing.allocator.free(input);

Â  Â  Â  Â  Â  Â  Â  Â  try fuzz_validation(input);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

}



// Label extension fuzzing

test "fuzz_label_extensions" {

Â  Â  const test_cases = [_][]const u8{

Â  Â  Â  Â  "ab--cd",

Â  Â  Â  Â  "xn--test",

Â  Â  Â  Â  "test--",

Â  Â  Â  Â  "--test",

Â  Â  Â  Â  "te--st",

Â  Â  Â  Â  "a--b",

Â  Â  Â  Â  "ab-cd",

Â  Â  Â  Â  "ab-c-d",

Â  Â  };

Â  Â Â 

Â  Â  for (test_cases) |case| {

Â  Â  Â  Â  try fuzz_validation(case);

Â  Â  }

}



// Length stress testing

test "fuzz_length_stress" {

Â  Â  const allocator = testing.allocator;

Â  Â Â 

Â  Â  const lengths = [_]usize{ 1, 10, 100, 1000 };

Â  Â  const patterns = [_][]const u8{ "a", "ab", "abc", "_test", "test_" };

Â  Â Â 

Â  Â  for (lengths) |len| {

Â  Â  Â  Â  for (patterns) |pattern| {

Â  Â  Â  Â  Â  Â  const input = try allocator.alloc(u8, len);

Â  Â  Â  Â  Â  Â  defer allocator.free(input);

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  var i: usize = 0;

Â  Â  Â  Â  Â  Â  while (i < len) {

Â  Â  Â  Â  Â  Â  Â  Â  const remaining = len - i;

Â  Â  Â  Â  Â  Â  Â  Â  const copy_len = @min(remaining, pattern.len);

Â  Â  Â  Â  Â  Â  Â  Â  @memcpy(input[i..i + copy_len], pattern[0..copy_len]);

Â  Â  Â  Â  Â  Â  Â  Â  i += copy_len;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  try fuzz_validation(input);

Â  Â  Â  Â  }

Â  Â  }

}



// Random input fuzzing

test "fuzz_random_inputs" {

Â  Â  const allocator = testing.allocator;

Â  Â Â 

Â  Â  var prng = std.Random.DefaultPrng.init(42);

Â  Â  const random = prng.random();

Â  Â Â 

Â  Â  var i: usize = 0;

Â  Â  while (i < 100) : (i += 1) {

Â  Â  Â  Â  const len = random.intRangeAtMost(usize, 0, 50);

Â  Â  Â  Â  const input = try allocator.alloc(u8, len);

Â  Â  Â  Â  defer allocator.free(input);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Fill with random ASCII chars

Â  Â  Â  Â  for (input) |*byte| {

Â  Â  Â  Â  Â  Â  byte.* = random.intRangeAtMost(u8, 32, 126);

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  try fuzz_validation(input);

Â  Â  }

}



// Unicode boundary fuzzing

test "fuzz_unicode_boundaries" {

Â  Â  const boundary_codepoints = [_]u21{

Â  Â  Â  Â  0x007F, // ASCII boundary

Â  Â  Â  Â  0x0080, // Latin-1 start

Â  Â  Â  Â  0x07FF, // 2-byte UTF-8 boundary

Â  Â  Â  Â  0x0800, // 3-byte UTF-8 start

Â  Â  Â  Â  0xD7FF, // Before surrogate range

Â  Â  Â  Â  0xE000, // After surrogate range

Â  Â  Â  Â  0xFFFD, // Replacement character

Â  Â  Â  Â  0x10000, // 4-byte UTF-8 start

Â  Â  Â  Â  0x10FFFF, // Maximum valid code point

Â  Â  };

Â  Â Â 

Â  Â  for (boundary_codepoints) |cp| {

Â  Â  Â  Â  var buf: [4]u8 = undefined;

Â  Â  Â  Â  const len = std.unicode.utf8Encode(cp, &buf) catch continue;

Â  Â  Â  Â  try fuzz_validation(buf[0..len]);

Â  Â  }

}



// Script mixing fuzzing

test "fuzz_script_mixing" {

Â  Â  const script_chars = [_]struct { []const u8, []const u8 }{

Â  Â  Â  Â  .{ "hello", "ASCII" },

Â  Â  Â  Â  .{ "cafÃ©", "Latin" },

Â  Â  Â  Â  .{ "Î³ÎµÎ¹Î±", "Greek" },

Â  Â  Â  Â  .{ "Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚", "Cyrillic" },

Â  Â  Â  Â  .{ "Ù…Ø±Ø­Ø¨Ø§", "Arabic" },

Â  Â  Â  Â  .{ "×©×œ×•×", "Hebrew" },

Â  Â  };

Â  Â Â 

Â  Â  for (script_chars) |script1| {

Â  Â  Â  Â  for (script_chars) |script2| {

Â  Â  Â  Â  Â  Â  if (std.mem.eql(u8, script1[1], script2[1])) continue;

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  const mixed = std.fmt.allocPrint(testing.allocator, "{s}{s}", .{ script1[0], script2[0] }) catch return;

Â  Â  Â  Â  Â  Â  defer testing.allocator.free(mixed);

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  try fuzz_validation(mixed);

Â  Â  Â  Â  }

Â  Â  }

}



// Performance fuzzing

test "fuzz_performance" {

Â  Â  const allocator = testing.allocator;

Â  Â Â 

Â  Â  const performance_patterns = [_]struct {

Â  Â  Â  Â  pattern: []const u8,

Â  Â  Â  Â  repeat_count: usize,

Â  Â  }{

Â  Â  Â  Â  .{ .pattern = "a", .repeat_count = 1000 },

Â  Â  Â  Â  .{ .pattern = "_", .repeat_count = 100 },

Â  Â  Â  Â  .{ .pattern = "'", .repeat_count = 50 },

Â  Â  Â  Â  .{ .pattern = "ab", .repeat_count = 500 },

Â  Â  Â  Â  .{ .pattern = "a_", .repeat_count = 200 },

Â  Â  };

Â  Â Â 

Â  Â  for (performance_patterns) |case| {

Â  Â  Â  Â  const input = try allocator.alloc(u8, case.pattern.len * case.repeat_count);

Â  Â  Â  Â  defer allocator.free(input);

Â  Â  Â  Â Â 

Â  Â  Â  Â  var i: usize = 0;

Â  Â  Â  Â  while (i < case.repeat_count) : (i += 1) {

Â  Â  Â  Â  Â  Â  const start = i * case.pattern.len;

Â  Â  Â  Â  Â  Â  const end = start + case.pattern.len;

Â  Â  Â  Â  Â  Â  @memcpy(input[start..end], case.pattern);

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  const start_time = std.time.microTimestamp();

Â  Â  Â  Â  try fuzz_validation(input);

Â  Â  Â  Â  const end_time = std.time.microTimestamp();

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Should complete within reasonable time

Â  Â  Â  Â  const duration_us = end_time - start_time;

Â  Â  Â  Â  try testing.expect(duration_us < 1_000_000); // 1 second max

Â  Â  }

}```

```zig [./tests/nsm_validation_tests.zig]

const std = @import("std");

const ens = @import("ens_normalize");

const nsm_validation = ens.nsm_validation;

const script_groups = ens.script_groups;

const static_data_loader = ens.static_data_loader;

const validator = ens.validator;

const tokenizer = ens.tokenizer;

const code_points = ens.code_points;



test "NSM validation - basic count limits" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Create mock script groups and group

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var arabic_group = script_groups.ScriptGroup.init(allocator, "Arabic", 0);

Â  Â  defer arabic_group.deinit();

Â  Â Â 

Â  Â  // Add some Arabic NSMs to the groups NSM set

Â  Â  try groups.nsm_set.put(0x064E, {}); // Fatha

Â  Â  try groups.nsm_set.put(0x064F, {}); // Damma

Â  Â  try groups.nsm_set.put(0x0650, {}); // Kasra

Â  Â  try groups.nsm_set.put(0x0651, {}); // Shadda

Â  Â  try groups.nsm_set.put(0x0652, {}); // Sukun

Â  Â Â 

Â  Â  // Add to script group CM set

Â  Â  try arabic_group.cm.put(0x064E, {});

Â  Â  try arabic_group.cm.put(0x064F, {});

Â  Â  try arabic_group.cm.put(0x0650, {});

Â  Â  try arabic_group.cm.put(0x0651, {});

Â  Â  try arabic_group.cm.put(0x0652, {});

Â  Â Â 

Â  Â  // Test valid sequence: base + 3 NSMs

Â  Â  const valid_seq = [_]u32{0x0628, 0x064E, 0x064F, 0x0650}; // Ø¨ÙÙÙ

Â  Â  try nsm_validation.validateNSM(&valid_seq, &groups, &arabic_group, allocator);

Â  Â Â 

Â  Â  // Test invalid sequence: base + 5 NSMs (exceeds limit)

Â  Â  const invalid_seq = [_]u32{0x0628, 0x064E, 0x064F, 0x0650, 0x0651, 0x0652};

Â  Â  const result = nsm_validation.validateNSM(&invalid_seq, &groups, &arabic_group, allocator);

Â  Â  try testing.expectError(nsm_validation.NSMValidationError.ExcessiveNSM, result);

}



test "NSM validation - duplicate detection" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var arabic_group = script_groups.ScriptGroup.init(allocator, "Arabic", 0);

Â  Â  defer arabic_group.deinit();

Â  Â Â 

Â  Â  try groups.nsm_set.put(0x064E, {});

Â  Â  try arabic_group.cm.put(0x064E, {});

Â  Â Â 

Â  Â  // Test duplicate NSMs

Â  Â  const duplicate_seq = [_]u32{0x0628, 0x064E, 0x064E}; // Ø¨ + fatha + fatha

Â  Â  const result = nsm_validation.validateNSM(&duplicate_seq, &groups, &arabic_group, allocator);

Â  Â  try testing.expectError(nsm_validation.NSMValidationError.DuplicateNSM, result);

}



test "NSM validation - leading NSM detection" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var arabic_group = script_groups.ScriptGroup.init(allocator, "Arabic", 0);

Â  Â  defer arabic_group.deinit();

Â  Â Â 

Â  Â  try groups.nsm_set.put(0x064E, {});

Â  Â Â 

Â  Â  // Test leading NSM

Â  Â  const leading_nsm = [_]u32{0x064E, 0x0628}; // fatha + Ø¨

Â  Â  const result = nsm_validation.validateNSM(&leading_nsm, &groups, &arabic_group, allocator);

Â  Â  try testing.expectError(nsm_validation.NSMValidationError.LeadingNSM, result);

}



test "NSM validation - emoji context" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var emoji_group = script_groups.ScriptGroup.init(allocator, "Emoji", 0);

Â  Â  defer emoji_group.deinit();

Â  Â Â 

Â  Â  try groups.nsm_set.put(0x064E, {});

Â  Â  try emoji_group.cm.put(0x064E, {});

Â  Â Â 

Â  Â  // Test NSM after emoji

Â  Â  const emoji_nsm = [_]u32{0x1F600, 0x064E}; // ğŸ˜€ + fatha

Â  Â  const result = nsm_validation.validateNSM(&emoji_nsm, &groups, &emoji_group, allocator);

Â  Â  try testing.expectError(nsm_validation.NSMValidationError.NSMAfterEmoji, result);

}



test "NSM validation - fenced character context" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var latin_group = script_groups.ScriptGroup.init(allocator, "Latin", 0);

Â  Â  defer latin_group.deinit();

Â  Â Â 

Â  Â  try groups.nsm_set.put(0x0300, {}); // Combining grave accent

Â  Â  try latin_group.cm.put(0x0300, {});

Â  Â Â 

Â  Â  // Test NSM after fenced character (period)

Â  Â  const fenced_nsm = [_]u32{'.', 0x0300}; // . + grave accent

Â  Â  const result = nsm_validation.validateNSM(&fenced_nsm, &groups, &latin_group, allocator);

Â  Â  try testing.expectError(nsm_validation.NSMValidationError.NSMAfterFenced, result);

}



test "NSM detection - comprehensive Unicode ranges" {

Â  Â  const testing = std.testing;

Â  Â Â 

Â  Â  // Test various NSM ranges

Â  Â  try testing.expect(nsm_validation.isNSM(0x0300)); // Combining grave accent

Â  Â  try testing.expect(nsm_validation.isNSM(0x064E)); // Arabic fatha

Â  Â  try testing.expect(nsm_validation.isNSM(0x05B4)); // Hebrew point hiriq

Â  Â  try testing.expect(nsm_validation.isNSM(0x093C)); // Devanagari nukta

Â  Â  try testing.expect(nsm_validation.isNSM(0x0951)); // Devanagari stress sign udatta

Â  Â Â 

Â  Â  // Test non-NSMs

Â  Â  try testing.expect(!nsm_validation.isNSM('a'));

Â  Â  try testing.expect(!nsm_validation.isNSM(0x0628)); // Arabic letter beh

Â  Â  try testing.expect(!nsm_validation.isNSM(0x05D0)); // Hebrew letter alef

}



test "NSM validation - Arabic script-specific rules" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var arabic_group = script_groups.ScriptGroup.init(allocator, "Arabic", 0);

Â  Â  defer arabic_group.deinit();

Â  Â Â 

Â  Â  try groups.nsm_set.put(0x064E, {}); // Fatha

Â  Â  try groups.nsm_set.put(0x064F, {}); // Damma

Â  Â  try groups.nsm_set.put(0x0650, {}); // Kasra

Â  Â  try groups.nsm_set.put(0x0651, {}); // Shadda

Â  Â Â 

Â  Â  try arabic_group.cm.put(0x064E, {});

Â  Â  try arabic_group.cm.put(0x064F, {});

Â  Â  try arabic_group.cm.put(0x0650, {});

Â  Â  try arabic_group.cm.put(0x0651, {});

Â  Â Â 

Â  Â  // Test valid Arabic sequence

Â  Â  const valid_arabic = [_]u32{0x0628, 0x064E, 0x0651}; // Ø¨ÙÙ‘ (beh + fatha + shadda)

Â  Â  try nsm_validation.validateNSM(&valid_arabic, &groups, &arabic_group, allocator);

Â  Â Â 

Â  Â  // Test invalid: too many Arabic diacritics on one consonant (Arabic limit is 3)

Â  Â  const invalid_arabic = [_]u32{0x0628, 0x064E, 0x064F, 0x0650, 0x0651}; // Ø¨ÙÙÙÙ‘

Â  Â  const result = nsm_validation.validateNSM(&invalid_arabic, &groups, &arabic_group, allocator);

Â  Â  try testing.expectError(nsm_validation.NSMValidationError.ExcessiveNSM, result);

}



test "NSM validation - Hebrew script-specific rules" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var hebrew_group = script_groups.ScriptGroup.init(allocator, "Hebrew", 0);

Â  Â  defer hebrew_group.deinit();

Â  Â Â 

Â  Â  try groups.nsm_set.put(0x05B4, {}); // Hebrew point hiriq

Â  Â  try groups.nsm_set.put(0x05B7, {}); // Hebrew point patah

Â  Â  try groups.nsm_set.put(0x05B8, {}); // Hebrew point qamats

Â  Â Â 

Â  Â  try hebrew_group.cm.put(0x05B4, {});

Â  Â  try hebrew_group.cm.put(0x05B7, {});

Â  Â  try hebrew_group.cm.put(0x05B8, {});

Â  Â Â 

Â  Â  // Test valid Hebrew sequence (Hebrew allows max 2 NSMs)

Â  Â  const valid_hebrew = [_]u32{0x05D0, 0x05B4, 0x05B7}; // × + hiriq + patah

Â  Â  try nsm_validation.validateNSM(&valid_hebrew, &groups, &hebrew_group, allocator);

Â  Â Â 

Â  Â  // Test invalid: too many Hebrew points (exceeds Hebrew limit of 2)

Â  Â  const invalid_hebrew = [_]u32{0x05D0, 0x05B4, 0x05B7, 0x05B8}; // × + 3 points

Â  Â  const result = nsm_validation.validateNSM(&invalid_hebrew, &groups, &hebrew_group, allocator);

Â  Â  try testing.expectError(nsm_validation.NSMValidationError.ExcessiveNSM, result);

}



test "NSM validation - Devanagari script-specific rules" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var devanagari_group = script_groups.ScriptGroup.init(allocator, "Devanagari", 0);

Â  Â  defer devanagari_group.deinit();

Â  Â Â 

Â  Â  try groups.nsm_set.put(0x093C, {}); // Devanagari nukta

Â  Â  try groups.nsm_set.put(0x0951, {}); // Devanagari stress sign udatta

Â  Â Â 

Â  Â  try devanagari_group.cm.put(0x093C, {});

Â  Â  try devanagari_group.cm.put(0x0951, {});

Â  Â Â 

Â  Â  // Test valid Devanagari sequence

Â  Â  const valid_devanagari = [_]u32{0x0915, 0x093C, 0x0951}; // à¤• + nukta + udatta

Â  Â  try nsm_validation.validateNSM(&valid_devanagari, &groups, &devanagari_group, allocator);

Â  Â Â 

Â  Â  // Test invalid: NSM on wrong base (vowel instead of consonant)

Â  Â  const invalid_devanagari = [_]u32{0x0905, 0x093C}; // à¤… (vowel) + nukta

Â  Â  const result = nsm_validation.validateNSM(&invalid_devanagari, &groups, &devanagari_group, allocator);

Â  Â  try testing.expectError(nsm_validation.NSMValidationError.InvalidNSMBase, result);

}



test "NSM validation - integration with full validator" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test with a valid Arabic name with NSMs

Â  Â  // Note: Using individual codepoints since we need NSM sequences

Â  Â  // In a real scenario, this would come from proper NFD normalization

Â  Â Â 

Â  Â  // For now, test basic ASCII to ensure no regression

Â  Â  {

Â  Â  Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "hello", &specs, false);

Â  Â  Â  Â  defer tokenized.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  const result = validator.validateLabel(allocator, tokenized, &specs);

Â  Â  Â  Â  if (result) |validated| {

Â  Â  Â  Â  Â  Â  defer validated.deinit();

Â  Â  Â  Â  Â  Â  // Should pass - ASCII names don't have NSMs

Â  Â  Â  Â  Â  Â  try testing.expect(true);

Â  Â  Â  Â  } else |err| {

Â  Â  Â  Â  Â  Â  // Should not fail due to NSM errors for ASCII

Â  Â  Â  Â  Â  Â  try testing.expect(err != validator.ValidationError.ExcessiveNSM);

Â  Â  Â  Â  Â  Â  try testing.expect(err != validator.ValidationError.DuplicateNSM);

Â  Â  Â  Â  Â  Â  try testing.expect(err != validator.ValidationError.LeadingNSM);

Â  Â  Â  Â  }

Â  Â  }

}



test "NSM validation - multiple base characters" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var arabic_group = script_groups.ScriptGroup.init(allocator, "Arabic", 0);

Â  Â  defer arabic_group.deinit();

Â  Â Â 

Â  Â  try groups.nsm_set.put(0x064E, {}); // Fatha

Â  Â  try groups.nsm_set.put(0x064F, {}); // Damma

Â  Â Â 

Â  Â  try arabic_group.cm.put(0x064E, {});

Â  Â  try arabic_group.cm.put(0x064F, {});

Â  Â Â 

Â  Â  // Test sequence with multiple base characters and their NSMs

Â  Â  const multi_base = [_]u32{

Â  Â  Â  Â  0x0628, 0x064E,Â  Â  Â  Â  // Ø¨Ù (beh + fatha)

Â  Â  Â  Â  0x062A, 0x064F,Â  Â  Â  Â  // ØªÙ (teh + damma)Â Â 

Â  Â  Â  Â  0x062B, 0x064E, 0x064F // Ø«ÙÙ (theh + fatha + damma)

Â  Â  };

Â  Â Â 

Â  Â  try nsm_validation.validateNSM(&multi_base, &groups, &arabic_group, allocator);

}



test "NSM validation - empty input" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var latin_group = script_groups.ScriptGroup.init(allocator, "Latin", 0);

Â  Â  defer latin_group.deinit();

Â  Â Â 

Â  Â  const empty_input = [_]u32{};

Â  Â  try nsm_validation.validateNSM(&empty_input, &groups, &latin_group, allocator);

Â  Â  // Should pass - empty input is valid

}



test "NSM validation - no NSMs present" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var latin_group = script_groups.ScriptGroup.init(allocator, "Latin", 0);

Â  Â  defer latin_group.deinit();

Â  Â Â 

Â  Â  const no_nsms = [_]u32{'h', 'e', 'l', 'l', 'o'};

Â  Â  try nsm_validation.validateNSM(&no_nsms, &groups, &latin_group, allocator);

Â  Â  // Should pass - no NSMs to validate

}



test "NSM validation - performance test" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var arabic_group = script_groups.ScriptGroup.init(allocator, "Arabic", 0);

Â  Â  defer arabic_group.deinit();

Â  Â Â 

Â  Â  try groups.nsm_set.put(0x064E, {});

Â  Â  try arabic_group.cm.put(0x064E, {});

Â  Â Â 

Â  Â  // Test with various input sizes

Â  Â  const test_sizes = [_]usize{ 1, 10, 50, 100, 500 };

Â  Â Â 

Â  Â  for (test_sizes) |size| {

Â  Â  Â  Â  const test_input = try allocator.alloc(u32, size);

Â  Â  Â  Â  defer allocator.free(test_input);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Fill with alternating Arabic letters and NSMs

Â  Â  Â  Â  for (test_input, 0..) |*cp, i| {

Â  Â  Â  Â  Â  Â  if (i % 2 == 0) {

Â  Â  Â  Â  Â  Â  Â  Â  cp.* = 0x0628; // Arabic beh

Â  Â  Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  Â  Â  cp.* = 0x064E; // Arabic fatha

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Should complete quickly

Â  Â  Â  Â  const start_time = std.time.nanoTimestamp();

Â  Â  Â  Â  try nsm_validation.validateNSM(test_input, &groups, &arabic_group, allocator);

Â  Â  Â  Â  const end_time = std.time.nanoTimestamp();

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Should complete in reasonable time (less than 1ms for these sizes)

Â  Â  Â  Â  const duration_ns = end_time - start_time;

Â  Â  Â  Â  try testing.expect(duration_ns < 1_000_000); // 1ms

Â  Â  }

}



test "NSM validation - edge cases" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var latin_group = script_groups.ScriptGroup.init(allocator, "Latin", 0);

Â  Â  defer latin_group.deinit();

Â  Â Â 

Â  Â  try groups.nsm_set.put(0x0300, {}); // Combining grave accent

Â  Â  try latin_group.cm.put(0x0300, {});

Â  Â Â 

Â  Â  // Test NSM after control character

Â  Â  const control_nsm = [_]u32{0x0001, 0x0300}; // Control char + NSM

Â  Â  const result1 = nsm_validation.validateNSM(&control_nsm, &groups, &latin_group, allocator);

Â  Â  try testing.expectError(nsm_validation.NSMValidationError.InvalidNSMBase, result1);

Â  Â Â 

Â  Â  // Test NSM after format characterÂ Â 

Â  Â  const format_nsm = [_]u32{0x200E, 0x0300}; // LTR mark + NSM

Â  Â  const result2 = nsm_validation.validateNSM(&format_nsm, &groups, &latin_group, allocator);

Â  Â  try testing.expectError(nsm_validation.NSMValidationError.InvalidNSMBase, result2);

}



test "NSM validation - load from actual data" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Load actual script groups from data

Â  Â  var groups = try static_data_loader.loadScriptGroups(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  // Test with actual NSM data

Â  Â  if (groups.nsm_set.count() > 0) {

Â  Â  Â  Â  // Find a real NSM from the data

Â  Â  Â  Â  var iter = groups.nsm_set.iterator();

Â  Â  Â  Â  if (iter.next()) |entry| {

Â  Â  Â  Â  Â  Â  const nsm = entry.key_ptr.*;

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Create a simple sequence with a base character + NSM

Â  Â  Â  Â  Â  Â  const sequence = [_]u32{0x0061, nsm}; // 'a' + real NSM

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Determine appropriate script group

Â  Â  Â  Â  Â  Â  const test_cps = [_]u32{0x0061}; // Just 'a' for script detection

Â  Â  Â  Â  Â  Â  const script_group = try groups.determineScriptGroup(&test_cps, allocator);

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Test NSM validation (might fail due to script mismatch, but shouldn't crash)

Â  Â  Â  Â  Â  Â  const result = nsm_validation.validateNSM(&sequence, &groups, script_group, allocator);

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // We expect either success or a specific NSM error, not a crash

Â  Â  Â  Â  Â  Â  if (result) |_| {

Â  Â  Â  Â  Â  Â  Â  Â  // Success case

Â  Â  Â  Â  Â  Â  Â  Â  try testing.expect(true);

Â  Â  Â  Â  Â  Â  } else |err| {

Â  Â  Â  Â  Â  Â  Â  Â  // Should be a known NSM validation error

Â  Â  Â  Â  Â  Â  Â  Â  const is_nsm_error = switch (err) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  nsm_validation.NSMValidationError.ExcessiveNSM,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  nsm_validation.NSMValidationError.DuplicateNSM,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  nsm_validation.NSMValidationError.LeadingNSM,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  nsm_validation.NSMValidationError.NSMAfterEmoji,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  nsm_validation.NSMValidationError.NSMAfterFenced,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  nsm_validation.NSMValidationError.InvalidNSMBase,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  nsm_validation.NSMValidationError.NSMOrderError,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  nsm_validation.NSMValidationError.DisallowedNSMScript => true,

Â  Â  Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  Â  Â  Â  try testing.expect(is_nsm_error);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

}```

```zig [./tests/ens_tests.zig]

const std = @import("std");

const testing = std.testing;

const ens_normalize = @import("ens_normalize");



const TestCase = struct {

Â  Â  name: []const u8,

Â  Â  comment: ?[]const u8,

Â  Â  error_expected: bool,

Â  Â  norm: ?[]const u8,

};



const Entry = union(enum) {

Â  Â  version_info: struct {

Â  Â  Â  Â  name: []const u8,

Â  Â  Â  Â  validated: []const u8,

Â  Â  Â  Â  built: []const u8,

Â  Â  Â  Â  cldr: []const u8,

Â  Â  Â  Â  derived: []const u8,

Â  Â  Â  Â  ens_hash_base64: []const u8,

Â  Â  Â  Â  nf_hash_base64: []const u8,

Â  Â  Â  Â  spec_hash: []const u8,

Â  Â  Â  Â  unicode: []const u8,

Â  Â  Â  Â  version: []const u8,

Â  Â  },

Â  Â  test_case: TestCase,

};



fn processTestCase(allocator: std.mem.Allocator, normalizer: *ens_normalize.EnsNameNormalizer, case: TestCase) !void {

Â  Â  const test_name = if (case.comment) |comment|Â 

Â  Â  Â  Â  if (case.name.len < 64)Â 

Â  Â  Â  Â  Â  Â  try std.fmt.allocPrint(allocator, "{s} (`{s}`)", .{comment, case.name})

Â  Â  Â  Â  else

Â  Â  Â  Â  Â  Â  try allocator.dupe(u8, comment)

Â  Â  else

Â  Â  Â  Â  try allocator.dupe(u8, case.name);

Â  Â  defer allocator.free(test_name);

Â  Â Â 

Â  Â  const result = normalizer.process(case.name);

Â  Â Â 

Â  Â  if (result) |processed| {

Â  Â  Â  Â  defer processed.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  if (case.error_expected) {

Â  Â  Â  Â  Â  Â  std.log.err("Test case '{s}': expected error, got success", .{test_name});

Â  Â  Â  Â  Â  Â  return error.UnexpectedSuccess;

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  const actual = try processed.normalize();

Â  Â  Â  Â  defer allocator.free(actual);

Â  Â  Â  Â Â 

Â  Â  Â  Â  if (case.norm) |expected| {

Â  Â  Â  Â  Â  Â  if (!std.mem.eql(u8, actual, expected)) {

Â  Â  Â  Â  Â  Â  Â  Â  std.log.err("Test case '{s}': expected '{s}', got '{s}'", .{test_name, expected, actual});

Â  Â  Â  Â  Â  Â  Â  Â  return error.NormalizationMismatch;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  if (!std.mem.eql(u8, actual, case.name)) {

Â  Â  Â  Â  Â  Â  Â  Â  std.log.err("Test case '{s}': expected '{s}', got '{s}'", .{test_name, case.name, actual});

Â  Â  Â  Â  Â  Â  Â  Â  return error.NormalizationMismatch;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  } else |err| {

Â  Â  Â  Â  if (!case.error_expected) {

Â  Â  Â  Â  Â  Â  std.log.err("Test case '{s}': expected no error, got {}", .{test_name, err});

Â  Â  Â  Â  Â  Â  return error.UnexpectedError;

Â  Â  Â  Â  }

Â  Â  }

}



test "basic ENS normalization test cases" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var normalizer = ens_normalize.EnsNameNormalizer.default(allocator);

Â  Â  defer normalizer.deinit();

Â  Â Â 

Â  Â  // Basic test cases

Â  Â  const test_cases = [_]TestCase{

Â  Â  Â  Â  .{ .name = "hello", .comment = null, .error_expected = false, .norm = null },

Â  Â  Â  Â  .{ .name = "hello.eth", .comment = null, .error_expected = false, .norm = null },

Â  Â  Â  Â  .{ .name = "test-domain", .comment = null, .error_expected = false, .norm = null },

Â  Â  Â  Â  .{ .name = "HELLO", .comment = null, .error_expected = false, .norm = "hello" },

Â  Â  Â  Â  .{ .name = "Hello.ETH", .comment = null, .error_expected = false, .norm = "hello.eth" },

Â  Â  Â  Â  .{ .name = "", .comment = null, .error_expected = true, .norm = null },

Â  Â  Â  Â  .{ .name = ".", .comment = null, .error_expected = true, .norm = null },

Â  Â  Â  Â  .{ .name = "test..domain", .comment = null, .error_expected = true, .norm = null },

Â  Â  };

Â  Â Â 

Â  Â  for (test_cases) |case| {

Â  Â  Â  Â  processTestCase(allocator, &normalizer, case) catch |err| {

Â  Â  Â  Â  Â  Â  // For now, most tests will fail due to incomplete implementation

Â  Â  Â  Â  Â  Â  // This is expected during development

Â  Â  Â  Â  Â  Â  std.log.warn("Test case '{s}' failed with error: {}", .{case.name, err});

Â  Â  Â  Â  };

Â  Â  }

}



test "unicode normalization test cases" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var normalizer = ens_normalize.EnsNameNormalizer.default(allocator);

Â  Â  defer normalizer.deinit();

Â  Â Â 

Â  Â  // Unicode test cases

Â  Â  const test_cases = [_]TestCase{

Â  Â  Â  Â  .{ .name = "cafÃ©", .comment = null, .error_expected = false, .norm = null },

Â  Â  Â  Â  .{ .name = "Î¾.eth", .comment = null, .error_expected = false, .norm = null },

Â  Â  Â  Â  .{ .name = "Ğ¼Ğ¾Ğ¹", .comment = null, .error_expected = false, .norm = null },

Â  Â  Â  Â  .{ .name = "æµ‹è¯•", .comment = null, .error_expected = false, .norm = null },

Â  Â  Â  Â  .{ .name = "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦", .comment = null, .error_expected = false, .norm = null },

Â  Â  Â  Â  .{ .name = "ğŸ‡ºğŸ‡¸", .comment = null, .error_expected = false, .norm = null },

Â  Â  };

Â  Â Â 

Â  Â  for (test_cases) |case| {

Â  Â  Â  Â  processTestCase(allocator, &normalizer, case) catch |err| {

Â  Â  Â  Â  Â  Â  // For now, most tests will fail due to incomplete implementation

Â  Â  Â  Â  Â  Â  // This is expected during development

Â  Â  Â  Â  Â  Â  std.log.warn("Unicode test case '{s}' failed with error: {}", .{case.name, err});

Â  Â  Â  Â  };

Â  Â  }

}



test "error cases" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var normalizer = ens_normalize.EnsNameNormalizer.default(allocator);

Â  Â  defer normalizer.deinit();

Â  Â Â 

Â  Â  // Error test cases

Â  Â  const test_cases = [_]TestCase{

Â  Â  Â  Â  .{ .name = "ab--", .comment = null, .error_expected = true, .norm = null },

Â  Â  Â  Â  .{ .name = "'85", .comment = null, .error_expected = true, .norm = null },

Â  Â  Â  Â  .{ .name = "test\u{300}", .comment = null, .error_expected = true, .norm = null },

Â  Â  Â  Â  .{ .name = "\u{200C}", .comment = null, .error_expected = true, .norm = null },

Â  Â  Â  Â  .{ .name = "\u{200D}", .comment = null, .error_expected = true, .norm = null },

Â  Â  };

Â  Â Â 

Â  Â  for (test_cases) |case| {

Â  Â  Â  Â  processTestCase(allocator, &normalizer, case) catch |err| {

Â  Â  Â  Â  Â  Â  // For now, most tests will fail due to incomplete implementation

Â  Â  Â  Â  Â  Â  // This is expected during development

Â  Â  Â  Â  Â  Â  std.log.warn("Error test case '{s}' failed with error: {}", .{case.name, err});

Â  Â  Â  Â  };

Â  Â  }

}



test "memory management" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var normalizer = ens_normalize.EnsNameNormalizer.default(allocator);

Â  Â  defer normalizer.deinit();

Â  Â Â 

Â  Â  // Test that memory is properly managed

Â  Â  const test_cases = [_][]const u8{

Â  Â  Â  Â  "hello",

Â  Â  Â  Â  "world",

Â  Â  Â  Â  "test.eth",

Â  Â  Â  Â  "domain.name",

Â  Â  };

Â  Â Â 

Â  Â  for (test_cases) |name| {

Â  Â  Â  Â  const result = normalizer.normalize(name) catch |err| {

Â  Â  Â  Â  Â  Â  // Expected to fail with current implementation

Â  Â  Â  Â  Â  Â  try testing.expect(err == ens_normalize.error_types.ProcessError.DisallowedSequence);

Â  Â  Â  Â  Â  Â  continue;

Â  Â  Â  Â  };

Â  Â  Â  Â  defer allocator.free(result);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Basic sanity check

Â  Â  Â  Â  try testing.expect(result.len > 0);

Â  Â  }

}



test "tokenization" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var normalizer = ens_normalize.EnsNameNormalizer.default(allocator);

Â  Â  defer normalizer.deinit();

Â  Â Â 

Â  Â  const input = "hello";

Â  Â  const tokenized = normalizer.tokenize(input) catch |err| {

Â  Â  Â  Â  // Expected to fail with current implementation

Â  Â  Â  Â  try testing.expect(err == ens_normalize.error_types.ProcessError.DisallowedSequence);

Â  Â  Â  Â  return;

Â  Â  };

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  try testing.expect(tokenized.tokens.len > 0);

Â  Â  try testing.expect(tokenized.tokens[0].isText());

}```

```zig [./tests/script_group_tests.zig]

const std = @import("std");

const ens_normalize = @import("ens_normalize");

const script_groups = ens_normalize.script_groups;

const static_data_loader = ens_normalize.static_data_loader;



test "script groups - load from spec.json" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = try static_data_loader.loadScriptGroups(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  // Should have loaded many groups

Â  Â  try testing.expect(groups.groups.len > 100);

Â  Â Â 

Â  Â  // Should have loaded NSM data

Â  Â  try testing.expect(groups.nsm_set.count() > 1000);

Â  Â  try testing.expectEqual(@as(u32, 4), groups.nsm_max);

Â  Â Â 

Â  Â  // Check some known groups exist

Â  Â  var found_latin = false;

Â  Â  var found_greek = false;

Â  Â  var found_cyrillic = false;

Â  Â  var found_han = false;

Â  Â Â 

Â  Â  for (groups.groups) |*group| {

Â  Â  Â  Â  if (std.mem.eql(u8, group.name, "Latin")) found_latin = true;

Â  Â  Â  Â  if (std.mem.eql(u8, group.name, "Greek")) found_greek = true;

Â  Â  Â  Â  if (std.mem.eql(u8, group.name, "Cyrillic")) found_cyrillic = true;

Â  Â  Â  Â  if (std.mem.eql(u8, group.name, "Han")) found_han = true;

Â  Â  }

Â  Â Â 

Â  Â  try testing.expect(found_latin);

Â  Â  try testing.expect(found_greek);

Â  Â  try testing.expect(found_cyrillic);

Â  Â  try testing.expect(found_han);

}



test "script groups - single script detection" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = try static_data_loader.loadScriptGroups(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  // Test Latin script

Â  Â  const latin_cps = [_]u32{ 'h', 'e', 'l', 'l', 'o' };

Â  Â  const latin_group = try groups.determineScriptGroup(&latin_cps, allocator);

Â  Â  try testing.expectEqualStrings("Latin", latin_group.name);

Â  Â Â 

Â  Â  // Test Greek script

Â  Â  const greek_cps = [_]u32{ 0x03B1, 0x03B2, 0x03B3 }; // Î±Î²Î³

Â  Â  const greek_group = try groups.determineScriptGroup(&greek_cps, allocator);

Â  Â  try testing.expectEqualStrings("Greek", greek_group.name);

Â  Â Â 

Â  Â  // Test Cyrillic script

Â  Â  const cyrillic_cps = [_]u32{ 0x0430, 0x0431, 0x0432 }; // Ğ°Ğ±Ğ²

Â  Â  const cyrillic_group = try groups.determineScriptGroup(&cyrillic_cps, allocator);

Â  Â  try testing.expectEqualStrings("Cyrillic", cyrillic_group.name);

}



test "script groups - mixed script rejection" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = try static_data_loader.loadScriptGroups(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  // Test Latin + Greek (should fail)

Â  Â  const latin_greek = [_]u32{ 'a', 'b', 0x03B1 }; // ab + Î±

Â  Â  const result1 = groups.determineScriptGroup(&latin_greek, allocator);

Â  Â  try testing.expectError(error.DisallowedCharacter, result1);

Â  Â Â 

Â  Â  // Test Latin + Cyrillic (should fail)

Â  Â  const latin_cyrillic = [_]u32{ 'a', 0x0430 }; // 'a' + Cyrillic 'Ğ°' (look similar!)

Â  Â  const result2 = groups.determineScriptGroup(&latin_cyrillic, allocator);

Â  Â  try testing.expectError(error.DisallowedCharacter, result2);

Â  Â Â 

Â  Â  // Test Greek + Cyrillic (should fail)

Â  Â  const greek_cyrillic = [_]u32{ 0x03B1, 0x0430 }; // Greek Î± + Cyrillic Ğ°

Â  Â  const result3 = groups.determineScriptGroup(&greek_cyrillic, allocator);

Â  Â  try testing.expectError(error.DisallowedCharacter, result3);

}



test "script groups - common characters" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = try static_data_loader.loadScriptGroups(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  // Numbers should work with Latin

Â  Â  const latin_numbers = [_]u32{ 'a', 'b', 'c', '1', '2', '3' };

Â  Â  const latin_group = try groups.determineScriptGroup(&latin_numbers, allocator);

Â  Â  try testing.expectEqualStrings("Latin", latin_group.name);

Â  Â Â 

Â  Â  // Numbers should work with Greek

Â  Â  const greek_numbers = [_]u32{ 0x03B1, 0x03B2, '1', '2' };

Â  Â  const greek_group = try groups.determineScriptGroup(&greek_numbers, allocator);

Â  Â  try testing.expectEqualStrings("Greek", greek_group.name);

Â  Â Â 

Â  Â  // Hyphen should work with many scripts

Â  Â  const latin_hyphen = [_]u32{ 'a', 'b', '-', 'c' };

Â  Â  const result = groups.determineScriptGroup(&latin_hyphen, allocator);

Â  Â  try testing.expect(result != error.DisallowedCharacter);

}



test "script groups - find conflicting groups" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = try static_data_loader.loadScriptGroups(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  // Test finding conflicts for mixed scripts

Â  Â  const mixed = [_]u32{ 'a', 0x03B1 }; // Latin 'a' + Greek 'Î±'

Â  Â Â 

Â  Â  const conflict = script_groups.findConflictingGroups(&groups, &mixed, allocator) catch |err| {

Â  Â  Â  Â  // If no conflict found, that's also ok for this test

Â  Â  Â  Â  if (err == error.NoConflict) return;

Â  Â  Â  Â  return err;

Â  Â  };

Â  Â  defer allocator.free(conflict.conflicting_groups);

Â  Â Â 

Â  Â  // First group should be Latin (contains 'a')

Â  Â  try testing.expectEqualStrings("Latin", conflict.first_group.name);

Â  Â Â 

Â  Â  // Conflicting codepoint should be Greek Î±

Â  Â  try testing.expectEqual(@as(u32, 0x03B1), conflict.conflicting_cp);

Â  Â Â 

Â  Â  // Conflicting groups should include Greek

Â  Â  var found_greek = false;

Â  Â  for (conflict.conflicting_groups) |g| {

Â  Â  Â  Â  if (std.mem.eql(u8, g.name, "Greek")) {

Â  Â  Â  Â  Â  Â  found_greek = true;

Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  }

Â  Â  }

Â  Â  try testing.expect(found_greek);

}



test "script groups - NSM validation" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = try static_data_loader.loadScriptGroups(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  // Test that we loaded NSM data

Â  Â  try testing.expect(groups.nsm_set.count() > 0);

Â  Â Â 

Â  Â  // Test some known NSM characters

Â  Â  try testing.expect(groups.isNSM(0x0300)); // Combining grave accent

Â  Â  try testing.expect(groups.isNSM(0x0301)); // Combining acute accent

Â  Â  try testing.expect(groups.isNSM(0x0302)); // Combining circumflex accent

Â  Â Â 

Â  Â  // Test non-NSM characters

Â  Â  try testing.expect(!groups.isNSM('a'));

Â  Â  try testing.expect(!groups.isNSM('1'));

Â  Â  try testing.expect(!groups.isNSM(0x03B1)); // Greek Î±

}```

```zig [./tests/character_mappings_tests.zig]

const std = @import("std");

const testing = std.testing;

const ens = @import("ens_normalize");



test "character mappings - ASCII case folding" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const test_cases = [_]struct {

Â  Â  Â  Â  input: []const u8,

Â  Â  Â  Â  expected: []const u8,

Â  Â  Â  Â  comment: []const u8,

Â  Â  }{

Â  Â  Â  Â  .{ .input = "HELLO", .expected = "hello", .comment = "Basic uppercase" },

Â  Â  Â  Â  .{ .input = "Hello", .expected = "hello", .comment = "Mixed case" },

Â  Â  Â  Â  .{ .input = "HeLLo", .expected = "hello", .comment = "Mixed case complex" },

Â  Â  Â  Â  .{ .input = "hello", .expected = "hello", .comment = "Already lowercase" },

Â  Â  Â  Â  .{ .input = "HELLO.ETH", .expected = "hello.eth", .comment = "Domain with uppercase" },

Â  Â  Â  Â  .{ .input = "Hello.ETH", .expected = "hello.eth", .comment = "Domain mixed case" },

Â  Â  Â  Â  .{ .input = "TEST.DOMAIN", .expected = "test.domain", .comment = "Multiple labels" },

Â  Â  Â  Â  .{ .input = "A", .expected = "a", .comment = "Single uppercase" },

Â  Â  Â  Â  .{ .input = "Z", .expected = "z", .comment = "Last uppercase" },

Â  Â  Â  Â  .{ .input = "123", .expected = "123", .comment = "Numbers unchanged" },

Â  Â  Â  Â  .{ .input = "test-123", .expected = "test-123", .comment = "Numbers with hyphens" },

Â  Â  };

Â  Â Â 

Â  Â  for (test_cases) |case| {

Â  Â  Â  Â  const result = try ens.normalize(allocator, case.input);

Â  Â  Â  Â  defer allocator.free(result);

Â  Â  Â  Â Â 

Â  Â  Â  Â  testing.expectEqualStrings(case.expected, result) catch |err| {

Â  Â  Â  Â  Â  Â  std.debug.print("FAIL: {s} - input: '{s}', expected: '{s}', got: '{s}'\n", .{ case.comment, case.input, case.expected, result });

Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  };

Â  Â  }

}



test "character mappings - Unicode character mappings" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const test_cases = [_]struct {

Â  Â  Â  Â  input: []const u8,

Â  Â  Â  Â  expected: []const u8,

Â  Â  Â  Â  comment: []const u8,

Â  Â  }{

Â  Â  Â  Â  // Mathematical symbols

Â  Â  Â  Â  .{ .input = "â„‚", .expected = "C", .comment = "Complex numbers symbol" },

Â  Â  Â  Â  .{ .input = "â„Œ", .expected = "H", .comment = "Hilbert space symbol" },

Â  Â  Â  Â  .{ .input = "â„", .expected = "H", .comment = "Quaternion symbol" },

Â  Â  Â  Â  .{ .input = "â„“", .expected = "l", .comment = "Script small l" },

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Fractions

Â  Â  Â  Â  .{ .input = "Â½", .expected = "1â„2", .comment = "One half" },

Â  Â  Â  Â  .{ .input = "â…“", .expected = "1â„3", .comment = "One third" },

Â  Â  Â  Â  .{ .input = "Â¼", .expected = "1â„4", .comment = "One quarter" },

Â  Â  Â  Â  .{ .input = "Â¾", .expected = "3â„4", .comment = "Three quarters" },

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Complex domains

Â  Â  Â  Â  .{ .input = "testÂ½.eth", .expected = "test1â„2.eth", .comment = "Domain with fraction" },

Â  Â  Â  Â  .{ .input = "â„Œello.eth", .expected = "Hello.eth", .comment = "Domain with math symbol" },

Â  Â  };

Â  Â Â 

Â  Â  for (test_cases) |case| {

Â  Â  Â  Â  const result = try ens.normalize(allocator, case.input);

Â  Â  Â  Â  defer allocator.free(result);

Â  Â  Â  Â Â 

Â  Â  Â  Â  testing.expectEqualStrings(case.expected, result) catch |err| {

Â  Â  Â  Â  Â  Â  std.debug.print("FAIL: {s} - input: '{s}', expected: '{s}', got: '{s}'\n", .{ case.comment, case.input, case.expected, result });

Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  };

Â  Â  }

}



test "character mappings - beautification" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const test_cases = [_]struct {

Â  Â  Â  Â  input: []const u8,

Â  Â  Â  Â  expected: []const u8,

Â  Â  Â  Â  comment: []const u8,

Â  Â  }{

Â  Â  Â  Â  // ASCII case folding should preserve original case for beautification

Â  Â  Â  Â  .{ .input = "HELLO", .expected = "HELLO", .comment = "Uppercase preserved" },

Â  Â  Â  Â  .{ .input = "Hello", .expected = "Hello", .comment = "Mixed case preserved" },

Â  Â  Â  Â  .{ .input = "hello", .expected = "hello", .comment = "Lowercase preserved" },

Â  Â  Â  Â  .{ .input = "Hello.ETH", .expected = "Hello.ETH", .comment = "Domain case preserved" },

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Unicode mappings should still apply

Â  Â  Â  Â  .{ .input = "Â½", .expected = "1â„2", .comment = "Fraction still mapped" },

Â  Â  Â  Â  .{ .input = "â„Œ", .expected = "H", .comment = "Math symbol still mapped" },

Â  Â  Â  Â  .{ .input = "testÂ½.eth", .expected = "test1â„2.eth", .comment = "Domain with fraction" },

Â  Â  };

Â  Â Â 

Â  Â  for (test_cases) |case| {

Â  Â  Â  Â  const result = try ens.beautify(allocator, case.input);

Â  Â  Â  Â  defer allocator.free(result);

Â  Â  Â  Â Â 

Â  Â  Â  Â  testing.expectEqualStrings(case.expected, result) catch |err| {

Â  Â  Â  Â  Â  Â  std.debug.print("FAIL: {s} - input: '{s}', expected: '{s}', got: '{s}'\n", .{ case.comment, case.input, case.expected, result });

Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  };

Â  Â  }

}



test "character mappings - tokenization" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const test_cases = [_]struct {

Â  Â  Â  Â  input: []const u8,

Â  Â  Â  Â  expected_types: []const ens.tokenizer.TokenType,

Â  Â  Â  Â  comment: []const u8,

Â  Â  }{

Â  Â  Â  Â  .{Â 

Â  Â  Â  Â  Â  Â  .input = "HELLO",Â 

Â  Â  Â  Â  Â  Â  .expected_types = &[_]ens.tokenizer.TokenType{.mapped, .mapped, .mapped, .mapped, .mapped},Â 

Â  Â  Â  Â  Â  Â  .comment = "All uppercase -> mapped"Â 

Â  Â  Â  Â  },

Â  Â  Â  Â  .{Â 

Â  Â  Â  Â  Â  Â  .input = "hello",Â 

Â  Â  Â  Â  Â  Â  .expected_types = &[_]ens.tokenizer.TokenType{.valid},Â 

Â  Â  Â  Â  Â  Â  .comment = "All lowercase -> valid (collapsed)"Â 

Â  Â  Â  Â  },

Â  Â  Â  Â  .{Â 

Â  Â  Â  Â  Â  Â  .input = "Hello",Â 

Â  Â  Â  Â  Â  Â  .expected_types = &[_]ens.tokenizer.TokenType{.mapped, .valid},Â 

Â  Â  Â  Â  Â  Â  .comment = "Mixed case -> mapped + valid"Â 

Â  Â  Â  Â  },

Â  Â  Â  Â  .{Â 

Â  Â  Â  Â  Â  Â  .input = "Â½",Â 

Â  Â  Â  Â  Â  Â  .expected_types = &[_]ens.tokenizer.TokenType{.mapped},Â 

Â  Â  Â  Â  Â  Â  .comment = "Unicode fraction -> mapped"Â 

Â  Â  Â  Â  },

Â  Â  Â  Â  .{Â 

Â  Â  Â  Â  Â  Â  .input = "testÂ½.eth",Â 

Â  Â  Â  Â  Â  Â  .expected_types = &[_]ens.tokenizer.TokenType{.valid, .mapped, .stop, .valid},Â 

Â  Â  Â  Â  Â  Â  .comment = "Domain with fraction"Â 

Â  Â  Â  Â  },

Â  Â  };

Â  Â Â 

Â  Â  for (test_cases) |case| {

Â  Â  Â  Â  const tokenized = try ens.tokenize(allocator, case.input);

Â  Â  Â  Â  defer tokenized.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  testing.expectEqual(case.expected_types.len, tokenized.tokens.len) catch |err| {

Â  Â  Â  Â  Â  Â  std.debug.print("FAIL: {s} - token count mismatch: expected {d}, got {d}\n", .{ case.comment, case.expected_types.len, tokenized.tokens.len });

Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  };

Â  Â  Â  Â Â 

Â  Â  Â  Â  for (case.expected_types, 0..) |expected_type, i| {

Â  Â  Â  Â  Â  Â  testing.expectEqual(expected_type, tokenized.tokens[i].type) catch |err| {

Â  Â  Â  Â  Â  Â  Â  Â  std.debug.print("FAIL: {s} - token {d} type mismatch: expected {s}, got {s}\n", .{ case.comment, i, expected_type.toString(), tokenized.tokens[i].type.toString() });

Â  Â  Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  }

Â  Â  }

}



test "character mappings - ignored characters" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const test_cases = [_]struct {

Â  Â  Â  Â  input: []const u8,

Â  Â  Â  Â  expected: []const u8,

Â  Â  Â  Â  comment: []const u8,

Â  Â  }{

Â  Â  Â  Â  .{ .input = "hel\u{00AD}lo", .expected = "hello", .comment = "Soft hyphen ignored" },

Â  Â  Â  Â  .{ .input = "hel\u{200C}lo", .expected = "hello", .comment = "ZWNJ ignored" },

Â  Â  Â  Â  .{ .input = "hel\u{200D}lo", .expected = "hello", .comment = "ZWJ ignored" },

Â  Â  Â  Â  .{ .input = "hel\u{FEFF}lo", .expected = "hello", .comment = "Zero-width no-break space ignored" },

Â  Â  };

Â  Â Â 

Â  Â  for (test_cases) |case| {

Â  Â  Â  Â  const result = try ens.normalize(allocator, case.input);

Â  Â  Â  Â  defer allocator.free(result);

Â  Â  Â  Â Â 

Â  Â  Â  Â  testing.expectEqualStrings(case.expected, result) catch |err| {

Â  Â  Â  Â  Â  Â  std.debug.print("FAIL: {s} - input: '{s}', expected: '{s}', got: '{s}'\n", .{ case.comment, case.input, case.expected, result });

Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  };

Â  Â  }

}



test "character mappings - performance test" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const test_inputs = [_][]const u8{

Â  Â  Â  Â  "HELLO.ETH",

Â  Â  Â  Â  "Hello.ETH",

Â  Â  Â  Â  "testÂ½.domain",

Â  Â  Â  Â  "â„Œello.world",

Â  Â  Â  Â  "MIXED.Case.Domain",

Â  Â  Â  Â  "withâ…“fraction.eth",

Â  Â  Â  Â  "Complex.â„‚.Domain",

Â  Â  Â  Â  "Multiple.Labels.With.UPPERCASE",

Â  Â  };

Â  Â Â 

Â  Â  const iterations = 100;

Â  Â  var timer = try std.time.Timer.start();

Â  Â Â 

Â  Â  for (0..iterations) |_| {

Â  Â  Â  Â  for (test_inputs) |input| {

Â  Â  Â  Â  Â  Â  const result = try ens.normalize(allocator, input);

Â  Â  Â  Â  Â  Â  defer allocator.free(result);

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Ensure result is valid

Â  Â  Â  Â  Â  Â  try testing.expect(result.len > 0);

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  const elapsed = timer.read();

Â  Â  const ns_per_normalization = elapsed / (iterations * test_inputs.len);

Â  Â Â 

Â  Â  std.debug.print("Character mappings performance: {d} iterations in {d}ns ({d}ns per normalization)\n", .{ iterations * test_inputs.len, elapsed, ns_per_normalization });

Â  Â Â 

Â  Â  // Performance should be reasonable (less than 100Î¼s per normalization)

Â  Â  try testing.expect(ns_per_normalization < 100_000);

}



test "character mappings - edge cases" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Empty string

Â  Â  {

Â  Â  Â  Â  const result = try ens.normalize(allocator, "");

Â  Â  Â  Â  defer allocator.free(result);

Â  Â  Â  Â  try testing.expectEqualStrings("", result);

Â  Â  }

Â  Â Â 

Â  Â  // Single character

Â  Â  {

Â  Â  Â  Â  const result = try ens.normalize(allocator, "A");

Â  Â  Â  Â  defer allocator.free(result);

Â  Â  Â  Â  try testing.expectEqualStrings("a", result);

Â  Â  }

Â  Â Â 

Â  Â  // Only periods

Â  Â  {

Â  Â  Â  Â  const result = try ens.normalize(allocator, "...");

Â  Â  Â  Â  defer allocator.free(result);

Â  Â  Â  Â  try testing.expectEqualStrings("...", result);

Â  Â  }

Â  Â Â 

Â  Â  // Mixed valid and ignored characters

Â  Â  {

Â  Â  Â  Â  const result = try ens.normalize(allocator, "a\u{00AD}b\u{200C}c");

Â  Â  Â  Â  defer allocator.free(result);

Â  Â  Â  Â  try testing.expectEqualStrings("abc", result);

Â  Â  }

}```

```zig [./tests/confusable_tests.zig]

const std = @import("std");

const ens = @import("ens_normalize");

const confusables = ens.confusables;

const static_data_loader = ens.static_data_loader;

const validator = ens.validator;

const tokenizer = ens.tokenizer;

const code_points = ens.code_points;



test "confusables - load from ZON" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();



Â  Â  var confusable_data = try static_data_loader.loadConfusables(allocator);

Â  Â  defer confusable_data.deinit();



Â  Â  try testing.expect(confusable_data.sets.len > 0);

Â  Â Â 

Â  Â  // Check that we have some known confusable sets

Â  Â  var found_digit_confusables = false;

Â  Â  for (confusable_data.sets) |*set| {

Â  Â  Â  Â  if (std.mem.eql(u8, set.target, "32")) { // Target "32" for digit 2

Â  Â  Â  Â  Â  Â  found_digit_confusables = true;

Â  Â  Â  Â  Â  Â  try testing.expect(set.valid.len > 0);

Â  Â  Â  Â  Â  Â  try testing.expect(set.confused.len > 0);

Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  }

Â  Â  }

Â  Â  try testing.expect(found_digit_confusables);

}



test "confusables - basic detection" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();



Â  Â  var confusable_data = try static_data_loader.loadConfusables(allocator);

Â  Â  defer confusable_data.deinit();



Â  Â  // Test empty input (should be safe)

Â  Â  const empty_cps = [_]u32{};

Â  Â  const is_empty_confusable = try confusable_data.checkWholeScriptConfusables(&empty_cps, allocator);

Â  Â  try testing.expect(!is_empty_confusable);



Â  Â  // Test single character (should be safe)

Â  Â  const single_cp = [_]u32{'a'};

Â  Â  const is_single_confusable = try confusable_data.checkWholeScriptConfusables(&single_cp, allocator);

Â  Â  try testing.expect(!is_single_confusable);

}



test "confusables - find sets containing characters" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();



Â  Â  var confusable_data = try static_data_loader.loadConfusables(allocator);

Â  Â  defer confusable_data.deinit();



Â  Â  // Test with known confusable characters

Â  Â  const test_cps = [_]u32{ '2', '3' }; // Digits that likely have confusables

Â  Â  const matching_sets = try confusable_data.findSetsContaining(&test_cps, allocator);

Â  Â  defer allocator.free(matching_sets);



Â  Â  // Should find some sets (digits have many confusables)

Â  Â  try testing.expect(matching_sets.len >= 0); // At least we don't crash

}



test "confusables - analysis functionality" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();



Â  Â  var confusable_data = try static_data_loader.loadConfusables(allocator);

Â  Â  defer confusable_data.deinit();



Â  Â  // Test analysis with simple ASCII

Â  Â  const ascii_cps = [_]u32{ 'h', 'e', 'l', 'l', 'o' };

Â  Â  var analysis = try confusable_data.analyzeConfusables(&ascii_cps, allocator);

Â  Â  defer analysis.deinit();



Â  Â  // ASCII letters might or might not have confusables, but analysis should work

Â  Â  try testing.expect(analysis.valid_count + analysis.confused_count + analysis.non_confusable_count == ascii_cps.len);

}



test "confusables - integration with validator" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();



Â  Â  // Test with a simple ASCII name (should pass)

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  var tokenized = try tokenizer.TokenizedName.fromInput(allocator, "hello", &specs, false);

Â  Â  defer tokenized.deinit();



Â  Â  // Should pass validation (ASCII names are generally safe)

Â  Â  const result = validator.validateLabel(allocator, tokenized, &specs);

Â  Â Â 

Â  Â  // Even if it fails for other reasons, it shouldn't be due to confusables

Â  Â  if (result) |validated| {

Â  Â  Â  Â  defer validated.deinit();

Â  Â  Â  Â  try testing.expect(true); // Passed validation

Â  Â  } else |err| {

Â  Â  Â  Â  // If it fails, make sure it's not due to confusables

Â  Â  Â  Â  try testing.expect(err != validator.ValidationError.WholeScriptConfusable);

Â  Â  }

}



test "confusables - mixed confusable detection" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();



Â  Â  var confusable_data = try static_data_loader.loadConfusables(allocator);

Â  Â  defer confusable_data.deinit();



Â  Â  // Create a test scenario with potentially confusable characters

Â  Â  // Note: We need to find actual confusable pairs from the loaded data

Â  Â Â 

Â  Â  if (confusable_data.sets.len > 0) {

Â  Â  Â  Â  // Find a set with both valid and confused characters

Â  Â  Â  Â  for (confusable_data.sets) |*set| {

Â  Â  Â  Â  Â  Â  if (set.valid.len > 0 and set.confused.len > 0) {

Â  Â  Â  Â  Â  Â  Â  Â  // Test mixing valid and confused from same set (should be safe)

Â  Â  Â  Â  Â  Â  Â  Â  const mixed_same_set = [_]u32{ set.valid[0], set.confused[0] };

Â  Â  Â  Â  Â  Â  Â  Â  const is_confusable = try confusable_data.checkWholeScriptConfusables(&mixed_same_set, allocator);

Â  Â  Â  Â  Â  Â  Â  Â  // This should be safe since they're from the same confusable set

Â  Â  Â  Â  Â  Â  Â  Â  try testing.expect(!is_confusable);

Â  Â  Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

}



test "confusables - performance test" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();



Â  Â  var confusable_data = try static_data_loader.loadConfusables(allocator);

Â  Â  defer confusable_data.deinit();



Â  Â  // Test with various input sizes

Â  Â  const test_sizes = [_]usize{ 1, 5, 10, 50, 100 };

Â  Â Â 

Â  Â  for (test_sizes) |size| {

Â  Â  Â  Â  const test_cps = try allocator.alloc(u32, size);

Â  Â  Â  Â  defer allocator.free(test_cps);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Fill with ASCII characters

Â  Â  Â  Â  for (test_cps, 0..) |*cp, i| {

Â  Â  Â  Â  Â  Â  cp.* = 'a' + @as(u32, @intCast(i % 26));

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Should complete quickly

Â  Â  Â  Â  const start_time = std.time.nanoTimestamp();

Â  Â  Â  Â  const is_confusable = try confusable_data.checkWholeScriptConfusables(test_cps, allocator);

Â  Â  Â  Â  const end_time = std.time.nanoTimestamp();

Â  Â  Â  Â Â 

Â  Â  Â  Â  _ = is_confusable; // We don't care about the result, just that it completes

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Should complete in reasonable time (less than 1ms for these sizes)

Â  Â  Â  Â  const duration_ns = end_time - start_time;

Â  Â  Â  Â  try testing.expect(duration_ns < 1_000_000); // 1ms

Â  Â  }

}



test "confusables - error handling" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();



Â  Â  // Test with a confusable data structure that we can control

Â  Â  var test_data = confusables.ConfusableData.init(allocator);

Â  Â  defer test_data.deinit();

Â  Â Â 

Â  Â  // Create test sets

Â  Â  test_data.sets = try allocator.alloc(confusables.ConfusableSet, 2);

Â  Â Â 

Â  Â  // Set 1: Latin-like

Â  Â  test_data.sets[0] = confusables.ConfusableSet.init(allocator, try allocator.dupe(u8, "latin"));

Â  Â  test_data.sets[0].valid = try allocator.dupe(u32, &[_]u32{ 'a', 'b' });

Â  Â  test_data.sets[0].confused = try allocator.dupe(u32, &[_]u32{ 0x0430, 0x0431 }); // Cyrillic Ğ°, Ğ±

Â  Â Â 

Â  Â  // Set 2: Different confusable set

Â  Â  test_data.sets[1] = confusables.ConfusableSet.init(allocator, try allocator.dupe(u8, "cyrillic"));

Â  Â  test_data.sets[1].valid = try allocator.dupe(u32, &[_]u32{ 'x', 'y' });

Â  Â  test_data.sets[1].confused = try allocator.dupe(u32, &[_]u32{ 0x0445, 0x0443 }); // Cyrillic Ñ…, Ñƒ

Â  Â Â 

Â  Â  // Test safe cases

Â  Â  const latin_only = [_]u32{ 'a', 'b' };

Â  Â  const is_latin_safe = try test_data.checkWholeScriptConfusables(&latin_only, allocator);

Â  Â  try testing.expect(!is_latin_safe);

Â  Â Â 

Â  Â  const cyrillic_only = [_]u32{ 0x0430, 0x0431 };

Â  Â  const is_cyrillic_safe = try test_data.checkWholeScriptConfusables(&cyrillic_only, allocator);

Â  Â  try testing.expect(!is_cyrillic_safe);

Â  Â Â 

Â  Â  // Test dangerous mixing between different confusable sets

Â  Â  const mixed_sets = [_]u32{ 'a', 'x' }; // From different confusable sets

Â  Â  const is_mixed_dangerous = try test_data.checkWholeScriptConfusables(&mixed_sets, allocator);

Â  Â  try testing.expect(is_mixed_dangerous);

}```

```zig [./tests/nfc_tests.zig]

const std = @import("std");

const tokenizer = @import("../src/tokenizer.zig");

const code_points = @import("../src/code_points.zig");

const nfc = @import("../src/nfc.zig");

const static_data_loader = @import("../src/static_data_loader.zig");

const utils = @import("../src/utils.zig");



test "NFC - basic composition" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Load NFC data

Â  Â  var nfc_data = try static_data_loader.loadNFCData(allocator);

Â  Â  defer nfc_data.deinit();

Â  Â Â 

Â  Â  // Test case: e + combining acute accent -> Ã©

Â  Â  const input = [_]u32{ 0x0065, 0x0301 }; // e + Ì

Â  Â  const expected = [_]u32{ 0x00E9 }; // Ã©

Â  Â Â 

Â  Â  const result = try nfc.nfc(allocator, &input, &nfc_data);

Â  Â  defer allocator.free(result);

Â  Â Â 

Â  Â  try testing.expectEqualSlices(u32, &expected, result);

}



test "NFC - decomposed string remains decomposed when excluded" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var nfc_data = try static_data_loader.loadNFCData(allocator);

Â  Â  defer nfc_data.deinit();

Â  Â Â 

Â  Â  // Test with an exclusion (need to check what's actually excluded in nf.json)

Â  Â  // For now, test that already composed stays composed

Â  Â  const input = [_]u32{ 0x00E9 }; // Ã© (already composed)

Â  Â Â 

Â  Â  const result = try nfc.nfc(allocator, &input, &nfc_data);

Â  Â  defer allocator.free(result);

Â  Â Â 

Â  Â  try testing.expectEqualSlices(u32, &input, result);

}



test "NFC - tokenization with NFC" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test: "cafÃ©" with combining accent

Â  Â  const input = "cafe\u{0301}"; // cafe + combining acute on e

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, input, &specs, true);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  // Should have created an NFC token for the e + accent

Â  Â  var has_nfc_token = false;

Â  Â  for (tokenized.tokens) |token| {

Â  Â  Â  Â  if (token.type == .nfc) {

Â  Â  Â  Â  Â  Â  has_nfc_token = true;

Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  try testing.expect(has_nfc_token);

}



test "NFC - no change when not needed" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test: regular ASCII doesn't need NFC

Â  Â  const input = "hello";

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, input, &specs, true);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  // Should not have any NFC tokens

Â  Â  for (tokenized.tokens) |token| {

Â  Â  Â  Â  try testing.expect(token.type != .nfc);

Â  Â  }

}



test "NFC - string conversion" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Test the full string NFC function

Â  Â  const input = "cafe\u{0301}"; // cafe with combining accent

Â  Â  const result = try utils.nfc(allocator, input);

Â  Â  defer allocator.free(result);

Â  Â Â 

Â  Â  const expected = "cafÃ©"; // Should be composed

Â  Â  try testing.expectEqualStrings(expected, result);

}```

```zig [./tests/combining_mark_tests.zig]

const std = @import("std");

const ens = @import("ens_normalize");

const combining_marks = ens.combining_marks;

const script_groups = ens.script_groups;

const static_data_loader = ens.static_data_loader;

const validator = ens.validator;

const tokenizer = ens.tokenizer;

const code_points = ens.code_points;



test "combining marks - basic detection" {

Â  Â  const testing = std.testing;

Â  Â Â 

Â  Â  // Test basic combining marks

Â  Â  try testing.expect(combining_marks.isCombiningMark(0x0301)); // Combining acute accent

Â  Â  try testing.expect(combining_marks.isCombiningMark(0x0300)); // Combining grave accent

Â  Â  try testing.expect(combining_marks.isCombiningMark(0x064E)); // Arabic fatha

Â  Â Â 

Â  Â  // Test non-combining marks

Â  Â  try testing.expect(!combining_marks.isCombiningMark('a'));

Â  Â  try testing.expect(!combining_marks.isCombiningMark('A'));

Â  Â  try testing.expect(!combining_marks.isCombiningMark(0x0041)); // Latin A

}



test "combining marks - leading CM validation" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Create a mock script group for testing

Â  Â  var latin_group = script_groups.ScriptGroup.init(allocator, "Latin", 0);

Â  Â  defer latin_group.deinit();

Â  Â Â 

Â  Â  // Add combining mark to allowed set

Â  Â  try latin_group.cm.put(0x0301, {});

Â  Â Â 

Â  Â  // Test leading combining mark (should fail)

Â  Â  const leading_cm = [_]u32{0x0301, 'a'};

Â  Â  const result = combining_marks.validateCombiningMarks(&leading_cm, &latin_group, allocator);

Â  Â  try testing.expectError(combining_marks.ValidationError.LeadingCombiningMark, result);

}



test "combining marks - disallowed CM for script group" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Create a mock script group that doesn't allow Arabic CMs

Â  Â  var latin_group = script_groups.ScriptGroup.init(allocator, "Latin", 0);

Â  Â  defer latin_group.deinit();

Â  Â Â 

Â  Â  // Don't add Arabic CM to allowed set

Â  Â Â 

Â  Â  // Test Arabic CM with Latin group (should fail)

Â  Â  const wrong_script_cm = [_]u32{'a', 0x064E}; // Latin + Arabic fatha

Â  Â  const result = combining_marks.validateCombiningMarks(&wrong_script_cm, &latin_group, allocator);

Â  Â  try testing.expectError(combining_marks.ValidationError.DisallowedCombiningMark, result);

}



test "combining marks - CM after emoji validation" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var emoji_group = script_groups.ScriptGroup.init(allocator, "Emoji", 0);

Â  Â  defer emoji_group.deinit();

Â  Â Â 

Â  Â  // Add combining mark to allowed set

Â  Â  try emoji_group.cm.put(0x0301, {});

Â  Â Â 

Â  Â  // Test emoji + combining mark (should fail)

Â  Â  const emoji_cm = [_]u32{0x1F600, 0x0301}; // Grinning face + acute

Â  Â  const result = combining_marks.validateCombiningMarks(&emoji_cm, &emoji_group, allocator);

Â  Â  try testing.expectError(combining_marks.ValidationError.CombiningMarkAfterEmoji, result);

}



test "combining marks - valid sequences" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var latin_group = script_groups.ScriptGroup.init(allocator, "Latin", 0);

Â  Â  defer latin_group.deinit();

Â  Â Â 

Â  Â  // Add combining marks to allowed set

Â  Â  try latin_group.cm.put(0x0301, {}); // Acute accent

Â  Â  try latin_group.cm.put(0x0300, {}); // Grave accent

Â  Â Â 

Â  Â  // Test valid sequences (should pass)

Â  Â  const valid_sequences = [_][]const u32{

Â  Â  Â  Â  &[_]u32{'a', 0x0301},Â  Â  Â  // Ã¡

Â  Â  Â  Â  &[_]u32{'e', 0x0300},Â  Â  Â  // Ã¨Â Â 

Â  Â  Â  Â  &[_]u32{'a', 0x0301, 0x0300}, // Multiple CMs

Â  Â  };

Â  Â Â 

Â  Â  for (valid_sequences) |seq| {

Â  Â  Â  Â  try combining_marks.validateCombiningMarks(seq, &latin_group, allocator);

Â  Â  }

}



test "combining marks - Arabic diacritic validation" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var arabic_group = script_groups.ScriptGroup.init(allocator, "Arabic", 0);

Â  Â  defer arabic_group.deinit();

Â  Â Â 

Â  Â  // Add Arabic combining marks

Â  Â  try arabic_group.cm.put(0x064E, {}); // Fatha

Â  Â  try arabic_group.cm.put(0x064F, {}); // Damma

Â  Â  try arabic_group.cm.put(0x0650, {}); // Kasra

Â  Â  try arabic_group.cm.put(0x0651, {}); // Shadda

Â  Â Â 

Â  Â  // Test valid Arabic with diacritics

Â  Â  const valid_arabic = [_]u32{0x0628, 0x064E}; // Ø¨Ù (beh + fatha)

Â  Â  try combining_marks.validateCombiningMarks(&valid_arabic, &arabic_group, allocator);

Â  Â Â 

Â  Â  // Test excessive diacritics (should fail)

Â  Â  const excessive = [_]u32{0x0628, 0x064E, 0x064F, 0x0650, 0x0651}; // Too many marks

Â  Â  const result = combining_marks.validateCombiningMarks(&excessive, &arabic_group, allocator);

Â  Â  try testing.expectError(combining_marks.ValidationError.ExcessiveArabicDiacritics, result);

}



test "combining marks - integration with full validation" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test Latin with accents (should work)

Â  Â  {

Â  Â  Â  Â  // Note: Using NFC-composed characters for now since our tokenizer expects pre-composed

Â  Â  Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "cafÃ©", &specs, false);

Â  Â  Â  Â  defer tokenized.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  const result = validator.validateLabel(allocator, tokenized, &specs);

Â  Â  Â  Â  if (result) |validated| {

Â  Â  Â  Â  Â  Â  defer validated.deinit();

Â  Â  Â  Â  Â  Â  // Should pass - Latin script with proper accents

Â  Â  Â  Â  Â  Â  try testing.expect(true);

Â  Â  Â  Â  } else |err| {

Â  Â  Â  Â  Â  Â  // Make sure it's not a combining mark error

Â  Â  Â  Â  Â  Â  try testing.expect(err != validator.ValidationError.LeadingCombiningMark);

Â  Â  Â  Â  Â  Â  try testing.expect(err != validator.ValidationError.DisallowedCombiningMark);

Â  Â  Â  Â  }

Â  Â  }

}



test "combining marks - empty input validation" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var latin_group = script_groups.ScriptGroup.init(allocator, "Latin", 0);

Â  Â  defer latin_group.deinit();

Â  Â Â 

Â  Â  const empty_cps = [_]u32{};

Â  Â  try combining_marks.validateCombiningMarks(&empty_cps, &latin_group, allocator);

Â  Â  // Should pass - nothing to validate

}



test "combining marks - no combining marks in input" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var latin_group = script_groups.ScriptGroup.init(allocator, "Latin", 0);

Â  Â  defer latin_group.deinit();

Â  Â Â 

Â  Â  // Just base characters, no CMs

Â  Â  const no_cms = [_]u32{'h', 'e', 'l', 'l', 'o'};

Â  Â  try combining_marks.validateCombiningMarks(&no_cms, &latin_group, allocator);

Â  Â  // Should pass - no CMs to validate

}



test "combining marks - script-specific rules" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Test Devanagari rules

Â  Â  {

Â  Â  Â  Â  var devanagari_group = script_groups.ScriptGroup.init(allocator, "Devanagari", 0);

Â  Â  Â  Â  defer devanagari_group.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  try devanagari_group.cm.put(0x093E, {}); // Aa matra

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Valid: consonant + vowel sign

Â  Â  Â  Â  const valid_devanagari = [_]u32{0x0915, 0x093E}; // à¤•à¤¾ (ka + aa-matra)

Â  Â  Â  Â  try combining_marks.validateCombiningMarks(&valid_devanagari, &devanagari_group, allocator);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Invalid: vowel sign without consonant

Â  Â  Â  Â  const invalid_devanagari = [_]u32{0x093E}; // Just matra

Â  Â  Â  Â  const result = combining_marks.validateCombiningMarks(&invalid_devanagari, &devanagari_group, allocator);

Â  Â  Â  Â  try testing.expectError(combining_marks.ValidationError.LeadingCombiningMark, result);

Â  Â  }

Â  Â Â 

Â  Â  // Test Thai rules

Â  Â  {

Â  Â  Â  Â  var thai_group = script_groups.ScriptGroup.init(allocator, "Thai", 0);

Â  Â  Â  Â  defer thai_group.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  try thai_group.cm.put(0x0E31, {}); // Mai han-akat

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Valid: consonant + vowel sign

Â  Â  Â  Â  const valid_thai = [_]u32{0x0E01, 0x0E31}; // à¸ + à¸±

Â  Â  Â  Â  try combining_marks.validateCombiningMarks(&valid_thai, &thai_group, allocator);

Â  Â  }

}



test "combining marks - performance test" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var latin_group = script_groups.ScriptGroup.init(allocator, "Latin", 0);

Â  Â  defer latin_group.deinit();

Â  Â Â 

Â  Â  // Add common combining marks

Â  Â  try latin_group.cm.put(0x0301, {});

Â  Â  try latin_group.cm.put(0x0300, {});

Â  Â Â 

Â  Â  // Test with various input sizes

Â  Â  const test_sizes = [_]usize{ 1, 5, 10, 50, 100 };

Â  Â Â 

Â  Â  for (test_sizes) |size| {

Â  Â  Â  Â  const test_cps = try allocator.alloc(u32, size);

Â  Â  Â  Â  defer allocator.free(test_cps);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Fill with alternating base chars and combining marks

Â  Â  Â  Â  for (test_cps, 0..) |*cp, i| {

Â  Â  Â  Â  Â  Â  if (i % 2 == 0) {

Â  Â  Â  Â  Â  Â  Â  Â  cp.* = 'a' + @as(u32, @intCast(i % 26));

Â  Â  Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  Â  Â  cp.* = 0x0301; // Acute accent

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Should complete quickly

Â  Â  Â  Â  const start_time = std.time.nanoTimestamp();

Â  Â  Â  Â  try combining_marks.validateCombiningMarks(test_cps, &latin_group, allocator);

Â  Â  Â  Â  const end_time = std.time.nanoTimestamp();

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Should complete in reasonable time (less than 1ms for these sizes)

Â  Â  Â  Â  const duration_ns = end_time - start_time;

Â  Â  Â  Â  try testing.expect(duration_ns < 1_000_000); // 1ms

Â  Â  }

}



test "combining marks - edge cases" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var latin_group = script_groups.ScriptGroup.init(allocator, "Latin", 0);

Â  Â  defer latin_group.deinit();

Â  Â Â 

Â  Â  try latin_group.cm.put(0x0300, {}); // Grave accent

Â  Â  try latin_group.cm.put(0x0308, {}); // Diaeresis

Â  Â Â 

Â  Â  // Test multiple valid CMs on one base

Â  Â  const multiple_cms = [_]u32{'a', 0x0300, 0x0308}; // Ã Ìˆ (grave + diaeresis)

Â  Â  try combining_marks.validateCombiningMarks(&multiple_cms, &latin_group, allocator);

Â  Â Â 

Â  Â  // Test CM after fenced character (should fail)

Â  Â  const fenced_cm = [_]u32{'.', 0x0300}; // Period + grave accent

Â  Â  const result = combining_marks.validateCombiningMarks(&fenced_cm, &latin_group, allocator);

Â  Â  try testing.expectError(combining_marks.ValidationError.CombiningMarkAfterFenced, result);

}



test "combining marks - load from actual data" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Load actual script groups from data

Â  Â  var groups = try static_data_loader.loadScriptGroups(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  // Test with actual script group data

Â  Â  const latin_cps = [_]u32{'a', 'b', 'c'};

Â  Â  const latin_group = try groups.determineScriptGroup(&latin_cps, allocator);

Â  Â Â 

Â  Â  // Test combining mark validation with real data

Â  Â  if (latin_group.cm.count() > 0) {

Â  Â  Â  Â  // Find a combining mark allowed by Latin script

Â  Â  Â  Â  var iter = latin_group.cm.iterator();

Â  Â  Â  Â  if (iter.next()) |entry| {

Â  Â  Â  Â  Â  Â  const cm = entry.key_ptr.*;

Â  Â  Â  Â  Â  Â  const valid_sequence = [_]u32{'a', cm};

Â  Â  Â  Â  Â  Â  try combining_marks.validateCombiningMarks(&valid_sequence, latin_group, allocator);

Â  Â  Â  Â  }

Â  Â  }

}```

```zig [./tests/official_test_vectors.zig]

const std = @import("std");

const ens = @import("ens_normalize");

const normalizer = ens.normalizer;

const validator = ens.validator;

const tokenizer = ens.tokenizer;

const code_points = ens.code_points;



/// Structure matching the official ENS test vector format

pub const TestVector = struct {

Â  Â  name: []const u8,

Â  Â  norm: ?[]const u8 = null,

Â  Â  should_error: ?bool = null,

Â  Â  comment: ?[]const u8 = null,

Â  Â Â 

Â  Â  pub fn isError(self: TestVector) bool {

Â  Â  Â  Â  return self.should_error orelse false;

Â  Â  }

Â  Â Â 

Â  Â  pub fn expectedNorm(self: TestVector) ?[]const u8 {

Â  Â  Â  Â  // If no norm field, the expected output is the input (unless it's an error)

Â  Â  Â  Â  if (self.norm) |n| return n;

Â  Â  Â  Â  if (self.isError()) return null;

Â  Â  Â  Â  return self.name;

Â  Â  }

};



/// Test result for reporting

pub const TestResult = struct {

Â  Â  vector: TestVector,

Â  Â  passed: bool,

Â  Â  actual_output: ?[]const u8,

Â  Â  actual_error: ?anyerror,

Â  Â  failure_reason: ?[]const u8,

};



/// Load test vectors from JSON file

pub fn loadTestVectors(allocator: std.mem.Allocator) ![]TestVector {

Â  Â  const json_data = @embedFile("ens_cases.json");

Â  Â Â 

Â  Â  const parsed = try std.json.parseFromSlice(

Â  Â  Â  Â  std.json.Value,Â 

Â  Â  Â  Â  allocator,Â 

Â  Â  Â  Â  json_data,Â 

Â  Â  Â  Â  .{ .max_value_len = json_data.len }

Â  Â  );

Â  Â  defer parsed.deinit();

Â  Â Â 

Â  Â  const array = parsed.value.array;

Â  Â  var vectors = std.ArrayList(TestVector).init(allocator);

Â  Â  errdefer vectors.deinit();

Â  Â Â 

Â  Â  // Skip the first element which contains version info

Â  Â  var start_index: usize = 0;

Â  Â  if (array.items.len > 0) {

Â  Â  Â  Â  if (array.items[0].object.get("version")) |_| {

Â  Â  Â  Â  Â  Â  start_index = 1;

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  for (array.items[start_index..]) |item| {

Â  Â  Â  Â  const obj = item.object;

Â  Â  Â  Â Â 

Â  Â  Â  Â  var vector = TestVector{

Â  Â  Â  Â  Â  Â  .name = try allocator.dupe(u8, obj.get("name").?.string),

Â  Â  Â  Â  };

Â  Â  Â  Â Â 

Â  Â  Â  Â  if (obj.get("norm")) |norm| {

Â  Â  Â  Â  Â  Â  vector.norm = try allocator.dupe(u8, norm.string);

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  if (obj.get("error")) |err| {

Â  Â  Â  Â  Â  Â  vector.should_error = err.bool;

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  if (obj.get("comment")) |comment| {

Â  Â  Â  Â  Â  Â  vector.comment = try allocator.dupe(u8, comment.string);

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  try vectors.append(vector);

Â  Â  }

Â  Â Â 

Â  Â  return vectors.toOwnedSlice();

}



/// Run a single test vector

pub fn runTestVector(

Â  Â  allocator: std.mem.Allocator,

Â  Â  vector: TestVector,

Â  Â  specs: *const code_points.CodePointsSpecs,

) TestResult {

Â  Â  _ = specs; // Not currently used

Â  Â Â 

Â  Â  var result = TestResult{

Â  Â  Â  Â  .vector = vector,

Â  Â  Â  Â  .passed = false,

Â  Â  Â  Â  .actual_output = null,

Â  Â  Â  Â  .actual_error = null,

Â  Â  Â  Â  .failure_reason = null,

Â  Â  };

Â  Â Â 

Â  Â  // Try to normalize the input

Â  Â  const normalized = normalizer.normalize(allocator, vector.name) catch |err| {

Â  Â  Â  Â  result.actual_error = err;

Â  Â  Â  Â Â 

Â  Â  Â  Â  if (vector.isError()) {

Â  Â  Â  Â  Â  Â  // Expected an error, got one

Â  Â  Â  Â  Â  Â  result.passed = true;

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  // Unexpected error

Â  Â  Â  Â  Â  Â  result.failure_reason = std.fmt.allocPrint(

Â  Â  Â  Â  Â  Â  Â  Â  allocator,Â 

Â  Â  Â  Â  Â  Â  Â  Â  "Unexpected error: {}",

Â  Â  Â  Â  Â  Â  Â  Â  .{err}

Â  Â  Â  Â  Â  Â  ) catch "Allocation failed";

Â  Â  Â  Â  }

Â  Â  Â  Â  return result;

Â  Â  };

Â  Â  defer allocator.free(normalized);

Â  Â Â 

Â  Â  result.actual_output = allocator.dupe(u8, normalized) catch normalized;

Â  Â Â 

Â  Â  if (vector.isError()) {

Â  Â  Â  Â  // Expected error but got success

Â  Â  Â  Â  result.failure_reason = std.fmt.allocPrint(

Â  Â  Â  Â  Â  Â  allocator,

Â  Â  Â  Â  Â  Â  "Expected error but got: '{s}'",

Â  Â  Â  Â  Â  Â  .{normalized}

Â  Â  Â  Â  ) catch "Allocation failed";

Â  Â  Â  Â  return result;

Â  Â  }

Â  Â Â 

Â  Â  // Compare with expected output

Â  Â  if (vector.expectedNorm()) |expected| {

Â  Â  Â  Â  if (std.mem.eql(u8, normalized, expected)) {

Â  Â  Â  Â  Â  Â  result.passed = true;

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  result.failure_reason = std.fmt.allocPrint(

Â  Â  Â  Â  Â  Â  Â  Â  allocator,

Â  Â  Â  Â  Â  Â  Â  Â  "Expected '{s}' but got '{s}'",

Â  Â  Â  Â  Â  Â  Â  Â  .{expected, normalized}

Â  Â  Â  Â  Â  Â  ) catch "Allocation failed";

Â  Â  Â  Â  }

Â  Â  } else {

Â  Â  Â  Â  // No expected output and no error - consider it passed

Â  Â  Â  Â  result.passed = true;

Â  Â  }

Â  Â Â 

Â  Â  return result;

}



/// Run all test vectors and report results

pub fn runAllTests(allocator: std.mem.Allocator, vectors: []const TestVector) !TestReport {

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  var report = TestReport{

Â  Â  Â  Â  .total = vectors.len,

Â  Â  Â  Â  .passed = 0,

Â  Â  Â  Â  .failed = 0,

Â  Â  Â  Â  .error_tests_passed = 0,

Â  Â  Â  Â  .error_tests_failed = 0,

Â  Â  Â  Â  .norm_tests_passed = 0,

Â  Â  Â  Â  .norm_tests_failed = 0,

Â  Â  };

Â  Â Â 

Â  Â  var failures = std.ArrayList(TestResult).init(allocator);

Â  Â  defer failures.deinit();

Â  Â Â 

Â  Â  for (vectors) |vector| {

Â  Â  Â  Â  const result = runTestVector(allocator, vector, &specs);

Â  Â  Â  Â Â 

Â  Â  Â  Â  if (result.passed) {

Â  Â  Â  Â  Â  Â  report.passed += 1;

Â  Â  Â  Â  Â  Â  if (vector.isError()) {

Â  Â  Â  Â  Â  Â  Â  Â  report.error_tests_passed += 1;

Â  Â  Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  Â  Â  report.norm_tests_passed += 1;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  report.failed += 1;

Â  Â  Â  Â  Â  Â  if (vector.isError()) {

Â  Â  Â  Â  Â  Â  Â  Â  report.error_tests_failed += 1;

Â  Â  Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  Â  Â  report.norm_tests_failed += 1;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  try failures.append(result);

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  report.failures = failures.toOwnedSlice() catch &.{};

Â  Â  return report;

}



pub const TestReport = struct {

Â  Â  total: usize,

Â  Â  passed: usize,

Â  Â  failed: usize,

Â  Â  error_tests_passed: usize,

Â  Â  error_tests_failed: usize,

Â  Â  norm_tests_passed: usize,

Â  Â  norm_tests_failed: usize,

Â  Â  failures: []const TestResult = &.{},

Â  Â Â 

Â  Â  pub fn printSummary(self: TestReport) void {

Â  Â  Â  Â  std.debug.print("\n=== ENS Official Test Vector Results ===\n", .{});

Â  Â  Â  Â  std.debug.print("Total tests: {}\n", .{self.total});

Â  Â  Â  Â  std.debug.print("Passed: {} ({d:.1}%)\n", .{self.passed, @as(f64, @floatFromInt(self.passed)) / @as(f64, @floatFromInt(self.total)) * 100});

Â  Â  Â  Â  std.debug.print("Failed: {}\n\n", .{self.failed});

Â  Â  Â  Â Â 

Â  Â  Â  Â  std.debug.print("Normalization tests: {} passed, {} failed\n", .{self.norm_tests_passed, self.norm_tests_failed});

Â  Â  Â  Â  std.debug.print("Error tests: {} passed, {} failed\n\n", .{self.error_tests_passed, self.error_tests_failed});

Â  Â  Â  Â Â 

Â  Â  Â  Â  if (self.failures.len > 0) {

Â  Â  Â  Â  Â  Â  std.debug.print("First 10 failures:\n", .{});

Â  Â  Â  Â  Â  Â  const max_show = @min(10, self.failures.len);

Â  Â  Â  Â  Â  Â  for (self.failures[0..max_show]) |failure| {

Â  Â  Â  Â  Â  Â  Â  Â  std.debug.print("Â  Input: '{s}'\n", .{failure.vector.name});

Â  Â  Â  Â  Â  Â  Â  Â  if (failure.vector.comment) |comment| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  std.debug.print("Â  Comment: {s}\n", .{comment});

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  if (failure.failure_reason) |reason| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  std.debug.print("Â  Reason: {s}\n", .{reason});

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  std.debug.print("\n", .{});

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  if (self.failures.len > 10) {

Â  Â  Â  Â  Â  Â  Â  Â  std.debug.print("... and {} more failures\n", .{self.failures.len - 10});

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: *TestReport, allocator: std.mem.Allocator) void {

Â  Â  Â  Â  for (self.failures) |failure| {

Â  Â  Â  Â  Â  Â  if (failure.actual_output) |output| {

Â  Â  Â  Â  Â  Â  Â  Â  allocator.free(output);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (failure.failure_reason) |reason| {

Â  Â  Â  Â  Â  Â  Â  Â  allocator.free(reason);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  allocator.free(self.failures);

Â  Â  }

};



// Tests

const testing = std.testing;



test "official test vectors - load and structure" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const vectors = try loadTestVectors(allocator);

Â  Â Â 

Â  Â  // Should have loaded many test vectors

Â  Â  try testing.expect(vectors.len > 100);

Â  Â Â 

Â  Â  // Check structure of first few non-version vectors

Â  Â  var found_error_test = false;

Â  Â  var found_norm_test = false;

Â  Â Â 

Â  Â  for (vectors[0..@min(20, vectors.len)]) |vector| {

Â  Â  Â  Â  if (vector.isError()) {

Â  Â  Â  Â  Â  Â  found_error_test = true;

Â  Â  Â  Â  }

Â  Â  Â  Â  if (vector.norm != null) {

Â  Â  Â  Â  Â  Â  found_norm_test = true;

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  try testing.expect(found_error_test);

Â  Â  try testing.expect(found_norm_test);

}



test "official test vectors - run sample tests" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test a few specific cases we know should work

Â  Â  const test_cases = [_]TestVector{

Â  Â  Â  Â  // Empty string should normalize to empty

Â  Â  Â  Â  TestVector{ .name = "" },

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Simple ASCII should pass through

Â  Â  Â  Â  TestVector{ .name = "hello" },

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Whitespace should error

Â  Â  Â  Â  TestVector{ .name = " ", .should_error = true },

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Period should error

Â  Â  Â  Â  TestVector{ .name = ".", .should_error = true },

Â  Â  };

Â  Â Â 

Â  Â  for (test_cases) |vector| {

Â  Â  Â  Â  const result = runTestVector(allocator, vector, &specs);

Â  Â  Â  Â  if (!result.passed) {

Â  Â  Â  Â  Â  Â  std.debug.print("Failed test: '{s}'\n", .{vector.name});

Â  Â  Â  Â  Â  Â  if (result.failure_reason) |reason| {

Â  Â  Â  Â  Â  Â  Â  Â  std.debug.print("Reason: {s}\n", .{reason});

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

}



test "official test vectors - run subset" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const vectors = try loadTestVectors(allocator);

Â  Â Â 

Â  Â  // Run first 100 tests as a sample

Â  Â  const subset = vectors[0..@min(100, vectors.len)];

Â  Â  var report = try runAllTests(allocator, subset);

Â  Â  defer report.deinit(allocator);

Â  Â Â 

Â  Â  report.printSummary();

Â  Â Â 

Â  Â  // We expect some failures initially

Â  Â  try testing.expect(report.total == subset.len);

}```

```zig [./tests/validation_tests.zig]

const std = @import("std");

const testing = std.testing;

const ens_normalize = @import("ens_normalize");

const validator = ens_normalize.validator;

const tokenizer = ens_normalize.tokenizer;

const code_points = ens_normalize.code_points;



// Test case structure

const ValidationTestCase = struct {

Â  Â  name: []const u8,

Â  Â  input: []const u8,

Â  Â  expected_error: ?validator.ValidationError = null,

Â  Â  expected_script: ?[]const u8 = null,

Â  Â  comment: ?[]const u8 = null,

};



// Empty label tests

const EMPTY_TESTS = [_]ValidationTestCase{

Â  Â  .{ .name = "empty_string", .input = "", .expected_error = validator.ValidationError.EmptyLabel, .comment = "Empty string" },

Â  Â  .{ .name = "whitespace", .input = " ", .expected_error = validator.ValidationError.EmptyLabel, .comment = "Whitespace only" },

Â  Â  .{ .name = "soft_hyphen", .input = "\u{00AD}", .expected_error = validator.ValidationError.EmptyLabel, .comment = "Soft hyphen (ignored)" },

};



// Basic valid tests

const BASIC_VALID_TESTS = [_]ValidationTestCase{

Â  Â  .{ .name = "simple_ascii", .input = "hello", .expected_script = "ASCII", .comment = "Simple ASCII" },

Â  Â  .{ .name = "digits", .input = "123", .expected_script = "ASCII", .comment = "Digits" },

Â  Â  .{ .name = "mixed_ascii", .input = "test123", .expected_script = "ASCII", .comment = "Mixed ASCII" },

Â  Â  .{ .name = "with_hyphen", .input = "test-name", .expected_script = "ASCII", .comment = "With hyphen" },

};



// Underscore rule tests

const UNDERSCORE_TESTS = [_]ValidationTestCase{

Â  Â  .{ .name = "leading_underscore", .input = "_hello", .expected_script = "ASCII", .comment = "Leading underscore" },

Â  Â  .{ .name = "multiple_leading", .input = "____hello", .expected_script = "ASCII", .comment = "Multiple leading underscores" },

Â  Â  .{ .name = "underscore_middle", .input = "hel_lo", .expected_error = validator.ValidationError.UnderscoreInMiddle, .comment = "Underscore in middle" },

Â  Â  .{ .name = "underscore_end", .input = "hello_", .expected_error = validator.ValidationError.UnderscoreInMiddle, .comment = "Underscore at end" },

};



// ASCII label extension tests

const LABEL_EXTENSION_TESTS = [_]ValidationTestCase{

Â  Â  .{ .name = "valid_hyphen", .input = "ab-cd", .expected_script = "ASCII", .comment = "Valid hyphen placement" },

Â  Â  .{ .name = "invalid_extension", .input = "ab--cd", .expected_error = validator.ValidationError.InvalidLabelExtension, .comment = "Invalid label extension" },

Â  Â  .{ .name = "xn_extension", .input = "xn--test", .expected_error = validator.ValidationError.InvalidLabelExtension, .comment = "XN label extension" },

};



// Fenced character tests

const FENCED_TESTS = [_]ValidationTestCase{

Â  Â  .{ .name = "apostrophe_leading", .input = "'hello", .expected_error = validator.ValidationError.FencedLeading, .comment = "Leading apostrophe" },

Â  Â  .{ .name = "apostrophe_trailing", .input = "hello'", .expected_error = validator.ValidationError.FencedTrailing, .comment = "Trailing apostrophe" },

Â  Â  .{ .name = "apostrophe_adjacent", .input = "hel''lo", .expected_error = validator.ValidationError.FencedAdjacent, .comment = "Adjacent apostrophes" },

Â  Â  .{ .name = "apostrophe_valid", .input = "hel'lo", .expected_script = "ASCII", .comment = "Valid apostrophe placement" },

};



// Run test cases

fn runTestCase(test_case: ValidationTestCase) !void {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, test_case.input, &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  // Debug: Print tokenized result for whitespace test

Â  Â  if (std.mem.eql(u8, test_case.input, " ")) {

Â  Â  Â  Â  std.debug.print("\nDEBUG: Whitespace test tokenization:\n", .{});

Â  Â  Â  Â  std.debug.print("Â  Input: '{s}' (len={})\n", .{test_case.input, test_case.input.len});

Â  Â  Â  Â  std.debug.print("Â  Tokens: {} total\n", .{tokenized.tokens.len});

Â  Â  Â  Â  for (tokenized.tokens, 0..) |token, i| {

Â  Â  Â  Â  Â  Â  std.debug.print("Â  Â  [{}] type={s}", .{i, @tagName(token.type)});

Â  Â  Â  Â  Â  Â  if (token.type == .disallowed) {

Â  Â  Â  Â  Â  Â  Â  Â  std.debug.print(" cp=0x{x}", .{token.data.disallowed.cp});

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  std.debug.print("\n", .{});

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  const result = validator.validateLabel(allocator, tokenized, &specs);

Â  Â Â 

Â  Â  if (test_case.expected_error) |expected_error| {

Â  Â  Â  Â  try testing.expectError(expected_error, result);

Â  Â  } else {

Â  Â  Â  Â  const validated = try result;

Â  Â  Â  Â  defer validated.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  if (test_case.expected_script) |expected_script| {

Â  Â  Â  Â  Â  Â  try testing.expectEqualStrings(expected_script, validated.script_group.name);

Â  Â  Â  Â  }

Â  Â  }

}



test "validation - empty labels" {

Â  Â  for (EMPTY_TESTS) |test_case| {

Â  Â  Â  Â  runTestCase(test_case) catch |err| {

Â  Â  Â  Â  Â  Â  std.debug.print("Test failed: {s} - {s}\n", .{ test_case.name, test_case.comment orelse "" });

Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  };

Â  Â  }

}



test "validation - basic valid cases" {

Â  Â  for (BASIC_VALID_TESTS) |test_case| {

Â  Â  Â  Â  runTestCase(test_case) catch |err| {

Â  Â  Â  Â  Â  Â  std.debug.print("Test failed: {s} - {s}\n", .{ test_case.name, test_case.comment orelse "" });

Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  };

Â  Â  }

}



test "validation - underscore rules" {

Â  Â  for (UNDERSCORE_TESTS) |test_case| {

Â  Â  Â  Â  runTestCase(test_case) catch |err| {

Â  Â  Â  Â  Â  Â  std.debug.print("Test failed: {s} - {s}\n", .{ test_case.name, test_case.comment orelse "" });

Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  };

Â  Â  }

}



test "validation - label extension rules" {

Â  Â  for (LABEL_EXTENSION_TESTS) |test_case| {

Â  Â  Â  Â  runTestCase(test_case) catch |err| {

Â  Â  Â  Â  Â  Â  std.debug.print("Test failed: {s} - {s}\n", .{ test_case.name, test_case.comment orelse "" });

Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  };

Â  Â  }

}



test "validation - fenced characters" {

Â  Â  for (FENCED_TESTS) |test_case| {

Â  Â  Â  Â  runTestCase(test_case) catch |err| {

Â  Â  Â  Â  Â  Â  std.debug.print("Test failed: {s} - {s}\n", .{ test_case.name, test_case.comment orelse "" });

Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  };

Â  Â  }

}



test "validation - script group detection" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // ASCII test

Â  Â  {

Â  Â  Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "hello", &specs, false);

Â  Â  Â  Â  defer tokenized.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  const result = try validator.validateLabel(allocator, tokenized, &specs);

Â  Â  Â  Â  defer result.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  try testing.expectEqualStrings("ASCII", result.script_group.name);

Â  Â  }

}



test "validation - performance test" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  const start_time = std.time.microTimestamp();

Â  Â Â 

Â  Â  var i: usize = 0;

Â  Â  while (i < 1000) : (i += 1) {

Â  Â  Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "hello", &specs, false);

Â  Â  Â  Â  defer tokenized.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  const result = try validator.validateLabel(allocator, tokenized, &specs);

Â  Â  Â  Â  defer result.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  try testing.expectEqualStrings("ASCII", result.script_group.name);

Â  Â  }

Â  Â Â 

Â  Â  const end_time = std.time.microTimestamp();

Â  Â  const duration_us = end_time - start_time;

Â  Â Â 

Â  Â  std.debug.print("Validated 1000 times in {d}ms ({d:.2}Î¼s per validation)\n", .{ @divTrunc(duration_us, 1000), @as(f64, @floatFromInt(duration_us)) / 1000.0 });

Â  Â Â 

Â  Â  // Should complete within reasonable time

Â  Â  try testing.expect(duration_us < 1_000_000); // 1 second

}```

```zig [./tests/tokenization_tests.zig]

const std = @import("std");

const testing = std.testing;

const ens_normalize = @import("ens_normalize");

const tokenizer = ens_normalize.tokenizer;

const code_points = ens_normalize.code_points;

const constants = ens_normalize.constants;

const utils = ens_normalize.utils;



// Test case structure based on reference implementations

const TokenizationTestCase = struct {

Â  Â  name: []const u8,

Â  Â  input: []const u8,

Â  Â  expected_tokens: []const ExpectedToken,

Â  Â  should_error: bool = false,

Â  Â  comment: ?[]const u8 = null,

};



const ExpectedToken = struct {

Â  Â  type: tokenizer.TokenType,

Â  Â  cps: ?[]const u32 = null,

Â  Â  cp: ?u32 = null,

Â  Â  input_size: ?usize = null,

};



// Test cases derived from JavaScript implementation

const BASIC_TOKENIZATION_TESTS = [_]TokenizationTestCase{

Â  Â  .{

Â  Â  Â  Â  .name = "empty_string",

Â  Â  Â  Â  .input = "",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{},

Â  Â  Â  Â  .comment = "Empty string should produce no tokens",

Â  Â  },

Â  Â  .{

Â  Â  Â  Â  .name = "simple_ascii",

Â  Â  Â  Â  .input = "hello",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 'h', 'e', 'l', 'l', 'o' } },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Simple ASCII should collapse into one valid token",

Â  Â  },

Â  Â  .{

Â  Â  Â  Â  .name = "single_character",

Â  Â  Â  Â  .input = "a",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{'a'} },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Single character should be valid token",

Â  Â  },

Â  Â  .{

Â  Â  Â  Â  .name = "with_stop",

Â  Â  Â  Â  .input = "hello.eth",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 'h', 'e', 'l', 'l', 'o' } },

Â  Â  Â  Â  Â  Â  .{ .type = .stop, .cp = constants.CP_STOP },

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 'e', 't', 'h' } },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Domain with stop character should separate labels",

Â  Â  },

Â  Â  .{

Â  Â  Â  Â  .name = "multiple_stops",

Â  Â  Â  Â  .input = "a.b.c",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{'a'} },

Â  Â  Â  Â  Â  Â  .{ .type = .stop, .cp = constants.CP_STOP },

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{'b'} },

Â  Â  Â  Â  Â  Â  .{ .type = .stop, .cp = constants.CP_STOP },

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{'c'} },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Multiple stops should separate multiple labels",

Â  Â  },

Â  Â  .{

Â  Â  Â  Â  .name = "with_hyphen",

Â  Â  Â  Â  .input = "test-domain",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 't', 'e', 's', 't', '-', 'd', 'o', 'm', 'a', 'i', 'n' } },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Hyphen should be valid and collapsed",

Â  Â  },

Â  Â  .{

Â  Â  Â  Â  .name = "mixed_case",

Â  Â  Â  Â  .input = "Hello",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 'H', 'e', 'l', 'l', 'o' } },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Mixed case should be valid (normalization happens later)",

Â  Â  },

Â  Â  .{

Â  Â  Â  Â  .name = "with_numbers",

Â  Â  Â  Â  .input = "test123",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 't', 'e', 's', 't', '1', '2', '3' } },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Numbers should be valid",

Â  Â  },

};



// Test cases for ignored characters (from JavaScript IGNORED set)

const IGNORED_CHARACTERS_TESTS = [_]TokenizationTestCase{

Â  Â  .{

Â  Â  Â  Â  .name = "soft_hyphen",

Â  Â  Â  Â  .input = "test\u{00AD}domain",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 't', 'e', 's', 't' } },

Â  Â  Â  Â  Â  Â  .{ .type = .ignored, .cp = 0x00AD },

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 'd', 'o', 'm', 'a', 'i', 'n' } },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Soft hyphen should be ignored",

Â  Â  },

Â  Â  .{

Â  Â  Â  Â  .name = "zero_width_non_joiner",

Â  Â  Â  Â  .input = "te\u{200C}st",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 't', 'e' } },

Â  Â  Â  Â  Â  Â  .{ .type = .ignored, .cp = 0x200C },

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 's', 't' } },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Zero width non-joiner should be ignored",

Â  Â  },

Â  Â  .{

Â  Â  Â  Â  .name = "zero_width_joiner",

Â  Â  Â  Â  .input = "te\u{200D}st",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 't', 'e' } },

Â  Â  Â  Â  Â  Â  .{ .type = .ignored, .cp = 0x200D },

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 's', 't' } },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Zero width joiner should be ignored",

Â  Â  },

Â  Â  .{

Â  Â  Â  Â  .name = "zero_width_no_break_space",

Â  Â  Â  Â  .input = "te\u{FEFF}st",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 't', 'e' } },

Â  Â  Â  Â  Â  Â  .{ .type = .ignored, .cp = 0xFEFF },

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 's', 't' } },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Zero width no-break space should be ignored",

Â  Â  },

};



// Test cases for disallowed characters

const DISALLOWED_CHARACTERS_TESTS = [_]TokenizationTestCase{

Â  Â  .{

Â  Â  Â  Â  .name = "special_symbols",

Â  Â  Â  Â  .input = "test!",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 't', 'e', 's', 't' } },

Â  Â  Â  Â  Â  Â  .{ .type = .disallowed, .cp = '!' },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Special symbols should be disallowed",

Â  Â  },

Â  Â  .{

Â  Â  Â  Â  .name = "at_symbol",

Â  Â  Â  Â  .input = "user@domain",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 'u', 's', 'e', 'r' } },

Â  Â  Â  Â  Â  Â  .{ .type = .disallowed, .cp = '@' },

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 'd', 'o', 'm', 'a', 'i', 'n' } },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "At symbol should be disallowed",

Â  Â  },

Â  Â  .{

Â  Â  Â  Â  .name = "hash_symbol",

Â  Â  Â  Â  .input = "test#hash",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 't', 'e', 's', 't' } },

Â  Â  Â  Â  Â  Â  .{ .type = .disallowed, .cp = '#' },

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 'h', 'a', 's', 'h' } },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Hash symbol should be disallowed",

Â  Â  },

};



// Test cases for edge cases

const EDGE_CASE_TESTS = [_]TokenizationTestCase{

Â  Â  .{

Â  Â  Â  Â  .name = "only_stop",

Â  Â  Â  Â  .input = ".",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .stop, .cp = constants.CP_STOP },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Single stop character",

Â  Â  },

Â  Â  .{

Â  Â  Â  Â  .name = "only_ignored",

Â  Â  Â  Â  .input = "\u{200C}",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .ignored, .cp = 0x200C },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Single ignored character",

Â  Â  },

Â  Â  .{

Â  Â  Â  Â  .name = "only_disallowed",

Â  Â  Â  Â  .input = "!",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .disallowed, .cp = '!' },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Single disallowed character",

Â  Â  },

Â  Â  .{

Â  Â  Â  Â  .name = "multiple_consecutive_stops",

Â  Â  Â  Â  .input = "a..b",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{'a'} },

Â  Â  Â  Â  Â  Â  .{ .type = .stop, .cp = constants.CP_STOP },

Â  Â  Â  Â  Â  Â  .{ .type = .stop, .cp = constants.CP_STOP },

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{'b'} },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Multiple consecutive stops",

Â  Â  },

Â  Â  .{

Â  Â  Â  Â  .name = "trailing_stop",

Â  Â  Â  Â  .input = "domain.",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 'd', 'o', 'm', 'a', 'i', 'n' } },

Â  Â  Â  Â  Â  Â  .{ .type = .stop, .cp = constants.CP_STOP },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Trailing stop character",

Â  Â  },

Â  Â  .{

Â  Â  Â  Â  .name = "leading_stop",

Â  Â  Â  Â  .input = ".domain",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .stop, .cp = constants.CP_STOP },

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 'd', 'o', 'm', 'a', 'i', 'n' } },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Leading stop character",

Â  Â  },

};



// Test cases for NFC normalization (simplified for now)

const NFC_TESTS = [_]TokenizationTestCase{

Â  Â  .{

Â  Â  Â  Â  .name = "nfc_simple",

Â  Â  Â  Â  .input = "test",

Â  Â  Â  Â  .expected_tokens = &[_]ExpectedToken{

Â  Â  Â  Â  Â  Â  .{ .type = .valid, .cps = &[_]u32{ 't', 'e', 's', 't' } },

Â  Â  Â  Â  },

Â  Â  Â  Â  .comment = "Simple case should not need NFC",

Â  Â  },

};



// Helper function to run a single test case

fn runTokenizationTest(test_case: TokenizationTestCase) !void {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Tokenize the input

Â  Â  const result = tokenizer.TokenizedName.fromInput(allocator, test_case.input, &specs, false) catch |err| {

Â  Â  Â  Â  if (test_case.should_error) {

Â  Â  Â  Â  Â  Â  return; // Expected error

Â  Â  Â  Â  }

Â  Â  Â  Â  std.debug.print("Unexpected error in test '{s}': {}\n", .{ test_case.name, err });

Â  Â  Â  Â  return err;

Â  Â  };

Â  Â Â 

Â  Â  if (test_case.should_error) {

Â  Â  Â  Â  std.debug.print("Test '{s}' should have failed but succeeded\n", .{test_case.name});

Â  Â  Â  Â  return error.UnexpectedSuccess;

Â  Â  }

Â  Â Â 

Â  Â  // Check token count

Â  Â  if (result.tokens.len != test_case.expected_tokens.len) {

Â  Â  Â  Â  std.debug.print("Test '{s}': expected {} tokens, got {}\n", .{ test_case.name, test_case.expected_tokens.len, result.tokens.len });

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Print actual tokens for debugging

Â  Â  Â  Â  std.debug.print("Actual tokens:\n", .{});

Â  Â  Â  Â  for (result.tokens, 0..) |token, i| {

Â  Â  Â  Â  Â  Â  std.debug.print("Â  [{}] type={s}", .{ i, @tagName(token.type) });

Â  Â  Â  Â  Â  Â  switch (token.type) {

Â  Â  Â  Â  Â  Â  Â  Â  .valid => std.debug.print(" cps={any}", .{token.getCps()}),

Â  Â  Â  Â  Â  Â  Â  Â  .ignored, .disallowed, .stop => std.debug.print(" cp={}", .{token.getCps()[0]}),

Â  Â  Â  Â  Â  Â  Â  Â  else => {},

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  std.debug.print("\n", .{});

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  return error.TokenCountMismatch;

Â  Â  }

Â  Â Â 

Â  Â  // Check each token

Â  Â  for (result.tokens, test_case.expected_tokens, 0..) |actual, expected, i| {

Â  Â  Â  Â  if (actual.type != expected.type) {

Â  Â  Â  Â  Â  Â  std.debug.print("Test '{s}' token {}: expected type {s}, got {s}\n", .{ test_case.name, i, @tagName(expected.type), @tagName(actual.type) });

Â  Â  Â  Â  Â  Â  return error.TokenTypeMismatch;

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  switch (expected.type) {

Â  Â  Â  Â  Â  Â  .valid => {

Â  Â  Â  Â  Â  Â  Â  Â  if (expected.cps) |expected_cps| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const actual_cps = actual.getCps();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (actual_cps.len != expected_cps.len) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  std.debug.print("Test '{s}' token {}: expected {} cps, got {}\n", .{ test_case.name, i, expected_cps.len, actual_cps.len });

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return error.TokenCpsMismatch;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (actual_cps, expected_cps) |actual_cp, expected_cp| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (actual_cp != expected_cp) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  std.debug.print("Test '{s}' token {}: expected cp {}, got {}\n", .{ test_case.name, i, expected_cp, actual_cp });

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return error.TokenCpMismatch;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  .ignored, .disallowed, .stop => {

Â  Â  Â  Â  Â  Â  Â  Â  if (expected.cp) |expected_cp| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const actual_cps = actual.getCps();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (actual_cps.len != 1 or actual_cps[0] != expected_cp) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  std.debug.print("Test '{s}' token {}: expected cp {}, got {any}\n", .{ test_case.name, i, expected_cp, actual_cps });

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return error.TokenCpMismatch;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  else => {

Â  Â  Â  Â  Â  Â  Â  Â  // Other token types not fully implemented yet

Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  }

Â  Â  }

}



// Individual test functions

test "basic tokenization" {

Â  Â  for (BASIC_TOKENIZATION_TESTS) |test_case| {

Â  Â  Â  Â  runTokenizationTest(test_case) catch |err| {

Â  Â  Â  Â  Â  Â  std.debug.print("Failed basic tokenization test: {s}\n", .{test_case.name});

Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  };

Â  Â  }

}



test "ignored characters" {

Â  Â  for (IGNORED_CHARACTERS_TESTS) |test_case| {

Â  Â  Â  Â  runTokenizationTest(test_case) catch |err| {

Â  Â  Â  Â  Â  Â  std.debug.print("Failed ignored characters test: {s}\n", .{test_case.name});

Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  };

Â  Â  }

}



test "disallowed characters" {

Â  Â  for (DISALLOWED_CHARACTERS_TESTS) |test_case| {

Â  Â  Â  Â  runTokenizationTest(test_case) catch |err| {

Â  Â  Â  Â  Â  Â  std.debug.print("Failed disallowed characters test: {s}\n", .{test_case.name});

Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  };

Â  Â  }

}



test "edge cases" {

Â  Â  for (EDGE_CASE_TESTS) |test_case| {

Â  Â  Â  Â  runTokenizationTest(test_case) catch |err| {

Â  Â  Â  Â  Â  Â  std.debug.print("Failed edge case test: {s}\n", .{test_case.name});

Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  };

Â  Â  }

}



test "nfc normalization" {

Â  Â  for (NFC_TESTS) |test_case| {

Â  Â  Â  Â  runTokenizationTest(test_case) catch |err| {

Â  Â  Â  Â  Â  Â  std.debug.print("Failed NFC test: {s}\n", .{test_case.name});

Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  };

Â  Â  }

}



// Performance test

test "tokenization performance" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test with a moderately sized input

Â  Â  const input = "this-is-a-longer-domain-name-for-performance-testing.eth";

Â  Â Â 

Â  Â  const start = std.time.nanoTimestamp();

Â  Â  for (0..1000) |_| {

Â  Â  Â  Â  const result = try tokenizer.TokenizedName.fromInput(allocator, input, &specs, false);

Â  Â  Â  Â  _ = result; // Use result to prevent optimization

Â  Â  }

Â  Â  const end = std.time.nanoTimestamp();

Â  Â Â 

Â  Â  const duration_ns = end - start;

Â  Â  const duration_ms = @as(f64, @floatFromInt(duration_ns)) / 1_000_000.0;

Â  Â Â 

Â  Â  std.debug.print("Tokenized 1000 times in {d:.2}ms ({d:.2}Î¼s per tokenization)\n", .{ duration_ms, duration_ms * 1000.0 / 1000.0 });

Â  Â Â 

Â  Â  // Should be reasonably fast

Â  Â  try testing.expect(duration_ms < 1000.0); // Less than 1 second total

}



// Memory usage test

test "tokenization memory usage" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test that we can tokenize without excessive memory usage

Â  Â  const inputs = [_][]const u8{

Â  Â  Â  Â  "short",

Â  Â  Â  Â  "medium-length-domain.eth",

Â  Â  Â  Â  "very-long-domain-name-with-many-hyphens-and-characters.subdomain.eth",

Â  Â  Â  Â  "a.b.c.d.e.f.g.h.i.j.k.l.m.n.o.p.q.r.s.t.u.v.w.x.y.z",

Â  Â  };

Â  Â Â 

Â  Â  for (inputs) |input| {

Â  Â  Â  Â  const result = try tokenizer.TokenizedName.fromInput(allocator, input, &specs, false);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Basic sanity checks

Â  Â  Â  Â  try testing.expect(result.tokens.len > 0);

Â  Â  Â  Â  try testing.expect(result.input.len == input.len);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Check that we can access all token data without issues

Â  Â  Â  Â  for (result.tokens) |token| {

Â  Â  Â  Â  Â  Â  _ = token.getCps();

Â  Â  Â  Â  Â  Â  _ = token.getInputSize();

Â  Â  Â  Â  Â  Â  _ = token.isText();

Â  Â  Â  Â  Â  Â  _ = token.isEmoji();

Â  Â  Â  Â  }

Â  Â  }

}



// Integration test with actual ENS names

test "real ens name tokenization" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  const real_names = [_][]const u8{

Â  Â  Â  Â  "vitalik.eth",

Â  Â  Â  Â  "ethereum.eth",

Â  Â  Â  Â  "test-domain.eth",

Â  Â  Â  Â  "a.eth",

Â  Â  Â  Â  "subdomain.domain.eth",

Â  Â  Â  Â  "1234.eth",

Â  Â  Â  Â  "mixed-Case.eth",

Â  Â  };

Â  Â Â 

Â  Â  for (real_names) |name| {

Â  Â  Â  Â  const result = try tokenizer.TokenizedName.fromInput(allocator, name, &specs, false);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Should have at least one token

Â  Â  Â  Â  try testing.expect(result.tokens.len > 0);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Should end with .eth

Â  Â  Â  Â  try testing.expect(result.tokens[result.tokens.len - 1].type == .valid);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Should contain a stop character (.)

Â  Â  Â  Â  var has_stop = false;

Â  Â  Â  Â  for (result.tokens) |token| {

Â  Â  Â  Â  Â  Â  if (token.type == .stop) {

Â  Â  Â  Â  Â  Â  Â  Â  has_stop = true;

Â  Â  Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  try testing.expect(has_stop);

Â  Â  }

}```

```zig [./tests/tokenization_fuzz.zig]

const std = @import("std");

const ens_normalize = @import("ens_normalize");

const tokenizer = ens_normalize.tokenizer;

const code_points = ens_normalize.code_points;

const testing = std.testing;



// Main fuzz testing function that should never crash

pub fn fuzz_tokenization(input: []const u8) !void {

Â  Â  var gpa = std.heap.GeneralPurposeAllocator(.{}){};

Â  Â  defer _ = gpa.deinit();

Â  Â  const allocator = gpa.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Should never crash, even with malformed input

Â  Â  const result = tokenizer.TokenizedName.fromInput(

Â  Â  Â  Â  allocator,Â 

Â  Â  Â  Â  input,Â 

Â  Â  Â  Â  &specs,Â 

Â  Â  Â  Â  false

Â  Â  ) catch |err| switch (err) {

Â  Â  Â  Â  error.InvalidUtf8 => return, // Expected for malformed UTF-8

Â  Â  Â  Â  error.OutOfMemory => return, // Expected for huge inputs

Â  Â  Â  Â  else => return err, // Unexpected errors should fail the test

Â  Â  };

Â  Â Â 

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  // Verify basic invariants hold for all outputs

Â  Â  try validateTokenInvariants(result.tokens);

}



// Validate that all tokens maintain basic invariants

fn validateTokenInvariants(tokens: []const tokenizer.Token) !void {

Â  Â  for (tokens) |token| {

Â  Â  Â  Â  // All tokens should have valid types

Â  Â  Â  Â  _ = token.type.toString();

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Memory should be properly managed

Â  Â  Â  Â  switch (token.data) {

Â  Â  Â  Â  Â  Â  .valid => |v| try testing.expect(v.cps.len > 0),

Â  Â  Â  Â  Â  Â  .mapped => |m| {

Â  Â  Â  Â  Â  Â  Â  Â  try testing.expect(m.cps.len > 0);

Â  Â  Â  Â  Â  Â  Â  Â  // Original codepoint should be different from mapped

Â  Â  Â  Â  Â  Â  Â  Â  if (m.cps.len == 1) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try testing.expect(m.cp != m.cps[0]);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  .ignored => |i| _ = i.cp, // Any codepoint is valid for ignored

Â  Â  Â  Â  Â  Â  .disallowed => |d| _ = d.cp, // Any codepoint is valid for disallowed

Â  Â  Â  Â  Â  Â  .stop => |s| try testing.expect(s.cp == '.'),

Â  Â  Â  Â  Â  Â  else => {},

Â  Â  Â  Â  }

Â  Â  }

}



// Test specific fuzzing scenarios

test "fuzz_utf8_boundary_cases" {

Â  Â Â 

Â  Â  // Test all single bytes (many will be invalid UTF-8)

Â  Â  var i: u8 = 0;

Â  Â  while (i < 255) : (i += 1) {

Â  Â  Â  Â  const input = [_]u8{i};

Â  Â  Â  Â  try fuzz_tokenization(&input);

Â  Â  }

Â  Â Â 

Â  Â  // Test invalid UTF-8 sequences

Â  Â  const invalid_utf8_cases = [_][]const u8{

Â  Â  Â  Â  &[_]u8{0x80}, // Continuation byte without start

Â  Â  Â  Â  &[_]u8{0xC0}, // Start byte without continuation

Â  Â  Â  Â  &[_]u8{0xC0, 0x80}, // Overlong encoding

Â  Â  Â  Â  &[_]u8{0xE0, 0x80, 0x80}, // Overlong encoding

Â  Â  Â  Â  &[_]u8{0xF0, 0x80, 0x80, 0x80}, // Overlong encoding

Â  Â  Â  Â  &[_]u8{0xFF, 0xFF}, // Invalid start bytes

Â  Â  Â  Â  &[_]u8{0xED, 0xA0, 0x80}, // High surrogate

Â  Â  Â  Â  &[_]u8{0xED, 0xB0, 0x80}, // Low surrogate

Â  Â  };

Â  Â Â 

Â  Â  for (invalid_utf8_cases) |case| {

Â  Â  Â  Â  try fuzz_tokenization(case);

Â  Â  }

}



test "fuzz_unicode_plane_cases" {

Â  Â Â 

Â  Â  // Test boundary code points from different Unicode planes

Â  Â  const boundary_codepoints = [_]u21{

Â  Â  Â  Â  0x007F, // ASCII boundary

Â  Â  Â  Â  0x0080, // Latin-1 start

Â  Â  Â  Â  0x07FF, // 2-byte UTF-8 boundary

Â  Â  Â  Â  0x0800, // 3-byte UTF-8 start

Â  Â  Â  Â  0xD7FF, // Before surrogate range

Â  Â  Â  Â  0xE000, // After surrogate range

Â  Â  Â  Â  0xFFFD, // Replacement character

Â  Â  Â  Â  0xFFFE, // Non-character

Â  Â  Â  Â  0xFFFF, // Non-character

Â  Â  Â  Â  0x10000, // 4-byte UTF-8 start

Â  Â  Â  Â  0x10FFFF, // Maximum valid code point

Â  Â  };

Â  Â Â 

Â  Â  for (boundary_codepoints) |cp| {

Â  Â  Â  Â  var buf: [4]u8 = undefined;

Â  Â  Â  Â  const len = std.unicode.utf8Encode(cp, &buf) catch continue;

Â  Â  Â  Â  try fuzz_tokenization(buf[0..len]);

Â  Â  }

}



test "fuzz_emoji_sequences" {

Â  Â Â 

Â  Â  // Test complex emoji sequences that might cause issues

Â  Â  const emoji_test_cases = [_][]const u8{

Â  Â  Â  Â  "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦", // Family emoji with ZWJ

Â  Â  Â  Â  "ğŸ³ï¸â€ğŸŒˆ", // Flag with variation selector and ZWJ

Â  Â  Â  Â  "ğŸ‘ğŸ»", // Emoji with skin tone modifier

Â  Â  Â  Â  "ğŸ”¥ğŸ’¯", // Multiple emoji

Â  Â  Â  Â  "ağŸ‘b", // Emoji between ASCII

Â  Â  Â  Â  "..ğŸ‘..", // Emoji between separators

Â  Â  Â  Â  "ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€", // Repeated emoji

Â  Â  Â  Â  "ğŸ‡ºğŸ‡¸", // Regional indicator sequence

Â  Â  Â  Â  "Â©ï¸", // Copyright with variation selector

Â  Â  Â  Â  "1ï¸âƒ£", // Keycap sequence

Â  Â  };

Â  Â Â 

Â  Â  for (emoji_test_cases) |case| {

Â  Â  Â  Â  try fuzz_tokenization(case);

Â  Â  }

}



test "fuzz_length_stress_cases" {

Â  Â  const allocator = testing.allocator;

Â  Â Â 

Â  Â  // Test various length inputs

Â  Â  const test_lengths = [_]usize{ 0, 1, 10, 100, 1000, 10000 };

Â  Â Â 

Â  Â  for (test_lengths) |len| {

Â  Â  Â  Â  // Create input of repeated 'a' characters

Â  Â  Â  Â  const input = try allocator.alloc(u8, len);

Â  Â  Â  Â  defer allocator.free(input);

Â  Â  Â  Â Â 

Â  Â  Â  Â  @memset(input, 'a');

Â  Â  Â  Â  try fuzz_tokenization(input);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Create input of repeated periods

Â  Â  Â  Â  @memset(input, '.');

Â  Â  Â  Â  try fuzz_tokenization(input);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Create input of repeated invalid characters

Â  Â  Â  Â  @memset(input, 0x80); // Invalid UTF-8 continuation byte

Â  Â  Â  Â  try fuzz_tokenization(input);

Â  Â  }

}



test "fuzz_mixed_input_cases" {

Â  Â Â 

Â  Â  // Test inputs that mix different character types rapidly

Â  Â  const mixed_cases = [_][]const u8{

Â  Â  Â  Â  "a.b.c.d", // Valid with stops

Â  Â  Â  Â  "a\u{00AD}b", // Valid with ignored (soft hyphen)

Â  Â  Â  Â  "a\u{0000}b", // Valid with null character

Â  Â  Â  Â  "Hello\u{0301}World", // Valid with combining character

Â  Â  Â  Â  "test@domain.eth", // Valid with disallowed character

Â  Â  Â  Â  "cafÃ©.eth", // Composed character

Â  Â  Â  Â  "cafe\u{0301}.eth", // Decomposed character

Â  Â  Â  Â  "test\u{200D}ing", // ZWJ between normal chars

Â  Â  Â  Â  "æ··åˆãƒ†ã‚¹ãƒˆ.eth", // Mixed scripts

Â  Â  Â  Â  "...........", // Many stops

Â  Â  Â  Â  "aaaaaaaaaa", // Many valid chars

Â  Â  Â  Â  "\u{00AD}\u{00AD}\u{00AD}", // Many ignored chars

Â  Â  Â  Â  "ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥", // Many emoji

Â  Â  };

Â  Â Â 

Â  Â  for (mixed_cases) |case| {

Â  Â  Â  Â  try fuzz_tokenization(case);

Â  Â  }

}



test "fuzz_pathological_inputs" {

Â  Â Â 

Â  Â  // Test inputs designed to trigger edge cases

Â  Â  const pathological_cases = [_][]const u8{

Â  Â  Â  Â  "", // Empty string

Â  Â  Â  Â  ".", // Single stop

Â  Â  Â  Â  "..", // Double stop

Â  Â  Â  Â  "...", // Triple stop

Â  Â  Â  Â  "a.", // Valid then stop

Â  Â  Â  Â  ".a", // Stop then valid

Â  Â  Â  Â  "a..", // Valid then double stop

Â  Â  Â  Â  "..a", // Double stop then valid

Â  Â  Â  Â  "\u{00AD}", // Single ignored character

Â  Â  Â  Â  "\u{00AD}\u{00AD}", // Multiple ignored characters

Â  Â  Â  Â  "a\u{00AD}", // Valid then ignored

Â  Â  Â  Â  "\u{00AD}a", // Ignored then valid

Â  Â  Â  Â  "\u{FFFD}", // Replacement character

Â  Â  Â  Â  "\u{FFFE}", // Non-character

Â  Â  Â  Â  "\u{10FFFF}", // Maximum code point

Â  Â  };

Â  Â Â 

Â  Â  for (pathological_cases) |case| {

Â  Â  Â  Â  try fuzz_tokenization(case);

Â  Â  }

}



test "fuzz_normalization_edge_cases" {

Â  Â Â 

Â  Â  // Test characters that might interact with normalization

Â  Â  const normalization_cases = [_][]const u8{

Â  Â  Â  Â  "cafÃ©", // Ã© (composed)

Â  Â  Â  Â  "cafe\u{0301}", // Ã© (decomposed)

Â  Â  Â  Â  "noe\u{0308}l", // Ã« (decomposed)

Â  Â  Â  Â  "noÃ«l", // Ã« (composed)

Â  Â  Â  Â  "A\u{0300}", // Ã€ (decomposed)

Â  Â  Â  Â  "Ã€", // Ã€ (composed)

Â  Â  Â  Â  "\u{1E9B}\u{0323}", // Long s with dot below

Â  Â  Â  Â  "\u{0FB2}\u{0F80}", // Tibetan characters

Â  Â  Â  Â  "\u{0F71}\u{0F72}\u{0F74}", // Tibetan vowel signs

Â  Â  };

Â  Â Â 

Â  Â  for (normalization_cases) |case| {

Â  Â  Â  Â  try fuzz_tokenization(case);

Â  Â  }

}



// Performance fuzzing - ensure no algorithmic complexity issues

test "fuzz_performance_cases" {

Â  Â  const allocator = testing.allocator;

Â  Â Â 

Â  Â  // Test patterns that might cause performance issues

Â  Â  const performance_cases = [_]struct {

Â  Â  Â  Â  pattern: []const u8,

Â  Â  Â  Â  repeat_count: usize,

Â  Â  }{

Â  Â  Â  Â  .{ .pattern = "a", .repeat_count = 1000 },

Â  Â  Â  Â  .{ .pattern = ".", .repeat_count = 1000 },

Â  Â  Â  Â  .{ .pattern = "\u{00AD}", .repeat_count = 1000 },

Â  Â  Â  Â  .{ .pattern = "ğŸ‘", .repeat_count = 100 },

Â  Â  Â  Â  .{ .pattern = "a.", .repeat_count = 500 },

Â  Â  Â  Â  .{ .pattern = ".a", .repeat_count = 500 },

Â  Â  Â  Â  .{ .pattern = "a\u{00AD}", .repeat_count = 500 },

Â  Â  };

Â  Â Â 

Â  Â  for (performance_cases) |case| {

Â  Â  Â  Â  const input = try allocator.alloc(u8, case.pattern.len * case.repeat_count);

Â  Â  Â  Â  defer allocator.free(input);

Â  Â  Â  Â Â 

Â  Â  Â  Â  var i: usize = 0;

Â  Â  Â  Â  while (i < case.repeat_count) : (i += 1) {

Â  Â  Â  Â  Â  Â  const start = i * case.pattern.len;

Â  Â  Â  Â  Â  Â  const end = start + case.pattern.len;

Â  Â  Â  Â  Â  Â  @memcpy(input[start..end], case.pattern);

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  const start_time = std.time.microTimestamp();

Â  Â  Â  Â  try fuzz_tokenization(input);

Â  Â  Â  Â  const end_time = std.time.microTimestamp();

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Should complete within reasonable time (1 second for 1000 repetitions)

Â  Â  Â  Â  const duration_us = end_time - start_time;

Â  Â  Â  Â  try testing.expect(duration_us < 1_000_000);

Â  Â  }

}



// Random input fuzzing using a simple PRNG

test "fuzz_random_inputs" {

Â  Â  const allocator = testing.allocator;

Â  Â Â 

Â  Â  var prng = std.Random.DefaultPrng.init(42);

Â  Â  const random = prng.random();

Â  Â Â 

Â  Â  // Test various random inputs

Â  Â  var i: usize = 0;

Â  Â  while (i < 100) : (i += 1) {

Â  Â  Â  Â  const len = random.intRangeAtMost(usize, 0, 100);

Â  Â  Â  Â  const input = try allocator.alloc(u8, len);

Â  Â  Â  Â  defer allocator.free(input);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Fill with random bytes

Â  Â  Â  Â  random.bytes(input);

Â  Â  Â  Â Â 

Â  Â  Â  Â  try fuzz_tokenization(input);

Â  Â  }

}```

```zig [./src/combining_marks.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;

const script_groups = @import("script_groups.zig");



/// Combining mark validation errors

pub const ValidationError = error{

Â  Â  LeadingCombiningMark,

Â  Â  CombiningMarkAfterEmoji,

Â  Â  DisallowedCombiningMark,

Â  Â  CombiningMarkAfterFenced,

Â  Â  InvalidCombiningMarkBase,

Â  Â  ExcessiveCombiningMarks,

Â  Â  InvalidArabicDiacritic,

Â  Â  ExcessiveArabicDiacritics,

Â  Â  InvalidDevanagariMatras,

Â  Â  InvalidThaiVowelSigns,

Â  Â  CombiningMarkOrderError,

};



/// Validate combining marks for a specific script group

pub fn validateCombiningMarks(

Â  Â  codepoints: []const CodePoint,

Â  Â  script_group: *const script_groups.ScriptGroup,

Â  Â  allocator: std.mem.Allocator,

) ValidationError!void {

Â  Â  _ = allocator; // For future use in complex validations

Â  Â Â 

Â  Â  for (codepoints, 0..) |cp, i| {

Â  Â  Â  Â  if (isCombiningMark(cp)) {

Â  Â  Â  Â  Â  Â  // Rule CM1: No leading combining marks

Â  Â  Â  Â  Â  Â  if (i == 0) {

Â  Â  Â  Â  Â  Â  Â  Â  return ValidationError.LeadingCombiningMark;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Rule CM3: CM must be allowed by this script group

Â  Â  Â  Â  Â  Â  if (!script_group.cm.contains(cp)) {

Â  Â  Â  Â  Â  Â  Â  Â  return ValidationError.DisallowedCombiningMark;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Rule CM4: Check preceding character context

Â  Â  Â  Â  Â  Â  const prev_cp = codepoints[i - 1];

Â  Â  Â  Â  Â  Â  try validateCombiningMarkContext(prev_cp, cp);

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  // Additional script-specific validation

Â  Â  try validateScriptSpecificCMRules(codepoints, script_group);

}



/// Validate combining mark context (what it can follow)

fn validateCombiningMarkContext(base_cp: CodePoint, cm_cp: CodePoint) ValidationError!void {

Â  Â  _ = cm_cp; // For future context-specific validations

Â  Â Â 

Â  Â  // Rule CM4a: No combining marks after emoji

Â  Â  if (isEmoji(base_cp)) {

Â  Â  Â  Â  return ValidationError.CombiningMarkAfterEmoji;

Â  Â  }

Â  Â Â 

Â  Â  // Rule CM4b: No combining marks after certain punctuation

Â  Â  if (isFenced(base_cp)) {

Â  Â  Â  Â  return ValidationError.CombiningMarkAfterFenced;

Â  Â  }

}



/// Script-specific combining mark rules

fn validateScriptSpecificCMRules(

Â  Â  codepoints: []const CodePoint,

Â  Â  script_group: *const script_groups.ScriptGroup,

) ValidationError!void {

Â  Â  if (std.mem.eql(u8, script_group.name, "Arabic")) {

Â  Â  Â  Â  try validateArabicCMRules(codepoints);

Â  Â  } else if (std.mem.eql(u8, script_group.name, "Devanagari")) {

Â  Â  Â  Â  try validateDevanagaricCMRules(codepoints);

Â  Â  } else if (std.mem.eql(u8, script_group.name, "Thai")) {

Â  Â  Â  Â  try validateThaiCMRules(codepoints);

Â  Â  }

}



/// Arabic-specific combining mark validation

fn validateArabicCMRules(codepoints: []const CodePoint) ValidationError!void {

Â  Â  var vowel_marks_count: usize = 0;

Â  Â  var prev_was_consonant = false;

Â  Â Â 

Â  Â  for (codepoints) |cp| {

Â  Â  Â  Â  if (isArabicVowelMark(cp)) {

Â  Â  Â  Â  Â  Â  vowel_marks_count += 1;

Â  Â  Â  Â  Â  Â  if (!prev_was_consonant) {

Â  Â  Â  Â  Â  Â  Â  Â  return ValidationError.InvalidArabicDiacritic;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  prev_was_consonant = false;

Â  Â  Â  Â  } else if (isArabicConsonant(cp)) {

Â  Â  Â  Â  Â  Â  vowel_marks_count = 0;

Â  Â  Â  Â  Â  Â  prev_was_consonant = true;

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Limit vowel marks per consonant

Â  Â  Â  Â  if (vowel_marks_count > 3) {

Â  Â  Â  Â  Â  Â  return ValidationError.ExcessiveArabicDiacritics;

Â  Â  Â  Â  }

Â  Â  }

}



/// Devanagari-specific combining mark validation

fn validateDevanagaricCMRules(codepoints: []const CodePoint) ValidationError!void {

Â  Â  for (codepoints, 0..) |cp, i| {

Â  Â  Â  Â  if (isDevanagariMatra(cp)) {

Â  Â  Â  Â  Â  Â  if (i == 0) {

Â  Â  Â  Â  Â  Â  Â  Â  return ValidationError.InvalidDevanagariMatras;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  const prev_cp = codepoints[i - 1];

Â  Â  Â  Â  Â  Â  if (!isDevanagariConsonant(prev_cp)) {

Â  Â  Â  Â  Â  Â  Â  Â  return ValidationError.InvalidDevanagariMatras;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

}



/// Thai-specific combining mark validation

fn validateThaiCMRules(codepoints: []const CodePoint) ValidationError!void {

Â  Â  for (codepoints, 0..) |cp, i| {

Â  Â  Â  Â  if (isThaiVowelSign(cp)) {

Â  Â  Â  Â  Â  Â  if (i == 0) {

Â  Â  Â  Â  Â  Â  Â  Â  return ValidationError.InvalidThaiVowelSigns;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  const prev_cp = codepoints[i - 1];

Â  Â  Â  Â  Â  Â  if (!isThaiConsonant(prev_cp)) {

Â  Â  Â  Â  Â  Â  Â  Â  return ValidationError.InvalidThaiVowelSigns;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

}



/// Check if codepoint is a combining mark

pub fn isCombiningMark(cp: CodePoint) bool {

Â  Â  // Unicode categories Mn, Mc, Me

Â  Â  return (cp >= 0x0300 and cp <= 0x036F) orÂ  // Combining Diacritical Marks

Â  Â  Â  Â  Â  Â (cp >= 0x1AB0 and cp <= 0x1AFF) orÂ  // Combining Diacritical Marks Extended

Â  Â  Â  Â  Â  Â (cp >= 0x1DC0 and cp <= 0x1DFF) orÂ  // Combining Diacritical Marks Supplement

Â  Â  Â  Â  Â  Â (cp >= 0x20D0 and cp <= 0x20FF) orÂ  // Combining Diacritical Marks for Symbols

Â  Â  Â  Â  Â  Â isScriptSpecificCM(cp);

}



/// Check for script-specific combining marks

fn isScriptSpecificCM(cp: CodePoint) bool {

Â  Â  return isArabicCM(cp) orÂ 

Â  Â  Â  Â  Â  Â isDevanagaricCM(cp) orÂ 

Â  Â  Â  Â  Â  Â isThaiCM(cp) or

Â  Â  Â  Â  Â  Â isHebrewCM(cp);

}



fn isArabicCM(cp: CodePoint) bool {

Â  Â  return (cp >= 0x064B and cp <= 0x065F) orÂ  // Arabic diacritics

Â  Â  Â  Â  Â  Â (cp >= 0x0670 and cp <= 0x0671) orÂ  // Arabic superscript alef

Â  Â  Â  Â  Â  Â (cp >= 0x06D6 and cp <= 0x06ED);Â  Â  // Arabic small high marks

}



fn isDevanagaricCM(cp: CodePoint) bool {

Â  Â  return (cp >= 0x093A and cp <= 0x094F) orÂ  // Devanagari vowel signs

Â  Â  Â  Â  Â  Â (cp >= 0x0951 and cp <= 0x0957);Â  Â  // Devanagari stress signs

}



fn isThaiCM(cp: CodePoint) bool {

Â  Â  return (cp >= 0x0E31 and cp <= 0x0E3A) orÂ  // Thai vowel signs and tone marks

Â  Â  Â  Â  Â  Â (cp >= 0x0E47 and cp <= 0x0E4E);Â  Â  // Thai tone marks

}



fn isHebrewCM(cp: CodePoint) bool {

Â  Â  return (cp >= 0x05B0 and cp <= 0x05BD) orÂ  // Hebrew points

Â  Â  Â  Â  Â  Â (cp >= 0x05BF and cp <= 0x05C7);Â  Â  // Hebrew points and marks

}



/// Check if codepoint is an emoji

fn isEmoji(cp: CodePoint) bool {

Â  Â  return (cp >= 0x1F600 and cp <= 0x1F64F) orÂ  // Emoticons

Â  Â  Â  Â  Â  Â (cp >= 0x1F300 and cp <= 0x1F5FF) orÂ  // Miscellaneous Symbols and Pictographs

Â  Â  Â  Â  Â  Â (cp >= 0x1F680 and cp <= 0x1F6FF) orÂ  // Transport and Map Symbols

Â  Â  Â  Â  Â  Â (cp >= 0x1F700 and cp <= 0x1F77F) orÂ  // Alchemical Symbols

Â  Â  Â  Â  Â  Â (cp >= 0x1F780 and cp <= 0x1F7FF) orÂ  // Geometric Shapes Extended

Â  Â  Â  Â  Â  Â (cp >= 0x1F800 and cp <= 0x1F8FF) orÂ  // Supplemental Arrows-C

Â  Â  Â  Â  Â  Â (cp >= 0x2600 and cp <= 0x26FF) orÂ  Â  // Miscellaneous Symbols

Â  Â  Â  Â  Â  Â (cp >= 0x2700 and cp <= 0x27BF);Â  Â  Â  // Dingbats

}



/// Check if codepoint is a fenced character (punctuation that shouldn't have CMs)

fn isFenced(cp: CodePoint) bool {

Â  Â  return cp == 0x002E orÂ  // Period

Â  Â  Â  Â  Â  Â cp == 0x002C orÂ  // Comma

Â  Â  Â  Â  Â  Â cp == 0x003A orÂ  // Colon

Â  Â  Â  Â  Â  Â cp == 0x003B orÂ  // Semicolon

Â  Â  Â  Â  Â  Â cp == 0x0021 orÂ  // Exclamation mark

Â  Â  Â  Â  Â  Â cp == 0x003F;Â  Â  // Question mark

}



/// Arabic vowel marks

fn isArabicVowelMark(cp: CodePoint) bool {

Â  Â  return (cp >= 0x064B and cp <= 0x0650) orÂ  // Fathatan, Dammatan, Kasratan, Fatha, Damma, Kasra

Â  Â  Â  Â  Â  Â cp == 0x0652 orÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Sukun

Â  Â  Â  Â  Â  Â cp == 0x0640;Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Tatweel

}



/// Arabic consonants (simplified check)

fn isArabicConsonant(cp: CodePoint) bool {

Â  Â  return (cp >= 0x0621 and cp <= 0x063A) orÂ  // Arabic letters

Â  Â  Â  Â  Â  Â (cp >= 0x0641 and cp <= 0x064A);Â  Â  // Arabic letters continued

}



/// Devanagari vowel signs (matras)

fn isDevanagariMatra(cp: CodePoint) bool {

Â  Â  return (cp >= 0x093E and cp <= 0x094F) and cp != 0x0940;Â  // Vowel signs except invalid ones

}



/// Devanagari consonants

fn isDevanagariConsonant(cp: CodePoint) bool {

Â  Â  return (cp >= 0x0915 and cp <= 0x0939) orÂ  // Consonants

Â  Â  Â  Â  Â  Â (cp >= 0x0958 and cp <= 0x095F);Â  Â  // Additional consonants

}



/// Thai vowel signs

fn isThaiVowelSign(cp: CodePoint) bool {

Â  Â  return (cp >= 0x0E31 and cp <= 0x0E3A) orÂ  // Vowel signs above and below

Â  Â  Â  Â  Â  Â cp == 0x0E47 or cp == 0x0E48 orÂ  Â  Â // Tone marks

Â  Â  Â  Â  Â  Â cp == 0x0E49 or cp == 0x0E4A or

Â  Â  Â  Â  Â  Â cp == 0x0E4B or cp == 0x0E4C;

}



/// Thai consonants

fn isThaiConsonant(cp: CodePoint) bool {

Â  Â  return (cp >= 0x0E01 and cp <= 0x0E2E);Â  // Thai consonants

}



// Tests

const testing = std.testing;



test "combining mark detection" {

Â  Â  // Test basic combining marks

Â  Â  try testing.expect(isCombiningMark(0x0301)); // Combining acute accent

Â  Â  try testing.expect(isCombiningMark(0x0300)); // Combining grave accent

Â  Â  try testing.expect(isCombiningMark(0x064E)); // Arabic fatha

Â  Â Â 

Â  Â  // Test non-combining marks

Â  Â  try testing.expect(!isCombiningMark('a'));

Â  Â  try testing.expect(!isCombiningMark('A'));

Â  Â  try testing.expect(!isCombiningMark(0x0041)); // Latin A

}



test "emoji detection" {

Â  Â  try testing.expect(isEmoji(0x1F600)); // Grinning face

Â  Â  try testing.expect(isEmoji(0x1F680)); // Rocket

Â  Â  try testing.expect(!isEmoji('a'));

Â  Â  try testing.expect(!isEmoji(0x0301)); // Combining accent

}



test "fenced character detection" {

Â  Â  try testing.expect(isFenced('.'));

Â  Â  try testing.expect(isFenced(','));

Â  Â  try testing.expect(isFenced(':'));

Â  Â  try testing.expect(!isFenced('a'));

Â  Â  try testing.expect(!isFenced(0x0301));

}



test "script-specific combining mark detection" {

Â  Â  // Arabic

Â  Â  try testing.expect(isArabicCM(0x064E)); // Fatha

Â  Â  try testing.expect(isArabicVowelMark(0x064E));

Â  Â  try testing.expect(isArabicConsonant(0x0628)); // Beh

Â  Â Â 

Â  Â  // DevanagariÂ Â 

Â  Â  try testing.expect(isDevanagaricCM(0x093E)); // Aa matra

Â  Â  try testing.expect(isDevanagariMatra(0x093E));

Â  Â  try testing.expect(isDevanagariConsonant(0x0915)); // Ka

Â  Â Â 

Â  Â  // Thai

Â  Â  try testing.expect(isThaiCM(0x0E31)); // Mai han-akat

Â  Â  try testing.expect(isThaiVowelSign(0x0E31));

Â  Â  try testing.expect(isThaiConsonant(0x0E01)); // Ko kai

}



test "leading combining mark validation" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Create a mock script group for testing

Â  Â  var latin_group = script_groups.ScriptGroup.init(allocator, "Latin", 0);

Â  Â  defer latin_group.deinit();

Â  Â Â 

Â  Â  // Add combining mark to allowed set

Â  Â  try latin_group.cm.put(0x0301, {});

Â  Â Â 

Â  Â  // Test leading combining mark (should fail)

Â  Â  const leading_cm = [_]CodePoint{0x0301, 'a'};

Â  Â  const result = validateCombiningMarks(&leading_cm, &latin_group, allocator);

Â  Â  try testing.expectError(ValidationError.LeadingCombiningMark, result);

}



test "disallowed combining mark validation" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Create a mock script group that doesn't allow Arabic CMs

Â  Â  var latin_group = script_groups.ScriptGroup.init(allocator, "Latin", 0);

Â  Â  defer latin_group.deinit();

Â  Â Â 

Â  Â  // Don't add Arabic CM to allowed set

Â  Â Â 

Â  Â  // Test Arabic CM with Latin group (should fail)

Â  Â  const wrong_script_cm = [_]CodePoint{'a', 0x064E}; // Latin + Arabic fatha

Â  Â  const result = validateCombiningMarks(&wrong_script_cm, &latin_group, allocator);

Â  Â  try testing.expectError(ValidationError.DisallowedCombiningMark, result);

}



test "combining mark after emoji validation" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var emoji_group = script_groups.ScriptGroup.init(allocator, "Emoji", 0);

Â  Â  defer emoji_group.deinit();

Â  Â Â 

Â  Â  // Add combining mark to allowed set

Â  Â  try emoji_group.cm.put(0x0301, {});

Â  Â Â 

Â  Â  // Test emoji + combining mark (should fail)

Â  Â  const emoji_cm = [_]CodePoint{0x1F600, 0x0301}; // Grinning face + acute

Â  Â  const result = validateCombiningMarks(&emoji_cm, &emoji_group, allocator);

Â  Â  try testing.expectError(ValidationError.CombiningMarkAfterEmoji, result);

}



test "valid combining mark sequences" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var latin_group = script_groups.ScriptGroup.init(allocator, "Latin", 0);

Â  Â  defer latin_group.deinit();

Â  Â Â 

Â  Â  // Add combining marks to allowed set

Â  Â  try latin_group.cm.put(0x0301, {}); // Acute accent

Â  Â  try latin_group.cm.put(0x0300, {}); // Grave accent

Â  Â Â 

Â  Â  // Test valid sequences (should pass)

Â  Â  const valid_sequences = [_][]const CodePoint{

Â  Â  Â  Â  &[_]CodePoint{'a', 0x0301},Â  Â  Â  // Ã¡

Â  Â  Â  Â  &[_]CodePoint{'e', 0x0300},Â  Â  Â  // Ã¨Â Â 

Â  Â  Â  Â  &[_]CodePoint{'a', 0x0301, 0x0300}, // Multiple CMs

Â  Â  };

Â  Â Â 

Â  Â  for (valid_sequences) |seq| {

Â  Â  Â  Â  try validateCombiningMarks(seq, &latin_group, allocator);

Â  Â  }

}



test "arabic diacritic validation" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var arabic_group = script_groups.ScriptGroup.init(allocator, "Arabic", 0);

Â  Â  defer arabic_group.deinit();

Â  Â Â 

Â  Â  // Add Arabic combining marks

Â  Â  try arabic_group.cm.put(0x064E, {}); // Fatha

Â  Â  try arabic_group.cm.put(0x064F, {}); // Damma

Â  Â Â 

Â  Â  // Test valid Arabic with diacritics

Â  Â  const valid_arabic = [_]CodePoint{0x0628, 0x064E}; // Ø¨Ù (beh + fatha)

Â  Â  try validateCombiningMarks(&valid_arabic, &arabic_group, allocator);

Â  Â Â 

Â  Â  // Test excessive diacritics (should fail)

Â  Â  const excessive = [_]CodePoint{0x0628, 0x064E, 0x064F, 0x0650, 0x0651}; // Too many marks

Â  Â  const result = validateCombiningMarks(&excessive, &arabic_group, allocator);

Â  Â  try testing.expectError(ValidationError.ExcessiveArabicDiacritics, result);

}```

```zig [./src/spec_data.zig]

const std = @import("std");



/// Load spec data at compile time

const spec_zon = @embedFile("data/spec.zon");



/// Parsed spec data structure

pub const SpecData = struct {

Â  Â  created: []const u8,

Â  Â  unicode: []const u8,

Â  Â  cldr: []const u8,

Â  Â  emoji: []const []const u32,

Â  Â  fenced: []const u32,

Â  Â  ignored: []const u32,

Â  Â  mapped: []const MappedChar,

Â  Â  nfc_check: []const u32,

Â  Â  nsm: []const u32,

Â  Â  nsm_max: u32,

Â  Â  cm: []const u32,

Â  Â  wholes: []const Whole,

Â  Â  groups: []const Group,

Â  Â Â 

Â  Â  pub const MappedChar = struct {

Â  Â  Â  Â  cp: u32,

Â  Â  Â  Â  mapped: []const u32,

Â  Â  };

Â  Â Â 

Â  Â  pub const Whole = struct {

Â  Â  Â  Â  valid: []const u32,

Â  Â  Â  Â  confused: []const u32,

Â  Â  };

Â  Â Â 

Â  Â  pub const Group = struct {

Â  Â  Â  Â  name: []const u8,

Â  Â  Â  Â  primary: []const u32,

Â  Â  Â  Â  secondary: ?[]const u32 = null,

Â  Â  Â  Â  cm: ?[]const u32 = null,

Â  Â  Â  Â  restricted: ?bool = null,

Â  Â  };

};



/// Parse spec at compile time

pub fn parseSpec() !SpecData {

Â  Â  @setEvalBranchQuota(1_000_000);

Â  Â Â 

Â  Â  var diagnostics: std.zig.Ast.Diagnostics = .{};

Â  Â  var ast = try std.zig.Ast.parse(std.heap.page_allocator, spec_zon, .zon, &diagnostics);

Â  Â  defer ast.deinit(std.heap.page_allocator);

Â  Â Â 

Â  Â  if (diagnostics.errors.len > 0) {

Â  Â  Â  Â  return error.ParseError;

Â  Â  }

Â  Â Â 

Â  Â  // For now, return a placeholder

Â  Â  // TODO: Implement actual ZON parsing

Â  Â  return SpecData{

Â  Â  Â  Â  .created = "",

Â  Â  Â  Â  .unicode = "",

Â  Â  Â  Â  .cldr = "",

Â  Â  Â  Â  .emoji = &.{},

Â  Â  Â  Â  .fenced = &.{},

Â  Â  Â  Â  .ignored = &.{},

Â  Â  Â  Â  .mapped = &.{},

Â  Â  Â  Â  .nfc_check = &.{},

Â  Â  Â  Â  .nsm = &.{},

Â  Â  Â  Â  .nsm_max = 4,

Â  Â  Â  Â  .cm = &.{},

Â  Â  Â  Â  .wholes = &.{},

Â  Â  Â  Â  .groups = &.{},

Â  Â  };

}



/// Get spec data (parsed once at compile time)

pub const spec = parseSpec() catch @panic("Failed to parse spec.zon");



/// Script group enum for the most common scripts

pub const ScriptGroup = enum(u8) {

Â  Â  Latin,

Â  Â  Greek,

Â  Â  Cyrillic,

Â  Â  Hebrew,

Â  Â  Arabic,

Â  Â  Devanagari,

Â  Â  Bengali,

Â  Â  Gurmukhi,

Â  Â  Gujarati,

Â  Â  Tamil,

Â  Â  Telugu,

Â  Â  Kannada,

Â  Â  Malayalam,

Â  Â  Thai,

Â  Â  Lao,

Â  Â  Tibetan,

Â  Â  Myanmar,

Â  Â  Georgian,

Â  Â  Hangul,

Â  Â  Hiragana,

Â  Â  Katakana,

Â  Â  Han,

Â  Â  Emoji,

Â  Â  ASCII,

Â  Â  Other,

Â  Â Â 

Â  Â  pub fn fromName(name: []const u8) ScriptGroup {

Â  Â  Â  Â  inline for (@typeInfo(ScriptGroup).Enum.fields) |field| {

Â  Â  Â  Â  Â  Â  if (std.mem.eql(u8, field.name, name)) {

Â  Â  Â  Â  Â  Â  Â  Â  return @enumFromInt(field.value);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  return .Other;

Â  Â  }

Â  Â Â 

Â  Â  pub fn toString(self: ScriptGroup) []const u8 {

Â  Â  Â  Â  return @tagName(self);

Â  Â  }

};```

```zig [./src/comptime_data.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;



// Define ZON data types

const MappedItem = struct { u32, []const u32 };

const FencedItem = struct { u32, []const u8 };

const WholeItem = struct {

Â  Â  target: ?[]const u8,

Â  Â  valid: []const u32,

Â  Â  confused: []const u32,

};

const GroupItem = struct {

Â  Â  name: []const u8,

Â  Â  primary: []const u32,

Â  Â  secondary: ?[]const u32 = null,

Â  Â  cm: ?[]const u32 = null,

Â  Â  restricted: ?bool = null,

};



const SpecData = struct {

Â  Â  created: []const u8,

Â  Â  unicode: []const u8,

Â  Â  cldr: []const u8,

Â  Â  emoji: []const []const u32,

Â  Â  ignored: []const u32,

Â  Â  mapped: []const MappedItem,

Â  Â  fenced: []const FencedItem,

Â  Â  groups: []const GroupItem,

Â  Â  nsm: []const u32,

Â  Â  nsm_max: u32,

Â  Â  nfc_check: []const u32,

Â  Â  wholes: []const WholeItem,

Â  Â  cm: []const u32,

Â  Â  escape: []const u32,

};



const DecompItem = struct { u32, []const u32 };

const RankItem = []const u32;



const NfData = struct {

Â  Â  created: []const u8,

Â  Â  unicode: []const u8,

Â  Â  exclusions: []const u32,

Â  Â  decomp: []const DecompItem,

Â  Â  ranks: []const RankItem,

Â  Â  qc: ?[]const u32 = null,

};



// Import ZON data at compile time

const spec_data: SpecData = @import("data/spec.zon");

const nf_data: NfData = @import("data/nf.zon");



// Comptime perfect hash for character mappings

pub const CharacterMappingEntry = struct {

Â  Â  from: CodePoint,

Â  Â  to: []const CodePoint,

};



// Generate a sorted array of character mappings at compile time

pub const character_mappings = blk: {

Â  Â  @setEvalBranchQuota(100000);

Â  Â  const count = spec_data.mapped.len;

Â  Â  var entries: [count]CharacterMappingEntry = undefined;

Â  Â Â 

Â  Â  for (spec_data.mapped, 0..) |mapping, i| {

Â  Â  Â  Â  entries[i] = .{

Â  Â  Â  Â  Â  Â  .from = mapping[0],

Â  Â  Â  Â  Â  Â  .to = mapping[1],

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  // Sort by 'from' codepoint for binary search

Â  Â  const Context = struct {

Â  Â  Â  Â  fn lessThan(_: void, a: CharacterMappingEntry, b: CharacterMappingEntry) bool {

Â  Â  Â  Â  Â  Â  return a.from < b.from;

Â  Â  Â  Â  }

Â  Â  };

Â  Â  std.sort.insertion(CharacterMappingEntry, &entries, {}, Context.lessThan);

Â  Â Â 

Â  Â  break :blk entries;

};



// Binary search for character mapping

pub fn getMappedCodePoints(cp: CodePoint) ?[]const CodePoint {

Â  Â  var left: usize = 0;

Â  Â  var right: usize = character_mappings.len;

Â  Â Â 

Â  Â  while (left < right) {

Â  Â  Â  Â  const mid = left + (right - left) / 2;

Â  Â  Â  Â  if (character_mappings[mid].from == cp) {

Â  Â  Â  Â  Â  Â  return character_mappings[mid].to;

Â  Â  Â  Â  } else if (character_mappings[mid].from < cp) {

Â  Â  Â  Â  Â  Â  left = mid + 1;

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  right = mid;

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  return null;

}



// Comptime set for ignored characters

pub const ignored_chars = blk: {

Â  Â  @setEvalBranchQuota(10000);

Â  Â  var set = std.StaticBitSet(0x110000).initEmpty();

Â  Â  for (spec_data.ignored) |cp| {

Â  Â  Â  Â  set.set(cp);

Â  Â  }

Â  Â  break :blk set;

};



pub fn isIgnored(cp: CodePoint) bool {

Â  Â  if (cp >= 0x110000) return false;

Â  Â  return ignored_chars.isSet(cp);

}



// Comptime set for fenced characters

pub const fenced_chars = blk: {

Â  Â  @setEvalBranchQuota(10000);

Â  Â  var set = std.StaticBitSet(0x110000).initEmpty();

Â  Â  for (spec_data.fenced) |item| {

Â  Â  Â  Â  set.set(item[0]);

Â  Â  }

Â  Â  break :blk set;

};



pub fn isFenced(cp: CodePoint) bool {

Â  Â  if (cp >= 0x110000) return false;

Â  Â  return fenced_chars.isSet(cp);

}



// Comptime set for valid characters (from all groups)

pub const valid_chars = blk: {

Â  Â  @setEvalBranchQuota(10000000); // Need very high quota for all Unicode characters

Â  Â  var set = std.StaticBitSet(0x110000).initEmpty();

Â  Â Â 

Â  Â  for (spec_data.groups) |group| {

Â  Â  Â  Â  // Add primary characters

Â  Â  Â  Â  for (group.primary) |cp| {

Â  Â  Â  Â  Â  Â  set.set(cp);

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Add secondary characters if present

Â  Â  Â  Â  if (group.secondary) |secondary| {

Â  Â  Â  Â  Â  Â  for (secondary) |cp| {

Â  Â  Â  Â  Â  Â  Â  Â  set.set(cp);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  break :blk set;

};



pub fn isValid(cp: CodePoint) bool {

Â  Â  if (cp >= 0x110000) return false;

Â  Â  return valid_chars.isSet(cp);

}



// Comptime emoji data structure

pub const EmojiEntry = struct {

Â  Â  sequence: []const CodePoint,

Â  Â  no_fe0f: []const CodePoint,

};



pub const emoji_sequences = blk: {

Â  Â  @setEvalBranchQuota(50000);

Â  Â  const count = spec_data.emoji.len;

Â  Â  var entries: [count]EmojiEntry = undefined;

Â  Â Â 

Â  Â  for (spec_data.emoji, 0..) |seq, i| {

Â  Â  Â  Â  // Calculate no_fe0f version

Â  Â  Â  Â  var no_fe0f_count: usize = 0;

Â  Â  Â  Â  for (seq) |cp| {

Â  Â  Â  Â  Â  Â  if (cp != 0xFE0F) no_fe0f_count += 1;

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  var no_fe0f: [no_fe0f_count]CodePoint = undefined;

Â  Â  Â  Â  var j: usize = 0;

Â  Â  Â  Â  for (seq) |cp| {

Â  Â  Â  Â  Â  Â  if (cp != 0xFE0F) {

Â  Â  Â  Â  Â  Â  Â  Â  no_fe0f[j] = cp;

Â  Â  Â  Â  Â  Â  Â  Â  j += 1;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  entries[i] = .{

Â  Â  Â  Â  Â  Â  .sequence = seq,

Â  Â  Â  Â  Â  Â  .no_fe0f = &no_fe0f,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  break :blk entries;

};



// Comptime NFC decomposition data

pub const NFCDecompEntry = struct {

Â  Â  cp: CodePoint,

Â  Â  decomp: []const CodePoint,

};



pub const nfc_decompositions = blk: {

Â  Â  @setEvalBranchQuota(50000);

Â  Â  const count = nf_data.decomp.len;

Â  Â  var entries: [count]NFCDecompEntry = undefined;

Â  Â Â 

Â  Â  for (nf_data.decomp, 0..) |entry, i| {

Â  Â  Â  Â  entries[i] = .{

Â  Â  Â  Â  Â  Â  .cp = entry[0],

Â  Â  Â  Â  Â  Â  .decomp = entry[1],

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  // Sort by codepoint for binary search

Â  Â  const Context = struct {

Â  Â  Â  Â  fn lessThan(_: void, a: NFCDecompEntry, b: NFCDecompEntry) bool {

Â  Â  Â  Â  Â  Â  return a.cp < b.cp;

Â  Â  Â  Â  }

Â  Â  };

Â  Â  std.sort.insertion(NFCDecompEntry, &entries, {}, Context.lessThan);

Â  Â Â 

Â  Â  break :blk entries;

};



pub fn getNFCDecomposition(cp: CodePoint) ?[]const CodePoint {

Â  Â  var left: usize = 0;

Â  Â  var right: usize = nfc_decompositions.len;

Â  Â Â 

Â  Â  while (left < right) {

Â  Â  Â  Â  const mid = left + (right - left) / 2;

Â  Â  Â  Â  if (nfc_decompositions[mid].cp == cp) {

Â  Â  Â  Â  Â  Â  return nfc_decompositions[mid].decomp;

Â  Â  Â  Â  } else if (nfc_decompositions[mid].cp < cp) {

Â  Â  Â  Â  Â  Â  left = mid + 1;

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  right = mid;

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  return null;

}



// Comptime NFC exclusions set

pub const nfc_exclusions = blk: {

Â  Â  @setEvalBranchQuota(10000);

Â  Â  var set = std.StaticBitSet(0x110000).initEmpty();

Â  Â  for (nf_data.exclusions) |cp| {

Â  Â  Â  Â  set.set(cp);

Â  Â  }

Â  Â  break :blk set;

};



pub fn isNFCExclusion(cp: CodePoint) bool {

Â  Â  if (cp >= 0x110000) return false;

Â  Â  return nfc_exclusions.isSet(cp);

}



// Comptime NFC check set

pub const nfc_check_set = blk: {

Â  Â  @setEvalBranchQuota(10000);

Â  Â  var set = std.StaticBitSet(0x110000).initEmpty();

Â  Â  for (spec_data.nfc_check) |cp| {

Â  Â  Â  Â  set.set(cp);

Â  Â  }

Â  Â  break :blk set;

};



pub fn needsNFCCheck(cp: CodePoint) bool {

Â  Â  if (cp >= 0x110000) return false;

Â  Â  return nfc_check_set.isSet(cp);

}



// Comptime NSM set

pub const nsm_set = blk: {

Â  Â  @setEvalBranchQuota(10000);

Â  Â  var set = std.StaticBitSet(0x110000).initEmpty();

Â  Â  for (spec_data.nsm) |cp| {

Â  Â  Â  Â  set.set(cp);

Â  Â  }

Â  Â  break :blk set;

};



pub fn isNSM(cp: CodePoint) bool {

Â  Â  if (cp >= 0x110000) return false;

Â  Â  return nsm_set.isSet(cp);

}



// Comptime combining marks set

pub const cm_set = blk: {

Â  Â  @setEvalBranchQuota(10000);

Â  Â  var set = std.StaticBitSet(0x110000).initEmpty();

Â  Â  for (spec_data.cm) |cp| {

Â  Â  Â  Â  set.set(cp);

Â  Â  }

Â  Â  break :blk set;

};



pub fn isCombiningMark(cp: CodePoint) bool {

Â  Â  if (cp >= 0x110000) return false;

Â  Â  return cm_set.isSet(cp);

}



// Comptime escape set

pub const escape_set = blk: {

Â  Â  @setEvalBranchQuota(10000);

Â  Â  var set = std.StaticBitSet(0x110000).initEmpty();

Â  Â  for (spec_data.escape) |cp| {

Â  Â  Â  Â  set.set(cp);

Â  Â  }

Â  Â  break :blk set;

};



pub fn needsEscape(cp: CodePoint) bool {

Â  Â  if (cp >= 0x110000) return false;

Â  Â  return escape_set.isSet(cp);

}



// Export spec data constants

pub const nsm_max = spec_data.nsm_max;

pub const spec_created = spec_data.created;

pub const spec_unicode = spec_data.unicode;

pub const spec_cldr = spec_data.cldr;



test "comptime character mappings" {

Â  Â  const testing = std.testing;

Â  Â Â 

Â  Â  // Test that we can look up a mapping

Â  Â  if (character_mappings.len > 0) {

Â  Â  Â  Â  const first = character_mappings[0];

Â  Â  Â  Â  const result = getMappedCodePoints(first.from);

Â  Â  Â  Â  try testing.expect(result != null);

Â  Â  Â  Â  try testing.expectEqualSlices(CodePoint, first.to, result.?);

Â  Â  }

Â  Â Â 

Â  Â  // Test non-existent mapping

Â  Â  const no_mapping = getMappedCodePoints(0xFFFFF);

Â  Â  try testing.expect(no_mapping == null);

}



test "comptime sets" {

Â  Â  const testing = std.testing;

Â  Â Â 

Â  Â  // Test ignored character

Â  Â  if (spec_data.ignored.len > 0) {

Â  Â  Â  Â  const first_ignored = spec_data.ignored[0];

Â  Â  Â  Â  try testing.expect(isIgnored(first_ignored));

Â  Â  }

Â  Â Â 

Â  Â  // Test non-ignored character

Â  Â  try testing.expect(!isIgnored('A'));

Â  Â Â 

Â  Â  // Test fenced character

Â  Â  if (spec_data.fenced.len > 0) {

Â  Â  Â  Â  const first_fenced = spec_data.fenced[0][0];

Â  Â  Â  Â  try testing.expect(isFenced(first_fenced));

Â  Â  }

}```

```zig [./src/nsm_validation.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;

const script_groups = @import("script_groups.zig");



/// NSM validation errors

pub const NSMValidationError = error{

Â  Â  ExcessiveNSM,Â  Â  Â  Â  Â  Â // More than 4 NSMs per base character

Â  Â  DuplicateNSM,Â  Â  Â  Â  Â  Â // Same NSM appears consecutively

Â  Â  LeadingNSM,Â  Â  Â  Â  Â  Â  Â // NSM at start of sequence

Â  Â  NSMAfterEmoji,Â  Â  Â  Â  Â  // NSM following emoji (not allowed)

Â  Â  NSMAfterFenced,Â  Â  Â  Â  Â // NSM following fenced character

Â  Â  InvalidNSMBase,Â  Â  Â  Â  Â // NSM following inappropriate base character

Â  Â  NSMOrderError,Â  Â  Â  Â  Â  // NSMs not in canonical order

Â  Â  DisallowedNSMScript,Â  Â  // NSM from wrong script group

};



/// NSM sequence information for validation

pub const NSMSequence = struct {

Â  Â  base_char: CodePoint,

Â  Â  nsms: []const CodePoint,

Â  Â  script_group: *const script_groups.ScriptGroup,

Â  Â Â 

Â  Â  pub fn validate(self: NSMSequence) NSMValidationError!void {

Â  Â  Â  Â  // Check NSM count (ENSIP-15: max 4 NSMs per base character)

Â  Â  Â  Â  if (self.nsms.len > 4) {

Â  Â  Â  Â  Â  Â  return NSMValidationError.ExcessiveNSM;

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Check for duplicate NSMs in sequence

Â  Â  Â  Â  for (self.nsms, 0..) |nsm1, i| {

Â  Â  Â  Â  Â  Â  for (self.nsms[i+1..]) |nsm2| {

Â  Â  Â  Â  Â  Â  Â  Â  if (nsm1 == nsm2) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return NSMValidationError.DuplicateNSM;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Check if all NSMs are allowed by this script group

Â  Â  Â  Â  for (self.nsms) |nsm| {

Â  Â  Â  Â  Â  Â  if (!self.script_group.cm.contains(nsm)) {

Â  Â  Â  Â  Â  Â  Â  Â  return NSMValidationError.DisallowedNSMScript;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // TODO: Check canonical ordering when we have full Unicode data

Â  Â  Â  Â  // For now, we assume input is already in canonical order

Â  Â  }

};



/// Comprehensive NSM validation for ENSIP-15 compliance

pub fn validateNSM(

Â  Â  codepoints: []const CodePoint,

Â  Â  groups: *const script_groups.ScriptGroups,

Â  Â  script_group: *const script_groups.ScriptGroup,

Â  Â  allocator: std.mem.Allocator,

) NSMValidationError!void {

Â  Â  _ = allocator; // Reserved for future use (NFD normalization, etc.)

Â  Â  if (codepoints.len == 0) return;

Â  Â Â 

Â  Â  // Check for leading NSM

Â  Â  if (groups.isNSM(codepoints[0])) {

Â  Â  Â  Â  return NSMValidationError.LeadingNSM;

Â  Â  }

Â  Â Â 

Â  Â  var i: usize = 0;

Â  Â  while (i < codepoints.len) {

Â  Â  Â  Â  const cp = codepoints[i];

Â  Â  Â  Â Â 

Â  Â  Â  Â  if (!groups.isNSM(cp)) {

Â  Â  Â  Â  Â  Â  // This is a base character, collect following NSMs

Â  Â  Â  Â  Â  Â  const nsm_start = i + 1;

Â  Â  Â  Â  Â  Â  var nsm_end = nsm_start;

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Find all consecutive NSMs following this base character

Â  Â  Â  Â  Â  Â  while (nsm_end < codepoints.len and groups.isNSM(codepoints[nsm_end])) {

Â  Â  Â  Â  Â  Â  Â  Â  nsm_end += 1;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  if (nsm_end > nsm_start) {

Â  Â  Â  Â  Â  Â  Â  Â  // We have NSMs following this base character

Â  Â  Â  Â  Â  Â  Â  Â  const nsms = codepoints[nsm_start..nsm_end];

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  // Validate context - check if base character can accept NSMs

Â  Â  Â  Â  Â  Â  Â  Â  try validateNSMContext(cp, nsms);

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  // Create NSM sequence and validate

Â  Â  Â  Â  Â  Â  Â  Â  const sequence = NSMSequence{

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .base_char = cp,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .nsms = nsms,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .script_group = script_group,

Â  Â  Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  Â  Â  Â  try sequence.validate();

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  // Apply script-specific validation

Â  Â  Â  Â  Â  Â  Â  Â  try validateScriptSpecificNSMRules(cp, nsms, script_group);

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  // Move past all NSMs

Â  Â  Â  Â  Â  Â  Â  Â  i = nsm_end;

Â  Â  Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  Â  Â  i += 1;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  // This should not happen if we handle base characters correctly

Â  Â  Â  Â  Â  Â  i += 1;

Â  Â  Â  Â  }

Â  Â  }

}



/// Validate NSM context (what base characters can accept NSMs)

fn validateNSMContext(base_cp: CodePoint, nsms: []const CodePoint) NSMValidationError!void {

Â  Â  _ = nsms; // For future context-specific validations

Â  Â Â 

Â  Â  // Rule: No NSMs after emoji

Â  Â  if (isEmoji(base_cp)) {

Â  Â  Â  Â  return NSMValidationError.NSMAfterEmoji;

Â  Â  }

Â  Â Â 

Â  Â  // Rule: No NSMs after certain punctuation

Â  Â  if (isFenced(base_cp)) {

Â  Â  Â  Â  return NSMValidationError.NSMAfterFenced;

Â  Â  }

Â  Â Â 

Â  Â  // Rule: No NSMs after certain symbols or control characters

Â  Â  if (isInvalidNSMBase(base_cp)) {

Â  Â  Â  Â  return NSMValidationError.InvalidNSMBase;

Â  Â  }

}



/// Script-specific NSM validation rules

fn validateScriptSpecificNSMRules(

Â  Â  base_cp: CodePoint,

Â  Â  nsms: []const CodePoint,

Â  Â  script_group: *const script_groups.ScriptGroup,

) NSMValidationError!void {

Â  Â  if (std.mem.eql(u8, script_group.name, "Arabic")) {

Â  Â  Â  Â  try validateArabicNSMRules(base_cp, nsms);

Â  Â  } else if (std.mem.eql(u8, script_group.name, "Hebrew")) {

Â  Â  Â  Â  try validateHebrewNSMRules(base_cp, nsms);

Â  Â  } else if (std.mem.eql(u8, script_group.name, "Devanagari")) {

Â  Â  Â  Â  try validateDevanagariNSMRules(base_cp, nsms);

Â  Â  }

}



/// Arabic-specific NSM validation

fn validateArabicNSMRules(base_cp: CodePoint, nsms: []const CodePoint) NSMValidationError!void {

Â  Â  // Arabic NSM rules:

Â  Â  // 1. Diacritics should only appear on Arabic letters

Â  Â  // 2. Maximum 3 diacritics per consonant (more restrictive than general 4)

Â  Â  // 3. Certain combinations are invalid

Â  Â Â 

Â  Â  if (!isArabicLetter(base_cp)) {

Â  Â  Â  Â  return NSMValidationError.InvalidNSMBase;

Â  Â  }

Â  Â Â 

Â  Â  if (nsms.len > 3) {

Â  Â  Â  Â  return NSMValidationError.ExcessiveNSM;

Â  Â  }

Â  Â Â 

Â  Â  // Check for invalid combinations

Â  Â  var has_vowel_mark = false;

Â  Â  var has_shadda = false;

Â  Â Â 

Â  Â  for (nsms) |nsm| {

Â  Â  Â  Â  if (isArabicVowelMark(nsm)) {

Â  Â  Â  Â  Â  Â  if (has_vowel_mark) {

Â  Â  Â  Â  Â  Â  Â  Â  // Multiple vowel marks on same consonant

Â  Â  Â  Â  Â  Â  Â  Â  return NSMValidationError.DuplicateNSM;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  has_vowel_mark = true;

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  if (nsm == 0x0651) { // Arabic Shadda

Â  Â  Â  Â  Â  Â  if (has_shadda) {

Â  Â  Â  Â  Â  Â  Â  Â  return NSMValidationError.DuplicateNSM;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  has_shadda = true;

Â  Â  Â  Â  }

Â  Â  }

}



/// Hebrew-specific NSM validation

fn validateHebrewNSMRules(base_cp: CodePoint, nsms: []const CodePoint) NSMValidationError!void {

Â  Â  // Hebrew NSM rules:

Â  Â  // 1. Points should only appear on Hebrew letters

Â  Â  // 2. Specific point combinations

Â  Â Â 

Â  Â  if (!isHebrewLetter(base_cp)) {

Â  Â  Â  Â  return NSMValidationError.InvalidNSMBase;

Â  Â  }

Â  Â Â 

Â  Â  // Hebrew allows fewer NSMs per character

Â  Â  if (nsms.len > 2) {

Â  Â  Â  Â  return NSMValidationError.ExcessiveNSM;

Â  Â  }

}



/// Devanagari-specific NSM validationÂ Â 

fn validateDevanagariNSMRules(base_cp: CodePoint, nsms: []const CodePoint) NSMValidationError!void {

Â  Â  // Devanagari NSM rules:

Â  Â  // 1. Vowel signs should only appear on consonants

Â  Â  // 2. Specific ordering requirements

Â  Â Â 

Â  Â  if (!isDevanagariConsonant(base_cp)) {

Â  Â  Â  Â  return NSMValidationError.InvalidNSMBase;

Â  Â  }

Â  Â Â 

Â  Â  if (nsms.len > 2) {

Â  Â  Â  Â  return NSMValidationError.ExcessiveNSM;

Â  Â  }

}



/// Check if codepoint is an emoji

fn isEmoji(cp: CodePoint) bool {

Â  Â  return (cp >= 0x1F600 and cp <= 0x1F64F) orÂ  // Emoticons

Â  Â  Â  Â  Â  Â (cp >= 0x1F300 and cp <= 0x1F5FF) orÂ  // Miscellaneous Symbols and Pictographs

Â  Â  Â  Â  Â  Â (cp >= 0x1F680 and cp <= 0x1F6FF) orÂ  // Transport and Map Symbols

Â  Â  Â  Â  Â  Â (cp >= 0x2600 and cp <= 0x26FF);Â  Â  Â  // Miscellaneous Symbols

}



/// Check if codepoint is a fenced character

fn isFenced(cp: CodePoint) bool {

Â  Â  return cp == 0x002E orÂ  // Period

Â  Â  Â  Â  Â  Â cp == 0x002C orÂ  // Comma

Â  Â  Â  Â  Â  Â cp == 0x003A orÂ  // Colon

Â  Â  Â  Â  Â  Â cp == 0x003B orÂ  // Semicolon

Â  Â  Â  Â  Â  Â cp == 0x0021 orÂ  // Exclamation mark

Â  Â  Â  Â  Â  Â cp == 0x003F;Â  Â  // Question mark

}



/// Check if codepoint is invalid as NSM base

fn isInvalidNSMBase(cp: CodePoint) bool {

Â  Â  // Control characters, format characters, etc.

Â  Â  return (cp >= 0x0000 and cp <= 0x001F) orÂ  // C0 controls

Â  Â  Â  Â  Â  Â (cp >= 0x007F and cp <= 0x009F) orÂ  // C1 controls

Â  Â  Â  Â  Â  Â (cp >= 0x2000 and cp <= 0x200F) orÂ  // General punctuation (some)

Â  Â  Â  Â  Â  Â (cp >= 0xFFF0 and cp <= 0xFFFF);Â  Â  // Specials

}



/// Arabic letter detection

fn isArabicLetter(cp: CodePoint) bool {

Â  Â  return (cp >= 0x0621 and cp <= 0x063A) orÂ  // Arabic letters

Â  Â  Â  Â  Â  Â (cp >= 0x0641 and cp <= 0x064A) orÂ  // Arabic letters continued

Â  Â  Â  Â  Â  Â (cp >= 0x0671 and cp <= 0x06D3) orÂ  // Arabic letters extended

Â  Â  Â  Â  Â  Â (cp >= 0x06FA and cp <= 0x06FF);Â  Â  // Arabic letters supplement

}



/// Arabic vowel mark detection

fn isArabicVowelMark(cp: CodePoint) bool {

Â  Â  return (cp >= 0x064B and cp <= 0x0650) orÂ  // Fathatan, Dammatan, Kasratan, Fatha, Damma, Kasra

Â  Â  Â  Â  Â  Â cp == 0x0652;Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Sukun

}



/// Hebrew letter detection

fn isHebrewLetter(cp: CodePoint) bool {

Â  Â  return (cp >= 0x05D0 and cp <= 0x05EA) orÂ  // Hebrew letters

Â  Â  Â  Â  Â  Â (cp >= 0x05F0 and cp <= 0x05F2);Â  Â  // Hebrew ligatures

}



/// Devanagari consonant detection

fn isDevanagariConsonant(cp: CodePoint) bool {

Â  Â  return (cp >= 0x0915 and cp <= 0x0939) orÂ  // Consonants

Â  Â  Â  Â  Â  Â (cp >= 0x0958 and cp <= 0x095F);Â  Â  // Additional consonants

}



/// Enhanced NSM detection with Unicode categories

pub fn isNSM(cp: CodePoint) bool {

Â  Â  // Unicode General Category Mn (Mark, nonspacing)

Â  Â  // This is a more comprehensive check than the basic one

Â  Â  return (cp >= 0x0300 and cp <= 0x036F) orÂ  // Combining Diacritical Marks

Â  Â  Â  Â  Â  Â (cp >= 0x0483 and cp <= 0x0489) orÂ  // Cyrillic combining marks

Â  Â  Â  Â  Â  Â (cp >= 0x0591 and cp <= 0x05BD) orÂ  // Hebrew points

Â  Â  Â  Â  Â  Â (cp >= 0x05BF and cp <= 0x05BF) orÂ  // Hebrew point

Â  Â  Â  Â  Â  Â (cp >= 0x05C1 and cp <= 0x05C2) orÂ  // Hebrew points

Â  Â  Â  Â  Â  Â (cp >= 0x05C4 and cp <= 0x05C5) orÂ  // Hebrew points

Â  Â  Â  Â  Â  Â (cp >= 0x05C7 and cp <= 0x05C7) orÂ  // Hebrew point

Â  Â  Â  Â  Â  Â (cp >= 0x0610 and cp <= 0x061A) orÂ  // Arabic marks

Â  Â  Â  Â  Â  Â (cp >= 0x064B and cp <= 0x065F) orÂ  // Arabic diacritics

Â  Â  Â  Â  Â  Â (cp >= 0x0670 and cp <= 0x0670) orÂ  // Arabic letter superscript alef

Â  Â  Â  Â  Â  Â (cp >= 0x06D6 and cp <= 0x06DC) orÂ  // Arabic small high marks

Â  Â  Â  Â  Â  Â (cp >= 0x06DF and cp <= 0x06E4) orÂ  // Arabic small high marks

Â  Â  Â  Â  Â  Â (cp >= 0x06E7 and cp <= 0x06E8) orÂ  // Arabic small high marks

Â  Â  Â  Â  Â  Â (cp >= 0x06EA and cp <= 0x06ED) orÂ  // Arabic small high marks

Â  Â  Â  Â  Â  Â (cp >= 0x0711 and cp <= 0x0711) orÂ  // Syriac letter superscript alaph

Â  Â  Â  Â  Â  Â (cp >= 0x0730 and cp <= 0x074A) orÂ  // Syriac points

Â  Â  Â  Â  Â  Â (cp >= 0x07A6 and cp <= 0x07B0) orÂ  // Thaana points

Â  Â  Â  Â  Â  Â (cp >= 0x07EB and cp <= 0x07F3) orÂ  // NKo combining marks

Â  Â  Â  Â  Â  Â (cp >= 0x0816 and cp <= 0x0819) orÂ  // Samaritan marks

Â  Â  Â  Â  Â  Â (cp >= 0x081B and cp <= 0x0823) orÂ  // Samaritan marks

Â  Â  Â  Â  Â  Â (cp >= 0x0825 and cp <= 0x0827) orÂ  // Samaritan marks

Â  Â  Â  Â  Â  Â (cp >= 0x0829 and cp <= 0x082D) orÂ  // Samaritan marks

Â  Â  Â  Â  Â  Â (cp >= 0x0859 and cp <= 0x085B) orÂ  // Mandaic marks

Â  Â  Â  Â  Â  Â (cp >= 0x08E3 and cp <= 0x0902) orÂ  // Arabic/Devanagari marks

Â  Â  Â  Â  Â  Â (cp >= 0x093A and cp <= 0x093A) orÂ  // Devanagari vowel sign oe

Â  Â  Â  Â  Â  Â (cp >= 0x093C and cp <= 0x093C) orÂ  // Devanagari sign nukta

Â  Â  Â  Â  Â  Â (cp >= 0x0941 and cp <= 0x0948) orÂ  // Devanagari vowel signs

Â  Â  Â  Â  Â  Â (cp >= 0x094D and cp <= 0x094D) orÂ  // Devanagari sign virama

Â  Â  Â  Â  Â  Â (cp >= 0x0951 and cp <= 0x0957) orÂ  // Devanagari stress signs

Â  Â  Â  Â  Â  Â (cp >= 0x0962 and cp <= 0x0963);Â  Â  // Devanagari vowel signs

}



// Tests

const testing = std.testing;



test "NSM validation - basic count limits" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Create mock script groups and group

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var arabic_group = script_groups.ScriptGroup.init(allocator, "Arabic", 0);

Â  Â  defer arabic_group.deinit();

Â  Â Â 

Â  Â  // Add some Arabic NSMs to the groups NSM set

Â  Â  try groups.nsm_set.put(0x064E, {}); // Fatha

Â  Â  try groups.nsm_set.put(0x064F, {}); // Damma

Â  Â  try groups.nsm_set.put(0x0650, {}); // Kasra

Â  Â  try groups.nsm_set.put(0x0651, {}); // Shadda

Â  Â  try groups.nsm_set.put(0x0652, {}); // Sukun

Â  Â Â 

Â  Â  // Add to script group CM set

Â  Â  try arabic_group.cm.put(0x064E, {});

Â  Â  try arabic_group.cm.put(0x064F, {});

Â  Â  try arabic_group.cm.put(0x0650, {});

Â  Â  try arabic_group.cm.put(0x0651, {});

Â  Â  try arabic_group.cm.put(0x0652, {});

Â  Â Â 

Â  Â  // Test valid sequence: base + 3 NSMs

Â  Â  const valid_seq = [_]CodePoint{0x0628, 0x064E, 0x064F, 0x0650}; // Ø¨ÙÙÙ

Â  Â  try validateNSM(&valid_seq, &groups, &arabic_group, allocator);

Â  Â Â 

Â  Â  // Test invalid sequence: base + 5 NSMs (exceeds limit)

Â  Â  const invalid_seq = [_]CodePoint{0x0628, 0x064E, 0x064F, 0x0650, 0x0651, 0x0652};

Â  Â  const result = validateNSM(&invalid_seq, &groups, &arabic_group, allocator);

Â  Â  try testing.expectError(NSMValidationError.ExcessiveNSM, result);

}



test "NSM validation - duplicate detection" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var arabic_group = script_groups.ScriptGroup.init(allocator, "Arabic", 0);

Â  Â  defer arabic_group.deinit();

Â  Â Â 

Â  Â  try groups.nsm_set.put(0x064E, {});

Â  Â  try arabic_group.cm.put(0x064E, {});

Â  Â Â 

Â  Â  // Test duplicate NSMs

Â  Â  const duplicate_seq = [_]CodePoint{0x0628, 0x064E, 0x064E}; // Ø¨ + fatha + fatha

Â  Â  const result = validateNSM(&duplicate_seq, &groups, &arabic_group, allocator);

Â  Â  try testing.expectError(NSMValidationError.DuplicateNSM, result);

}



test "NSM validation - leading NSM detection" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var arabic_group = script_groups.ScriptGroup.init(allocator, "Arabic", 0);

Â  Â  defer arabic_group.deinit();

Â  Â Â 

Â  Â  try groups.nsm_set.put(0x064E, {});

Â  Â Â 

Â  Â  // Test leading NSM

Â  Â  const leading_nsm = [_]CodePoint{0x064E, 0x0628}; // fatha + Ø¨

Â  Â  const result = validateNSM(&leading_nsm, &groups, &arabic_group, allocator);

Â  Â  try testing.expectError(NSMValidationError.LeadingNSM, result);

}



test "NSM validation - emoji context" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var emoji_group = script_groups.ScriptGroup.init(allocator, "Emoji", 0);

Â  Â  defer emoji_group.deinit();

Â  Â Â 

Â  Â  try groups.nsm_set.put(0x064E, {});

Â  Â  try emoji_group.cm.put(0x064E, {});

Â  Â Â 

Â  Â  // Test NSM after emoji

Â  Â  const emoji_nsm = [_]CodePoint{0x1F600, 0x064E}; // ğŸ˜€ + fatha

Â  Â  const result = validateNSM(&emoji_nsm, &groups, &emoji_group, allocator);

Â  Â  try testing.expectError(NSMValidationError.NSMAfterEmoji, result);

}



test "NSM detection - comprehensive Unicode ranges" {

Â  Â  // Test various NSM ranges

Â  Â  try testing.expect(isNSM(0x0300)); // Combining grave accent

Â  Â  try testing.expect(isNSM(0x064E)); // Arabic fatha

Â  Â  try testing.expect(isNSM(0x05B4)); // Hebrew point hiriq

Â  Â  try testing.expect(isNSM(0x093C)); // Devanagari nukta

Â  Â  try testing.expect(isNSM(0x0951)); // Devanagari stress sign udatta

Â  Â Â 

Â  Â  // Test non-NSMs

Â  Â  try testing.expect(!isNSM('a'));

Â  Â  try testing.expect(!isNSM(0x0628)); // Arabic letter beh

Â  Â  try testing.expect(!isNSM(0x05D0)); // Hebrew letter alef

}



test "NSM validation - script-specific rules" {

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  var arabic_group = script_groups.ScriptGroup.init(allocator, "Arabic", 0);

Â  Â  defer arabic_group.deinit();

Â  Â Â 

Â  Â  try groups.nsm_set.put(0x064E, {});

Â  Â  try groups.nsm_set.put(0x064F, {});

Â  Â  try groups.nsm_set.put(0x0650, {});

Â  Â  try groups.nsm_set.put(0x0651, {});

Â  Â Â 

Â  Â  try arabic_group.cm.put(0x064E, {});

Â  Â  try arabic_group.cm.put(0x064F, {});

Â  Â  try arabic_group.cm.put(0x0650, {});

Â  Â  try arabic_group.cm.put(0x0651, {});

Â  Â Â 

Â  Â  // Test valid Arabic sequence

Â  Â  const valid_arabic = [_]CodePoint{0x0628, 0x064E, 0x0651}; // Ø¨ÙÙ‘ (beh + fatha + shadda)

Â  Â  try validateNSM(&valid_arabic, &groups, &arabic_group, allocator);

Â  Â Â 

Â  Â  // Test invalid: too many Arabic diacritics on one consonant

Â  Â  const invalid_arabic = [_]CodePoint{0x0628, 0x064E, 0x064F, 0x0650, 0x0651}; // Ø¨ÙÙÙÙ‘

Â  Â  const result = validateNSM(&invalid_arabic, &groups, &arabic_group, allocator);

Â  Â  try testing.expectError(NSMValidationError.ExcessiveNSM, result);

}```

```zig [./src/spec.zig]

const std = @import("std");



// Since we can't directly import ZON with heterogeneous arrays,

// we'll use a simplified approach for compile-time constants

const spec_zon_source = @embedFile("data/spec.zon");



// For now, we'll define constants that can be used at compile time

// These would need to be manually extracted or generated from the ZON file

pub const spec_data = struct {

Â  Â  pub const groups = [_]struct {

Â  Â  Â  Â  name: []const u8,

Â  Â  }{

Â  Â  Â  Â  .{ .name = "ASCII" },

Â  Â  Â  Â  .{ .name = "Latin" },

Â  Â  Â  Â  .{ .name = "Greek" },

Â  Â  Â  Â  .{ .name = "Cyrillic" },

Â  Â  Â  Â  .{ .name = "Hebrew" },

Â  Â  Â  Â  .{ .name = "Arabic" },

Â  Â  Â  Â  .{ .name = "Devanagari" },

Â  Â  Â  Â  .{ .name = "Bengali" },

Â  Â  Â  Â  .{ .name = "Gurmukhi" },

Â  Â  Â  Â  .{ .name = "Gujarati" },

Â  Â  Â  Â  .{ .name = "Oriya" },

Â  Â  Â  Â  .{ .name = "Tamil" },

Â  Â  Â  Â  .{ .name = "Telugu" },

Â  Â  Â  Â  .{ .name = "Kannada" },

Â  Â  Â  Â  .{ .name = "Malayalam" },

Â  Â  Â  Â  .{ .name = "Thai" },

Â  Â  Â  Â  .{ .name = "Lao" },

Â  Â  Â  Â  .{ .name = "Tibetan" },

Â  Â  Â  Â  .{ .name = "Myanmar" },

Â  Â  Â  Â  .{ .name = "Georgian" },

Â  Â  Â  Â  .{ .name = "Hangul" },

Â  Â  Â  Â  .{ .name = "Ethiopic" },

Â  Â  Â  Â  .{ .name = "Cherokee" },

Â  Â  Â  Â  .{ .name = "Canadian_Aboriginal" },

Â  Â  Â  Â  .{ .name = "Mongolian" },

Â  Â  Â  Â  .{ .name = "Japanese" },

Â  Â  Â  Â  .{ .name = "Han" },

Â  Â  Â  Â  .{ .name = "Emoji" },

Â  Â  Â  Â  // Add more as needed

Â  Â  };

};



/// Generate script group enum from spec data

pub const ScriptGroup = blk: {

Â  Â  const groups = spec_data.groups;

Â  Â  var fields: [groups.len]std.builtin.Type.EnumField = undefined;

Â  Â Â 

Â  Â  for (groups, 0..) |group, i| {

Â  Â  Â  Â  fields[i] = .{

Â  Â  Â  Â  Â  Â  .name = group.name,

Â  Â  Â  Â  Â  Â  .value = i,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  break :blk @Type(.{

Â  Â  Â  Â  .Enum = .{

Â  Â  Â  Â  Â  Â  .tag_type = u8,

Â  Â  Â  Â  Â  Â  .fields = &fields,

Â  Â  Â  Â  Â  Â  .decls = &.{},

Â  Â  Â  Â  Â  Â  .is_exhaustive = true,

Â  Â  Â  Â  },

Â  Â  });

};



/// Get script group by name

pub fn getScriptGroupByName(name: []const u8) ?ScriptGroup {

Â  Â  inline for (@typeInfo(ScriptGroup).Enum.fields) |field| {

Â  Â  Â  Â  if (std.mem.eql(u8, field.name, name)) {

Â  Â  Â  Â  Â  Â  return @enumFromInt(field.value);

Â  Â  Â  Â  }

Â  Â  }

Â  Â  return null;

}



/// Get script group name

pub fn getScriptGroupName(group: ScriptGroup) []const u8 {

Â  Â  return @tagName(group);

}



/// Get script group index

pub fn getScriptGroupIndex(group: ScriptGroup) usize {

Â  Â  return @intFromEnum(group);

}



/// Get script group data by enum

pub fn getScriptGroupData(group: ScriptGroup) ScriptGroupData {

Â  Â  const index = getScriptGroupIndex(group);

Â  Â  return ScriptGroupData{

Â  Â  Â  Â  .name = spec_data.groups[index].name,

Â  Â  Â  Â  .primary = spec_data.groups[index].primary,

Â  Â  Â  Â  .secondary = spec_data.groups[index].secondary orelse &.{},

Â  Â  Â  Â  .cm = spec_data.groups[index].cm orelse &.{},

Â  Â  Â  Â  .restricted = spec_data.groups[index].restricted orelse false,

Â  Â  };

}



pub const ScriptGroupData = struct {

Â  Â  name: []const u8,

Â  Â  primary: []const u32,

Â  Â  secondary: []const u32,

Â  Â  cm: []const u32,

Â  Â  restricted: bool,

};



/// All mapped characters from spec

pub const mapped_characters = spec_data.mapped;



/// All ignored characters from spec

pub const ignored_characters = spec_data.ignored;



/// All fenced characters from spec

pub const fenced_characters = spec_data.fenced;



/// All emoji sequences from spec

pub const emoji_sequences = spec_data.emoji;



/// NSM characters and max count

pub const nsm_characters = spec_data.nsm;

pub const nsm_max = spec_data.nsm_max;



/// NFC check data

pub const nfc_check = spec_data.nfc_check;



/// Whole script confusables

pub const whole_confusables = spec_data.wholes;



/// CM characters

pub const cm_characters = spec_data.cm;



test "script group enum generation" {

Â  Â  const testing = std.testing;

Â  Â Â 

Â  Â  // Test that we can get groups by name

Â  Â  const latin = getScriptGroupByName("Latin");

Â  Â  try testing.expect(latin != null);

Â  Â  try testing.expectEqualStrings("Latin", getScriptGroupName(latin.?));

Â  Â Â 

Â  Â  // Test that we can get group data

Â  Â  const latin_data = getScriptGroupData(latin.?);

Â  Â  try testing.expect(latin_data.primary.len > 0);

}```

```zig [./src/nfc.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;

const static_data_loader = @import("static_data_loader.zig");



// NFC Data structure to hold normalization data

pub const NFCData = struct {

Â  Â  // Decomposition mappings

Â  Â  decomp: std.AutoHashMap(CodePoint, []const CodePoint),

Â  Â  // Recomposition mappings (pair of codepoints -> single codepoint)

Â  Â  recomp: std.AutoHashMap(CodePointPair, CodePoint),

Â  Â  // Exclusions set

Â  Â  exclusions: std.AutoHashMap(CodePoint, void),

Â  Â  // Combining class rankings

Â  Â  combining_class: std.AutoHashMap(CodePoint, u8),

Â  Â  // Characters that need NFC checking

Â  Â  nfc_check: std.AutoHashMap(CodePoint, void),

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub const CodePointPair = struct {

Â  Â  Â  Â  first: CodePoint,

Â  Â  Â  Â  second: CodePoint,

Â  Â  Â  Â Â 

Â  Â  Â  Â  pub fn hash(self: CodePointPair) u64 {

Â  Â  Â  Â  Â  Â  var hasher = std.hash.Wyhash.init(0);

Â  Â  Â  Â  Â  Â  hasher.update(std.mem.asBytes(&self.first));

Â  Â  Â  Â  Â  Â  hasher.update(std.mem.asBytes(&self.second));

Â  Â  Â  Â  Â  Â  return hasher.final();

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  pub fn eql(a: CodePointPair, b: CodePointPair) bool {

Â  Â  Â  Â  Â  Â  return a.first == b.first and a.second == b.second;

Â  Â  Â  Â  }

Â  Â  };

Â  Â Â 

Â  Â  pub fn init(allocator: std.mem.Allocator) NFCData {

Â  Â  Â  Â  return NFCData{

Â  Â  Â  Â  Â  Â  .decomp = std.AutoHashMap(CodePoint, []const CodePoint).init(allocator),

Â  Â  Â  Â  Â  Â  .recomp = std.AutoHashMap(CodePointPair, CodePoint).init(allocator),

Â  Â  Â  Â  Â  Â  .exclusions = std.AutoHashMap(CodePoint, void).init(allocator),

Â  Â  Â  Â  Â  Â  .combining_class = std.AutoHashMap(CodePoint, u8).init(allocator),

Â  Â  Â  Â  Â  Â  .nfc_check = std.AutoHashMap(CodePoint, void).init(allocator),

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: *NFCData) void {

Â  Â  Â  Â  // Free decomposition values

Â  Â  Â  Â  var decomp_iter = self.decomp.iterator();

Â  Â  Â  Â  while (decomp_iter.next()) |entry| {

Â  Â  Â  Â  Â  Â  self.allocator.free(entry.value_ptr.*);

Â  Â  Â  Â  }

Â  Â  Â  Â  self.decomp.deinit();

Â  Â  Â  Â  self.recomp.deinit();

Â  Â  Â  Â  self.exclusions.deinit();

Â  Â  Â  Â  self.combining_class.deinit();

Â  Â  Â  Â  self.nfc_check.deinit();

Â  Â  }

Â  Â Â 

Â  Â  pub fn requiresNFCCheck(self: *const NFCData, cp: CodePoint) bool {

Â  Â  Â  Â  return self.nfc_check.contains(cp);

Â  Â  }

Â  Â Â 

Â  Â  pub fn getCombiningClass(self: *const NFCData, cp: CodePoint) u8 {

Â  Â  Â  Â  return self.combining_class.get(cp) orelse 0;

Â  Â  }

};



// Hangul syllable constants (from JavaScript reference)

const S0: CodePoint = 0xAC00;

const L0: CodePoint = 0x1100;

const V0: CodePoint = 0x1161;

const T0: CodePoint = 0x11A7;

const L_COUNT: CodePoint = 19;

const V_COUNT: CodePoint = 21;

const T_COUNT: CodePoint = 28;

const N_COUNT: CodePoint = V_COUNT * T_COUNT;

const S_COUNT: CodePoint = L_COUNT * N_COUNT;

const S1: CodePoint = S0 + S_COUNT;

const L1: CodePoint = L0 + L_COUNT;

const V1: CodePoint = V0 + V_COUNT;

const T1: CodePoint = T0 + T_COUNT;



pub fn isHangul(cp: CodePoint) bool {

Â  Â  return cp >= S0 and cp < S1;

}



// Decompose a single Hangul syllable

pub fn decomposeHangul(cp: CodePoint, result: *std.ArrayList(CodePoint)) !void {

Â  Â  if (!isHangul(cp)) return;

Â  Â Â 

Â  Â  const s_index = cp - S0;

Â  Â  const l_index = s_index / N_COUNT;

Â  Â  const v_index = (s_index % N_COUNT) / T_COUNT;

Â  Â  const t_index = s_index % T_COUNT;

Â  Â Â 

Â  Â  try result.append(L0 + l_index);

Â  Â  try result.append(V0 + v_index);

Â  Â  if (t_index > 0) {

Â  Â  Â  Â  try result.append(T0 + t_index);

Â  Â  }

}



// Compose Hangul syllables

pub fn composeHangul(a: CodePoint, b: CodePoint) ?CodePoint {

Â  Â  // L + V

Â  Â  if (a >= L0 and a < L1 and b >= V0 and b < V1) {

Â  Â  Â  Â  return S0 + (a - L0) * N_COUNT + (b - V0) * T_COUNT;

Â  Â  }

Â  Â  // LV + T

Â  Â  if (isHangul(a) and b > T0 and b < T1 and (a - S0) % T_COUNT == 0) {

Â  Â  Â  Â  return a + (b - T0);

Â  Â  }

Â  Â  return null;

}



// Decompose a string of codepoints

pub fn decompose(allocator: std.mem.Allocator, cps: []const CodePoint, nfc_data: *const NFCData) ![]CodePoint {

Â  Â  var result = std.ArrayList(CodePoint).init(allocator);

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  for (cps) |cp| {

Â  Â  Â  Â  // Check for Hangul syllable

Â  Â  Â  Â  if (isHangul(cp)) {

Â  Â  Â  Â  Â  Â  try decomposeHangul(cp, &result);

Â  Â  Â  Â  } else if (nfc_data.decomp.get(cp)) |decomposed| {

Â  Â  Â  Â  Â  Â  // Recursive decomposition

Â  Â  Â  Â  Â  Â  const sub_decomposed = try decompose(allocator, decomposed, nfc_data);

Â  Â  Â  Â  Â  Â  defer allocator.free(sub_decomposed);

Â  Â  Â  Â  Â  Â  try result.appendSlice(sub_decomposed);

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  // No decomposition

Â  Â  Â  Â  Â  Â  try result.append(cp);

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  // Apply canonical ordering

Â  Â  try canonicalOrder(result.items, nfc_data);

Â  Â Â 

Â  Â  return result.toOwnedSlice();

}



// Apply canonical ordering based on combining classes

fn canonicalOrder(cps: []CodePoint, nfc_data: *const NFCData) !void {

Â  Â  if (cps.len <= 1) return;

Â  Â Â 

Â  Â  // Bubble sort for canonical ordering (stable sort)

Â  Â  var i: usize = 1;

Â  Â  while (i < cps.len) : (i += 1) {

Â  Â  Â  Â  const cc = nfc_data.getCombiningClass(cps[i]);

Â  Â  Â  Â  if (cc != 0) {

Â  Â  Â  Â  Â  Â  var j = i;

Â  Â  Â  Â  Â  Â  while (j > 0) : (j -= 1) {

Â  Â  Â  Â  Â  Â  Â  Â  const prev_cc = nfc_data.getCombiningClass(cps[j - 1]);

Â  Â  Â  Â  Â  Â  Â  Â  if (prev_cc == 0 or prev_cc <= cc) break;

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  // Swap

Â  Â  Â  Â  Â  Â  Â  Â  const tmp = cps[j];

Â  Â  Â  Â  Â  Â  Â  Â  cps[j] = cps[j - 1];

Â  Â  Â  Â  Â  Â  Â  Â  cps[j - 1] = tmp;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

}



// Compose a string of decomposed codepoints

pub fn compose(allocator: std.mem.Allocator, decomposed: []const CodePoint, nfc_data: *const NFCData) ![]CodePoint {

Â  Â  if (decomposed.len == 0) {

Â  Â  Â  Â  return try allocator.alloc(CodePoint, 0);

Â  Â  }

Â  Â Â 

Â  Â  var result = std.ArrayList(CodePoint).init(allocator);

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  var i: usize = 0;

Â  Â  while (i < decomposed.len) {

Â  Â  Â  Â  const cp = decomposed[i];

Â  Â  Â  Â  const cc = nfc_data.getCombiningClass(cp);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Try to compose with previous character

Â  Â  Â  Â  if (result.items.len > 0 and cc == 0) {

Â  Â  Â  Â  Â  Â  const last_cp = result.items[result.items.len - 1];

Â  Â  Â  Â  Â  Â  const last_cc = nfc_data.getCombiningClass(last_cp);

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  if (last_cc == 0) {

Â  Â  Â  Â  Â  Â  Â  Â  // Try Hangul composition first

Â  Â  Â  Â  Â  Â  Â  Â  if (composeHangul(last_cp, cp)) |composed| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  result.items[result.items.len - 1] = composed;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  i += 1;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  // Try regular composition

Â  Â  Â  Â  Â  Â  Â  Â  const pair = NFCData.CodePointPair{ .first = last_cp, .second = cp };

Â  Â  Â  Â  Â  Â  Â  Â  if (nfc_data.recomp.get(pair)) |composed| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (!nfc_data.exclusions.contains(composed)) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  result.items[result.items.len - 1] = composed;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  i += 1;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // No composition, just append

Â  Â  Â  Â  try result.append(cp);

Â  Â  Â  Â  i += 1;

Â  Â  }

Â  Â Â 

Â  Â  return result.toOwnedSlice();

}



// Main NFC function

pub fn nfc(allocator: std.mem.Allocator, cps: []const CodePoint, nfc_data: *const NFCData) ![]CodePoint {

Â  Â  // First decompose

Â  Â  const decomposed = try decompose(allocator, cps, nfc_data);

Â  Â  defer allocator.free(decomposed);

Â  Â Â 

Â  Â  // Then compose

Â  Â  return try compose(allocator, decomposed, nfc_data);

}



// Check if codepoints need NFC normalization

pub fn needsNFC(cps: []const CodePoint, nfc_data: *const NFCData) bool {

Â  Â  for (cps) |cp| {

Â  Â  Â  Â  if (nfc_data.requiresNFCCheck(cp)) {

Â  Â  Â  Â  Â  Â  return true;

Â  Â  Â  Â  }

Â  Â  }

Â  Â  return false;

}



// Compare two codepoint arrays

pub fn compareCodePoints(a: []const CodePoint, b: []const CodePoint) bool {

Â  Â  if (a.len != b.len) return false;

Â  Â  for (a, b) |cp_a, cp_b| {

Â  Â  Â  Â  if (cp_a != cp_b) return false;

Â  Â  }

Â  Â  return true;

}



test "Hangul decomposition" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var result = std.ArrayList(CodePoint).init(allocator);

Â  Â Â 

Â  Â  // Test Hangul syllable ê°€ (GA)

Â  Â  try decomposeHangul(0xAC00, &result);

Â  Â  try testing.expectEqualSlices(CodePoint, &[_]CodePoint{ 0x1100, 0x1161 }, result.items);

Â  Â Â 

Â  Â  result.clearRetainingCapacity();

Â  Â Â 

Â  Â  // Test Hangul syllable ê° (GAK)

Â  Â  try decomposeHangul(0xAC01, &result);

Â  Â  try testing.expectEqualSlices(CodePoint, &[_]CodePoint{ 0x1100, 0x1161, 0x11A8 }, result.items);

}



test "Hangul composition" {

Â  Â  const testing = std.testing;

Â  Â Â 

Â  Â  // Test L + V

Â  Â  try testing.expectEqual(@as(?CodePoint, 0xAC00), composeHangul(0x1100, 0x1161));

Â  Â Â 

Â  Â  // Test LV + T

Â  Â  try testing.expectEqual(@as(?CodePoint, 0xAC01), composeHangul(0xAC00, 0x11A8));

Â  Â Â 

Â  Â  // Test invalid composition

Â  Â  try testing.expectEqual(@as(?CodePoint, null), composeHangul(0x1100, 0x11A8));

}```

```zig [./src/tokens.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;

const constants = @import("constants.zig");

const utils = @import("utils.zig");



pub const EnsNameToken = union(enum) {

Â  Â  valid: TokenValid,

Â  Â  mapped: TokenMapped,

Â  Â  ignored: TokenIgnored,

Â  Â  disallowed: TokenDisallowed,

Â  Â  stop: TokenStop,

Â  Â  nfc: TokenNfc,

Â  Â  emoji: TokenEmoji,

Â  Â Â 

Â  Â  pub fn getCps(self: EnsNameToken, allocator: std.mem.Allocator) ![]CodePoint {

Â  Â  Â  Â  switch (self) {

Â  Â  Â  Â  Â  Â  .valid => |t| return allocator.dupe(CodePoint, t.cps),

Â  Â  Â  Â  Â  Â  .mapped => |t| return allocator.dupe(CodePoint, t.cps),

Â  Â  Â  Â  Â  Â  .nfc => |t| return allocator.dupe(CodePoint, t.cps),

Â  Â  Â  Â  Â  Â  .emoji => |t| return allocator.dupe(CodePoint, t.cps_no_fe0f),

Â  Â  Â  Â  Â  Â  .disallowed => |t| {

Â  Â  Â  Â  Â  Â  Â  Â  var result = try allocator.alloc(CodePoint, 1);

Â  Â  Â  Â  Â  Â  Â  Â  result[0] = t.cp;

Â  Â  Â  Â  Â  Â  Â  Â  return result;

Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  .stop => |t| {

Â  Â  Â  Â  Â  Â  Â  Â  var result = try allocator.alloc(CodePoint, 1);

Â  Â  Â  Â  Â  Â  Â  Â  result[0] = t.cp;

Â  Â  Â  Â  Â  Â  Â  Â  return result;

Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  .ignored => |t| {

Â  Â  Â  Â  Â  Â  Â  Â  var result = try allocator.alloc(CodePoint, 1);

Â  Â  Â  Â  Â  Â  Â  Â  result[0] = t.cp;

Â  Â  Â  Â  Â  Â  Â  Â  return result;

Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  pub fn getInputSize(self: EnsNameToken) usize {

Â  Â  Â  Â  switch (self) {

Â  Â  Â  Â  Â  Â  .valid => |t| return t.cps.len,

Â  Â  Â  Â  Â  Â  .nfc => |t| return t.input.len,

Â  Â  Â  Â  Â  Â  .emoji => |t| return t.cps_input.len,

Â  Â  Â  Â  Â  Â  .mapped, .disallowed, .ignored, .stop => return 1,

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  pub fn isText(self: EnsNameToken) bool {

Â  Â  Â  Â  return switch (self) {

Â  Â  Â  Â  Â  Â  .valid, .mapped, .nfc => true,

Â  Â  Â  Â  Â  Â  else => false,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn isEmoji(self: EnsNameToken) bool {

Â  Â  Â  Â  return switch (self) {

Â  Â  Â  Â  Â  Â  .emoji => true,

Â  Â  Â  Â  Â  Â  else => false,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn isIgnored(self: EnsNameToken) bool {

Â  Â  Â  Â  return switch (self) {

Â  Â  Â  Â  Â  Â  .ignored => true,

Â  Â  Â  Â  Â  Â  else => false,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn isDisallowed(self: EnsNameToken) bool {

Â  Â  Â  Â  return switch (self) {

Â  Â  Â  Â  Â  Â  .disallowed => true,

Â  Â  Â  Â  Â  Â  else => false,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn isStop(self: EnsNameToken) bool {

Â  Â  Â  Â  return switch (self) {

Â  Â  Â  Â  Â  Â  .stop => true,

Â  Â  Â  Â  Â  Â  else => false,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn createStop() EnsNameToken {

Â  Â  Â  Â  return EnsNameToken{ .stop = TokenStop{ .cp = constants.CP_STOP } };

Â  Â  }

Â  Â Â 

Â  Â  pub fn asString(self: EnsNameToken, allocator: std.mem.Allocator) ![]u8 {

Â  Â  Â  Â  const cps = try self.getCps(allocator);

Â  Â  Â  Â  defer allocator.free(cps);

Â  Â  Â  Â  return utils.cps2str(allocator, cps);

Â  Â  }

};



pub const TokenValid = struct {

Â  Â  cps: []const CodePoint,

};



pub const TokenMapped = struct {

Â  Â  cps: []const CodePoint,

Â  Â  cp: CodePoint,

};



pub const TokenIgnored = struct {

Â  Â  cp: CodePoint,

};



pub const TokenDisallowed = struct {

Â  Â  cp: CodePoint,

};



pub const TokenStop = struct {

Â  Â  cp: CodePoint,

};



pub const TokenNfc = struct {

Â  Â  cps: []const CodePoint,

Â  Â  input: []const CodePoint,

};



pub const TokenEmoji = struct {

Â  Â  input: []const u8,

Â  Â  emoji: []const CodePoint,

Â  Â  cps_input: []const CodePoint,

Â  Â  cps_no_fe0f: []const CodePoint,

};



pub const CollapsedEnsNameToken = union(enum) {

Â  Â  text: TokenValid,

Â  Â  emoji: TokenEmoji,

Â  Â Â 

Â  Â  pub fn getInputSize(self: CollapsedEnsNameToken) usize {

Â  Â  Â  Â  switch (self) {

Â  Â  Â  Â  Â  Â  .text => |t| return t.cps.len,

Â  Â  Â  Â  Â  Â  .emoji => |t| return t.cps_input.len,

Â  Â  Â  Â  }

Â  Â  }

};



pub const TokenizedName = struct {

Â  Â  tokens: []const EnsNameToken,

Â  Â Â 

Â  Â  pub fn deinit(self: TokenizedName, allocator: std.mem.Allocator) void {

Â  Â  Â  Â  allocator.free(self.tokens);

Â  Â  }

Â  Â Â 

Â  Â  pub fn fromInput(

Â  Â  Â  Â  allocator: std.mem.Allocator,

Â  Â  Â  Â  input: []const u8,

Â  Â  Â  Â  specs: anytype,

Â  Â  Â  Â  should_nfc: bool,

Â  Â  ) !TokenizedName {

Â  Â  Â  Â  // This is a placeholder implementation

Â  Â  Â  Â  // The actual tokenization logic would need to be implemented

Â  Â  Â  Â  // based on the Rust implementation

Â  Â  Â  Â  _ = specs;

Â  Â  Â  Â  _ = should_nfc;

Â  Â  Â  Â Â 

Â  Â  Â  Â  var tokens = std.ArrayList(EnsNameToken).init(allocator);

Â  Â  Â  Â  defer tokens.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Basic tokenization - convert string to code points

Â  Â  Â  Â  const cps = try utils.str2cps(allocator, input);

Â  Â  Â  Â  defer allocator.free(cps);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Create a single valid token for now

Â  Â  Â  Â  const owned_cps = try allocator.dupe(CodePoint, cps);

Â  Â  Â  Â  try tokens.append(EnsNameToken{ .valid = TokenValid{ .cps = owned_cps } });

Â  Â  Â  Â Â 

Â  Â  Â  Â  return TokenizedName{

Â  Â  Â  Â  Â  Â  .tokens = try tokens.toOwnedSlice(),

Â  Â  Â  Â  };

Â  Â  }

};



test "EnsNameToken basic operations" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â Â 

Â  Â  const stop_token = EnsNameToken.createStop();

Â  Â  try testing.expect(stop_token.isStop());

Â  Â  try testing.expect(!stop_token.isText());

Â  Â  try testing.expect(!stop_token.isEmoji());

Â  Â Â 

Â  Â  const input_size = stop_token.getInputSize();

Â  Â  try testing.expectEqual(@as(usize, 1), input_size);

}```

```zig [./src/script_groups.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;

const utils = @import("utils.zig");



/// Script group for validating character sets

pub const ScriptGroup = struct {

Â  Â  /// Name of the script group (e.g., "Latin", "Greek", "Cyrillic")

Â  Â  name: []const u8,

Â  Â  /// Primary valid codepoints for this group

Â  Â  primary: std.AutoHashMap(CodePoint, void),

Â  Â  /// Secondary valid codepoints for this group

Â  Â  secondary: std.AutoHashMap(CodePoint, void),

Â  Â  /// Combined primary + secondary for quick lookup

Â  Â  combined: std.AutoHashMap(CodePoint, void),

Â  Â  /// Combining marks specific to this group (empty if none)

Â  Â  cm: std.AutoHashMap(CodePoint, void),

Â  Â  /// Whether to check NSM rules for this group

Â  Â  check_nsm: bool,

Â  Â  /// Index in the groups array (for error messages)

Â  Â  index: usize,

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub fn init(allocator: std.mem.Allocator, name: []const u8, index: usize) ScriptGroup {

Â  Â  Â  Â  return ScriptGroup{

Â  Â  Â  Â  Â  Â  .name = name,

Â  Â  Â  Â  Â  Â  .primary = std.AutoHashMap(CodePoint, void).init(allocator),

Â  Â  Â  Â  Â  Â  .secondary = std.AutoHashMap(CodePoint, void).init(allocator),

Â  Â  Â  Â  Â  Â  .combined = std.AutoHashMap(CodePoint, void).init(allocator),

Â  Â  Â  Â  Â  Â  .cm = std.AutoHashMap(CodePoint, void).init(allocator),

Â  Â  Â  Â  Â  Â  .check_nsm = true, // Default to checking NSM

Â  Â  Â  Â  Â  Â  .index = index,

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: *ScriptGroup) void {

Â  Â  Â  Â  self.primary.deinit();

Â  Â  Â  Â  self.secondary.deinit();

Â  Â  Â  Â  self.combined.deinit();

Â  Â  Â  Â  self.cm.deinit();

Â  Â  Â  Â  self.allocator.free(self.name);

Â  Â  }

Â  Â Â 

Â  Â  /// Add a primary codepoint

Â  Â  pub fn addPrimary(self: *ScriptGroup, cp: CodePoint) !void {

Â  Â  Â  Â  try self.primary.put(cp, {});

Â  Â  Â  Â  try self.combined.put(cp, {});

Â  Â  }

Â  Â Â 

Â  Â  /// Add a secondary codepoint

Â  Â  pub fn addSecondary(self: *ScriptGroup, cp: CodePoint) !void {

Â  Â  Â  Â  try self.secondary.put(cp, {});

Â  Â  Â  Â  try self.combined.put(cp, {});

Â  Â  }

Â  Â Â 

Â  Â  /// Add a combining mark

Â  Â  pub fn addCombiningMark(self: *ScriptGroup, cp: CodePoint) !void {

Â  Â  Â  Â  try self.cm.put(cp, {});

Â  Â  }

Â  Â Â 

Â  Â  /// Check if this group contains a codepoint (primary or secondary)

Â  Â  pub fn containsCp(self: *const ScriptGroup, cp: CodePoint) bool {

Â  Â  Â  Â  return self.combined.contains(cp);

Â  Â  }

Â  Â Â 

Â  Â  /// Check if this group contains all codepoints

Â  Â  pub fn containsAllCps(self: *const ScriptGroup, cps: []const CodePoint) bool {

Â  Â  Â  Â  for (cps) |cp| {

Â  Â  Â  Â  Â  Â  if (!self.containsCp(cp)) {

Â  Â  Â  Â  Â  Â  Â  Â  return false;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  return true;

Â  Â  }

Â  Â Â 

Â  Â  /// Check if a codepoint is in primary set

Â  Â  pub fn isPrimary(self: *const ScriptGroup, cp: CodePoint) bool {

Â  Â  Â  Â  return self.primary.contains(cp);

Â  Â  }

Â  Â Â 

Â  Â  /// Check if a codepoint is in secondary set

Â  Â  pub fn isSecondary(self: *const ScriptGroup, cp: CodePoint) bool {

Â  Â  Â  Â  return self.secondary.contains(cp);

Â  Â  }

};



/// Collection of all script groups

pub const ScriptGroups = struct {

Â  Â  groups: []ScriptGroup,

Â  Â  /// Set of all NSM (non-spacing marks) for validation

Â  Â  nsm_set: std.AutoHashMap(CodePoint, void),

Â  Â  /// Maximum consecutive NSM allowed

Â  Â  nsm_max: u32,

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub fn init(allocator: std.mem.Allocator) ScriptGroups {

Â  Â  Â  Â  return ScriptGroups{

Â  Â  Â  Â  Â  Â  .groups = &[_]ScriptGroup{},

Â  Â  Â  Â  Â  Â  .nsm_set = std.AutoHashMap(CodePoint, void).init(allocator),

Â  Â  Â  Â  Â  Â  .nsm_max = 4, // Default from spec

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: *ScriptGroups) void {

Â  Â  Â  Â  for (self.groups) |*group| {

Â  Â  Â  Â  Â  Â  group.deinit();

Â  Â  Â  Â  }

Â  Â  Â  Â  self.allocator.free(self.groups);

Â  Â  Â  Â  self.nsm_set.deinit();

Â  Â  }

Â  Â Â 

Â  Â  /// Add NSM codepoint

Â  Â  pub fn addNSM(self: *ScriptGroups, cp: CodePoint) !void {

Â  Â  Â  Â  try self.nsm_set.put(cp, {});

Â  Â  }

Â  Â Â 

Â  Â  /// Check if a codepoint is NSM

Â  Â  pub fn isNSM(self: *const ScriptGroups, cp: CodePoint) bool {

Â  Â  Â  Â  return self.nsm_set.contains(cp);

Â  Â  }

Â  Â Â 

Â  Â  /// Find which groups contain a codepoint

Â  Â  pub fn findGroupsContaining(self: *const ScriptGroups, cp: CodePoint, allocator: std.mem.Allocator) ![]const *const ScriptGroup {

Â  Â  Â  Â  var matching = std.ArrayList(*const ScriptGroup).init(allocator);

Â  Â  Â  Â  errdefer matching.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  for (self.groups) |*group| {

Â  Â  Â  Â  Â  Â  if (group.containsCp(cp)) {

Â  Â  Â  Â  Â  Â  Â  Â  try matching.append(group);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  return matching.toOwnedSlice();

Â  Â  }

Â  Â Â 

Â  Â  /// Determine the script group for a set of unique codepoints

Â  Â  pub fn determineScriptGroup(self: *const ScriptGroups, unique_cps: []const CodePoint, allocator: std.mem.Allocator) !*const ScriptGroup {

Â  Â  Â  Â  if (unique_cps.len == 0) {

Â  Â  Â  Â  Â  Â  return error.EmptyInput;

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Start with all groups

Â  Â  Â  Â  var remaining = try allocator.alloc(*const ScriptGroup, self.groups.len);

Â  Â  Â  Â  defer allocator.free(remaining);

Â  Â  Â  Â Â 

Â  Â  Â  Â  for (self.groups, 0..) |*group, i| {

Â  Â  Â  Â  Â  Â  remaining[i] = group;

Â  Â  Â  Â  }

Â  Â  Â  Â  var remaining_count = self.groups.len;

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Filter by each codepoint

Â  Â  Â  Â  for (unique_cps) |cp| {

Â  Â  Â  Â  Â  Â  var new_count: usize = 0;

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Keep only groups that contain this codepoint

Â  Â  Â  Â  Â  Â  for (remaining[0..remaining_count]) |group| {

Â  Â  Â  Â  Â  Â  Â  Â  if (group.containsCp(cp)) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  remaining[new_count] = group;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  new_count += 1;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  if (new_count == 0) {

Â  Â  Â  Â  Â  Â  Â  Â  // No group contains this codepoint

Â  Â  Â  Â  Â  Â  Â  Â  return error.DisallowedCharacter;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  remaining_count = new_count;

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Return the first remaining group (highest priority)

Â  Â  Â  Â  return remaining[0];

Â  Â  }

};



/// Result of script group determination

pub const ScriptGroupResult = struct {

Â  Â  group: *const ScriptGroup,

Â  Â  mixed_scripts: bool,

};



/// Find conflicting groups when script mixing is detected

pub fn findConflictingGroups(

Â  Â  groups: *const ScriptGroups,

Â  Â  unique_cps: []const CodePoint,

Â  Â  allocator: std.mem.Allocator

) !struct { first_group: *const ScriptGroup, conflicting_cp: CodePoint, conflicting_groups: []const *const ScriptGroup } {

Â  Â  if (unique_cps.len == 0) {

Â  Â  Â  Â  return error.EmptyInput;

Â  Â  }

Â  Â Â 

Â  Â  // Find groups for first codepoint

Â  Â  const remaining = try groups.findGroupsContaining(unique_cps[0], allocator);

Â  Â  defer allocator.free(remaining);

Â  Â Â 

Â  Â  if (remaining.len == 0) {

Â  Â  Â  Â  return error.DisallowedCharacter;

Â  Â  }

Â  Â Â 

Â  Â  // Check each subsequent codepoint

Â  Â  for (unique_cps[1..]) |cp| {

Â  Â  Â  Â  const cp_groups = try groups.findGroupsContaining(cp, allocator);

Â  Â  Â  Â  defer allocator.free(cp_groups);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Check if any remaining groups contain this cp

Â  Â  Â  Â  var found = false;

Â  Â  Â  Â  for (remaining) |group| {

Â  Â  Â  Â  Â  Â  for (cp_groups) |cp_group| {

Â  Â  Â  Â  Â  Â  Â  Â  if (group == cp_group) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  found = true;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (found) break;

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  if (!found) {

Â  Â  Â  Â  Â  Â  // This cp causes the conflict

Â  Â  Â  Â  Â  Â  return .{

Â  Â  Â  Â  Â  Â  Â  Â  .first_group = remaining[0],

Â  Â  Â  Â  Â  Â  Â  Â  .conflicting_cp = cp,

Â  Â  Â  Â  Â  Â  Â  Â  .conflicting_groups = cp_groups,

Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  return error.NoConflict;

}



test "script group basic operations" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const name = try allocator.dupe(u8, "Latin");

Â  Â  var group = ScriptGroup.init(allocator, name, 0);

Â  Â  defer group.deinit();

Â  Â Â 

Â  Â  // Add some codepoints

Â  Â  try group.addPrimary('A');

Â  Â  try group.addPrimary('B');

Â  Â  try group.addSecondary('1');

Â  Â  try group.addSecondary('2');

Â  Â Â 

Â  Â  // Test contains

Â  Â  try testing.expect(group.containsCp('A'));

Â  Â  try testing.expect(group.containsCp('1'));

Â  Â  try testing.expect(!group.containsCp('X'));

Â  Â Â 

Â  Â  // Test primary/secondary

Â  Â  try testing.expect(group.isPrimary('A'));

Â  Â  try testing.expect(!group.isPrimary('1'));

Â  Â  try testing.expect(group.isSecondary('1'));

Â  Â  try testing.expect(!group.isSecondary('A'));

}



test "script group determination" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var groups = ScriptGroups.init(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  // Create more realistic test groups with some overlap

Â  Â  var test_groups = try allocator.alloc(ScriptGroup, 3);

Â  Â Â 

Â  Â  const latin_name = try allocator.dupe(u8, "Latin");

Â  Â  test_groups[0] = ScriptGroup.init(allocator, latin_name, 0);

Â  Â  try test_groups[0].addPrimary('A');

Â  Â  try test_groups[0].addPrimary('B');

Â  Â  try test_groups[0].addPrimary('C');

Â  Â  try test_groups[0].addSecondary('0'); // Numbers are secondary in many scripts

Â  Â  try test_groups[0].addSecondary('1');

Â  Â Â 

Â  Â  const greek_name = try allocator.dupe(u8, "Greek");

Â  Â  test_groups[1] = ScriptGroup.init(allocator, greek_name, 1);

Â  Â  try test_groups[1].addPrimary(0x03B1); // Î±

Â  Â  try test_groups[1].addPrimary(0x03B2); // Î²

Â  Â  try test_groups[1].addSecondary('0'); // Numbers are secondary in many scripts

Â  Â  try test_groups[1].addSecondary('1');

Â  Â Â 

Â  Â  const common_name = try allocator.dupe(u8, "Common");

Â  Â  test_groups[2] = ScriptGroup.init(allocator, common_name, 2);

Â  Â  try test_groups[2].addPrimary('-');

Â  Â  try test_groups[2].addPrimary('_');

Â  Â Â 

Â  Â  groups.groups = test_groups;

Â  Â Â 

Â  Â  // Test single script

Â  Â  const latin_cps = [_]CodePoint{'A', 'B', 'C'};

Â  Â  const latin_group = try groups.determineScriptGroup(&latin_cps, allocator);

Â  Â  try testing.expectEqualStrings("Latin", latin_group.name);

Â  Â Â 

Â  Â  // Test Greek

Â  Â  const greek_cps = [_]CodePoint{0x03B1, 0x03B2};

Â  Â  const greek_group = try groups.determineScriptGroup(&greek_cps, allocator);

Â  Â  try testing.expectEqualStrings("Greek", greek_group.name);

Â  Â Â 

Â  Â  // Test with common characters (numbers)

Â  Â  const latin_with_numbers = [_]CodePoint{'A', '1'};

Â  Â  const latin_num_group = try groups.determineScriptGroup(&latin_with_numbers, allocator);

Â  Â  try testing.expectEqualStrings("Latin", latin_num_group.name);

Â  Â Â 

Â  Â  // Test mixed scripts (should error because no single group contains both)

Â  Â  const mixed_cps = [_]CodePoint{'A', 0x03B1}; // Latin A + Greek Î±

Â  Â  const result = groups.determineScriptGroup(&mixed_cps, allocator);

Â  Â  try testing.expectError(error.DisallowedCharacter, result);

}```

```zig [./src/emoji.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;

const utils = @import("utils.zig");



/// Single emoji sequence data

pub const EmojiData = struct {

Â  Â  /// Canonical form with FE0F

Â  Â  emoji: []const CodePoint,

Â  Â  /// Form without FE0F for matching

Â  Â  no_fe0f: []const CodePoint,

Â  Â Â 

Â  Â  pub fn deinit(self: EmojiData, allocator: std.mem.Allocator) void {

Â  Â  Â  Â  allocator.free(self.emoji);

Â  Â  Â  Â  allocator.free(self.no_fe0f);

Â  Â  }

};



/// Map for efficient emoji lookup

pub const EmojiMap = struct {

Â  Â  /// Map from no_fe0f codepoint sequence to emoji data

Â  Â  /// Using string key for simpler lookup

Â  Â  emojis: std.StringHashMap(EmojiData),

Â  Â  /// Maximum emoji sequence length (for optimization)

Â  Â  max_length: usize,

Â  Â  /// All emoji sequences for building regex pattern

Â  Â  all_emojis: std.ArrayList(EmojiData),

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub fn init(allocator: std.mem.Allocator) EmojiMap {

Â  Â  Â  Â  return EmojiMap{

Â  Â  Â  Â  Â  Â  .emojis = std.StringHashMap(EmojiData).init(allocator),

Â  Â  Â  Â  Â  Â  .max_length = 0,

Â  Â  Â  Â  Â  Â  .all_emojis = std.ArrayList(EmojiData).init(allocator),

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: *EmojiMap) void {

Â  Â  Â  Â  // Free all emoji data

Â  Â  Â  Â  for (self.all_emojis.items) |emoji_data| {

Â  Â  Â  Â  Â  Â  emoji_data.deinit(self.allocator);

Â  Â  Â  Â  }

Â  Â  Â  Â  self.all_emojis.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Free all keys in the map

Â  Â  Â  Â  var iter = self.emojis.iterator();

Â  Â  Â  Â  while (iter.next()) |entry| {

Â  Â  Â  Â  Â  Â  self.allocator.free(entry.key_ptr.*);

Â  Â  Â  Â  }

Â  Â  Â  Â  self.emojis.deinit();

Â  Â  }

Â  Â Â 

Â  Â  /// Add an emoji sequence to the map

Â  Â  pub fn addEmoji(self: *EmojiMap, no_fe0f: []const CodePoint, canonical: []const CodePoint) !void {

Â  Â  Â  Â  // Create owned copies

Â  Â  Â  Â  const owned_no_fe0f = try self.allocator.dupe(CodePoint, no_fe0f);

Â  Â  Â  Â  errdefer self.allocator.free(owned_no_fe0f);

Â  Â  Â  Â Â 

Â  Â  Â  Â  const owned_canonical = try self.allocator.dupe(CodePoint, canonical);

Â  Â  Â  Â  errdefer self.allocator.free(owned_canonical);

Â  Â  Â  Â Â 

Â  Â  Â  Â  const emoji_data = EmojiData{

Â  Â  Â  Â  Â  Â  .emoji = owned_canonical,

Â  Â  Â  Â  Â  Â  .no_fe0f = owned_no_fe0f,

Â  Â  Â  Â  };

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Convert no_fe0f to string key

Â  Â  Â  Â  const key = try utils.cps2str(self.allocator, no_fe0f);

Â  Â  Â  Â  defer self.allocator.free(key);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Add to map with owned key

Â  Â  Â  Â  const owned_key = try self.allocator.dupe(u8, key);

Â  Â  Â  Â  try self.emojis.put(owned_key, emoji_data);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Add to all emojis list

Â  Â  Â  Â  try self.all_emojis.append(emoji_data);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Update max length

Â  Â  Â  Â  const len = std.unicode.utf8CountCodepoints(key) catch key.len;

Â  Â  Â  Â  if (len > self.max_length) {

Â  Â  Â  Â  Â  Â  self.max_length = len;

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  /// Find emoji at given position in string

Â  Â  pub fn findEmojiAt(self: *const EmojiMap, allocator: std.mem.Allocator, input: []const u8, pos: usize) ?EmojiMatch {

Â  Â  Â  Â  if (pos >= input.len) return null;

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Try from longest possible match down to single character

Â  Â  Â  Â  var len = @min(input.len - pos, self.max_length * 4); // rough estimate for max UTF-8 bytes

Â  Â  Â  Â Â 

Â  Â  Â  Â  while (len > 0) : (len -= 1) {

Â  Â  Â  Â  Â  Â  if (pos + len > input.len) continue;

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  const slice = input[pos..pos + len];

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Check if this is a valid UTF-8 boundary

Â  Â  Â  Â  Â  Â  if (len < input.len - pos and !std.unicode.utf8ValidateSlice(slice)) {

Â  Â  Â  Â  Â  Â  Â  Â  continue;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Convert to codepoints and remove FE0F

Â  Â  Â  Â  Â  Â  const cps = utils.str2cps(allocator, slice) catch continue;

Â  Â  Â  Â  Â  Â  defer allocator.free(cps);

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  const no_fe0f = utils.filterFe0f(allocator, cps) catch continue;

Â  Â  Â  Â  Â  Â  defer allocator.free(no_fe0f);

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Convert to string key

Â  Â  Â  Â  Â  Â  const key = utils.cps2str(allocator, no_fe0f) catch continue;

Â  Â  Â  Â  Â  Â  defer allocator.free(key);

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Look up in map

Â  Â  Â  Â  Â  Â  if (self.emojis.get(key)) |emoji_data| {

Â  Â  Â  Â  Â  Â  Â  Â  // Need to return owned copies since we're deferring the frees

Â  Â  Â  Â  Â  Â  Â  Â  const owned_cps = allocator.dupe(CodePoint, cps) catch continue;

Â  Â  Â  Â  Â  Â  Â  Â  return EmojiMatch{

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .emoji_data = emoji_data,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .input = slice,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .cps_input = owned_cps,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .byte_len = len,

Â  Â  Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  return null;

Â  Â  }

};



/// Result of emoji matching

pub const EmojiMatch = struct {

Â  Â  emoji_data: EmojiData,

Â  Â  input: []const u8,

Â  Â  cps_input: []const CodePoint,

Â  Â  byte_len: usize,

};



/// Remove FE0F (variation selector) from codepoint sequence

pub fn filterFE0F(allocator: std.mem.Allocator, cps: []const CodePoint) ![]CodePoint {

Â  Â  return utils.filterFe0f(allocator, cps);

}



test "emoji map basic operations" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var emoji_map = EmojiMap.init(allocator);

Â  Â  defer emoji_map.deinit();

Â  Â Â 

Â  Â  // Add simple emoji

Â  Â  const smile_no_fe0f = [_]CodePoint{0x263A}; // â˜º

Â  Â  const smile_canonical = [_]CodePoint{0x263A, 0xFE0F}; // â˜ºï¸

Â  Â  try emoji_map.addEmoji(&smile_no_fe0f, &smile_canonical);

Â  Â Â 

Â  Â  // Test lookup

Â  Â  const key = try utils.cps2str(allocator, &smile_no_fe0f);

Â  Â  defer allocator.free(key);

Â  Â Â 

Â  Â  const found = emoji_map.emojis.get(key);

Â  Â  try testing.expect(found != null);

Â  Â  try testing.expectEqualSlices(CodePoint, &smile_canonical, found.?.emoji);

}



test "emoji map population - incorrect way" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var emoji_map = EmojiMap.init(allocator);

Â  Â  defer emoji_map.deinit();

Â  Â Â 

Â  Â  // Create emoji data

Â  Â  const thumbs_emoji = try allocator.alloc(CodePoint, 1);

Â  Â  thumbs_emoji[0] = 0x1F44D;

Â  Â  const thumbs_no_fe0f = try allocator.dupe(CodePoint, thumbs_emoji);

Â  Â Â 

Â  Â  const emoji_data = EmojiData{

Â  Â  Â  Â  .emoji = thumbs_emoji,

Â  Â  Â  Â  .no_fe0f = thumbs_no_fe0f,

Â  Â  };

Â  Â Â 

Â  Â  // Add to all_emojis (what our loader does)

Â  Â  try emoji_map.all_emojis.append(emoji_data);

Â  Â Â 

Â  Â  // But this doesn't populate the hash map!

Â  Â  // Let's verify the hash map is empty

Â  Â  const key = try utils.cps2str(allocator, thumbs_no_fe0f);

Â  Â  defer allocator.free(key);

Â  Â Â 

Â  Â  const found = emoji_map.emojis.get(key);

Â  Â  try testing.expect(found == null); // This should pass, showing the bug

Â  Â Â 

Â  Â  // Now test findEmojiAt - it should fail to find the emoji

Â  Â  const input = "Hello ğŸ‘ World";

Â  Â  const match = emoji_map.findEmojiAt(allocator, input, 6);

Â  Â  try testing.expect(match == null); // This should pass, confirming the bug

}



test "emoji map population - correct way" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var emoji_map = EmojiMap.init(allocator);

Â  Â  defer emoji_map.deinit();

Â  Â Â 

Â  Â  // Use addEmoji which populates both structures

Â  Â  const thumbs_no_fe0f = [_]CodePoint{0x1F44D};

Â  Â  const thumbs_emoji = [_]CodePoint{0x1F44D};

Â  Â  try emoji_map.addEmoji(&thumbs_no_fe0f, &thumbs_emoji);

Â  Â Â 

Â  Â  // Verify the hash map is populated

Â  Â  const key = try utils.cps2str(allocator, &thumbs_no_fe0f);

Â  Â  defer allocator.free(key);

Â  Â Â 

Â  Â  const found = emoji_map.emojis.get(key);

Â  Â  try testing.expect(found != null);

Â  Â Â 

Â  Â  // Now test findEmojiAt - it should find the emoji

Â  Â  const input = "Hello ğŸ‘ World";

Â  Â  const match = emoji_map.findEmojiAt(allocator, input, 6);

Â  Â  try testing.expect(match != null);

Â  Â  if (match) |m| {

Â  Â  Â  Â  defer allocator.free(m.cps_input);

Â  Â  Â  Â  try testing.expectEqualSlices(CodePoint, &thumbs_emoji, m.emoji_data.emoji);

Â  Â  }

}



test "emoji matching" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var emoji_map = EmojiMap.init(allocator);

Â  Â  defer emoji_map.deinit();

Â  Â Â 

Â  Â  // Add thumbs up emoji

Â  Â  const thumbs_no_fe0f = [_]CodePoint{0x1F44D}; // ğŸ‘

Â  Â  const thumbs_canonical = [_]CodePoint{0x1F44D};

Â  Â  try emoji_map.addEmoji(&thumbs_no_fe0f, &thumbs_canonical);

Â  Â Â 

Â  Â  // Test finding emoji in string

Â  Â  const input = "Hello ğŸ‘ World";

Â  Â  const match = emoji_map.findEmojiAt(allocator, input, 6); // Position of ğŸ‘

Â  Â Â 

Â  Â  try testing.expect(match != null);

Â  Â  if (match) |m| {

Â  Â  Â  Â  defer allocator.free(m.cps_input);

Â  Â  Â  Â  try testing.expectEqualSlices(CodePoint, &thumbs_canonical, m.emoji_data.emoji);

Â  Â  }

}```

```zig [./src/main.zig]

const std = @import("std");

const ens_normalize = @import("root.zig");



pub fn main() !void {

Â  Â  var gpa = std.heap.GeneralPurposeAllocator(.{}){};

Â  Â  defer _ = gpa.deinit();

Â  Â  const allocator = gpa.allocator();

Â  Â Â 

Â  Â  const stdout = std.io.getStdOut().writer();

Â  Â Â 

Â  Â  try stdout.print("ENS Normalize Zig Implementation\n", .{});

Â  Â  try stdout.print("=================================\n\n", .{});

Â  Â Â 

Â  Â  // Example usage

Â  Â  const test_names = [_][]const u8{

Â  Â  Â  Â  "hello.eth",

Â  Â  Â  Â  "test-domain.eth",

Â  Â  Â  Â  "Î¾.eth",

Â  Â  Â  Â  "hello.eth",

Â  Â  };

Â  Â Â 

Â  Â  for (test_names) |name| {

Â  Â  Â  Â  try stdout.print("Input: {s}\n", .{name});

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Try to normalize the name

Â  Â  Â  Â  const normalized = ens_normalize.normalize(allocator, name) catch |err| {

Â  Â  Â  Â  Â  Â  try stdout.print("Error: {}\n", .{err});

Â  Â  Â  Â  Â  Â  continue;

Â  Â  Â  Â  };

Â  Â  Â  Â  defer allocator.free(normalized);

Â  Â  Â  Â Â 

Â  Â  Â  Â  try stdout.print("Normalized: {s}\n", .{normalized});

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Try to beautify the name

Â  Â  Â  Â  const beautified = ens_normalize.beautify_fn(allocator, name) catch |err| {

Â  Â  Â  Â  Â  Â  try stdout.print("Beautify Error: {}\n", .{err});

Â  Â  Â  Â  Â  Â  continue;

Â  Â  Â  Â  };

Â  Â  Â  Â  defer allocator.free(beautified);

Â  Â  Â  Â Â 

Â  Â  Â  Â  try stdout.print("Beautified: {s}\n", .{beautified});

Â  Â  Â  Â  try stdout.print("\n", .{});

Â  Â  }

Â  Â Â 

Â  Â  try stdout.print("Note: This is a basic implementation. Full ENS normalization\n", .{});

Â  Â  try stdout.print("requires additional Unicode data and processing logic.\n", .{});

}



test "basic library functionality" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Test basic tokenization

Â  Â  const input = "hello";

Â  Â  const tokenized = ens_normalize.tokenize(allocator, input) catch |err| {

Â  Â  Â  Â  // For now, expect errors since we haven't implemented full functionality

Â  Â  Â  Â  try testing.expect(err == ens_normalize.error_types.ProcessError.DisallowedSequence);

Â  Â  Â  Â  return;

Â  Â  };

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  try testing.expect(tokenized.tokens.len > 0);

}



test "memory management" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Test that we properly manage memory

Â  Â  var normalizer = ens_normalize.normalizer.EnsNameNormalizer.default(allocator);

Â  Â  defer normalizer.deinit();

Â  Â Â 

Â  Â  const input = "test";

Â  Â  const result = normalizer.normalize(input) catch |err| {

Â  Â  Â  Â  // Expected to fail with current implementation

Â  Â  Â  Â  try testing.expect(err == ens_normalize.error_types.ProcessError.DisallowedSequence);

Â  Â  Â  Â  return;

Â  Â  };

Â  Â  defer allocator.free(result);

}```

```zig [./src/normalizer.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;

const code_points = @import("code_points.zig");

const validate = @import("validate.zig");

const error_types = @import("error.zig");

const beautify_mod = @import("beautify.zig");

const join = @import("join.zig");

const tokenizer = @import("tokenizer.zig");

const character_mappings = @import("character_mappings.zig");

const static_data_loader = @import("static_data_loader.zig");



pub const EnsNameNormalizer = struct {

Â  Â  specs: code_points.CodePointsSpecs,

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub fn init(allocator: std.mem.Allocator, specs: code_points.CodePointsSpecs) EnsNameNormalizer {

Â  Â  Â  Â  return EnsNameNormalizer{

Â  Â  Â  Â  Â  Â  .specs = specs,

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: *EnsNameNormalizer) void {

Â  Â  Â  Â  self.specs.deinit();

Â  Â  }

Â  Â Â 

Â  Â  pub fn tokenize(self: *const EnsNameNormalizer, input: []const u8) !tokenizer.TokenizedName {

Â  Â  Â  Â  return tokenizer.TokenizedName.fromInput(self.allocator, input, &self.specs, true);

Â  Â  }

Â  Â Â 

Â  Â  pub fn process(self: *const EnsNameNormalizer, input: []const u8) !ProcessedName {

Â  Â  Â  Â  const tokenized = try self.tokenize(input);

Â  Â  Â  Â  const labels = try validate.validateName(self.allocator, tokenized, &self.specs);

Â  Â  Â  Â Â 

Â  Â  Â  Â  return ProcessedName{

Â  Â  Â  Â  Â  Â  .labels = labels,

Â  Â  Â  Â  Â  Â  .tokenized = tokenized,

Â  Â  Â  Â  Â  Â  .allocator = self.allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn normalize(self: *const EnsNameNormalizer, input: []const u8) ![]u8 {

Â  Â  Â  Â  const processed = try self.process(input);

Â  Â  Â  Â  defer processed.deinit();

Â  Â  Â  Â  return processed.normalize();

Â  Â  }

Â  Â Â 

Â  Â  pub fn beautify_fn(self: *const EnsNameNormalizer, input: []const u8) ![]u8 {

Â  Â  Â  Â  const processed = try self.process(input);

Â  Â  Â  Â  defer processed.deinit();

Â  Â  Â  Â  return processed.beautify();

Â  Â  }

Â  Â Â 

Â  Â  pub fn default(allocator: std.mem.Allocator) EnsNameNormalizer {

Â  Â  Â  Â  return EnsNameNormalizer.init(allocator, code_points.CodePointsSpecs.init(allocator));

Â  Â  }

};



pub const ProcessedName = struct {

Â  Â  labels: []validate.ValidatedLabel,

Â  Â  tokenized: tokenizer.TokenizedName,

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub fn deinit(self: ProcessedName) void {

Â  Â  Â  Â  for (self.labels) |label| {

Â  Â  Â  Â  Â  Â  label.deinit();

Â  Â  Â  Â  }

Â  Â  Â  Â  self.allocator.free(self.labels);

Â  Â  Â  Â  self.tokenized.deinit();

Â  Â  }

Â  Â Â 

Â  Â  pub fn normalize(self: *const ProcessedName) ![]u8 {

Â  Â  Â  Â  return normalizeTokens(self.allocator, self.tokenized.tokens);

Â  Â  }

Â  Â Â 

Â  Â  pub fn beautify(self: *const ProcessedName) ![]u8 {

Â  Â  Â  Â  return beautifyTokens(self.allocator, self.tokenized.tokens);

Â  Â  }

};



// Convenience functions that use default normalizer

pub fn tokenize(allocator: std.mem.Allocator, input: []const u8) !tokenizer.TokenizedName {

Â  Â  var normalizer = EnsNameNormalizer.default(allocator);

Â  Â  defer normalizer.deinit();

Â  Â  return normalizer.tokenize(input);

}



pub fn process(allocator: std.mem.Allocator, input: []const u8) !ProcessedName {

Â  Â  var normalizer = EnsNameNormalizer.default(allocator);

Â  Â  defer normalizer.deinit();

Â  Â  return normalizer.process(input);

}



pub fn normalize(allocator: std.mem.Allocator, input: []const u8) ![]u8 {

Â  Â  // Use character mappings directly for better performance

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, input, &code_points.CodePointsSpecs.init(allocator), false);

Â  Â  defer tokenized.deinit();

Â  Â  return normalizeTokens(allocator, tokenized.tokens);

}



pub fn beautify(allocator: std.mem.Allocator, input: []const u8) ![]u8 {

Â  Â  // Use character mappings directly for better performance

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, input, &code_points.CodePointsSpecs.init(allocator), false);

Â  Â  defer tokenized.deinit();

Â  Â  return beautifyTokens(allocator, tokenized.tokens);

}



// Token processing functions

fn normalizeTokens(allocator: std.mem.Allocator, token_list: []const tokenizer.Token) ![]u8 {

Â  Â  var result = std.ArrayList(u8).init(allocator);

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  for (token_list) |token| {

Â  Â  Â  Â  // Get the normalized code points for this token

Â  Â  Â  Â  const cps = token.getCps();

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Convert code points to UTF-8 and append to result

Â  Â  Â  Â  for (cps) |cp| {

Â  Â  Â  Â  Â  Â  const utf8_len = std.unicode.utf8CodepointSequenceLength(@as(u21, @intCast(cp))) catch continue;

Â  Â  Â  Â  Â  Â  const old_len = result.items.len;

Â  Â  Â  Â  Â  Â  try result.resize(old_len + utf8_len);

Â  Â  Â  Â  Â  Â  _ = std.unicode.utf8Encode(@as(u21, @intCast(cp)), result.items[old_len..]) catch continue;

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  return result.toOwnedSlice();

}



fn beautifyTokens(allocator: std.mem.Allocator, token_list: []const tokenizer.Token) ![]u8 {

Â  Â  var result = std.ArrayList(u8).init(allocator);

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  for (token_list) |token| {

Â  Â  Â  Â  switch (token.type) {

Â  Â  Â  Â  Â  Â  .mapped => {

Â  Â  Â  Â  Â  Â  Â  Â  // For beautification, use original character for case folding

Â  Â  Â  Â  Â  Â  Â  Â  const original_cp = token.data.mapped.cp;

Â  Â  Â  Â  Â  Â  Â  Â  const utf8_len = std.unicode.utf8CodepointSequenceLength(@as(u21, @intCast(original_cp))) catch continue;

Â  Â  Â  Â  Â  Â  Â  Â  const old_len = result.items.len;

Â  Â  Â  Â  Â  Â  Â  Â  try result.resize(old_len + utf8_len);

Â  Â  Â  Â  Â  Â  Â  Â  _ = std.unicode.utf8Encode(@as(u21, @intCast(original_cp)), result.items[old_len..]) catch continue;

Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  else => {

Â  Â  Â  Â  Â  Â  Â  Â  // For other tokens, use normalized form

Â  Â  Â  Â  Â  Â  Â  Â  const cps = token.getCps();

Â  Â  Â  Â  Â  Â  Â  Â  for (cps) |cp| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const utf8_len = std.unicode.utf8CodepointSequenceLength(@as(u21, @intCast(cp))) catch continue;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const old_len = result.items.len;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try result.resize(old_len + utf8_len);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  _ = std.unicode.utf8Encode(@as(u21, @intCast(cp)), result.items[old_len..]) catch continue;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  return result.toOwnedSlice();

}



test "EnsNameNormalizer basic functionality" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var normalizer = EnsNameNormalizer.default(allocator);

Â  Â  defer normalizer.deinit();

Â  Â Â 

Â  Â  const input = "hello.eth";

Â  Â  const result = normalizer.normalize(input) catch |err| {

Â  Â  Â  Â  // For now, expect errors since we haven't implemented full functionality

Â  Â  Â  Â  try testing.expect(err == error_types.ProcessError.DisallowedSequence);

Â  Â  Â  Â  return;

Â  Â  };

Â  Â  defer allocator.free(result);

}```

```zig [./src/static_data_loader.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;

const character_mappings = @import("character_mappings.zig");

const CharacterMappings = character_mappings.CharacterMappings;

const nfc = @import("nfc.zig");

const emoji = @import("emoji.zig");

const script_groups = @import("script_groups.zig");

const confusables = @import("confusables.zig");

const utils = @import("utils.zig");



// Define ZON data types

const MappedItem = struct { u32, []const u32 };

const FencedItem = struct { u32, []const u8 };

const WholeItem = struct {

Â  Â  target: ?[]const u8,

Â  Â  valid: []const u32,

Â  Â  confused: []const u32,

};

const GroupItem = struct {

Â  Â  name: []const u8,

Â  Â  primary: []const u32,

Â  Â  secondary: ?[]const u32 = null,

Â  Â  cm: ?[]const u32 = null,

Â  Â  restricted: ?bool = null,

};



const SpecData = struct {

Â  Â  created: []const u8,

Â  Â  unicode: []const u8,

Â  Â  cldr: []const u8,

Â  Â  emoji: []const []const u32,

Â  Â  ignored: []const u32,

Â  Â  mapped: []const MappedItem,

Â  Â  fenced: []const FencedItem,

Â  Â  groups: []const GroupItem,

Â  Â  nsm: []const u32,

Â  Â  nsm_max: u32,

Â  Â  nfc_check: []const u32,

Â  Â  wholes: []const WholeItem,

Â  Â  cm: []const u32,

Â  Â  escape: []const u32,

};



const DecompItem = struct { u32, []const u32 };

const RankItem = []const u32;



const NfData = struct {

Â  Â  created: []const u8,

Â  Â  unicode: []const u8,

Â  Â  exclusions: []const u32,

Â  Â  decomp: []const DecompItem,

Â  Â  ranks: []const RankItem,

Â  Â  qc: ?[]const u32 = null,

};



// Import ZON data at compile time

const spec_data: SpecData = @import("data/spec.zon");

const nf_data: NfData = @import("data/nf.zon");



/// Load character mappings - now just returns the comptime-based struct

pub fn loadCharacterMappings(allocator: std.mem.Allocator) !CharacterMappings {

Â  Â  // With comptime data, we don't need to load anything at runtime!

Â  Â  return CharacterMappings.init(allocator);

}



/// Load NFC data from ZON

pub fn loadNFC(allocator: std.mem.Allocator) !nfc.NFCData {

Â  Â  var nfc_data = nfc.NFCData.init(allocator);

Â  Â  errdefer nfc_data.deinit();

Â  Â Â 

Â  Â  // Load exclusions

Â  Â  for (nf_data.exclusions) |cp| {

Â  Â  Â  Â  try nfc_data.exclusions.put(@as(CodePoint, cp), {});

Â  Â  }

Â  Â Â 

Â  Â  // Load decomposition mappings

Â  Â  for (nf_data.decomp) |entry| {

Â  Â  Â  Â  const cp = @as(CodePoint, entry[0]);

Â  Â  Â  Â  const decomp_array = entry[1];

Â  Â  Â  Â  var decomp = try allocator.alloc(CodePoint, decomp_array.len);

Â  Â  Â  Â  for (decomp_array, 0..) |decomp_cp, i| {

Â  Â  Â  Â  Â  Â  decomp[i] = @as(CodePoint, decomp_cp);

Â  Â  Â  Â  }

Â  Â  Â  Â  try nfc_data.decomp.put(cp, decomp);

Â  Â  }

Â  Â Â 

Â  Â  // Note: The ranks field in nf.zon appears to be arrays of codepoints

Â  Â  // grouped by their combining class. We'll need to determine the actual

Â  Â  // combining class values from the Unicode standard or reference implementation.

Â  Â  // For now, we'll leave combining_class empty as it might not be needed

Â  Â  // for basic normalization.

Â  Â Â 

Â  Â  // Load NFC check from spec data

Â  Â  for (spec_data.nfc_check) |cp| {

Â  Â  Â  Â  try nfc_data.nfc_check.put(@as(CodePoint, cp), {});

Â  Â  }

Â  Â Â 

Â  Â  return nfc_data;

}



/// Load emoji data from ZON

pub fn loadEmoji(allocator: std.mem.Allocator) !emoji.EmojiMap {

Â  Â  var emoji_data = emoji.EmojiMap.init(allocator);

Â  Â  errdefer emoji_data.deinit();

Â  Â Â 

Â  Â  for (spec_data.emoji) |seq| {

Â  Â  Â  Â  var cps = try allocator.alloc(CodePoint, seq.len);

Â  Â  Â  Â  for (seq, 0..) |cp, i| {

Â  Â  Â  Â  Â  Â  cps[i] = @as(CodePoint, cp);

Â  Â  Â  Â  }

Â  Â  Â  Â  defer allocator.free(cps);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Calculate no_fe0f version

Â  Â  Â  Â  const no_fe0f = utils.filterFe0f(allocator, cps) catch cps;

Â  Â  Â  Â  defer if (no_fe0f.ptr != cps.ptr) allocator.free(no_fe0f);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Use addEmoji to properly populate both hash map and list

Â  Â  Â  Â  try emoji_data.addEmoji(no_fe0f, cps);

Â  Â  }

Â  Â Â 

Â  Â  return emoji_data;

}



/// Load script groups from ZON

pub fn loadScriptGroups(allocator: std.mem.Allocator) !script_groups.ScriptGroups {

Â  Â  var groups = script_groups.ScriptGroups.init(allocator);

Â  Â  groups.groups = try allocator.alloc(script_groups.ScriptGroup, spec_data.groups.len);

Â  Â  errdefer {

Â  Â  Â  Â  allocator.free(groups.groups);

Â  Â  Â  Â  groups.deinit();

Â  Â  }

Â  Â Â 

Â  Â  // Load each script group

Â  Â  for (spec_data.groups, 0..) |group_data, i| {

Â  Â  Â  Â  // Duplicate the name to ensure it's owned by the allocator

Â  Â  Â  Â  const name = try allocator.dupe(u8, group_data.name);

Â  Â  Â  Â  var group = script_groups.ScriptGroup.init(allocator, name, i);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Add primary characters

Â  Â  Â  Â  for (group_data.primary) |cp| {

Â  Â  Â  Â  Â  Â  try group.addPrimary(@as(CodePoint, cp));

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Add secondary characters (if present)

Â  Â  Â  Â  if (group_data.secondary) |secondary| {

Â  Â  Â  Â  Â  Â  for (secondary) |cp| {

Â  Â  Â  Â  Â  Â  Â  Â  try group.addSecondary(@as(CodePoint, cp));

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Add combining marks (if present)

Â  Â  Â  Â  if (group_data.cm) |cm| {

Â  Â  Â  Â  Â  Â  for (cm) |cp| {

Â  Â  Â  Â  Â  Â  Â  Â  try group.addCombiningMark(@as(CodePoint, cp));

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  groups.groups[i] = group;

Â  Â  }

Â  Â Â 

Â  Â  // Load NSM characters

Â  Â  for (spec_data.nsm) |cp| {

Â  Â  Â  Â  try groups.addNSM(@as(CodePoint, cp));

Â  Â  }

Â  Â Â 

Â  Â  // Set NSM max

Â  Â  groups.nsm_max = spec_data.nsm_max;

Â  Â Â 

Â  Â  return groups;

}



/// Load confusable data from ZON

pub fn loadConfusables(allocator: std.mem.Allocator) !confusables.ConfusableData {

Â  Â  var confusable_data = confusables.ConfusableData.init(allocator);

Â  Â  errdefer confusable_data.deinit();

Â  Â Â 

Â  Â  confusable_data.sets = try allocator.alloc(confusables.ConfusableSet, spec_data.wholes.len);

Â  Â Â 

Â  Â  for (spec_data.wholes, 0..) |whole, i| {

Â  Â  Â  Â  // Get target

Â  Â  Â  Â  const target = if (whole.target) |t|Â 

Â  Â  Â  Â  Â  Â  try allocator.dupe(u8, t)

Â  Â  Â  Â  elseÂ 

Â  Â  Â  Â  Â  Â  try allocator.dupe(u8, "unknown");

Â  Â  Â  Â Â 

Â  Â  Â  Â  var set = confusables.ConfusableSet.init(allocator, target);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Load valid characters

Â  Â  Â  Â  var valid_slice = try allocator.alloc(CodePoint, whole.valid.len);

Â  Â  Â  Â  for (whole.valid, 0..) |cp, j| {

Â  Â  Â  Â  Â  Â  valid_slice[j] = @as(CodePoint, cp);

Â  Â  Â  Â  }

Â  Â  Â  Â  set.valid = valid_slice;

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Load confused characters

Â  Â  Â  Â  var confused_slice = try allocator.alloc(CodePoint, whole.confused.len);

Â  Â  Â  Â  for (whole.confused, 0..) |cp, j| {

Â  Â  Â  Â  Â  Â  confused_slice[j] = @as(CodePoint, cp);

Â  Â  Â  Â  }

Â  Â  Â  Â  set.confused = confused_slice;

Â  Â  Â  Â Â 

Â  Â  Â  Â  confusable_data.sets[i] = set;

Â  Â  }

Â  Â Â 

Â  Â  return confusable_data;

}



test "static data loading from ZON" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Just verify that the compile-time imports work

Â  Â  try testing.expect(spec_data.created.len > 0);

Â  Â  try testing.expect(spec_data.groups.len > 0);

Â  Â  try testing.expect(nf_data.decomp.len > 0);

Â  Â Â 

Â  Â  // Test loading character mappings

Â  Â  const mappings = try loadCharacterMappings(allocator);

Â  Â  // With comptime data, we just verify the struct was created

Â  Â  _ = mappings;

Â  Â Â 

Â  Â  // Test loading emoji

Â  Â  const emoji_map = try loadEmoji(allocator);

Â  Â  std.debug.print("Loaded {} emoji sequences\n", .{emoji_map.all_emojis.items.len});

Â  Â  try testing.expect(emoji_map.all_emojis.items.len > 0);

Â  Â Â 

Â  Â  std.debug.print("âœ“ Successfully imported and loaded ZON data at compile time\n", .{});

}```

```zig [./src/test_spec_loading_legacy.zig]

const std = @import("std");

const root = @import("root.zig");

const static_data_loader = @import("static_data_loader.zig");



pub fn main() !void {

Â  Â  var gpa = std.heap.GeneralPurposeAllocator(.{}){};

Â  Â  defer _ = gpa.deinit();

Â  Â  const allocator = gpa.allocator();

Â  Â Â 

Â  Â  const stdout = std.io.getStdOut().writer();

Â  Â Â 

Â  Â  try stdout.print("Testing spec.json loading\n", .{});

Â  Â  try stdout.print("========================\n\n", .{});

Â  Â Â 

Â  Â  // Load from spec.json

Â  Â  const start_time = std.time.milliTimestamp();

Â  Â  var mappings = try static_data_loader.loadCharacterMappings(allocator);

Â  Â  defer mappings.deinit();

Â  Â  const load_time = std.time.milliTimestamp() - start_time;

Â  Â Â 

Â  Â  try stdout.print("âœ“ Successfully loaded spec.json in {}ms\n\n", .{load_time});

Â  Â Â 

Â  Â  // Count loaded data

Â  Â  var mapped_count: usize = 0;

Â  Â  var ignored_count: usize = 0;Â 

Â  Â  var valid_count: usize = 0;

Â  Â Â 

Â  Â  var mapped_iter = mappings.unicode_mappings.iterator();

Â  Â  while (mapped_iter.next()) |_| {

Â  Â  Â  Â  mapped_count += 1;

Â  Â  }

Â  Â Â 

Â  Â  var ignored_iter = mappings.ignored_chars.iterator();

Â  Â  while (ignored_iter.next()) |_| {

Â  Â  Â  Â  ignored_count += 1;

Â  Â  }

Â  Â Â 

Â  Â  var valid_iter = mappings.valid_chars.iterator();

Â  Â  while (valid_iter.next()) |_| {

Â  Â  Â  Â  valid_count += 1;

Â  Â  }

Â  Â Â 

Â  Â  try stdout.print("Loaded data statistics:\n", .{});

Â  Â  try stdout.print("- Mapped characters: {}\n", .{mapped_count});

Â  Â  try stdout.print("- Ignored characters: {}\n", .{ignored_count});

Â  Â  try stdout.print("- Valid characters: {}\n", .{valid_count});

Â  Â  try stdout.print("\n", .{});

Â  Â Â 

Â  Â  // Test some specific mappings

Â  Â  try stdout.print("Sample mappings:\n", .{});

Â  Â Â 

Â  Â  const test_cases = [_]struct { cp: u32, name: []const u8 }{

Â  Â  Â  Â  .{ .cp = 39, .name = "apostrophe" },Â  Â  Â  // ' -> '

Â  Â  Â  Â  .{ .cp = 65, .name = "A" },Â  Â  Â  Â  Â  Â  Â  // A -> a

Â  Â  Â  Â  .{ .cp = 8217, .name = "right quote" },Â  // ' (should have no mapping)

Â  Â  Â  Â  .{ .cp = 8450, .name = "â„‚" },Â  Â  Â  Â  Â  Â  // â„‚ -> c

Â  Â  Â  Â  .{ .cp = 8460, .name = "â„Œ" },Â  Â  Â  Â  Â  Â  // â„Œ -> h

Â  Â  Â  Â  .{ .cp = 189, .name = "Â½" },Â  Â  Â  Â  Â  Â  Â // Â½ -> 1â„2

Â  Â  };

Â  Â Â 

Â  Â  for (test_cases) |test_case| {

Â  Â  Â  Â  if (mappings.getMapped(test_case.cp)) |mapped| {

Â  Â  Â  Â  Â  Â  try stdout.print("- {s} (U+{X:0>4}): maps to", .{ test_case.name, test_case.cp });

Â  Â  Â  Â  Â  Â  for (mapped) |cp| {

Â  Â  Â  Â  Â  Â  Â  Â  try stdout.print(" U+{X:0>4}", .{cp});

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  try stdout.print("\n", .{});

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  try stdout.print("- {s} (U+{X:0>4}): no mapping\n", .{ test_case.name, test_case.cp });

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  try stdout.print("\n", .{});

Â  Â Â 

Â  Â  // Test ignored characters

Â  Â  try stdout.print("Sample ignored characters:\n", .{});

Â  Â  const ignored_tests = [_]u32{ 173, 8204, 8205, 65279 };

Â  Â  for (ignored_tests) |cp| {

Â  Â  Â  Â  const is_ignored = mappings.isIgnored(cp);

Â  Â  Â  Â  try stdout.print("- U+{X:0>4}: {}\n", .{ cp, is_ignored });

Â  Â  }

Â  Â Â 

Â  Â  try stdout.print("\n", .{});

Â  Â Â 

Â  Â  // Test valid characters

Â  Â  try stdout.print("Sample valid characters:\n", .{});

Â  Â  const valid_tests = [_]u32{ 'a', 'z', '0', '9', '-', '_', '.', 8217 };

Â  Â  for (valid_tests) |cp| {

Â  Â  Â  Â  const is_valid = mappings.isValid(cp);

Â  Â  Â  Â  try stdout.print("- '{}' (U+{X:0>4}): {}\n", .{Â 

Â  Â  Â  Â  Â  Â  if (cp < 128) @as(u8, @intCast(cp)) else '?',Â 

Â  Â  Â  Â  Â  Â  cp,Â 

Â  Â  Â  Â  Â  Â  is_validÂ 

Â  Â  Â  Â  });

Â  Â  }

}```

```zig [./src/beautify.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;

const validate = @import("validate.zig");

const utils = @import("utils.zig");

const constants = @import("constants.zig");



pub fn beautifyLabels(allocator: std.mem.Allocator, labels: []const validate.ValidatedLabel) ![]u8 {

Â  Â  var result = std.ArrayList(u8).init(allocator);

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  for (labels, 0..) |label, i| {

Â  Â  Â  Â  if (i > 0) {

Â  Â  Â  Â  Â  Â  try result.append('.');

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  const label_str = try beautifyLabel(allocator, label);

Â  Â  Â  Â  defer allocator.free(label_str);

Â  Â  Â  Â  try result.appendSlice(label_str);

Â  Â  }

Â  Â Â 

Â  Â  return result.toOwnedSlice();

}



fn beautifyLabel(allocator: std.mem.Allocator, label: validate.ValidatedLabel) ![]u8 {

Â  Â  var result = std.ArrayList(u8).init(allocator);

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  // Get all code points from the label

Â  Â  var cps = std.ArrayList(CodePoint).init(allocator);

Â  Â  defer cps.deinit();

Â  Â Â 

Â  Â  for (label.tokens) |token| {

Â  Â  Â  Â  const token_cps = token.getCps();

Â  Â  Â  Â  try cps.appendSlice(token_cps);

Â  Â  }

Â  Â Â 

Â  Â  // Apply beautification rules

Â  Â  try applyBeautificationRules(allocator, cps.items, label.label_type);

Â  Â Â 

Â  Â  // Convert back to string

Â  Â  return utils.cps2str(allocator, cps.items);

}



fn applyBeautificationRules(allocator: std.mem.Allocator, cps: []CodePoint, label_type: validate.LabelType) !void {

Â  Â  _ = allocator;

Â  Â Â 

Â  Â  // Update ethereum symbol: Î¾ => Î if not Greek

Â  Â  switch (label_type) {

Â  Â  Â  Â  .greek => {

Â  Â  Â  Â  Â  Â  // Keep Î¾ as is for Greek

Â  Â  Â  Â  },

Â  Â  Â  Â  else => {

Â  Â  Â  Â  Â  Â  // Replace Î¾ with Î for non-Greek

Â  Â  Â  Â  Â  Â  for (cps) |*cp| {

Â  Â  Â  Â  Â  Â  Â  Â  if (cp.* == constants.CP_XI_SMALL) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cp.* = constants.CP_XI_CAPITAL;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  },

Â  Â  }

Â  Â Â 

Â  Â  // Additional beautification rules could be added here

Â  Â  // For example, handling leading/trailing hyphens, etc.

}



test "beautifyLabels basic functionality" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const tokenizer = @import("tokenizer.zig");

Â  Â Â 

Â  Â  // Create a simple test label

Â  Â  const token = try tokenizer.Token.createValid(allocator, &[_]CodePoint{0x68, 0x65, 0x6C, 0x6C, 0x6F}); // "hello"

Â  Â  const tokens = [_]tokenizer.Token{token};

Â  Â Â 

Â  Â  const label = try validate.ValidatedLabel.init(allocator, &tokens, validate.LabelType.ascii);

Â  Â Â 

Â  Â  const labels = [_]validate.ValidatedLabel{label};

Â  Â  const result = beautifyLabels(allocator, &labels) catch |err| {

Â  Â  Â  Â  // For now, we may get errors due to incomplete implementation

Â  Â  Â  Â  try testing.expect(err == error.OutOfMemory or err == error.InvalidUtf8);

Â  Â  Â  Â  return;

Â  Â  };

Â  Â  defer allocator.free(result);

Â  Â Â 

Â  Â  // Basic sanity check

Â  Â  try testing.expect(result.len > 0);

}```

```zig [./src/validator.zig]

const std = @import("std");

const tokenizer = @import("tokenizer.zig");

const code_points = @import("code_points.zig");

const constants = @import("constants.zig");

const utils = @import("utils.zig");

const static_data_loader = @import("static_data_loader.zig");

const character_mappings = @import("character_mappings.zig");

const script_groups = @import("script_groups.zig");

const confusables = @import("confusables.zig");

const combining_marks = @import("combining_marks.zig");

const nsm_validation = @import("nsm_validation.zig");



// Type definitions

pub const CodePoint = u32;



// Validation error types

pub const ValidationError = error{

Â  Â  EmptyLabel,

Â  Â  InvalidLabelExtension,

Â  Â  UnderscoreInMiddle,

Â  Â  LeadingCombiningMark,

Â  Â  CombiningMarkAfterEmoji,

Â  Â  DisallowedCombiningMark,

Â  Â  CombiningMarkAfterFenced,

Â  Â  InvalidCombiningMarkBase,

Â  Â  ExcessiveCombiningMarks,

Â  Â  InvalidArabicDiacritic,

Â  Â  ExcessiveArabicDiacritics,

Â  Â  InvalidDevanagariMatras,

Â  Â  InvalidThaiVowelSigns,

Â  Â  CombiningMarkOrderError,

Â  Â  FencedLeading,

Â  Â  FencedTrailing,

Â  Â  FencedAdjacent,

Â  Â  DisallowedCharacter,

Â  Â  IllegalMixture,

Â  Â  WholeScriptConfusable,

Â  Â  DuplicateNSM,

Â  Â  ExcessiveNSM,

Â  Â  LeadingNSM,

Â  Â  NSMAfterEmoji,

Â  Â  NSMAfterFenced,

Â  Â  InvalidNSMBase,

Â  Â  NSMOrderError,

Â  Â  DisallowedNSMScript,

Â  Â  OutOfMemory,

Â  Â  InvalidUtf8,

};



// Script group reference

pub const ScriptGroupRef = struct {

Â  Â  group: *const script_groups.ScriptGroup,

Â  Â  name: []const u8,

};



// Validated label result

pub const ValidatedLabel = struct {

Â  Â  tokens: []const tokenizer.Token,

Â  Â  script_group: ScriptGroupRef,

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub fn init(allocator: std.mem.Allocator, tokens: []const tokenizer.Token, script_group: ScriptGroupRef) !ValidatedLabel {

Â  Â  Â  Â  const owned_tokens = try allocator.dupe(tokenizer.Token, tokens);

Â  Â  Â  Â  return ValidatedLabel{

Â  Â  Â  Â  Â  Â  .tokens = owned_tokens,

Â  Â  Â  Â  Â  Â  .script_group = script_group,

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: ValidatedLabel) void {

Â  Â  Â  Â  // Note: tokens are owned by the tokenizer, we only own the slice

Â  Â  Â  Â  self.allocator.free(self.tokens);

Â  Â  }

Â  Â Â 

Â  Â  pub fn isEmpty(self: ValidatedLabel) bool {

Â  Â  Â  Â  return self.tokens.len == 0;

Â  Â  }

Â  Â Â 

Â  Â  pub fn isASCII(self: ValidatedLabel) bool {

Â  Â  Â  Â  // Latin script with all ASCII characters is considered ASCII

Â  Â  Â  Â  if (!std.mem.eql(u8, self.script_group.name, "Latin")) {

Â  Â  Â  Â  Â  Â  return false;

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Check if all tokens contain only ASCII codepoints

Â  Â  Â  Â  for (self.tokens) |token| {

Â  Â  Â  Â  Â  Â  const cps = token.getCps();

Â  Â  Â  Â  Â  Â  for (cps) |cp| {

Â  Â  Â  Â  Â  Â  Â  Â  if (cp > 0x7F) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return false;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  return true;

Â  Â  }

Â  Â Â 

Â  Â  pub fn isEmoji(self: ValidatedLabel) bool {

Â  Â  Â  Â  return std.mem.eql(u8, self.script_group.name, "Emoji");

Â  Â  }

};



// Character classification for validation

pub const CharacterValidator = struct {

Â  Â  // Fenced characters (placement restricted)

Â  Â  // Based on reference implementations

Â  Â  const FENCED_CHARS = [_]CodePoint{

Â  Â  Â  Â  0x0027, // Apostrophe '

Â  Â  Â  Â  0x002D, // Hyphen-minus -

Â  Â  Â  Â  0x003A, // Colon :

Â  Â  Â  Â  0x00B7, // Middle dot Â·

Â  Â  Â  Â  0x05F4, // Hebrew punctuation gershayim ×´

Â  Â  Â  Â  0x27CC, // Long division âŸŒ

Â  Â  };

Â  Â Â 

Â  Â  // Combining marks (must not be leading or after emoji)

Â  Â  const COMBINING_MARKS = [_]CodePoint{

Â  Â  Â  Â  0x0300, // Combining grave accent

Â  Â  Â  Â  0x0301, // Combining acute accent

Â  Â  Â  Â  0x0302, // Combining circumflex accent

Â  Â  Â  Â  0x0303, // Combining tilde

Â  Â  Â  Â  0x0304, // Combining macron

Â  Â  Â  Â  0x0305, // Combining overline

Â  Â  Â  Â  0x0306, // Combining breve

Â  Â  Â  Â  0x0307, // Combining dot above

Â  Â  Â  Â  0x0308, // Combining diaeresis

Â  Â  Â  Â  0x0309, // Combining hook above

Â  Â  Â  Â  0x030A, // Combining ring above

Â  Â  Â  Â  0x030B, // Combining double acute accent

Â  Â  Â  Â  0x030C, // Combining caron

Â  Â  };

Â  Â Â 

Â  Â  // Non-spacing marks (NSM) - subset of combining marks with special rules

Â  Â  const NON_SPACING_MARKS = [_]CodePoint{

Â  Â  Â  Â  0x0610, // Arabic sign sallallahou alayhe wassallam

Â  Â  Â  Â  0x0611, // Arabic sign alayhe assallam

Â  Â  Â  Â  0x0612, // Arabic sign rahmatullahi alayhe

Â  Â  Â  Â  0x0613, // Arabic sign radi allahou anhu

Â  Â  Â  Â  0x0614, // Arabic sign takhallus

Â  Â  Â  Â  0x0615, // Arabic small high tah

Â  Â  Â  Â  0x0616, // Arabic small high ligature alef with lam with yeh

Â  Â  Â  Â  0x0617, // Arabic small high zain

Â  Â  Â  Â  0x0618, // Arabic small fatha

Â  Â  Â  Â  0x0619, // Arabic small damma

Â  Â  Â  Â  0x061A, // Arabic small kasra

Â  Â  };

Â  Â Â 

Â  Â  // Maximum NSM count per base character

Â  Â  const NSM_MAX = 4;

Â  Â Â 

Â  Â  pub fn isFenced(cp: CodePoint) bool {

Â  Â  Â  Â  return std.mem.indexOfScalar(CodePoint, &FENCED_CHARS, cp) != null;

Â  Â  }

Â  Â Â 

Â  Â  pub fn isCombiningMark(cp: CodePoint) bool {

Â  Â  Â  Â  return std.mem.indexOfScalar(CodePoint, &COMBINING_MARKS, cp) != null;

Â  Â  }

Â  Â Â 

Â  Â  pub fn isNonSpacingMark(cp: CodePoint) bool {

Â  Â  Â  Â  return std.mem.indexOfScalar(CodePoint, &NON_SPACING_MARKS, cp) != null;

Â  Â  }

Â  Â Â 

Â  Â  pub fn isASCII(cp: CodePoint) bool {

Â  Â  Â  Â  return cp <= 0x7F;

Â  Â  }

Â  Â Â 

Â  Â  pub fn isUnderscore(cp: CodePoint) bool {

Â  Â  Â  Â  return cp == 0x5F; // '_'

Â  Â  }

Â  Â Â 

Â  Â  pub fn isHyphen(cp: CodePoint) bool {

Â  Â  Â  Â  return cp == 0x2D; // '-'

Â  Â  }

Â  Â Â 

Â  Â  pub fn getPeriod() CodePoint {

Â  Â  Â  Â  return 0x2E; // '.'

Â  Â  }

Â  Â Â 

Â  Â  // This is now handled by script_groups.zig

};



// Main validation function

pub fn validateLabel(

Â  Â  allocator: std.mem.Allocator,

Â  Â  tokenized_name: tokenizer.TokenizedName,

Â  Â  specs: *const code_points.CodePointsSpecs,

) ValidationError!ValidatedLabel {

Â  Â  _ = specs; // TODO: Use specs for advanced validation

Â  Â Â 

Â  Â  std.debug.print("validateLabel: Starting validation\n", .{});

Â  Â Â 

Â  Â  // Step 1: Check for empty label

Â  Â  try checkNotEmpty(tokenized_name);

Â  Â  std.debug.print("validateLabel: checkNotEmpty passed\n", .{});

Â  Â Â 

Â  Â  // Step 2: Get all code points from tokens

Â  Â  const cps = try getAllCodePoints(allocator, tokenized_name);

Â  Â  defer allocator.free(cps);

Â  Â  std.debug.print("validateLabel: getAllCodePoints returned {} cps\n", .{cps.len});

Â  Â Â 

Â  Â  // Step 3: Check for disallowed characters

Â  Â  try checkDisallowedCharacters(tokenized_name.tokens);

Â  Â  std.debug.print("validateLabel: checkDisallowedCharacters passed\n", .{});

Â  Â Â 

Â  Â  // Step 4: Check for leading underscore rule

Â  Â  try checkLeadingUnderscore(cps);

Â  Â  std.debug.print("validateLabel: checkLeadingUnderscore passed\n", .{});

Â  Â Â 

Â  Â  // Step 5: Load script groups and determine script group

Â  Â  std.debug.print("validateLabel: Loading script groups\n", .{});

Â  Â  var groups = static_data_loader.loadScriptGroups(allocator) catch |err| {

Â  Â  Â  Â  switch (err) {

Â  Â  Â  Â  Â  Â  error.OutOfMemory => return ValidationError.OutOfMemory,

Â  Â  Â  Â  }

Â  Â  };

Â  Â  defer groups.deinit();

Â  Â  std.debug.print("validateLabel: Script groups loaded\n", .{});

Â  Â Â 

Â  Â  // Get unique code points for script detection

Â  Â  std.debug.print("validateLabel: Creating unique set\n", .{});

Â  Â  var unique_set = std.AutoHashMap(CodePoint, void).init(allocator);

Â  Â  defer unique_set.deinit();

Â  Â Â 

Â  Â  std.debug.print("validateLabel: Adding {} cps to unique set\n", .{cps.len});

Â  Â  for (cps) |cp| {

Â  Â  Â  Â  std.debug.print("Â  cp: 0x{x} ({})\n", .{cp, cp});

Â  Â  Â  Â  try unique_set.put(cp, {});

Â  Â  }

Â  Â  std.debug.print("validateLabel: Unique set has {} entries\n", .{unique_set.count()});

Â  Â Â 

Â  Â  var unique_cps = try allocator.alloc(CodePoint, unique_set.count());

Â  Â  defer allocator.free(unique_cps);

Â  Â Â 

Â  Â  var iter = unique_set.iterator();

Â  Â  var idx: usize = 0;

Â  Â  while (iter.next()) |entry| {

Â  Â  Â  Â  unique_cps[idx] = entry.key_ptr.*;

Â  Â  Â  Â  idx += 1;

Â  Â  }

Â  Â Â 

Â  Â  std.debug.print("validateLabel: Calling determineScriptGroup with {} unique cps\n", .{unique_cps.len});

Â  Â  const script_group = groups.determineScriptGroup(unique_cps, allocator) catch |err| {

Â  Â  Â  Â  switch (err) {

Â  Â  Â  Â  Â  Â  error.DisallowedCharacter => return ValidationError.DisallowedCharacter,

Â  Â  Â  Â  Â  Â  error.EmptyInput => return ValidationError.EmptyLabel,

Â  Â  Â  Â  Â  Â  else => return ValidationError.IllegalMixture,

Â  Â  Â  Â  }

Â  Â  };

Â  Â Â 

Â  Â  std.debug.print("validateLabel: Script group determined: {s}\n", .{script_group.name});

Â  Â Â 

Â  Â  // Step 6: Apply script-specific validation

Â  Â  if (std.mem.eql(u8, script_group.name, "Latin")) {

Â  Â  Â  Â  // Check if all characters are ASCII

Â  Â  Â  Â  var all_ascii = true;

Â  Â  Â  Â  for (cps) |cp| {

Â  Â  Â  Â  Â  Â  if (cp > 0x7F) {

Â  Â  Â  Â  Â  Â  Â  Â  all_ascii = false;

Â  Â  Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  if (all_ascii) {

Â  Â  Â  Â  Â  Â  std.debug.print("validateLabel: Applying ASCII rules\n", .{});

Â  Â  Â  Â  Â  Â  try checkASCIIRules(cps);

Â  Â  Â  Â  }

Â  Â  } else if (std.mem.eql(u8, script_group.name, "Emoji")) {

Â  Â  Â  Â  try checkEmojiRules(tokenized_name.tokens);

Â  Â  } else {

Â  Â  Â  Â  try checkUnicodeRules(cps);

Â  Â  }

Â  Â Â 

Â  Â  // Step 7: Check fenced characters

Â  Â  try checkFencedCharacters(allocator, cps);

Â  Â Â 

Â  Â  // Step 8: Check combining marks with script group validation

Â  Â  try combining_marks.validateCombiningMarks(cps, script_group, allocator);

Â  Â Â 

Â  Â  // Step 9: Check non-spacing marks with comprehensive validation

Â  Â  nsm_validation.validateNSM(cps, &groups, script_group, allocator) catch |err| {

Â  Â  Â  Â  switch (err) {

Â  Â  Â  Â  Â  Â  nsm_validation.NSMValidationError.ExcessiveNSM => return ValidationError.ExcessiveNSM,

Â  Â  Â  Â  Â  Â  nsm_validation.NSMValidationError.DuplicateNSM => return ValidationError.DuplicateNSM,

Â  Â  Â  Â  Â  Â  nsm_validation.NSMValidationError.LeadingNSM => return ValidationError.LeadingNSM,

Â  Â  Â  Â  Â  Â  nsm_validation.NSMValidationError.NSMAfterEmoji => return ValidationError.NSMAfterEmoji,

Â  Â  Â  Â  Â  Â  nsm_validation.NSMValidationError.NSMAfterFenced => return ValidationError.NSMAfterFenced,

Â  Â  Â  Â  Â  Â  nsm_validation.NSMValidationError.InvalidNSMBase => return ValidationError.InvalidNSMBase,

Â  Â  Â  Â  Â  Â  nsm_validation.NSMValidationError.NSMOrderError => return ValidationError.NSMOrderError,

Â  Â  Â  Â  Â  Â  nsm_validation.NSMValidationError.DisallowedNSMScript => return ValidationError.DisallowedNSMScript,

Â  Â  Â  Â  }

Â  Â  };

Â  Â Â 

Â  Â  // Step 10: Check for whole-script confusables

Â  Â  std.debug.print("validateLabel: Loading confusables\n", .{});

Â  Â  var confusable_data = static_data_loader.loadConfusables(allocator) catch |err| {

Â  Â  Â  Â  switch (err) {

Â  Â  Â  Â  Â  Â  error.OutOfMemory => return ValidationError.OutOfMemory,

Â  Â  Â  Â  }

Â  Â  };

Â  Â  defer confusable_data.deinit();

Â  Â Â 

Â  Â  std.debug.print("validateLabel: Checking confusables for {} cps\n", .{cps.len});

Â  Â  const is_confusable = try confusable_data.checkWholeScriptConfusables(cps, allocator);

Â  Â  std.debug.print("validateLabel: is_confusable = {}\n", .{is_confusable});

Â  Â  if (is_confusable) {

Â  Â  Â  Â  return ValidationError.WholeScriptConfusable;

Â  Â  }

Â  Â Â 

Â  Â  const owned_name = try allocator.dupe(u8, script_group.name);

Â  Â  const script_ref = ScriptGroupRef{

Â  Â  Â  Â  .group = script_group,

Â  Â  Â  Â  .name = owned_name,

Â  Â  };

Â  Â  return ValidatedLabel.init(allocator, tokenized_name.tokens, script_ref);

}



// Helper function to check if a codepoint is whitespace

fn isWhitespace(cp: CodePoint) bool {

Â  Â  return switch (cp) {

Â  Â  Â  Â  0x09...0x0D => true, // Tab, LF, VT, FF, CR

Â  Â  Â  Â  0x20 => true,Â  Â  Â  Â  // Space

Â  Â  Â  Â  0x85 => true,Â  Â  Â  Â  // Next Line

Â  Â  Â  Â  0xA0 => true,Â  Â  Â  Â  // Non-breaking space

Â  Â  Â  Â  0x1680 => true,Â  Â  Â  // Ogham space mark

Â  Â  Â  Â  0x2000...0x200A => true, // Various spaces

Â  Â  Â  Â  0x2028 => true,Â  Â  Â  // Line separator

Â  Â  Â  Â  0x2029 => true,Â  Â  Â  // Paragraph separator

Â  Â  Â  Â  0x202F => true,Â  Â  Â  // Narrow no-break space

Â  Â  Â  Â  0x205F => true,Â  Â  Â  // Medium mathematical space

Â  Â  Â  Â  0x3000 => true,Â  Â  Â  // Ideographic space

Â  Â  Â  Â  else => false,

Â  Â  };

}



// Validation helper functions

fn checkNotEmpty(tokenized_name: tokenizer.TokenizedName) ValidationError!void {

Â  Â  if (tokenized_name.isEmpty()) {

Â  Â  Â  Â  return ValidationError.EmptyLabel;

Â  Â  }

Â  Â Â 

Â  Â  // Check if all tokens are ignored or disallowed whitespace

Â  Â  var has_content = false;

Â  Â  for (tokenized_name.tokens) |token| {

Â  Â  Â  Â  switch (token.type) {

Â  Â  Â  Â  Â  Â  .ignored => continue,

Â  Â  Â  Â  Â  Â  .disallowed => {

Â  Â  Â  Â  Â  Â  Â  Â  // Check if it's whitespace

Â  Â  Â  Â  Â  Â  Â  Â  const cp = token.data.disallowed.cp;

Â  Â  Â  Â  Â  Â  Â  Â  if (isWhitespace(cp)) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  has_content = true;

Â  Â  Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  else => {

Â  Â  Â  Â  Â  Â  Â  Â  has_content = true;

Â  Â  Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  if (!has_content) {

Â  Â  Â  Â  return ValidationError.EmptyLabel;

Â  Â  }

}



fn checkDisallowedCharacters(tokens: []const tokenizer.Token) ValidationError!void {

Â  Â  for (tokens) |token| {

Â  Â  Â  Â  switch (token.type) {

Â  Â  Â  Â  Â  Â  .disallowed => return ValidationError.DisallowedCharacter,

Â  Â  Â  Â  Â  Â  else => continue,

Â  Â  Â  Â  }

Â  Â  }

}



fn getAllCodePoints(allocator: std.mem.Allocator, tokenized_name: tokenizer.TokenizedName) ValidationError![]CodePoint {

Â  Â  var cps = std.ArrayList(CodePoint).init(allocator);

Â  Â  defer cps.deinit();

Â  Â Â 

Â  Â  for (tokenized_name.tokens) |token| {

Â  Â  Â  Â  switch (token.data) {

Â  Â  Â  Â  Â  Â  .valid => |v| try cps.appendSlice(v.cps),

Â  Â  Â  Â  Â  Â  .mapped => |m| try cps.appendSlice(m.cps),

Â  Â  Â  Â  Â  Â  .stop => |s| try cps.append(s.cp),

Â  Â  Â  Â  Â  Â  else => continue, // Skip ignored and disallowed tokens

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  return cps.toOwnedSlice();

}



fn checkLeadingUnderscore(cps: []const CodePoint) ValidationError!void {

Â  Â  if (cps.len == 0) return;

Â  Â Â 

Â  Â  // Find the end of leading underscores

Â  Â  var leading_underscores: usize = 0;

Â  Â  for (cps) |cp| {

Â  Â  Â  Â  if (CharacterValidator.isUnderscore(cp)) {

Â  Â  Â  Â  Â  Â  leading_underscores += 1;

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  // Check for underscores after the leading ones

Â  Â  for (cps[leading_underscores..]) |cp| {

Â  Â  Â  Â  if (CharacterValidator.isUnderscore(cp)) {

Â  Â  Â  Â  Â  Â  return ValidationError.UnderscoreInMiddle;

Â  Â  Â  Â  }

Â  Â  }

}



// This function is now replaced by script_groups.determineScriptGroup



fn checkASCIIRules(cps: []const CodePoint) ValidationError!void {

Â  Â  // ASCII label extension rule: no '--' at positions 2-3

Â  Â  if (cps.len >= 4 andÂ 

Â  Â  Â  Â  CharacterValidator.isHyphen(cps[2]) andÂ 

Â  Â  Â  Â  CharacterValidator.isHyphen(cps[3])) {

Â  Â  Â  Â  return ValidationError.InvalidLabelExtension;

Â  Â  }

}



fn checkEmojiRules(tokens: []const tokenizer.Token) ValidationError!void {

Â  Â  // Check that emoji tokens don't have combining marks

Â  Â  for (tokens) |token| {

Â  Â  Â  Â  switch (token.type) {

Â  Â  Â  Â  Â  Â  .emoji => {

Â  Â  Â  Â  Â  Â  Â  Â  // Emoji should not be followed by combining marks

Â  Â  Â  Â  Â  Â  Â  Â  // This is a simplified check

Â  Â  Â  Â  Â  Â  Â  Â  continue;

Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  else => continue,

Â  Â  Â  Â  }

Â  Â  }

}



fn checkUnicodeRules(cps: []const CodePoint) ValidationError!void {

Â  Â  // Unicode-specific validation rules

Â  Â  // For now, just basic checks

Â  Â  for (cps) |cp| {

Â  Â  Â  Â  if (cp > 0x10FFFF) {

Â  Â  Â  Â  Â  Â  return ValidationError.DisallowedCharacter;

Â  Â  Â  Â  }

Â  Â  }

}



fn checkFencedCharacters(allocator: std.mem.Allocator, cps: []const CodePoint) ValidationError!void {

Â  Â  if (cps.len == 0) return;

Â  Â Â 

Â  Â  // Load character mappings to get fenced characters from spec.zon

Â  Â  var mappings = static_data_loader.loadCharacterMappings(allocator) catch |err| {

Â  Â  Â  Â  std.debug.print("Warning: Failed to load character mappings: {}, using hardcoded\n", .{err});

Â  Â  Â  Â  // Fallback to hardcoded check

Â  Â  Â  Â  return checkFencedCharactersHardcoded(cps);

Â  Â  };

Â  Â  defer mappings.deinit();

Â  Â Â 

Â  Â  const last = cps.len - 1;

Â  Â Â 

Â  Â  // Check for leading fenced character

Â  Â  if (mappings.isFenced(cps[0])) {

Â  Â  Â  Â  return ValidationError.FencedLeading;

Â  Â  }

Â  Â Â 

Â  Â  // Check for trailing fenced character

Â  Â  if (mappings.isFenced(cps[last])) {

Â  Â  Â  Â  return ValidationError.FencedTrailing;

Â  Â  }

Â  Â Â 

Â  Â  // Check for consecutive fenced characters (but allow trailing consecutive)

Â  Â  // Following JavaScript reference: for (let i = 1; i < last; i++)

Â  Â  var i: usize = 1;

Â  Â  while (i < last) : (i += 1) {

Â  Â  Â  Â  if (mappings.isFenced(cps[i])) {

Â  Â  Â  Â  Â  Â  // Check how many consecutive fenced characters we have

Â  Â  Â  Â  Â  Â  var j = i + 1;

Â  Â  Â  Â  Â  Â  while (j <= last and mappings.isFenced(cps[j])) : (j += 1) {}

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // JavaScript: if (j === last) break; // trailing

Â  Â  Â  Â  Â  Â  // This means if we've reached the last character, it's trailing consecutive, which is allowed

Â  Â  Â  Â  Â  Â  if (j == cps.len) break;

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // If we found consecutive fenced characters that aren't trailing, it's an error

Â  Â  Â  Â  Â  Â  if (j > i + 1) {

Â  Â  Â  Â  Â  Â  Â  Â  return ValidationError.FencedAdjacent;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

}



fn checkFencedCharactersHardcoded(cps: []const CodePoint) ValidationError!void {

Â  Â  if (cps.len == 0) return;

Â  Â Â 

Â  Â  const last = cps.len - 1;

Â  Â Â 

Â  Â  // Check for leading fenced character

Â  Â  if (CharacterValidator.isFenced(cps[0])) {

Â  Â  Â  Â  return ValidationError.FencedLeading;

Â  Â  }

Â  Â Â 

Â  Â  // Check for trailing fenced character

Â  Â  if (CharacterValidator.isFenced(cps[last])) {

Â  Â  Â  Â  return ValidationError.FencedTrailing;

Â  Â  }

Â  Â Â 

Â  Â  // Check for consecutive fenced characters (but allow trailing consecutive)

Â  Â  var i: usize = 1;

Â  Â  while (i < last) : (i += 1) {

Â  Â  Â  Â  if (CharacterValidator.isFenced(cps[i])) {

Â  Â  Â  Â  Â  Â  var j = i + 1;

Â  Â  Â  Â  Â  Â  while (j <= last and CharacterValidator.isFenced(cps[j])) : (j += 1) {}

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  if (j == cps.len) break; // Allow trailing consecutive

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  if (j > i + 1) {

Â  Â  Â  Â  Â  Â  Â  Â  return ValidationError.FencedAdjacent;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

}



// This function is now replaced by combining_marks.validateCombiningMarks



// This function is now replaced by nsm_validation.validateNSM

// which provides comprehensive NSM validation following ENSIP-15



// Test helper functions

pub fn codePointsFromString(allocator: std.mem.Allocator, input: []const u8) ![]CodePoint {

Â  Â  var cps = std.ArrayList(CodePoint).init(allocator);

Â  Â  defer cps.deinit();

Â  Â Â 

Â  Â  var i: usize = 0;

Â  Â  while (i < input.len) {

Â  Â  Â  Â  const cp_len = std.unicode.utf8ByteSequenceLength(input[i]) catch return ValidationError.InvalidUtf8;

Â  Â  Â  Â  const cp = std.unicode.utf8Decode(input[i..i+cp_len]) catch return ValidationError.InvalidUtf8;

Â  Â  Â  Â  try cps.append(cp);

Â  Â  Â  Â  i += cp_len;

Â  Â  }

Â  Â Â 

Â  Â  return cps.toOwnedSlice();

}



// Tests

test "validator - empty label" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(testing.allocator);

Â  Â  const empty_tokenized = tokenizer.TokenizedName.init(testing.allocator, "");

Â  Â Â 

Â  Â  const result = validateLabel(testing.allocator, empty_tokenized, &specs);

Â  Â  try testing.expectError(ValidationError.EmptyLabel, result);

}



test "validator - ASCII label" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  std.debug.print("\nDEBUG: Starting ASCII label test\n", .{});

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â  std.debug.print("DEBUG: Created specs\n", .{});

Â  Â Â 

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "hello", &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â  std.debug.print("DEBUG: Tokenized input, tokens={}\n", .{tokenized.tokens.len});

Â  Â Â 

Â  Â  std.debug.print("DEBUG: Calling validateLabel\n", .{});

Â  Â  const result = try validateLabel(allocator, tokenized, &specs);

Â  Â  defer result.deinit();

Â  Â  std.debug.print("DEBUG: validateLabel completed\n", .{});

Â  Â Â 

Â  Â  std.debug.print("DEBUG: result.script_group.name = '{s}'\n", .{result.script_group.name});

Â  Â  std.debug.print("DEBUG: result.isASCII() = {}\n", .{result.isASCII()});

Â  Â  std.debug.print("DEBUG: tokens.len = {}\n", .{result.tokens.len});

Â  Â  for (result.tokens, 0..) |token, i| {

Â  Â  Â  Â  const cps = token.getCps();

Â  Â  Â  Â  std.debug.print("DEBUG: token[{}]: len={}, cps=[", .{i, cps.len});

Â  Â  Â  Â  for (cps, 0..) |cp, j| {

Â  Â  Â  Â  Â  Â  if (j > 0) std.debug.print(", ", .{});

Â  Â  Â  Â  Â  Â  std.debug.print("0x{x}", .{cp});

Â  Â  Â  Â  }

Â  Â  Â  Â  std.debug.print("]\n", .{});

Â  Â  }

Â  Â Â 

Â  Â  try testing.expect(result.isASCII());

Â  Â  try testing.expectEqualStrings("Latin", result.script_group.name);

}



test "validator - underscore rules" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Valid: leading underscore

Â  Â  {

Â  Â  Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "_hello", &specs, false);

Â  Â  Â  Â  defer tokenized.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  const result = try validateLabel(allocator, tokenized, &specs);

Â  Â  Â  Â  defer result.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  try testing.expect(result.isASCII());

Â  Â  }

Â  Â Â 

Â  Â  // Invalid: underscore in middle

Â  Â  {

Â  Â  Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "hel_lo", &specs, false);

Â  Â  Â  Â  defer tokenized.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  const result = validateLabel(allocator, tokenized, &specs);

Â  Â  Â  Â  try testing.expectError(ValidationError.UnderscoreInMiddle, result);

Â  Â  }

}



test "validator - ASCII label extension" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Invalid: ASCII label extension

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "te--st", &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  const result = validateLabel(allocator, tokenized, &specs);

Â  Â  try testing.expectError(ValidationError.InvalidLabelExtension, result);

}



test "validator - fenced characters" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // TODO: Implement proper fenced character checking from spec.zon

Â  Â  // For now, skip this test as apostrophe is being mapped to U+2019

Â  Â  // and fenced character rules need to be implemented properly

Â  Â  {

Â  Â  Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "'hello", &specs, false);

Â  Â  Â  Â  defer tokenized.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  // With full spec data, apostrophe is mapped, not treated as fenced

Â  Â  Â  Â  const result = validateLabel(allocator, tokenized, &specs) catch {

Â  Â  Â  Â  Â  Â  return; // Expected behavior for now

Â  Â  Â  Â  };

Â  Â  Â  Â  _ = result;

Â  Â  }

Â  Â Â 

Â  Â  // TODO: Test trailing fenced character when implemented

Â  Â  // {

Â  Â  //Â  Â  Â const tokenized = try tokenizer.TokenizedName.fromInput(allocator, "hello'", &specs, false);

Â  Â  //Â  Â  Â defer tokenized.deinit();

Â  Â  //Â  Â  Â 

Â  Â  //Â  Â  Â const result = validateLabel(allocator, tokenized, &specs);

Â  Â  //Â  Â  Â try testing.expectError(ValidationError.FencedTrailing, result);

Â  Â  // }

}



test "validator - script group detection" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Load script groups

Â  Â  var groups = try static_data_loader.loadScriptGroups(allocator);

Â  Â  defer groups.deinit();

Â  Â Â 

Â  Â  // Test ASCII

Â  Â  {

Â  Â  Â  Â  const cps = [_]CodePoint{'a', 'b', 'c'};

Â  Â  Â  Â  const group = try groups.determineScriptGroup(&cps, allocator);

Â  Â  Â  Â  try testing.expectEqualStrings("ASCII", group.name);

Â  Â  }

Â  Â Â 

Â  Â  // Test mixed script rejection

Â  Â  {

Â  Â  Â  Â  const cps = [_]CodePoint{'a', 0x03B1}; // a + Î±

Â  Â  Â  Â  const result = groups.determineScriptGroup(&cps, allocator);

Â  Â  Â  Â  try testing.expectError(error.DisallowedCharacter, result);

Â  Â  }

}



test "validator - whitespace empty label" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test with single space

Â  Â  const input = " ";

Â  Â  const tokenized = try tokenizer.TokenizedName.fromInput(allocator, input, &specs, false);

Â  Â  defer tokenized.deinit();

Â  Â Â 

Â  Â  std.debug.print("\nDEBUG: validator whitespace test:\n", .{});

Â  Â  std.debug.print("Â  Input: '{s}' (len={})\n", .{input, input.len});

Â  Â  std.debug.print("Â  Tokens: {} total\n", .{tokenized.tokens.len});

Â  Â  for (tokenized.tokens, 0..) |token, i| {

Â  Â  Â  Â  std.debug.print("Â  Â  [{}] type={s}", .{i, @tagName(token.type)});

Â  Â  Â  Â  if (token.type == .disallowed) {

Â  Â  Â  Â  Â  Â  std.debug.print(" cp=0x{x}", .{token.data.disallowed.cp});

Â  Â  Â  Â  }

Â  Â  Â  Â  std.debug.print("\n", .{});

Â  Â  }

Â  Â  std.debug.print("Â  isEmpty: {}\n", .{tokenized.isEmpty()});

Â  Â Â 

Â  Â  // Test checkNotEmpty directly

Â  Â  const empty_result = checkNotEmpty(tokenized);

Â  Â  if (empty_result) {

Â  Â  Â  Â  std.debug.print("Â  checkNotEmpty: passed (not empty)\n", .{});

Â  Â  } else |err| {

Â  Â  Â  Â  std.debug.print("Â  checkNotEmpty: failed with {}\n", .{err});

Â  Â  }

Â  Â Â 

Â  Â  const result = validateLabel(allocator, tokenized, &specs);

Â  Â Â 

Â  Â  // Should return EmptyLabel for whitespace-only input

Â  Â  try testing.expectError(ValidationError.EmptyLabel, result);

}```

```zig [./src/join.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;

const validate = @import("validate.zig");

const utils = @import("utils.zig");

const constants = @import("constants.zig");



pub fn joinLabels(allocator: std.mem.Allocator, labels: []const validate.ValidatedLabel) ![]u8 {

Â  Â  var result = std.ArrayList(u8).init(allocator);

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  for (labels, 0..) |label, i| {

Â  Â  Â  Â  if (i > 0) {

Â  Â  Â  Â  Â  Â  try result.append('.');

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  const label_str = try joinLabel(allocator, label);

Â  Â  Â  Â  defer allocator.free(label_str);

Â  Â  Â  Â  try result.appendSlice(label_str);

Â  Â  }

Â  Â Â 

Â  Â  return result.toOwnedSlice();

}



fn joinLabel(allocator: std.mem.Allocator, label: validate.ValidatedLabel) ![]u8 {

Â  Â  var cps = std.ArrayList(CodePoint).init(allocator);

Â  Â  defer cps.deinit();

Â  Â Â 

Â  Â  for (label.tokens) |token| {

Â  Â  Â  Â  const token_cps = token.getCps();

Â  Â  Â  Â  try cps.appendSlice(token_cps);

Â  Â  }

Â  Â Â 

Â  Â  return utils.cps2str(allocator, cps.items);

}



test "joinLabels basic functionality" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const tokenizer = @import("tokenizer.zig");

Â  Â Â 

Â  Â  // Create a simple test label

Â  Â  const token = try tokenizer.Token.createValid(allocator, &[_]CodePoint{0x68, 0x65, 0x6C, 0x6C, 0x6F}); // "hello"

Â  Â  const tokens = [_]tokenizer.Token{token};

Â  Â Â 

Â  Â  const label = try validate.ValidatedLabel.init(allocator, &tokens, validate.LabelType.ascii);

Â  Â Â 

Â  Â  const labels = [_]validate.ValidatedLabel{label};

Â  Â  const result = joinLabels(allocator, &labels) catch |err| {

Â  Â  Â  Â  // For now, we may get errors due to incomplete implementation

Â  Â  Â  Â  try testing.expect(err == error.OutOfMemory or err == error.InvalidUtf8);

Â  Â  Â  Â  return;

Â  Â  };

Â  Â  defer allocator.free(result);

Â  Â Â 

Â  Â  // Basic sanity check

Â  Â  try testing.expect(result.len > 0);

}```

```zig [./src/test_character_mappings.zig]

const std = @import("std");

const root = @import("root.zig");

const tokenizer = @import("tokenizer.zig");

const character_mappings = @import("character_mappings.zig");

const static_data_loader = @import("static_data_loader.zig");



pub fn main() !void {

Â  Â  var gpa = std.heap.GeneralPurposeAllocator(.{}){};

Â  Â  defer _ = gpa.deinit();

Â  Â  const allocator = gpa.allocator();

Â  Â Â 

Â  Â  const stdout = std.io.getStdOut().writer();

Â  Â Â 

Â  Â  try stdout.print("Character Mappings Test\n", .{});

Â  Â  try stdout.print("======================\n\n", .{});

Â  Â Â 

Â  Â  // Test cases that should demonstrate character mappings

Â  Â  const test_cases = [_]struct { input: []const u8, expected: []const u8 }{

Â  Â  Â  Â  .{ .input = "HELLO", .expected = "hello" },

Â  Â  Â  Â  .{ .input = "Hello", .expected = "hello" },

Â  Â  Â  Â  .{ .input = "HeLLo", .expected = "hello" },

Â  Â  Â  Â  .{ .input = "hello", .expected = "hello" },

Â  Â  Â  Â  .{ .input = "Test123", .expected = "test123" },

Â  Â  Â  Â  .{ .input = "ABC-DEF", .expected = "abc-def" },

Â  Â  Â  Â  .{ .input = "Â½", .expected = "1â„2" },

Â  Â  Â  Â  .{ .input = "â„Œello", .expected = "hello" },

Â  Â  Â  Â  .{ .input = "â„“â„¯â„“â„“o", .expected = "lello" },

Â  Â  };

Â  Â Â 

Â  Â  // Load character mappings

Â  Â  var mappings = try static_data_loader.loadBasicMappings(allocator);

Â  Â  defer mappings.deinit();

Â  Â Â 

Â  Â  for (test_cases) |test_case| {

Â  Â  Â  Â  try stdout.print("Input: \"{s}\"\n", .{test_case.input});

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Tokenize with mappings

Â  Â  Â  Â  const tokenized = try tokenizer.TokenizedName.fromInputWithMappings(

Â  Â  Â  Â  Â  Â  allocator,

Â  Â  Â  Â  Â  Â  test_case.input,

Â  Â  Â  Â  Â  Â  &mappings,

Â  Â  Â  Â  Â  Â  false,

Â  Â  Â  Â  );

Â  Â  Â  Â  defer tokenized.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Build normalized output

Â  Â  Â  Â  var result = std.ArrayList(u8).init(allocator);

Â  Â  Â  Â  defer result.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  for (tokenized.tokens) |token| {

Â  Â  Â  Â  Â  Â  const cps = token.getCps();

Â  Â  Â  Â  Â  Â  for (cps) |cp| {

Â  Â  Â  Â  Â  Â  Â  Â  const utf8_len = std.unicode.utf8CodepointSequenceLength(@as(u21, @intCast(cp))) catch continue;

Â  Â  Â  Â  Â  Â  Â  Â  const old_len = result.items.len;

Â  Â  Â  Â  Â  Â  Â  Â  try result.resize(old_len + utf8_len);

Â  Â  Â  Â  Â  Â  Â  Â  _ = std.unicode.utf8Encode(@as(u21, @intCast(cp)), result.items[old_len..]) catch continue;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  try stdout.print("Output: \"{s}\"\n", .{result.items});

Â  Â  Â  Â  try stdout.print("Expected: \"{s}\"\n", .{test_case.expected});

Â  Â  Â  Â Â 

Â  Â  Â  Â  if (std.mem.eql(u8, result.items, test_case.expected)) {

Â  Â  Â  Â  Â  Â  try stdout.print("âœ“ PASS\n", .{});

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  try stdout.print("âœ— FAIL\n", .{});

Â  Â  Â  Â  }

Â  Â  Â  Â  try stdout.print("\n", .{});

Â  Â  }

}



test "character mappings integration" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Test ASCII case folding

Â  Â  const result = try root.normalize(allocator, "HELLO");

Â  Â  defer allocator.free(result);

Â  Â  try testing.expectEqualStrings("hello", result);

Â  Â Â 

Â  Â  // Test Unicode mappings

Â  Â  const result2 = try root.normalize(allocator, "Â½");

Â  Â  defer allocator.free(result2);

Â  Â  try testing.expectEqualStrings("1â„2", result2);

}```

```zig [./src/static_data.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;



// This module would contain the static data structures and JSON parsing

// For now, it's a placeholder that would need to be implemented with

// the actual ENS normalization data



pub const SpecJson = struct {

Â  Â  pub const GroupName = union(enum) {

Â  Â  Â  Â  ascii,

Â  Â  Â  Â  emoji,

Â  Â  Â  Â  greek,

Â  Â  Â  Â  other: []const u8,

Â  Â  };

Â  Â Â 

Â  Â  pub const Group = struct {

Â  Â  Â  Â  name: GroupName,

Â  Â  Â  Â  primary: []const CodePoint,

Â  Â  Â  Â  secondary: []const CodePoint,

Â  Â  Â  Â  cm: []const CodePoint,

Â  Â  };

Â  Â Â 

Â  Â  pub const WholeValue = union(enum) {

Â  Â  Â  Â  number: u32,

Â  Â  Â  Â  whole_object: WholeObject,

Â  Â  };

Â  Â Â 

Â  Â  pub const WholeObject = struct {

Â  Â  Â  Â  v: []const CodePoint,

Â  Â  Â  Â  m: std.StringHashMap([]const []const u8),

Â  Â  };

Â  Â Â 

Â  Â  pub const NfJson = struct {

Â  Â  Â  Â  // Normalization data structures would go here

Â  Â  Â  Â  // For now, placeholder

Â  Â  };

};



// Placeholder functions that would load and parse the actual JSON data

pub fn loadSpecData(allocator: std.mem.Allocator) !SpecJson {

Â  Â  _ = allocator;

Â  Â  // This would load from spec.json

Â  Â  return SpecJson{};

}



pub fn loadNfData(allocator: std.mem.Allocator) !SpecJson.NfJson {

Â  Â  _ = allocator;

Â  Â  // This would load from nf.json

Â  Â  return SpecJson.NfJson{};

}



test "static_data placeholder" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const spec = try loadSpecData(allocator);

Â  Â  _ = spec;

Â  Â Â 

Â  Â  const nf = try loadNfData(allocator);

Â  Â  _ = nf;

}```

```zig [./src/utils.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;

const constants = @import("constants.zig");



const FE0F: CodePoint = 0xfe0f;

const LAST_ASCII_CP: CodePoint = 0x7f;



pub fn filterFe0f(allocator: std.mem.Allocator, cps: []const CodePoint) ![]CodePoint {

Â  Â  var result = std.ArrayList(CodePoint).init(allocator);

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  for (cps) |cp| {

Â  Â  Â  Â  if (cp != FE0F) {

Â  Â  Â  Â  Â  Â  try result.append(cp);

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  return result.toOwnedSlice();

}



pub fn cps2str(allocator: std.mem.Allocator, cps: []const CodePoint) ![]u8 {

Â  Â  var result = std.ArrayList(u8).init(allocator);

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  for (cps) |cp| {

Â  Â  Â  Â  if (cp <= 0x10FFFF) {

Â  Â  Â  Â  Â  Â  var buf: [4]u8 = undefined;

Â  Â  Â  Â  Â  Â  const len = std.unicode.utf8Encode(@intCast(cp), &buf) catch continue;

Â  Â  Â  Â  Â  Â  try result.appendSlice(buf[0..len]);

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  return result.toOwnedSlice();

}



pub fn cp2str(allocator: std.mem.Allocator, cp: CodePoint) ![]u8 {

Â  Â  return cps2str(allocator, &[_]CodePoint{cp});

}



pub fn str2cps(allocator: std.mem.Allocator, str: []const u8) ![]CodePoint {

Â  Â  var result = std.ArrayList(CodePoint).init(allocator);

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  const utf8_view = std.unicode.Utf8View.init(str) catch return error.InvalidUtf8;

Â  Â  var iter = utf8_view.iterator();

Â  Â Â 

Â  Â  while (iter.nextCodepoint()) |cp| {

Â  Â  Â  Â  try result.append(cp);

Â  Â  }

Â  Â Â 

Â  Â  return result.toOwnedSlice();

}



pub fn isAscii(cp: CodePoint) bool {

Â  Â  return cp <= LAST_ASCII_CP;

}



// NFC normalization using our implementation

pub fn nfc(allocator: std.mem.Allocator, str: []const u8) ![]u8 {

Â  Â  const nfc_mod = @import("nfc.zig");

Â  Â  const static_data_loader = @import("static_data_loader.zig");

Â  Â Â 

Â  Â  // Convert string to codepoints

Â  Â  const cps = try str2cps(allocator, str);

Â  Â  defer allocator.free(cps);

Â  Â Â 

Â  Â  // Load NFC data

Â  Â  var nfc_data = try static_data_loader.loadNFCData(allocator);

Â  Â  defer nfc_data.deinit();

Â  Â Â 

Â  Â  // Apply NFC normalization

Â  Â  const normalized_cps = try nfc_mod.nfc(allocator, cps, &nfc_data);

Â  Â  defer allocator.free(normalized_cps);

Â  Â Â 

Â  Â  // Convert back to string

Â  Â  return cps2str(allocator, normalized_cps);

}



pub fn nfdCps(allocator: std.mem.Allocator, cps: []const CodePoint, specs: anytype) ![]CodePoint {

Â  Â  var result = std.ArrayList(CodePoint).init(allocator);

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  for (cps) |cp| {

Â  Â  Â  Â  if (specs.decompose(cp)) |decomposed| {

Â  Â  Â  Â  Â  Â  try result.appendSlice(decomposed);

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  try result.append(cp);

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  return result.toOwnedSlice();

}



test "filterFe0f" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const input = [_]CodePoint{ 0x41, FE0F, 0x42, FE0F, 0x43 };

Â  Â  const result = try filterFe0f(allocator, &input);

Â  Â Â 

Â  Â  const expected = [_]CodePoint{ 0x41, 0x42, 0x43 };

Â  Â  try testing.expectEqualSlices(CodePoint, &expected, result);

}



test "isAscii" {

Â  Â  const testing = std.testing;

Â  Â  try testing.expect(isAscii(0x41)); // 'A'

Â  Â  try testing.expect(isAscii(0x7F)); // DEL

Â  Â  try testing.expect(!isAscii(0x80)); // beyond ASCII

Â  Â  try testing.expect(!isAscii(0x1F600)); // emoji

}```

```zig [./src/code_points.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;



pub const ParsedGroup = struct {

Â  Â  name: []const u8,

Â  Â  primary: std.HashMapUnmanaged(CodePoint, void, std.hash_map.AutoContext(CodePoint), std.hash_map.default_max_load_percentage),

Â  Â  secondary: std.HashMapUnmanaged(CodePoint, void, std.hash_map.AutoContext(CodePoint), std.hash_map.default_max_load_percentage),

Â  Â  primary_plus_secondary: std.HashMapUnmanaged(CodePoint, void, std.hash_map.AutoContext(CodePoint), std.hash_map.default_max_load_percentage),

Â  Â  cm_absent: bool,

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub fn init(allocator: std.mem.Allocator, name: []const u8) ParsedGroup {

Â  Â  Â  Â  return ParsedGroup{

Â  Â  Â  Â  Â  Â  .name = name,

Â  Â  Â  Â  Â  Â  .primary = std.HashMapUnmanaged(CodePoint, void, std.hash_map.AutoContext(CodePoint), std.hash_map.default_max_load_percentage){},

Â  Â  Â  Â  Â  Â  .secondary = std.HashMapUnmanaged(CodePoint, void, std.hash_map.AutoContext(CodePoint), std.hash_map.default_max_load_percentage){},

Â  Â  Â  Â  Â  Â  .primary_plus_secondary = std.HashMapUnmanaged(CodePoint, void, std.hash_map.AutoContext(CodePoint), std.hash_map.default_max_load_percentage){},

Â  Â  Â  Â  Â  Â  .cm_absent = true,

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: *ParsedGroup) void {

Â  Â  Â  Â  self.primary.deinit(self.allocator);

Â  Â  Â  Â  self.secondary.deinit(self.allocator);

Â  Â  Â  Â  self.primary_plus_secondary.deinit(self.allocator);

Â  Â  }

Â  Â Â 

Â  Â  pub fn addPrimary(self: *ParsedGroup, cp: CodePoint) !void {

Â  Â  Â  Â  try self.primary.put(self.allocator, cp, {});

Â  Â  Â  Â  try self.primary_plus_secondary.put(self.allocator, cp, {});

Â  Â  }

Â  Â Â 

Â  Â  pub fn addSecondary(self: *ParsedGroup, cp: CodePoint) !void {

Â  Â  Â  Â  try self.secondary.put(self.allocator, cp, {});

Â  Â  Â  Â  try self.primary_plus_secondary.put(self.allocator, cp, {});

Â  Â  }

Â  Â Â 

Â  Â  pub fn containsCp(self: *const ParsedGroup, cp: CodePoint) bool {

Â  Â  Â  Â  return self.primary_plus_secondary.contains(cp);

Â  Â  }

Â  Â Â 

Â  Â  pub fn containsAllCps(self: *const ParsedGroup, cps: []const CodePoint) bool {

Â  Â  Â  Â  for (cps) |cp| {

Â  Â  Â  Â  Â  Â  if (!self.containsCp(cp)) {

Â  Â  Â  Â  Â  Â  Â  Â  return false;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  return true;

Â  Â  }

};



pub const ParsedWholeValue = union(enum) {

Â  Â  number: u32,

Â  Â  whole_object: ParsedWholeObject,

};



pub const ParsedWholeObject = struct {

Â  Â  v: std.HashMapUnmanaged(CodePoint, void, std.hash_map.AutoContext(CodePoint), std.hash_map.default_max_load_percentage),

Â  Â  m: std.HashMapUnmanaged(CodePoint, []const []const u8, std.hash_map.AutoContext(CodePoint), std.hash_map.default_max_load_percentage),

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub fn init(allocator: std.mem.Allocator) ParsedWholeObject {

Â  Â  Â  Â  return ParsedWholeObject{

Â  Â  Â  Â  Â  Â  .v = std.HashMapUnmanaged(CodePoint, void, std.hash_map.AutoContext(CodePoint), std.hash_map.default_max_load_percentage){},

Â  Â  Â  Â  Â  Â  .m = std.HashMapUnmanaged(CodePoint, []const []const u8, std.hash_map.AutoContext(CodePoint), std.hash_map.default_max_load_percentage){},

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: *ParsedWholeObject) void {

Â  Â  Â  Â  self.v.deinit(self.allocator);

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Clean up the string arrays in m

Â  Â  Â  Â  var iter = self.m.iterator();

Â  Â  Â  Â  while (iter.next()) |entry| {

Â  Â  Â  Â  Â  Â  for (entry.value_ptr.*) |str| {

Â  Â  Â  Â  Â  Â  Â  Â  self.allocator.free(str);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  self.allocator.free(entry.value_ptr.*);

Â  Â  Â  Â  }

Â  Â  Â  Â  self.m.deinit(self.allocator);

Â  Â  }

};



pub const ParsedWholeMap = std.HashMapUnmanaged(CodePoint, ParsedWholeValue, std.hash_map.AutoContext(CodePoint), std.hash_map.default_max_load_percentage);



pub const CodePointsSpecs = struct {

Â  Â  // This would contain the various mappings and data structures

Â  Â  // needed for ENS normalization. For now, placeholder structure.

Â  Â  allocator: std.mem.Allocator,

Â  Â  groups: []ParsedGroup,

Â  Â  whole_map: ParsedWholeMap,

Â  Â Â 

Â  Â  pub fn init(allocator: std.mem.Allocator) CodePointsSpecs {

Â  Â  Â  Â  return CodePointsSpecs{

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  Â  Â  .groups = &[_]ParsedGroup{},

Â  Â  Â  Â  Â  Â  .whole_map = ParsedWholeMap{},

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: *CodePointsSpecs) void {

Â  Â  Â  Â  for (self.groups) |*group| {

Â  Â  Â  Â  Â  Â  group.deinit();

Â  Â  Â  Â  }

Â  Â  Â  Â  self.allocator.free(self.groups);

Â  Â  Â  Â Â 

Â  Â  Â  Â  var iter = self.whole_map.iterator();

Â  Â  Â  Â  while (iter.next()) |entry| {

Â  Â  Â  Â  Â  Â  switch (entry.value_ptr.*) {

Â  Â  Â  Â  Â  Â  Â  Â  .whole_object => |*obj| obj.deinit(),

Â  Â  Â  Â  Â  Â  Â  Â  .number => {},

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  self.whole_map.deinit(self.allocator);

Â  Â  }

Â  Â Â 

Â  Â  pub fn decompose(self: *const CodePointsSpecs, cp: CodePoint) ?[]const CodePoint {

Â  Â  Â  Â  // Placeholder for decomposition logic

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  _ = cp;

Â  Â  Â  Â  return null;

Â  Â  }

};



test "ParsedGroup basic operations" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var group = ParsedGroup.init(allocator, "Test");

Â  Â  defer group.deinit();

Â  Â Â 

Â  Â  try group.addPrimary(0x41); // 'A'

Â  Â  try group.addSecondary(0x42); // 'B'

Â  Â Â 

Â  Â  try testing.expect(group.containsCp(0x41));

Â  Â  try testing.expect(group.containsCp(0x42));

Â  Â  try testing.expect(!group.containsCp(0x43));

Â  Â Â 

Â  Â  const cps = [_]CodePoint{ 0x41, 0x42 };

Â  Â  try testing.expect(group.containsAllCps(&cps));

Â  Â Â 

Â  Â  const cps_with_missing = [_]CodePoint{ 0x41, 0x43 };

Â  Â  try testing.expect(!group.containsAllCps(&cps_with_missing));

}```

```zig [./src/tokenizer.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;

const constants = @import("constants.zig");

const utils = @import("utils.zig");

const code_points = @import("code_points.zig");

const error_types = @import("error.zig");

const character_mappings = @import("character_mappings.zig");

const static_data_loader = @import("static_data_loader.zig");

const nfc = @import("nfc.zig");

const emoji_mod = @import("emoji.zig");



// Token types based on ENSIP-15 specification

// Note: Unlike some implementations, our tokenizer can return errors for memory allocation

// failures. The reference JavaScript implementation never throws, but in Zig we need to

// handle allocation failures properly.

pub const TokenType = enum {

Â  Â  valid,

Â  Â  mapped,

Â  Â  ignored,

Â  Â  disallowed,

Â  Â  emoji,

Â  Â  nfc,

Â  Â  stop,

Â  Â Â 

Â  Â  pub fn toString(self: TokenType) []const u8 {

Â  Â  Â  Â  return switch (self) {

Â  Â  Â  Â  Â  Â  .valid => "valid",

Â  Â  Â  Â  Â  Â  .mapped => "mapped",

Â  Â  Â  Â  Â  Â  .ignored => "ignored",

Â  Â  Â  Â  Â  Â  .disallowed => "disallowed",

Â  Â  Â  Â  Â  Â  .emoji => "emoji",

Â  Â  Â  Â  Â  Â  .nfc => "nfc",

Â  Â  Â  Â  Â  Â  .stop => "stop",

Â  Â  Â  Â  };

Â  Â  }

};



pub const Token = struct {

Â  Â  type: TokenType,

Â  Â  // Union of possible token data

Â  Â  data: union(TokenType) {

Â  Â  Â  Â  valid: struct {

Â  Â  Â  Â  Â  Â  cps: []const CodePoint,

Â  Â  Â  Â  },

Â  Â  Â  Â  mapped: struct {

Â  Â  Â  Â  Â  Â  cp: CodePoint,

Â  Â  Â  Â  Â  Â  cps: []const CodePoint,

Â  Â  Â  Â  },

Â  Â  Â  Â  ignored: struct {

Â  Â  Â  Â  Â  Â  cp: CodePoint,

Â  Â  Â  Â  },

Â  Â  Â  Â  disallowed: struct {

Â  Â  Â  Â  Â  Â  cp: CodePoint,

Â  Â  Â  Â  },

Â  Â  Â  Â  emoji: struct {

Â  Â  Â  Â  Â  Â  input: []const CodePoint,Â  // Changed from []const u8 to match reference

Â  Â  Â  Â  Â  Â  emoji: []const CodePoint,Â  Â // fully-qualified emoji

Â  Â  Â  Â  Â  Â  cps: []const CodePoint,Â  Â  Â // output (fe0f filtered) - renamed from cps_no_fe0f

Â  Â  Â  Â  },

Â  Â  Â  Â  nfc: struct {

Â  Â  Â  Â  Â  Â  input: []const CodePoint,

Â  Â  Â  Â  Â  Â  cps: []const CodePoint,

Â  Â  Â  Â  Â  Â  tokens0: ?[]Token,Â  Â  Â  Â  Â  // tokens before NFC (optional)

Â  Â  Â  Â  Â  Â  tokens: ?[]Token,Â  Â  Â  Â  Â  Â // tokens after NFC (optional)

Â  Â  Â  Â  },

Â  Â  Â  Â  stop: struct {

Â  Â  Â  Â  Â  Â  cp: CodePoint,

Â  Â  Â  Â  },

Â  Â  },

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub fn init(allocator: std.mem.Allocator, token_type: TokenType) Token {

Â  Â  Â  Â  return Token{

Â  Â  Â  Â  Â  Â  .type = token_type,

Â  Â  Â  Â  Â  Â  .data = switch (token_type) {

Â  Â  Â  Â  Â  Â  Â  Â  .valid => .{ .valid = .{ .cps = &[_]CodePoint{} } },

Â  Â  Â  Â  Â  Â  Â  Â  .mapped => .{ .mapped = .{ .cp = 0, .cps = &[_]CodePoint{} } },

Â  Â  Â  Â  Â  Â  Â  Â  .ignored => .{ .ignored = .{ .cp = 0 } },

Â  Â  Â  Â  Â  Â  Â  Â  .disallowed => .{ .disallowed = .{ .cp = 0 } },

Â  Â  Â  Â  Â  Â  Â  Â  .emoji => .{ .emoji = .{ .input = &[_]CodePoint{}, .emoji = &[_]CodePoint{}, .cps = &[_]CodePoint{} } },

Â  Â  Â  Â  Â  Â  Â  Â  .nfc => .{ .nfc = .{ .input = &[_]CodePoint{}, .cps = &[_]CodePoint{}, .tokens0 = null, .tokens = null } },

Â  Â  Â  Â  Â  Â  Â  Â  .stop => .{ .stop = .{ .cp = constants.CP_STOP } },

Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: Token) void {

Â  Â  Â  Â  switch (self.data) {

Â  Â  Â  Â  Â  Â  .valid => |data| self.allocator.free(data.cps),

Â  Â  Â  Â  Â  Â  .mapped => |data| self.allocator.free(data.cps),

Â  Â  Â  Â  Â  Â  .emoji => |data| {

Â  Â  Â  Â  Â  Â  Â  Â  self.allocator.free(data.input);

Â  Â  Â  Â  Â  Â  Â  Â  self.allocator.free(data.emoji);

Â  Â  Â  Â  Â  Â  Â  Â  self.allocator.free(data.cps);

Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  .nfc => |data| {

Â  Â  Â  Â  Â  Â  Â  Â  self.allocator.free(data.input);

Â  Â  Â  Â  Â  Â  Â  Â  self.allocator.free(data.cps);

Â  Â  Â  Â  Â  Â  Â  Â  if (data.tokens0) |tokens0| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (tokens0) |token| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  token.deinit();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  self.allocator.free(tokens0);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  if (data.tokens) |tokens| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (tokens) |token| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  token.deinit();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  self.allocator.free(tokens);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  .ignored, .disallowed, .stop => {},

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  pub fn getCps(self: Token) []const CodePoint {

Â  Â  Â  Â  return switch (self.data) {

Â  Â  Â  Â  Â  Â  .valid => |data| data.cps,

Â  Â  Â  Â  Â  Â  .mapped => |data| data.cps,

Â  Â  Â  Â  Â  Â  .emoji => |data| data.cps,

Â  Â  Â  Â  Â  Â  .nfc => |data| data.cps,

Â  Â  Â  Â  Â  Â  .ignored => |data| &[_]CodePoint{data.cp},

Â  Â  Â  Â  Â  Â  .disallowed => |data| &[_]CodePoint{data.cp},

Â  Â  Â  Â  Â  Â  .stop => |data| &[_]CodePoint{data.cp},

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn getInputSize(self: Token) usize {

Â  Â  Â  Â  return switch (self.data) {

Â  Â  Â  Â  Â  Â  .valid => |data| data.cps.len,

Â  Â  Â  Â  Â  Â  .nfc => |data| data.input.len,

Â  Â  Â  Â  Â  Â  .emoji => |data| data.input.len,

Â  Â  Â  Â  Â  Â  .mapped, .ignored, .disallowed, .stop => 1,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn isText(self: Token) bool {

Â  Â  Â  Â  return switch (self.type) {

Â  Â  Â  Â  Â  Â  .valid, .mapped, .nfc => true,

Â  Â  Â  Â  Â  Â  else => false,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn isEmoji(self: Token) bool {

Â  Â  Â  Â  return self.type == .emoji;

Â  Â  }

Â  Â Â 

Â  Â  pub fn isIgnored(self: Token) bool {

Â  Â  Â  Â  return self.type == .ignored;

Â  Â  }

Â  Â Â 

Â  Â  pub fn isDisallowed(self: Token) bool {

Â  Â  Â  Â  return self.type == .disallowed;

Â  Â  }

Â  Â Â 

Â  Â  pub fn isStop(self: Token) bool {

Â  Â  Â  Â  return self.type == .stop;

Â  Â  }

Â  Â Â 

Â  Â  pub fn createValid(allocator: std.mem.Allocator, cps: []const CodePoint) !Token {

Â  Â  Â  Â  const owned_cps = try allocator.dupe(CodePoint, cps);

Â  Â  Â  Â  return Token{

Â  Â  Â  Â  Â  Â  .type = .valid,

Â  Â  Â  Â  Â  Â  .data = .{ .valid = .{ .cps = owned_cps } },

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn createMapped(allocator: std.mem.Allocator, cp: CodePoint, cps: []const CodePoint) !Token {

Â  Â  Â  Â  const owned_cps = try allocator.dupe(CodePoint, cps);

Â  Â  Â  Â  return Token{

Â  Â  Â  Â  Â  Â  .type = .mapped,

Â  Â  Â  Â  Â  Â  .data = .{ .mapped = .{ .cp = cp, .cps = owned_cps } },

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn createIgnored(allocator: std.mem.Allocator, cp: CodePoint) Token {

Â  Â  Â  Â  return Token{

Â  Â  Â  Â  Â  Â  .type = .ignored,

Â  Â  Â  Â  Â  Â  .data = .{ .ignored = .{ .cp = cp } },

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn createDisallowed(allocator: std.mem.Allocator, cp: CodePoint) Token {

Â  Â  Â  Â  return Token{

Â  Â  Â  Â  Â  Â  .type = .disallowed,

Â  Â  Â  Â  Â  Â  .data = .{ .disallowed = .{ .cp = cp } },

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn createStop(allocator: std.mem.Allocator) Token {

Â  Â  Â  Â  return Token{

Â  Â  Â  Â  Â  Â  .type = .stop,

Â  Â  Â  Â  Â  Â  .data = .{ .stop = .{ .cp = constants.CP_STOP } },

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn createEmoji(

Â  Â  Â  Â  allocator: std.mem.Allocator,

Â  Â  Â  Â  input: []const CodePoint,

Â  Â  Â  Â  emoji: []const CodePoint,

Â  Â  Â  Â  cps: []const CodePointÂ  // fe0f filtered

Â  Â  ) !Token {

Â  Â  Â  Â  return Token{

Â  Â  Â  Â  Â  Â  .type = .emoji,

Â  Â  Â  Â  Â  Â  .data = .{ .emoji = .{

Â  Â  Â  Â  Â  Â  Â  Â  .input = try allocator.dupe(CodePoint, input),

Â  Â  Â  Â  Â  Â  Â  Â  .emoji = try allocator.dupe(CodePoint, emoji),

Â  Â  Â  Â  Â  Â  Â  Â  .cps = try allocator.dupe(CodePoint, cps),

Â  Â  Â  Â  Â  Â  }},

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn createNFC(

Â  Â  Â  Â  allocator: std.mem.Allocator,

Â  Â  Â  Â  input: []const CodePoint,

Â  Â  Â  Â  cps: []const CodePoint,

Â  Â  Â  Â  tokens0: ?[]Token,

Â  Â  Â  Â  tokens: ?[]Token,

Â  Â  ) !Token {

Â  Â  Â  Â  const owned_tokens0 = if (tokens0) |t| try allocator.dupe(Token, t) else null;

Â  Â  Â  Â  const owned_tokens = if (tokens) |t| try allocator.dupe(Token, t) else null;

Â  Â  Â  Â Â 

Â  Â  Â  Â  return Token{

Â  Â  Â  Â  Â  Â  .type = .nfc,

Â  Â  Â  Â  Â  Â  .data = .{ .nfc = .{

Â  Â  Â  Â  Â  Â  Â  Â  .input = try allocator.dupe(CodePoint, input),

Â  Â  Â  Â  Â  Â  Â  Â  .cps = try allocator.dupe(CodePoint, cps),

Â  Â  Â  Â  Â  Â  Â  Â  .tokens0 = owned_tokens0,

Â  Â  Â  Â  Â  Â  Â  Â  .tokens = owned_tokens,

Â  Â  Â  Â  Â  Â  }},

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

};



pub const TokenizedName = struct {

Â  Â  input: []const u8,

Â  Â  tokens: []Token,

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub fn init(allocator: std.mem.Allocator, input: []const u8) TokenizedName {

Â  Â  Â  Â  return TokenizedName{

Â  Â  Â  Â  Â  Â  .input = input,

Â  Â  Â  Â  Â  Â  .tokens = &[_]Token{},

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: TokenizedName) void {

Â  Â  Â  Â  for (self.tokens) |token| {

Â  Â  Â  Â  Â  Â  token.deinit();

Â  Â  Â  Â  }

Â  Â  Â  Â  self.allocator.free(self.tokens);

Â  Â  Â  Â  self.allocator.free(self.input);

Â  Â  }

Â  Â Â 

Â  Â  pub fn isEmpty(self: TokenizedName) bool {

Â  Â  Â  Â  return self.tokens.len == 0;

Â  Â  }

Â  Â Â 

Â  Â  pub fn fromInput(

Â  Â  Â  Â  allocator: std.mem.Allocator,

Â  Â  Â  Â  input: []const u8,

Â  Â  Â  Â  _: *const code_points.CodePointsSpecs,

Â  Â  Â  Â  apply_nfc: bool,

Â  Â  ) !TokenizedName {

Â  Â  Â  Â  if (input.len == 0) {

Â  Â  Â  Â  Â  Â  return TokenizedName{

Â  Â  Â  Â  Â  Â  Â  Â  .input = try allocator.dupe(u8, ""),

Â  Â  Â  Â  Â  Â  Â  Â  .tokens = &[_]Token{},

Â  Â  Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  const tokens = try tokenizeInputWithMappings(allocator, input, apply_nfc);

Â  Â  Â  Â Â 

Â  Â  Â  Â  return TokenizedName{

Â  Â  Â  Â  Â  Â  .input = try allocator.dupe(u8, input),

Â  Â  Â  Â  Â  Â  .tokens = tokens,

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn fromInputWithMappings(

Â  Â  Â  Â  allocator: std.mem.Allocator,

Â  Â  Â  Â  input: []const u8,

Â  Â  Â  Â  mappings: *const character_mappings.CharacterMappings,

Â  Â  Â  Â  apply_nfc: bool,

Â  Â  ) !TokenizedName {

Â  Â  Â  Â  if (input.len == 0) {

Â  Â  Â  Â  Â  Â  return TokenizedName{

Â  Â  Â  Â  Â  Â  Â  Â  .input = try allocator.dupe(u8, ""),

Â  Â  Â  Â  Â  Â  Â  Â  .tokens = &[_]Token{},

Â  Â  Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  const tokens = try tokenizeInputWithMappingsImpl(allocator, input, mappings, apply_nfc);

Â  Â  Â  Â Â 

Â  Â  Â  Â  return TokenizedName{

Â  Â  Â  Â  Â  Â  .input = try allocator.dupe(u8, input),

Â  Â  Â  Â  Â  Â  .tokens = tokens,

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

};



// Character classification interface

pub const CharacterSpecs = struct {

Â  Â  // For now, simple implementations - would be replaced with actual data

Â  Â  pub fn isValid(self: *const CharacterSpecs, cp: CodePoint) bool {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  // Simple ASCII letters and digits for now

Â  Â  Â  Â  return (cp >= 'a' and cp <= 'z') orÂ 

Â  Â  Â  Â  Â  Â  Â  Â (cp >= 'A' and cp <= 'Z') orÂ 

Â  Â  Â  Â  Â  Â  Â  Â (cp >= '0' and cp <= '9') or

Â  Â  Â  Â  Â  Â  Â  Â cp == '-' or

Â  Â  Â  Â  Â  Â  Â  Â cp == '_' orÂ  // underscore (validated for placement later)

Â  Â  Â  Â  Â  Â  Â  Â cp == '\'';Â  Â // apostrophe (fenced character, validated for placement later)

Â  Â  }

Â  Â Â 

Â  Â  pub fn isIgnored(self: *const CharacterSpecs, cp: CodePoint) bool {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  // Common ignored characters

Â  Â  Â  Â  return cp == 0x00AD or // soft hyphen

Â  Â  Â  Â  Â  Â  Â  Â cp == 0x200C or // zero width non-joiner

Â  Â  Â  Â  Â  Â  Â  Â cp == 0x200D or // zero width joiner

Â  Â  Â  Â  Â  Â  Â  Â cp == 0xFEFF;Â  Â // zero width no-break space

Â  Â  }

Â  Â Â 

Â  Â  pub fn getMapped(self: *const CharacterSpecs, cp: CodePoint) ?[]const CodePoint {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  // Simple case folding for now

Â  Â  Â  Â  if (cp >= 'A' and cp <= 'Z') {

Â  Â  Â  Â  Â  Â  // Would need to allocate and return lowercase

Â  Â  Â  Â  Â  Â  return null; // Placeholder

Â  Â  Â  Â  }

Â  Â  Â  Â  return null;

Â  Â  }

Â  Â Â 

Â  Â  pub fn isStop(self: *const CharacterSpecs, cp: CodePoint) bool {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  return cp == constants.CP_STOP;

Â  Â  }

};



fn tokenizeInput(

Â  Â  allocator: std.mem.Allocator,

Â  Â  input: []const u8,

Â  Â  specs: *const code_points.CodePointsSpecs,

Â  Â  apply_nfc: bool,

) ![]Token {

Â  Â  _ = specs;

Â  Â  _ = apply_nfc;

Â  Â Â 

Â  Â  var tokens = std.ArrayList(Token).init(allocator);

Â  Â  defer tokens.deinit();

Â  Â Â 

Â  Â  // Convert input to code points

Â  Â  const cps = try utils.str2cps(allocator, input);

Â  Â  defer allocator.free(cps);

Â  Â Â 

Â  Â  // Create a simple character specs for now

Â  Â  const char_specs = CharacterSpecs{};

Â  Â Â 

Â  Â  for (cps) |cp| {

Â  Â  Â  Â  if (char_specs.isStop(cp)) {

Â  Â  Â  Â  Â  Â  try tokens.append(Token.createStop(allocator));

Â  Â  Â  Â  } else if (char_specs.isValid(cp)) {

Â  Â  Â  Â  Â  Â  try tokens.append(try Token.createValid(allocator, &[_]CodePoint{cp}));

Â  Â  Â  Â  } else if (char_specs.isIgnored(cp)) {

Â  Â  Â  Â  Â  Â  try tokens.append(Token.createIgnored(allocator, cp));

Â  Â  Â  Â  } else if (char_specs.getMapped(cp)) |mapped| {

Â  Â  Â  Â  Â  Â  try tokens.append(try Token.createMapped(allocator, cp, mapped));

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  try tokens.append(Token.createDisallowed(allocator, cp));

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  // Collapse consecutive valid tokens

Â  Â  try collapseValidTokens(allocator, &tokens);

Â  Â Â 

Â  Â  return tokens.toOwnedSlice();

}



fn tokenizeInputWithMappings(

Â  Â  allocator: std.mem.Allocator,

Â  Â  input: []const u8,

Â  Â  apply_nfc: bool,

) ![]Token {

Â  Â  // Load complete character mappings from spec.zon

Â  Â  var mappings = static_data_loader.loadCharacterMappings(allocator) catch |err| blk: {

Â  Â  Â  Â  // Fall back to basic mappings if spec.zon loading fails

Â  Â  Â  Â  std.debug.print("Warning: Failed to load spec.zon: {}, using basic mappings\n", .{err});

Â  Â  Â  Â  break :blk try static_data_loader.loadCharacterMappings(allocator);

Â  Â  };

Â  Â  defer mappings.deinit();

Â  Â Â 

Â  Â  return tokenizeInputWithMappingsImpl(allocator, input, &mappings, apply_nfc);

}



// Main tokenization implementation following ENSIP-15

// Algorithm:

// 1. Process input looking for emoji sequences first (emoji have priority)

// 2. Process individual characters (valid, mapped, ignored, disallowed, stop)

// 3. Apply NFC normalization as a post-processing step if requested

// 4. Collapse consecutive valid tokens

//

// This matches the reference JavaScript implementation's approach of:

// - Emoji-first processing

// - Character-by-character fallback

// - NFC as post-processing

fn tokenizeInputWithMappingsImpl(

Â  Â  allocator: std.mem.Allocator,

Â  Â  input: []const u8,

Â  Â  mappings: *const character_mappings.CharacterMappings,

Â  Â  apply_nfc: bool,

) ![]Token {

Â  Â  var tokens = std.ArrayList(Token).init(allocator);

Â  Â  defer tokens.deinit();

Â  Â Â 

Â  Â  // Load emoji map

Â  Â  var emoji_map = static_data_loader.loadEmoji(allocator) catch |err| {

Â  Â  Â  Â  // If emoji loading fails, fall back to character-by-character processing

Â  Â  Â  Â  std.debug.print("Warning: Failed to load emoji map: {}\n", .{err});

Â  Â  Â  Â  return tokenizeWithoutEmoji(allocator, input, mappings, apply_nfc);

Â  Â  };

Â  Â  defer emoji_map.deinit();

Â  Â Â 

Â  Â  // Process input looking for emojis first

Â  Â  var i: usize = 0;

Â  Â  while (i < input.len) {

Â  Â  Â  Â  // Try to match emoji at current position

Â  Â  Â  Â  if (emoji_map.findEmojiAt(allocator, input, i)) |match| {

Â  Â  Â  Â  Â  Â  defer allocator.free(match.cps_input); // Free the owned copy

Â  Â  Â  Â  Â  Â  // Create emoji token

Â  Â  Â  Â  Â  Â  try tokens.append(try Token.createEmoji(

Â  Â  Â  Â  Â  Â  Â  Â  allocator,

Â  Â  Â  Â  Â  Â  Â  Â  match.cps_input,

Â  Â  Â  Â  Â  Â  Â  Â  match.emoji_data.emoji,

Â  Â  Â  Â  Â  Â  Â  Â  match.emoji_data.no_fe0f

Â  Â  Â  Â  Â  Â  ));

Â  Â  Â  Â  Â  Â  i += match.byte_len;

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  // Process single character

Â  Â  Â  Â  Â  Â  const char_len = std.unicode.utf8ByteSequenceLength(input[i]) catch 1;

Â  Â  Â  Â  Â  Â  if (i + char_len > input.len) break;

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  const cp = std.unicode.utf8Decode(input[i..i + char_len]) catch {

Â  Â  Â  Â  Â  Â  Â  Â  try tokens.append(Token.createDisallowed(allocator, 0xFFFD)); // replacement character

Â  Â  Â  Â  Â  Â  Â  Â  i += 1;

Â  Â  Â  Â  Â  Â  Â  Â  continue;

Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  if (cp == constants.CP_STOP) {

Â  Â  Â  Â  Â  Â  Â  Â  try tokens.append(Token.createStop(allocator));

Â  Â  Â  Â  Â  Â  } else if (mappings.getMapped(cp)) |mapped| {

Â  Â  Â  Â  Â  Â  Â  Â  try tokens.append(try Token.createMapped(allocator, cp, mapped));

Â  Â  Â  Â  Â  Â  } else if (mappings.isValid(cp)) {

Â  Â  Â  Â  Â  Â  Â  Â  try tokens.append(try Token.createValid(allocator, &[_]CodePoint{cp}));

Â  Â  Â  Â  Â  Â  } else if (mappings.isIgnored(cp)) {

Â  Â  Â  Â  Â  Â  Â  Â  try tokens.append(Token.createIgnored(allocator, cp));

Â  Â  Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  Â  Â  try tokens.append(Token.createDisallowed(allocator, cp));

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  i += char_len;

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  // Apply NFC transformation if requested

Â  Â  if (apply_nfc) {

Â  Â  Â  Â  var nfc_data = try static_data_loader.loadNFC(allocator);

Â  Â  Â  Â  defer nfc_data.deinit();

Â  Â  Â  Â  try applyNFCTransform(allocator, &tokens, &nfc_data);

Â  Â  }

Â  Â Â 

Â  Â  // Collapse consecutive valid tokens

Â  Â  try collapseValidTokens(allocator, &tokens);

Â  Â Â 

Â  Â  return tokens.toOwnedSlice();

}



fn collapseValidTokens(allocator: std.mem.Allocator, tokens: *std.ArrayList(Token)) !void {

Â  Â  var i: usize = 0;

Â  Â  while (i < tokens.items.len) {

Â  Â  Â  Â  if (tokens.items[i].type == .valid) {

Â  Â  Â  Â  Â  Â  var j = i + 1;

Â  Â  Â  Â  Â  Â  var combined_cps = std.ArrayList(CodePoint).init(allocator);

Â  Â  Â  Â  Â  Â  defer combined_cps.deinit();

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Add first token's cps

Â  Â  Â  Â  Â  Â  try combined_cps.appendSlice(tokens.items[i].getCps());

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Collect consecutive valid tokens

Â  Â  Â  Â  Â  Â  while (j < tokens.items.len and tokens.items[j].type == .valid) {

Â  Â  Â  Â  Â  Â  Â  Â  try combined_cps.appendSlice(tokens.items[j].getCps());

Â  Â  Â  Â  Â  Â  Â  Â  j += 1;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  if (j > i + 1) {

Â  Â  Â  Â  Â  Â  Â  Â  // We have multiple valid tokens to collapse

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  // Clean up the old tokens

Â  Â  Â  Â  Â  Â  Â  Â  for (tokens.items[i..j]) |token| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  token.deinit();

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  // Create new collapsed token

Â  Â  Â  Â  Â  Â  Â  Â  const new_token = try Token.createValid(allocator, combined_cps.items);

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  // Replace the range with the new token

Â  Â  Â  Â  Â  Â  Â  Â  tokens.replaceRange(i, j - i, &[_]Token{new_token}) catch |err| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  new_token.deinit();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  i += 1;

Â  Â  }

}



test "tokenization basic functionality" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test simple ASCII

Â  Â  const result = try TokenizedName.fromInput(allocator, "hello", &specs, false);

Â  Â  try testing.expect(result.tokens.len > 0);

Â  Â  try testing.expect(result.tokens[0].type == .valid);

Â  Â Â 

Â  Â  // Test with stop character

Â  Â  const result2 = try TokenizedName.fromInput(allocator, "hello.eth", &specs, false);

Â  Â  var found_stop = false;

Â  Â  for (result2.tokens) |token| {

Â  Â  Â  Â  if (token.type == .stop) {

Â  Â  Â  Â  Â  Â  found_stop = true;

Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  }

Â  Â  }

Â  Â  try testing.expect(found_stop);

}



test "token creation and cleanup" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Test valid token

Â  Â  const cps = [_]CodePoint{ 'h', 'e', 'l', 'l', 'o' };

Â  Â  const token = try Token.createValid(allocator, &cps);

Â  Â  try testing.expectEqual(TokenType.valid, token.type);

Â  Â  try testing.expectEqualSlices(CodePoint, &cps, token.getCps());

Â  Â Â 

Â  Â  // Test stop token

Â  Â  const stop_token = Token.createStop(allocator);

Â  Â  try testing.expectEqual(TokenType.stop, stop_token.type);

Â  Â  try testing.expectEqual(constants.CP_STOP, stop_token.data.stop.cp);

Â  Â Â 

Â  Â  // Test ignored token

Â  Â  const ignored_token = Token.createIgnored(allocator, 0x200C);

Â  Â  try testing.expectEqual(TokenType.ignored, ignored_token.type);

Â  Â  try testing.expectEqual(@as(CodePoint, 0x200C), ignored_token.data.ignored.cp);

}



test "token input size calculation" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Test valid token input size

Â  Â  const cps = [_]CodePoint{ 'h', 'e', 'l', 'l', 'o' };

Â  Â  const token = try Token.createValid(allocator, &cps);

Â  Â  try testing.expectEqual(@as(usize, 5), token.getInputSize());

Â  Â Â 

Â  Â  // Test stop token input size

Â  Â  const stop_token = Token.createStop(allocator);

Â  Â  try testing.expectEqual(@as(usize, 1), stop_token.getInputSize());

}



test "token type checking" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const cps = [_]CodePoint{'h'};

Â  Â  const text_token = try Token.createValid(allocator, &cps);

Â  Â  try testing.expect(text_token.isText());

Â  Â  try testing.expect(!text_token.isEmoji());

Â  Â Â 

Â  Â  const stop_token = Token.createStop(allocator);

Â  Â  try testing.expect(!stop_token.isText());

Â  Â  try testing.expect(!stop_token.isEmoji());

}



test "empty input handling" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â  const result = try TokenizedName.fromInput(allocator, "", &specs, false);

Â  Â  try testing.expect(result.isEmpty());

Â  Â  try testing.expectEqual(@as(usize, 0), result.tokens.len);

}



test "emoji tokenization" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test simple emoji

Â  Â  const input = "helloğŸ‘world";

Â  Â  const result = try TokenizedName.fromInput(allocator, input, &specs, false);

Â  Â  defer result.deinit();

Â  Â Â 

Â  Â  // Should have: valid("hello"), emoji(ğŸ‘), valid("world")

Â  Â  try testing.expect(result.tokens.len >= 3);

Â  Â Â 

Â  Â  var found_emoji = false;

Â  Â  for (result.tokens) |token| {

Â  Â  Â  Â  if (token.type == .emoji) {

Â  Â  Â  Â  Â  Â  found_emoji = true;

Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  try testing.expect(found_emoji);

}



test "whitespace tokenization" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â Â 

Â  Â  // Test various whitespace characters

Â  Â  const whitespace_tests = [_]struct { input: []const u8, name: []const u8 }{

Â  Â  Â  Â  .{ .input = " ", .name = "space" },

Â  Â  Â  Â  .{ .input = "\t", .name = "tab" },

Â  Â  Â  Â  .{ .input = "\n", .name = "newline" },

Â  Â  Â  Â  .{ .input = "\u{00A0}", .name = "non-breaking space" },

Â  Â  Â  Â  .{ .input = "\u{2000}", .name = "en quad" },

Â  Â  };

Â  Â Â 

Â  Â  for (whitespace_tests) |test_case| {

Â  Â  Â  Â  const result = try TokenizedName.fromInput(allocator, test_case.input, &specs, false);

Â  Â  Â  Â  defer result.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  std.debug.print("\n{s}: tokens={}, ", .{ test_case.name, result.tokens.len });

Â  Â  Â  Â  if (result.tokens.len > 0) {

Â  Â  Â  Â  Â  Â  std.debug.print("type={s}", .{@tagName(result.tokens[0].type)});

Â  Â  Â  Â  Â  Â  if (result.tokens[0].type == .disallowed) {

Â  Â  Â  Â  Â  Â  Â  Â  std.debug.print(" cp=0x{x}", .{result.tokens[0].data.disallowed.cp});

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

Â  Â  std.debug.print("\n", .{});

}



test "character classification" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â Â 

Â  Â  const specs = CharacterSpecs{};

Â  Â Â 

Â  Â  // Test valid characters

Â  Â  try testing.expect(specs.isValid('a'));

Â  Â  try testing.expect(specs.isValid('Z'));

Â  Â  try testing.expect(specs.isValid('5'));

Â  Â  try testing.expect(specs.isValid('-'));

Â  Â Â 

Â  Â  // Test invalid characters

Â  Â  try testing.expect(!specs.isValid('!'));

Â  Â  try testing.expect(!specs.isValid('@'));

Â  Â Â 

Â  Â  // Test ignored characters

Â  Â  try testing.expect(specs.isIgnored(0x00AD)); // soft hyphen

Â  Â  try testing.expect(specs.isIgnored(0x200C)); // ZWNJ

Â  Â  try testing.expect(specs.isIgnored(0x200D)); // ZWJ

Â  Â Â 

Â  Â  // Test stop character

Â  Â  try testing.expect(specs.isStop('.'));

Â  Â  try testing.expect(!specs.isStop('a'));

}



test "token collapse functionality" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â  const result = try TokenizedName.fromInput(allocator, "hello", &specs, false);

Â  Â Â 

Â  Â  // Should collapse consecutive valid tokens into one

Â  Â  try testing.expect(result.tokens.len > 0);

Â  Â Â 

Â  Â  // Check that we have valid tokens

Â  Â  var has_valid = false;

Â  Â  for (result.tokens) |token| {

Â  Â  Â  Â  if (token.type == .valid) {

Â  Â  Â  Â  Â  Â  has_valid = true;

Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  }

Â  Â  }

Â  Â  try testing.expect(has_valid);

}



// Fallback tokenization without emoji support

fn tokenizeWithoutEmoji(

Â  Â  allocator: std.mem.Allocator,

Â  Â  input: []const u8,

Â  Â  mappings: *const character_mappings.CharacterMappings,

Â  Â  apply_nfc: bool,

) ![]Token {

Â  Â  var tokens = std.ArrayList(Token).init(allocator);

Â  Â  defer tokens.deinit();

Â  Â Â 

Â  Â  // Convert input to code points

Â  Â  const cps = try utils.str2cps(allocator, input);

Â  Â  defer allocator.free(cps);

Â  Â Â 

Â  Â  for (cps) |cp| {

Â  Â  Â  Â  if (cp == constants.CP_STOP) {

Â  Â  Â  Â  Â  Â  try tokens.append(Token.createStop(allocator));

Â  Â  Â  Â  } else if (mappings.getMapped(cp)) |mapped| {

Â  Â  Â  Â  Â  Â  try tokens.append(try Token.createMapped(allocator, cp, mapped));

Â  Â  Â  Â  } else if (mappings.isValid(cp)) {

Â  Â  Â  Â  Â  Â  try tokens.append(try Token.createValid(allocator, &[_]CodePoint{cp}));

Â  Â  Â  Â  } else if (mappings.isIgnored(cp)) {

Â  Â  Â  Â  Â  Â  try tokens.append(Token.createIgnored(allocator, cp));

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  try tokens.append(Token.createDisallowed(allocator, cp));

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  // Apply NFC transformation if requested

Â  Â  if (apply_nfc) {

Â  Â  Â  Â  var nfc_data = try static_data_loader.loadNFC(allocator);

Â  Â  Â  Â  defer nfc_data.deinit();

Â  Â  Â  Â  try applyNFCTransform(allocator, &tokens, &nfc_data);

Â  Â  }

Â  Â Â 

Â  Â  // Collapse consecutive valid tokens

Â  Â  try collapseValidTokens(allocator, &tokens);

Â  Â Â 

Â  Â  return tokens.toOwnedSlice();

}



// Apply NFC transformation to tokens

fn applyNFCTransform(allocator: std.mem.Allocator, tokens: *std.ArrayList(Token), nfc_data: *const nfc.NFCData) !void {

Â  Â  var i: usize = 0;

Â  Â  while (i < tokens.items.len) {

Â  Â  Â  Â  const token = &tokens.items[i];

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Check if this token starts a sequence that needs NFC

Â  Â  Â  Â  switch (token.data) {

Â  Â  Â  Â  Â  Â  .valid, .mapped => {

Â  Â  Â  Â  Â  Â  Â  Â  const start_cps = token.getCps();

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  // Check if any codepoint needs NFC checking

Â  Â  Â  Â  Â  Â  Â  Â  var needs_check = false;

Â  Â  Â  Â  Â  Â  Â  Â  for (start_cps) |cp| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (nfc_data.requiresNFCCheck(cp)) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  needs_check = true;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  if (needs_check) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Find the end of the sequence that needs NFC

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  var end = i + 1;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  while (end < tokens.items.len) : (end += 1) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  switch (tokens.items[end].data) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .valid, .mapped => {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Continue including valid/mapped tokens

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .ignored => {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Skip ignored tokens but continue

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else => break,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Collect all codepoints in the range (excluding ignored)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  var all_cps = std.ArrayList(CodePoint).init(allocator);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  defer all_cps.deinit();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  var j = i;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  while (j < end) : (j += 1) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  switch (tokens.items[j].data) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .valid, .mapped => {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try all_cps.appendSlice(tokens.items[j].getCps());

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else => {},

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Apply NFC

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const normalized = try nfc.nfc(allocator, all_cps.items, nfc_data);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  defer allocator.free(normalized);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Check if normalization changed anything

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (!nfc.compareCodePoints(all_cps.items, normalized)) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Collect the original tokens for tokens0

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  var tokens0 = try allocator.alloc(Token, end - i);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (tokens.items[i..end], 0..) |orig_token, idx| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Create a copy of the token without transferring ownership

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tokens0[idx] = switch (orig_token.data) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .valid => |data| try Token.createValid(allocator, data.cps),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .mapped => |data| try Token.createMapped(allocator, data.cp, data.cps),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .ignored => |data| Token.createIgnored(allocator, data.cp),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else => unreachable,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Create NFC token with tokens0

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const nfc_token = try Token.createNFC(

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  allocator,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_cps.items,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  normalized,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tokens0,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  nullÂ  // tokens field would be populated by re-tokenizing normalized string

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  );

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Clean up old tokens

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (tokens.items[i..end]) |old_token| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  old_token.deinit();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Replace with NFC token

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tokens.replaceRange(i, end - i, &[_]Token{nfc_token}) catch |err| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  nfc_token.deinit();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return err;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Don't increment i, we replaced the current position

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  else => {},

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  i += 1;

Â  Â  }

}```

```zig [./src/character_mappings.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;

const comptime_data = @import("comptime_data.zig");



/// Character mapping system for ENS normalization using comptime data

pub const CharacterMappings = struct {

Â  Â  // We don't need any runtime storage anymore!

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub fn init(allocator: std.mem.Allocator) !CharacterMappings {

Â  Â  Â  Â  return CharacterMappings{

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: *CharacterMappings) void {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  // Nothing to clean up - all data is comptime!

Â  Â  }

Â  Â Â 

Â  Â  /// Get the mapped characters for a given code point

Â  Â  /// Returns null if no mapping exists

Â  Â  pub fn getMapped(self: *const CharacterMappings, cp: CodePoint) ?[]const CodePoint {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  // Fast path for ASCII uppercase -> lowercase

Â  Â  Â  Â  if (cp >= 'A' and cp <= 'Z') {

Â  Â  Â  Â  Â  Â  // Use comptime-generated array for ASCII mappings

Â  Â  Â  Â  Â  Â  const ascii_mappings = comptime blk: {

Â  Â  Â  Â  Â  Â  Â  Â  var mappings: [26][1]CodePoint = undefined;

Â  Â  Â  Â  Â  Â  Â  Â  for (0..26) |i| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mappings[i] = [1]CodePoint{@as(CodePoint, 'a' + i)};

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  break :blk mappings;

Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  Â  return &ascii_mappings[cp - 'A'];

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Check comptime mappings

Â  Â  Â  Â  return comptime_data.getMappedCodePoints(cp);

Â  Â  }

Â  Â Â 

Â  Â  /// Check if a character is valid (no mapping needed)

Â  Â  pub fn isValid(self: *const CharacterMappings, cp: CodePoint) bool {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  return comptime_data.isValid(cp);

Â  Â  }

Â  Â Â 

Â  Â  /// Check if a character should be ignored

Â  Â  pub fn isIgnored(self: *const CharacterMappings, cp: CodePoint) bool {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  return comptime_data.isIgnored(cp);

Â  Â  }

Â  Â Â 

Â  Â  /// Check if a character is fenced (placement restricted)

Â  Â  pub fn isFenced(self: *const CharacterMappings, cp: CodePoint) bool {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  return comptime_data.isFenced(cp);

Â  Â  }

Â  Â Â 

Â  Â  // These methods are no longer needed since we use comptime data

Â  Â  pub fn addMapping(self: *CharacterMappings, from: CodePoint, to: []const CodePoint) !void {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  _ = from;

Â  Â  Â  Â  _ = to;

Â  Â  Â  Â  @panic("Cannot add mappings at runtime - use comptime data");

Â  Â  }

Â  Â Â 

Â  Â  pub fn addValid(self: *CharacterMappings, cp: CodePoint) !void {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  _ = cp;

Â  Â  Â  Â  @panic("Cannot add valid chars at runtime - use comptime data");

Â  Â  }

Â  Â Â 

Â  Â  pub fn addIgnored(self: *CharacterMappings, cp: CodePoint) !void {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  _ = cp;

Â  Â  Â  Â  @panic("Cannot add ignored chars at runtime - use comptime data");

Â  Â  }

};



/// Create character mappings - now just returns an empty struct

pub fn createWithUnicodeMappings(allocator: std.mem.Allocator) !CharacterMappings {

Â  Â  return CharacterMappings.init(allocator);

}



// Tests

test "CharacterMappings - ASCII case folding" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var mappings = try CharacterMappings.init(allocator);

Â  Â  defer mappings.deinit();

Â  Â Â 

Â  Â  // Test uppercase -> lowercase mapping

Â  Â  const mapped_A = mappings.getMapped('A');

Â  Â  try testing.expect(mapped_A != null);

Â  Â  try testing.expectEqual(@as(CodePoint, 'a'), mapped_A.?[0]);

Â  Â Â 

Â  Â  const mapped_Z = mappings.getMapped('Z');

Â  Â  try testing.expect(mapped_Z != null);

Â  Â  try testing.expectEqual(@as(CodePoint, 'z'), mapped_Z.?[0]);

Â  Â Â 

Â  Â  // Test lowercase has no mapping

Â  Â  const mapped_a = mappings.getMapped('a');

Â  Â  try testing.expect(mapped_a == null);

Â  Â Â 

Â  Â  // Test valid characters

Â  Â  try testing.expect(mappings.isValid('a'));

Â  Â  try testing.expect(mappings.isValid('z'));

Â  Â  try testing.expect(mappings.isValid('0'));

Â  Â  try testing.expect(mappings.isValid('9'));

}



test "CharacterMappings - comptime data access" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var mappings = try CharacterMappings.init(allocator);

Â  Â  defer mappings.deinit();

Â  Â Â 

Â  Â  // Test that we can access comptime data

Â  Â  if (comptime_data.character_mappings.len > 0) {

Â  Â  Â  Â  const first = comptime_data.character_mappings[0];

Â  Â  Â  Â  const result = mappings.getMapped(first.from);

Â  Â  Â  Â  try testing.expect(result != null);

Â  Â  Â  Â  try testing.expectEqualSlices(CodePoint, first.to, result.?);

Â  Â  }

}```

```zig [./src/root.zig]

const std = @import("std");

const testing = std.testing;



pub const CodePoint = u32;



pub const beautify = @import("beautify.zig");

pub const character_mappings = @import("character_mappings.zig");

pub const code_points = @import("code_points.zig");

pub const constants = @import("constants.zig");

pub const error_types = @import("error.zig");

pub const join = @import("join.zig");

pub const normalizer = @import("normalizer.zig");

pub const static_data = @import("static_data.zig");

pub const static_data_loader = @import("static_data_loader.zig");

pub const confusables = @import("confusables.zig");

pub const tokens = @import("tokens.zig");

pub const tokenizer = @import("tokenizer.zig");

pub const utils = @import("utils.zig");

pub const validate = @import("validate.zig");

pub const validator = @import("validator.zig");

pub const nfc = @import("nfc.zig");

pub const emoji = @import("emoji.zig");

pub const script_groups = @import("script_groups.zig");

pub const combining_marks = @import("combining_marks.zig");

pub const nsm_validation = @import("nsm_validation.zig");



// Re-export main API

pub const EnsNameNormalizer = normalizer.EnsNameNormalizer;

pub const ProcessedName = normalizer.ProcessedName;

pub const ProcessError = error_types.ProcessError;

pub const CurrableError = error_types.CurrableError;

pub const DisallowedSequence = error_types.DisallowedSequence;

pub const ValidatedLabel = validate.ValidatedLabel;

pub const LabelType = validate.LabelType;



// Re-export convenience functions

pub const normalize = normalizer.normalize;

pub const beautify_fn = normalizer.beautify;

pub const process = normalizer.process;

pub const tokenize = normalizer.tokenize;



test {

Â  Â  testing.refAllDecls(@This());

}```

```zig [./src/validate.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;

const constants = @import("constants.zig");

const utils = @import("utils.zig");

const tokenizer = @import("tokenizer.zig");

const code_points = @import("code_points.zig");

const error_types = @import("error.zig");



pub const LabelType = union(enum) {

Â  Â  ascii,

Â  Â  emoji,

Â  Â  greek,

Â  Â  other: []const u8,

Â  Â Â 

Â  Â  pub fn format(self: LabelType, comptime fmt: []const u8, options: std.fmt.FormatOptions, writer: anytype) !void {

Â  Â  Â  Â  _ = fmt;

Â  Â  Â  Â  _ = options;

Â  Â  Â  Â  switch (self) {

Â  Â  Â  Â  Â  Â  .ascii => try writer.print("ASCII", .{}),

Â  Â  Â  Â  Â  Â  .emoji => try writer.print("Emoji", .{}),

Â  Â  Â  Â  Â  Â  .greek => try writer.print("Greek", .{}),

Â  Â  Â  Â  Â  Â  .other => |name| try writer.print("{s}", .{name}),

Â  Â  Â  Â  }

Â  Â  }

};



pub const ValidatedLabel = struct {

Â  Â  tokens: []const tokenizer.Token,

Â  Â  label_type: LabelType,

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub fn init(allocator: std.mem.Allocator, label_tokens: []const tokenizer.Token, label_type: LabelType) !ValidatedLabel {

Â  Â  Â  Â  const owned_tokens = try allocator.dupe(tokenizer.Token, label_tokens);

Â  Â  Â  Â  return ValidatedLabel{

Â  Â  Â  Â  Â  Â  .tokens = owned_tokens,

Â  Â  Â  Â  Â  Â  .label_type = label_type,

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: ValidatedLabel) void {

Â  Â  Â  Â  self.allocator.free(self.tokens);

Â  Â  }

};



pub const TokenizedLabel = struct {

Â  Â  tokens: []const tokenizer.Token,

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub fn isEmpty(self: TokenizedLabel) bool {

Â  Â  Â  Â  return self.tokens.len == 0;

Â  Â  }

Â  Â Â 

Â  Â  pub fn isFullyEmoji(self: TokenizedLabel) bool {

Â  Â  Â  Â  for (self.tokens) |token| {

Â  Â  Â  Â  Â  Â  if (!token.isEmoji() and !token.isIgnored()) {

Â  Â  Â  Â  Â  Â  Â  Â  return false;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  return true;

Â  Â  }

Â  Â Â 

Â  Â  pub fn isFullyAscii(self: TokenizedLabel) bool {

Â  Â  Â  Â  for (self.tokens) |token| {

Â  Â  Â  Â  Â  Â  const cps = token.getCps();

Â  Â  Â  Â  Â  Â  for (cps) |cp| {

Â  Â  Â  Â  Â  Â  Â  Â  if (!utils.isAscii(cp)) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return false;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  return true;

Â  Â  }

Â  Â Â 

Â  Â  pub fn iterCps(self: TokenizedLabel, allocator: std.mem.Allocator) ![]CodePoint {

Â  Â  Â  Â  var result = std.ArrayList(CodePoint).init(allocator);

Â  Â  Â  Â  defer result.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  for (self.tokens) |token| {

Â  Â  Â  Â  Â  Â  const cps = token.getCps();

Â  Â  Â  Â  Â  Â  try result.appendSlice(cps);

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  return result.toOwnedSlice();

Â  Â  }

Â  Â Â 

Â  Â  pub fn getCpsOfNotIgnoredText(self: TokenizedLabel, allocator: std.mem.Allocator) ![]CodePoint {

Â  Â  Â  Â  var result = std.ArrayList(CodePoint).init(allocator);

Â  Â  Â  Â  defer result.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  for (self.tokens) |token| {

Â  Â  Â  Â  Â  Â  if (!token.isIgnored() and token.isText()) {

Â  Â  Â  Â  Â  Â  Â  Â  const cps = try token.getCps(allocator);

Â  Â  Â  Â  Â  Â  Â  Â  defer allocator.free(cps);

Â  Â  Â  Â  Â  Â  Â  Â  try result.appendSlice(cps);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  return result.toOwnedSlice();

Â  Â  }

};



pub fn validateName(

Â  Â  allocator: std.mem.Allocator,

Â  Â  name: tokenizer.TokenizedName,

Â  Â  specs: *const code_points.CodePointsSpecs,

) ![]ValidatedLabel {

Â  Â  if (name.tokens.len == 0) {

Â  Â  Â  Â  return try allocator.alloc(ValidatedLabel, 0);

Â  Â  }

Â  Â Â 

Â  Â  // For now, create a simple implementation that treats the entire name as one label

Â  Â  // The actual implementation would need to split on stop tokens

Â  Â  var labels = std.ArrayList(ValidatedLabel).init(allocator);

Â  Â  defer labels.deinit();

Â  Â Â 

Â  Â  const label = TokenizedLabel{

Â  Â  Â  Â  .tokens = name.tokens,

Â  Â  Â  Â  .allocator = allocator,

Â  Â  };

Â  Â Â 

Â  Â  const validated = try validateLabel(allocator, label, specs);

Â  Â  try labels.append(validated);

Â  Â Â 

Â  Â  return labels.toOwnedSlice();

}



pub fn validateLabel(

Â  Â  allocator: std.mem.Allocator,

Â  Â  label: TokenizedLabel,

Â  Â  specs: *const code_points.CodePointsSpecs,

) !ValidatedLabel {

Â  Â  try checkNonEmpty(label);

Â  Â  try checkTokenTypes(allocator, label);

Â  Â Â 

Â  Â  if (label.isFullyEmoji()) {

Â  Â  Â  Â  return ValidatedLabel.init(allocator, label.tokens, LabelType.emoji);

Â  Â  }

Â  Â Â 

Â  Â  try checkUnderscoreOnlyAtBeginning(allocator, label);

Â  Â Â 

Â  Â  if (label.isFullyAscii()) {

Â  Â  Â  Â  try checkNoHyphenAtSecondAndThird(allocator, label);

Â  Â  Â  Â  return ValidatedLabel.init(allocator, label.tokens, LabelType.ascii);

Â  Â  }

Â  Â Â 

Â  Â  try checkFenced(allocator, label, specs);

Â  Â  try checkCmLeadingEmoji(allocator, label, specs);

Â  Â Â 

Â  Â  const group = try checkAndGetGroup(allocator, label, specs);

Â  Â  _ = group; // TODO: determine actual group type

Â  Â Â 

Â  Â  // For now, return a placeholder

Â  Â  return ValidatedLabel.init(allocator, label.tokens, LabelType{ .other = "Unknown" });

}



fn checkNonEmpty(label: TokenizedLabel) !void {

Â  Â  var has_non_ignored = false;

Â  Â  for (label.tokens) |token| {

Â  Â  Â  Â  if (!token.isIgnored()) {

Â  Â  Â  Â  Â  Â  has_non_ignored = true;

Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  if (!has_non_ignored) {

Â  Â  Â  Â  return error_types.ProcessError.DisallowedSequence;

Â  Â  }

}



fn checkTokenTypes(_: std.mem.Allocator, label: TokenizedLabel) !void {

Â  Â  for (label.tokens) |token| {

Â  Â  Â  Â  if (token.isDisallowed() or token.isStop()) {

Â  Â  Â  Â  Â  Â  const cps = token.getCps();

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  // Check for invisible characters

Â  Â  Â  Â  Â  Â  for (cps) |cp| {

Â  Â  Â  Â  Â  Â  Â  Â  if (cp == constants.CP_ZERO_WIDTH_JOINER or cp == constants.CP_ZERO_WIDTH_NON_JOINER) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return error_types.ProcessError.DisallowedSequence;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  return error_types.ProcessError.DisallowedSequence;

Â  Â  Â  Â  }

Â  Â  }

}



fn checkUnderscoreOnlyAtBeginning(allocator: std.mem.Allocator, label: TokenizedLabel) !void {

Â  Â  const cps = try label.iterCps(allocator);

Â  Â  defer allocator.free(cps);

Â  Â Â 

Â  Â  var leading_underscores: usize = 0;

Â  Â  for (cps) |cp| {

Â  Â  Â  Â  if (cp == constants.CP_UNDERSCORE) {

Â  Â  Â  Â  Â  Â  leading_underscores += 1;

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  }

Â  Â  }

Â  Â Â 

Â  Â  for (cps[leading_underscores..]) |cp| {

Â  Â  Â  Â  if (cp == constants.CP_UNDERSCORE) {

Â  Â  Â  Â  Â  Â  return error_types.ProcessError.CurrableError;

Â  Â  Â  Â  }

Â  Â  }

}



fn checkNoHyphenAtSecondAndThird(allocator: std.mem.Allocator, label: TokenizedLabel) !void {

Â  Â  const cps = try label.iterCps(allocator);

Â  Â  defer allocator.free(cps);

Â  Â Â 

Â  Â  if (cps.len >= 4 and cps[2] == constants.CP_HYPHEN and cps[3] == constants.CP_HYPHEN) {

Â  Â  Â  Â  return error_types.ProcessError.CurrableError;

Â  Â  }

}



fn checkFenced(allocator: std.mem.Allocator, label: TokenizedLabel, specs: *const code_points.CodePointsSpecs) !void {

Â  Â  const cps = try label.iterCps(allocator);

Â  Â  defer allocator.free(cps);

Â  Â Â 

Â  Â  if (cps.len == 0) return;

Â  Â Â 

Â  Â  // Check for fenced characters at start and end

Â  Â  // For now, placeholder implementation

Â  Â  _ = specs;

Â  Â Â 

Â  Â  // Check for consecutive fenced characters

Â  Â  for (cps[0..cps.len-1], 0..) |cp, i| {

Â  Â  Â  Â  const next_cp = cps[i + 1];

Â  Â  Â  Â  // TODO: implement actual fenced character checking

Â  Â  Â  Â  _ = cp;

Â  Â  Â  Â  _ = next_cp;

Â  Â  }

}



fn checkCmLeadingEmoji(allocator: std.mem.Allocator, label: TokenizedLabel, specs: *const code_points.CodePointsSpecs) !void {

Â  Â  _ = allocator;

Â  Â  _ = label;

Â  Â  _ = specs;

Â  Â  // TODO: implement combining mark checking

}



fn checkAndGetGroup(allocator: std.mem.Allocator, label: TokenizedLabel, specs: *const code_points.CodePointsSpecs) !*const code_points.ParsedGroup {

Â  Â  _ = allocator;

Â  Â  _ = label;

Â  Â  _ = specs;

Â  Â  // TODO: implement group determination

Â  Â  return error_types.ProcessError.Confused;

}



test "validateLabel basic functionality" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  // Test with empty label

Â  Â  const empty_label = TokenizedLabel{

Â  Â  Â  Â  .tokens = &[_]tokenizer.Token{},

Â  Â  Â  Â  .allocator = allocator,

Â  Â  };

Â  Â Â 

Â  Â  const specs = code_points.CodePointsSpecs.init(allocator);

Â  Â  const result = validateLabel(allocator, empty_label, &specs);

Â  Â  try testing.expectError(error_types.ProcessError.DisallowedSequence, result);

}```

```zig [./src/constants.zig]

const root = @import("root.zig");

const CodePoint = root.CodePoint;



pub const CP_STOP: CodePoint = 0x2E;

pub const CP_FE0F: CodePoint = 0xFE0F;

pub const CP_APOSTROPHE: CodePoint = 8217;

pub const CP_SLASH: CodePoint = 8260;

pub const CP_MIDDLE_DOT: CodePoint = 12539;

pub const CP_XI_SMALL: CodePoint = 0x3BE;

pub const CP_XI_CAPITAL: CodePoint = 0x39E;

pub const CP_UNDERSCORE: CodePoint = 0x5F;

pub const CP_HYPHEN: CodePoint = 0x2D;

pub const CP_ZERO_WIDTH_JOINER: CodePoint = 0x200D;

pub const CP_ZERO_WIDTH_NON_JOINER: CodePoint = 0x200C;



pub const GREEK_GROUP_NAME: []const u8 = "Greek";

pub const MAX_EMOJI_LEN: usize = 0x2d;

pub const STR_FE0F: []const u8 = "\u{fe0f}";```

```zig [./src/character_mappings_comptime.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;

const comptime_data = @import("comptime_data.zig");



/// Character mapping system for ENS normalization using comptime data

pub const CharacterMappings = struct {

Â  Â  // We don't need any runtime storage anymore!

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub fn init(allocator: std.mem.Allocator) !CharacterMappings {

Â  Â  Â  Â  return CharacterMappings{

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: *CharacterMappings) void {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  // Nothing to clean up - all data is comptime!

Â  Â  }

Â  Â Â 

Â  Â  /// Get the mapped characters for a given code point

Â  Â  /// Returns null if no mapping exists

Â  Â  pub fn getMapped(self: *const CharacterMappings, cp: CodePoint) ?[]const CodePoint {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  // Fast path for ASCII uppercase -> lowercase

Â  Â  Â  Â  if (cp >= 'A' and cp <= 'Z') {

Â  Â  Â  Â  Â  Â  // Return a slice to a static array

Â  Â  Â  Â  Â  Â  const lowercase = [1]CodePoint{cp + 32};

Â  Â  Â  Â  Â  Â  return &lowercase;

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Check comptime mappings

Â  Â  Â  Â  return comptime_data.getMappedCodePoints(cp);

Â  Â  }

Â  Â Â 

Â  Â  /// Check if a character is valid (no mapping needed)

Â  Â  pub fn isValid(self: *const CharacterMappings, cp: CodePoint) bool {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  return comptime_data.isValid(cp);

Â  Â  }

Â  Â Â 

Â  Â  /// Check if a character should be ignored

Â  Â  pub fn isIgnored(self: *const CharacterMappings, cp: CodePoint) bool {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  return comptime_data.isIgnored(cp);

Â  Â  }

Â  Â Â 

Â  Â  /// Check if a character is fenced (placement restricted)

Â  Â  pub fn isFenced(self: *const CharacterMappings, cp: CodePoint) bool {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  return comptime_data.isFenced(cp);

Â  Â  }

Â  Â Â 

Â  Â  // These methods are no longer needed since we use comptime data

Â  Â  pub fn addMapping(self: *CharacterMappings, from: CodePoint, to: []const CodePoint) !void {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  _ = from;

Â  Â  Â  Â  _ = to;

Â  Â  Â  Â  @panic("Cannot add mappings at runtime - use comptime data");

Â  Â  }

Â  Â Â 

Â  Â  pub fn addValid(self: *CharacterMappings, cp: CodePoint) !void {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  _ = cp;

Â  Â  Â  Â  @panic("Cannot add valid chars at runtime - use comptime data");

Â  Â  }

Â  Â Â 

Â  Â  pub fn addIgnored(self: *CharacterMappings, cp: CodePoint) !void {

Â  Â  Â  Â  _ = self;

Â  Â  Â  Â  _ = cp;

Â  Â  Â  Â  @panic("Cannot add ignored chars at runtime - use comptime data");

Â  Â  }

};



/// Create character mappings - now just returns an empty struct

pub fn createWithUnicodeMappings(allocator: std.mem.Allocator) !CharacterMappings {

Â  Â  return CharacterMappings.init(allocator);

}



// Tests

test "CharacterMappings - ASCII case folding" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var mappings = try CharacterMappings.init(allocator);

Â  Â  defer mappings.deinit();

Â  Â Â 

Â  Â  // Test uppercase -> lowercase mapping

Â  Â  const mapped_A = mappings.getMapped('A');

Â  Â  try testing.expect(mapped_A != null);

Â  Â  try testing.expectEqual(@as(CodePoint, 'a'), mapped_A.?[0]);

Â  Â Â 

Â  Â  const mapped_Z = mappings.getMapped('Z');

Â  Â  try testing.expect(mapped_Z != null);

Â  Â  try testing.expectEqual(@as(CodePoint, 'z'), mapped_Z.?[0]);

Â  Â Â 

Â  Â  // Test lowercase has no mapping

Â  Â  const mapped_a = mappings.getMapped('a');

Â  Â  try testing.expect(mapped_a == null);

Â  Â Â 

Â  Â  // Test valid characters

Â  Â  try testing.expect(mappings.isValid('a'));

Â  Â  try testing.expect(mappings.isValid('z'));

Â  Â  try testing.expect(mappings.isValid('0'));

Â  Â  try testing.expect(mappings.isValid('9'));

}



test "CharacterMappings - comptime data access" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var mappings = try CharacterMappings.init(allocator);

Â  Â  defer mappings.deinit();

Â  Â Â 

Â  Â  // Test that we can access comptime data

Â  Â  if (comptime_data.character_mappings.len > 0) {

Â  Â  Â  Â  const first = comptime_data.character_mappings[0];

Â  Â  Â  Â  const result = mappings.getMapped(first.from);

Â  Â  Â  Â  try testing.expect(result != null);

Â  Â  Â  Â  try testing.expectEqualSlices(CodePoint, first.to, result.?);

Â  Â  }

}```

```zig [./src/confusables.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;



/// A set of confusable characters

pub const ConfusableSet = struct {

Â  Â  target: []const u8,Â  // Target string (like "32" for the digit 2)

Â  Â  valid: []const CodePoint,Â  // Valid characters for this confusable set

Â  Â  confused: []const CodePoint,Â  // Characters that look like the valid ones

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub fn init(allocator: std.mem.Allocator, target: []const u8) ConfusableSet {

Â  Â  Â  Â  return ConfusableSet{

Â  Â  Â  Â  Â  Â  .target = target,

Â  Â  Â  Â  Â  Â  .valid = &.{},

Â  Â  Â  Â  Â  Â  .confused = &.{},

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: *ConfusableSet) void {

Â  Â  Â  Â  self.allocator.free(self.target);

Â  Â  Â  Â  self.allocator.free(self.valid);

Â  Â  Â  Â  self.allocator.free(self.confused);

Â  Â  }

Â  Â Â 

Â  Â  /// Check if this set contains the given codepoint (in valid or confused)

Â  Â  pub fn contains(self: *const ConfusableSet, cp: CodePoint) bool {

Â  Â  Â  Â  return self.containsValid(cp) or self.containsConfused(cp);

Â  Â  }

Â  Â Â 

Â  Â  /// Check if this set contains the codepoint in the valid set

Â  Â  pub fn containsValid(self: *const ConfusableSet, cp: CodePoint) bool {

Â  Â  Â  Â  return std.mem.indexOfScalar(CodePoint, self.valid, cp) != null;

Â  Â  }

Â  Â Â 

Â  Â  /// Check if this set contains the codepoint in the confused set

Â  Â  pub fn containsConfused(self: *const ConfusableSet, cp: CodePoint) bool {

Â  Â  Â  Â  return std.mem.indexOfScalar(CodePoint, self.confused, cp) != null;

Â  Â  }

};



/// Collection of all confusable sets

pub const ConfusableData = struct {

Â  Â  sets: []ConfusableSet,

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub fn init(allocator: std.mem.Allocator) ConfusableData {

Â  Â  Â  Â  return ConfusableData{

Â  Â  Â  Â  Â  Â  .sets = &.{},

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: *ConfusableData) void {

Â  Â  Â  Â  for (self.sets) |*set| {

Â  Â  Â  Â  Â  Â  set.deinit();

Â  Â  Â  Â  }

Â  Â  Â  Â  self.allocator.free(self.sets);

Â  Â  }

Â  Â Â 

Â  Â  /// Find all confusable sets that contain any of the given codepoints

Â  Â  pub fn findSetsContaining(self: *const ConfusableData, codepoints: []const CodePoint, allocator: std.mem.Allocator) ![]const *const ConfusableSet {

Â  Â  Â  Â  var matching = std.ArrayList(*const ConfusableSet).init(allocator);

Â  Â  Â  Â  errdefer matching.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  std.debug.print("findSetsContaining: {} total sets\n", .{self.sets.len});

Â  Â  Â  Â Â 

Â  Â  Â  Â  for (self.sets, 0..) |*set, i| {

Â  Â  Â  Â  Â  Â  for (codepoints) |cp| {

Â  Â  Â  Â  Â  Â  Â  Â  if (set.contains(cp)) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  std.debug.print("Â  Set {} (target={s}) contains cp 0x{x}\n", .{i, set.target, cp});

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try matching.append(set);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break; // Found one, no need to check more codepoints for this set

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  return matching.toOwnedSlice();

Â  Â  }

Â  Â Â 

Â  Â  /// Check if codepoints form a whole-script confusable (security violation)

Â  Â  pub fn checkWholeScriptConfusables(self: *const ConfusableData, codepoints: []const CodePoint, allocator: std.mem.Allocator) !bool {

Â  Â  Â  Â  if (codepoints.len == 0) return false; // Empty input is safe

Â  Â  Â  Â Â 

Â  Â  Â  Â  std.debug.print("checkWholeScriptConfusables: checking {} cps\n", .{codepoints.len});

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Find all sets that contain any of our codepoints

Â  Â  Â  Â  const matching_sets = try self.findSetsContaining(codepoints, allocator);

Â  Â  Â  Â  defer allocator.free(matching_sets);

Â  Â  Â  Â Â 

Â  Â  Â  Â  std.debug.print("checkWholeScriptConfusables: found {} matching sets\n", .{matching_sets.len});

Â  Â  Â  Â Â 

Â  Â  Â  Â  if (matching_sets.len <= 1) {

Â  Â  Â  Â  Â  Â  return false; // No confusables or all from same set - safe

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Check for dangerous mixing between different confusable sets

Â  Â  Â  Â  // Key insight: mixing valid characters from different sets is OK

Â  Â  Â  Â  // Only mixing when at least one confused character is present is dangerous

Â  Â  Â  Â Â 

Â  Â  Â  Â  var has_confused = false;

Â  Â  Â  Â  for (codepoints) |cp| {

Â  Â  Â  Â  Â  Â  for (matching_sets) |set| {

Â  Â  Â  Â  Â  Â  Â  Â  if (set.containsConfused(cp)) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  has_confused = true;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (has_confused) break;

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // If there are no confused characters, it's safe even with multiple sets

Â  Â  Â  Â  if (!has_confused) {

Â  Â  Â  Â  Â  Â  std.debug.print("checkWholeScriptConfusables: no confused characters found, safe\n", .{});

Â  Â  Â  Â  Â  Â  return false;

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Now check if we're mixing characters from different sets

Â  Â  Â  Â  // when at least one confused character is present

Â  Â  Â  Â  for (matching_sets, 0..) |set1, i| {

Â  Â  Â  Â  Â  Â  for (matching_sets[i+1..]) |set2| {

Â  Â  Â  Â  Â  Â  Â  Â  // Check if we have characters from both sets

Â  Â  Â  Â  Â  Â  Â  Â  var has_from_set1 = false;

Â  Â  Â  Â  Â  Â  Â  Â  var has_from_set2 = false;

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  for (codepoints) |cp| {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (set1.contains(cp)) has_from_set1 = true;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (set2.contains(cp)) has_from_set2 = true;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Early exit if we found both

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (has_from_set1 and has_from_set2) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  std.debug.print("checkWholeScriptConfusables: mixing sets with confused chars = DANGEROUS\n", .{});

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return true; // DANGEROUS: mixing confusable sets with confused characters

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  return false; // Safe

Â  Â  }

Â  Â Â 

Â  Â  /// Get diagnostic information about confusable usage

Â  Â  pub fn analyzeConfusables(self: *const ConfusableData, codepoints: []const CodePoint, allocator: std.mem.Allocator) !ConfusableAnalysis {

Â  Â  Â  Â  var analysis = ConfusableAnalysis.init(allocator);

Â  Â  Â  Â  errdefer analysis.deinit();

Â  Â  Â  Â Â 

Â  Â  Â  Â  const matching_sets = try self.findSetsContaining(codepoints, allocator);

Â  Â  Â  Â  defer allocator.free(matching_sets);

Â  Â  Â  Â Â 

Â  Â  Â  Â  analysis.sets_involved = try allocator.dupe(*const ConfusableSet, matching_sets);

Â  Â  Â  Â  analysis.is_confusable = matching_sets.len > 1;

Â  Â  Â  Â Â 

Â  Â  Â  Â  // Count characters by type

Â  Â  Â  Â  for (codepoints) |cp| {

Â  Â  Â  Â  Â  Â  var found_in_set = false;

Â  Â  Â  Â  Â  Â  for (matching_sets) |set| {

Â  Â  Â  Â  Â  Â  Â  Â  if (set.containsValid(cp)) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  analysis.valid_count += 1;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  found_in_set = true;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  Â  Â  Â  Â  } else if (set.containsConfused(cp)) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  analysis.confused_count += 1;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  found_in_set = true;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (!found_in_set) {

Â  Â  Â  Â  Â  Â  Â  Â  analysis.non_confusable_count += 1;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  return analysis;

Â  Â  }

};



/// Analysis result for confusable detection

pub const ConfusableAnalysis = struct {

Â  Â  sets_involved: []const *const ConfusableSet,

Â  Â  is_confusable: bool,

Â  Â  valid_count: usize,

Â  Â  confused_count: usize,

Â  Â  non_confusable_count: usize,

Â  Â  allocator: std.mem.Allocator,

Â  Â Â 

Â  Â  pub fn init(allocator: std.mem.Allocator) ConfusableAnalysis {

Â  Â  Â  Â  return ConfusableAnalysis{

Â  Â  Â  Â  Â  Â  .sets_involved = &.{},

Â  Â  Â  Â  Â  Â  .is_confusable = false,

Â  Â  Â  Â  Â  Â  .valid_count = 0,

Â  Â  Â  Â  Â  Â  .confused_count = 0,

Â  Â  Â  Â  Â  Â  .non_confusable_count = 0,

Â  Â  Â  Â  Â  Â  .allocator = allocator,

Â  Â  Â  Â  };

Â  Â  }

Â  Â Â 

Â  Â  pub fn deinit(self: *ConfusableAnalysis) void {

Â  Â  Â  Â  self.allocator.free(self.sets_involved);

Â  Â  }

};



test "confusable set basic operations" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var set = ConfusableSet.init(allocator, try allocator.dupe(u8, "test"));

Â  Â  defer set.deinit();

Â  Â Â 

Â  Â  // Add some test data

Â  Â  var valid_data = try allocator.alloc(CodePoint, 2);

Â  Â  valid_data[0] = 'a';

Â  Â  valid_data[1] = 'b';

Â  Â  set.valid = valid_data;

Â  Â Â 

Â  Â  var confused_data = try allocator.alloc(CodePoint, 2);

Â  Â  confused_data[0] = 0x0430; // Cyrillic 'Ğ°'

Â  Â  confused_data[1] = 0x0431; // Cyrillic 'Ğ±'

Â  Â  set.confused = confused_data;

Â  Â Â 

Â  Â  // Test containment

Â  Â  try testing.expect(set.contains('a'));

Â  Â  try testing.expect(set.contains(0x0430));

Â  Â  try testing.expect(!set.contains('z'));

Â  Â Â 

Â  Â  try testing.expect(set.containsValid('a'));

Â  Â  try testing.expect(!set.containsValid(0x0430));

Â  Â Â 

Â  Â  try testing.expect(set.containsConfused(0x0430));

Â  Â  try testing.expect(!set.containsConfused('a'));

}



test "confusable data empty input" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var data = ConfusableData.init(allocator);

Â  Â  defer data.deinit();

Â  Â Â 

Â  Â  const empty_cps = [_]CodePoint{};

Â  Â  const is_confusable = try data.checkWholeScriptConfusables(&empty_cps, allocator);

Â  Â  try testing.expect(!is_confusable);

}



test "confusable data single set safe" {

Â  Â  const testing = std.testing;

Â  Â  var arena = std.heap.ArenaAllocator.init(testing.allocator);

Â  Â  defer arena.deinit();

Â  Â  const allocator = arena.allocator();

Â  Â Â 

Â  Â  var data = ConfusableData.init(allocator);

Â  Â  defer data.deinit();

Â  Â Â 

Â  Â  // Create a test set

Â  Â  data.sets = try allocator.alloc(ConfusableSet, 1);

Â  Â  data.sets[0] = ConfusableSet.init(allocator, try allocator.dupe(u8, "latin"));

Â  Â Â 

Â  Â  var valid_test_data = try allocator.alloc(CodePoint, 2);

Â  Â  valid_test_data[0] = 'a';

Â  Â  valid_test_data[1] = 'b';

Â  Â  data.sets[0].valid = valid_test_data;

Â  Â Â 

Â  Â  var confused_test_data = try allocator.alloc(CodePoint, 2);

Â  Â  confused_test_data[0] = 0x0430;

Â  Â  confused_test_data[1] = 0x0431;

Â  Â  data.sets[0].confused = confused_test_data;

Â  Â Â 

Â  Â  // Test with only valid characters - should be safe

Â  Â  const valid_only = [_]CodePoint{ 'a', 'b' };

Â  Â  const is_confusable1 = try data.checkWholeScriptConfusables(&valid_only, allocator);

Â  Â  try testing.expect(!is_confusable1);

Â  Â Â 

Â  Â  // Test with only confused characters - should be safe (single set)

Â  Â  const confused_only = [_]CodePoint{ 0x0430, 0x0431 };

Â  Â  const is_confusable2 = try data.checkWholeScriptConfusables(&confused_only, allocator);

Â  Â  try testing.expect(!is_confusable2);

}```

```zig [./src/error.zig]

const std = @import("std");

const root = @import("root.zig");

const CodePoint = root.CodePoint;



pub const ProcessError = error{

Â  Â  Confused,

Â  Â  ConfusedGroups,

Â  Â  CurrableError,

Â  Â  DisallowedSequence,

Â  Â  OutOfMemory,

Â  Â  InvalidUtf8,

Â  Â  InvalidCodePoint,

};



pub const ProcessErrorInfo = union(ProcessError) {

Â  Â  Confused: struct {

Â  Â  Â  Â  message: []const u8,

Â  Â  },

Â  Â  ConfusedGroups: struct {

Â  Â  Â  Â  group1: []const u8,

Â  Â  Â  Â  group2: []const u8,

Â  Â  },

Â  Â  CurrableError: struct {

Â  Â  Â  Â  inner: CurrableError,

Â  Â  Â  Â  index: usize,

Â  Â  Â  Â  sequence: []const u8,

Â  Â  Â  Â  maybe_suggest: ?[]const u8,

Â  Â  },

Â  Â  DisallowedSequence: DisallowedSequence,

Â  Â  OutOfMemory: void,

Â  Â  InvalidUtf8: void,

Â  Â  InvalidCodePoint: void,

};



pub const CurrableError = enum {

Â  Â  UnderscoreInMiddle,

Â  Â  HyphenAtSecondAndThird,

Â  Â  CmStart,

Â  Â  CmAfterEmoji,

Â  Â  FencedLeading,

Â  Â  FencedTrailing,

Â  Â  FencedConsecutive,

};



pub const DisallowedSequence = enum {

Â  Â  Invalid,

Â  Â  InvisibleCharacter,

Â  Â  EmptyLabel,

Â  Â  NsmTooMany,

Â  Â  NsmRepeated,

};



pub const DisallowedSequenceInfo = union(DisallowedSequence) {

Â  Â  Invalid: struct {

Â  Â  Â  Â  message: []const u8,

Â  Â  },

Â  Â  InvisibleCharacter: struct {

Â  Â  Â  Â  code_point: CodePoint,

Â  Â  },

Â  Â  EmptyLabel: void,

Â  Â  NsmTooMany: void,

Â  Â  NsmRepeated: void,

};



pub fn formatProcessError(

Â  Â  allocator: std.mem.Allocator,

Â  Â  error_info: ProcessErrorInfo,

) ![]u8 {

Â  Â  switch (error_info) {

Â  Â  Â  Â  .Confused => |info| {

Â  Â  Â  Â  Â  Â  return try std.fmt.allocPrint(

Â  Â  Â  Â  Â  Â  Â  Â  allocator,

Â  Â  Â  Â  Â  Â  Â  Â  "contains visually confusing characters from multiple scripts: {s}",

Â  Â  Â  Â  Â  Â  Â  Â  .{info.message},

Â  Â  Â  Â  Â  Â  );

Â  Â  Â  Â  },

Â  Â  Â  Â  .ConfusedGroups => |info| {

Â  Â  Â  Â  Â  Â  return try std.fmt.allocPrint(

Â  Â  Â  Â  Â  Â  Â  Â  allocator,

Â  Â  Â  Â  Â  Â  Â  Â  "contains visually confusing characters from {s} and {s} scripts",

Â  Â  Â  Â  Â  Â  Â  Â  .{ info.group1, info.group2 },

Â  Â  Â  Â  Â  Â  );

Â  Â  Â  Â  },

Â  Â  Â  Â  .CurrableError => |info| {

Â  Â  Â  Â  Â  Â  var suggest_part: []const u8 = "";

Â  Â  Â  Â  Â  Â  if (info.maybe_suggest) |suggest| {

Â  Â  Â  Â  Â  Â  Â  Â  suggest_part = try std.fmt.allocPrint(

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  allocator,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  " (suggestion: {s})",

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .{suggest},

Â  Â  Â  Â  Â  Â  Â  Â  );

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  return try std.fmt.allocPrint(

Â  Â  Â  Â  Â  Â  Â  Â  allocator,

Â  Â  Â  Â  Â  Â  Â  Â  "invalid character ('{s}') at position {d}: {s}{s}",

Â  Â  Â  Â  Â  Â  Â  Â  .{ info.sequence, info.index, formatCurrableError(info.inner), suggest_part },

Â  Â  Â  Â  Â  Â  );

Â  Â  Â  Â  },

Â  Â  Â  Â  .DisallowedSequence => |seq| {

Â  Â  Â  Â  Â  Â  return try formatDisallowedSequence(allocator, seq);

Â  Â  Â  Â  },

Â  Â  Â  Â  .OutOfMemory => return try allocator.dupe(u8, "out of memory"),

Â  Â  Â  Â  .InvalidUtf8 => return try allocator.dupe(u8, "invalid UTF-8"),

Â  Â  Â  Â  .InvalidCodePoint => return try allocator.dupe(u8, "invalid code point"),

Â  Â  }

}



fn formatCurrableError(err: CurrableError) []const u8 {

Â  Â  return switch (err) {

Â  Â  Â  Â  .UnderscoreInMiddle => "underscore in middle",

Â  Â  Â  Â  .HyphenAtSecondAndThird => "hyphen at second and third position",

Â  Â  Â  Â  .CmStart => "combining mark in disallowed position at the start of the label",

Â  Â  Â  Â  .CmAfterEmoji => "combining mark in disallowed position after an emoji",

Â  Â  Â  Â  .FencedLeading => "fenced character at the start of a label",

Â  Â  Â  Â  .FencedTrailing => "fenced character at the end of a label",

Â  Â  Â  Â  .FencedConsecutive => "consecutive sequence of fenced characters",

Â  Â  };

}



fn formatDisallowedSequence(allocator: std.mem.Allocator, seq: DisallowedSequence) ![]u8 {

Â  Â  return switch (seq) {

Â  Â  Â  Â  .Invalid => try allocator.dupe(u8, "disallowed sequence"),

Â  Â  Â  Â  .InvisibleCharacter => try allocator.dupe(u8, "invisible character"),

Â  Â  Â  Â  .EmptyLabel => try allocator.dupe(u8, "empty label"),

Â  Â  Â  Â  .NsmTooMany => try allocator.dupe(u8, "nsm too many"),

Â  Â  Â  Â  .NsmRepeated => try allocator.dupe(u8, "nsm repeated"),

Â  Â  };

}```

</zig>

I shared a productionized csharp implementation along with a non working zig implementation. Can you please give me a complete code review on my zig code? I also shared a rust implementation that is also producitonized
